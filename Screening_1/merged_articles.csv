paper_id,title,abstract,authors,year,doi,link,database
6a7a6955695693a6,130 years of fiscal vulnerabilities and currency crashes in advanced economies,"This paper investigates the empirical link between fiscal vulnerabilities and currency crashes in advanced economies over the last 130 years, building on a new data set of real effective exchange rates andfiscal balances for 21 countries since 1880. The paper finds evidence that crashes depend more on prospective fiscal deficits than on actual ones, and more on the composition of public debt (that is, rollover/sudden stop risk) than on its level. The paper also uncovers significant nonlinear effects at high levels of public debt as well as significantly negative risk premiums for major reserve currencies, which enjoy a lower probability of currency crash than other currencies ceteris paribus. Yet, the estimates indicate that such premiums remain small in size relative to the conditional probability of a currency crash if prospective fiscal deficits or rollover/sudden stop risk are high. © 2011 International Monetary Fund. © 2016 Elsevier B.V., All rights reserved.","Fratzscher, M.; Mehl, A.; Vansteenkiste, I.",2011,10.1057/imfer.2011.23,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984735363&doi=10.1057%2Fimfer.2011.23&partnerID=40&md5=10412f6505b457691d3ab1474055c9fc,scopus
adc084ce37ecd5d8,A Bayesian Approach for Dynamic Variation of Specific Sectors in Stock Exchange: A Case Study of Stock Exchange Thailand (SET) Indexes,"This paper aims to investigate the identification of sectors of stock exchange that were positively or negatively driven by fundamental monetary tools.A Bayesian approach for dynamic model averaging (DMA) algorithm is analyzed and implemented to deliver the results for identifying what actually drives specific sector of stock exchange, where the posterior inclusion probability is crucial quantity for this investigation. Stock Exchange Thailand (SET) indexes was used as a case study for this work. The predictors used in this paper are: borrowing rate: BR, policy rate: PR, treasury bill rate: TBR, government bond yield: GBYLT, minimum overdraft rate: MOR, minimum loan rate: MLR, minimum retail rate: MRR, discount rate: DISR, savings rate: SAVER, deposit rate: DEPR and lending rate: LENDR. These factors are considered as the most important monetary policy tools from Bank of Thailand. The empirical results demonstrated that each SET index sector responses to those economic variables differently. Some of them are not actually related for specific point of time; some other times, however, they affect SET indexes. Filtered time-varying parameters allow us to indicate the relationship between stock price return and interest rates. According to statistical evidence, we found that the relationship is as of the time-varying characteristic and is unable to absolute identify whether it is positively or negatively related to stock price return for each sector. The impact of a sector on SET indexes depends on a period of time and can also be considered by using seasoning parameters. © 2020 Elsevier B.V., All rights reserved.","Taveeapiradeecharoen, P.; Aunsri, N.",2020,10.1007/s11277-020-07217-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082804266&doi=10.1007%2Fs11277-020-07217-1&partnerID=40&md5=81cc5fcbff5e37f99c07219bc7a0a7d3,scopus
7887726f5a97f696,A Bayesian approach to term structure modeling using heavy-tailed distributions,"In this paper, we introduce a robust extension of the three-factor model of Diebold and Li (J. Econometrics, 130: 337-364, 2006) using the class of symmetric scale mixtures of normal distributions. Specific distributions examined include the multivariate normal, Student-t, slash, and variance gamma distributions. In the presence of non-normality in the data, these distributions provide an appealing robust alternative to the routine use of the normal distribution. Using a Bayesian paradigm, we developed an efficient MCMC algorithm for parameter estimation. Moreover, the mixing parameters obtained as a by-product of the scale mixture representation can be used to identify outliers. Our results reveal that the Diebold-Li models based on the Student-t and slash distributions provide significant improvement in in-sample fit and out-of-sample forecast to the US yield data than the usual normal-based model. Copyright © 2011 John Wiley & Sons, Ltd. © 2012 Elsevier B.V., All rights reserved.","Abanto-Valle, C.A.; Lachos, V.H.; Ghosh, P.",2012,10.1002/asmb.920,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867581627&doi=10.1002%2Fasmb.920&partnerID=40&md5=d0718ed07907681fd60bc5e4fb51dca0,scopus
16b768df753f1bf5,A Chaos Analysis of the Dry Bulk Shipping Market,"Finding low-dimensional chaos is a relevant issue as it could allow short-term reliable forecasting. However, the existence of chaos in shipping freight rates remains an open and outstanding matter as previous research used methodology that can produce misleading results. Using daily data, this paper aims to unveil the nonlinear dynamics of the Baltic Dry Index that has been proposed as a measure of the shipping rates for certain raw materials. We tested for the existence of nonlinearity and low-dimensional chaos. We have also examined the chaotic dynamics throughout three sub-sampling periods, which have been determined by the volatility pattern of the series. For this purpose, from a comprehensive view we apply several metric and topological techniques, including the most suitable methods for noisy time series analysis. The proposed methodology considers the characteristics of chaotic time series, such as nonlinearity, determinism, sensitivity to initial conditions, fractal dimension and recurrence. Although there is strong evidence of a nonlinear structure, a chaotic and, therefore, deterministic behavior cannot be assumed during the whole or the three periods considered. Our findings indicate that the generalized autoregressive conditional heteroscedastic (GARCH) model and exponential GARCH (EGARCH) model explain a significant part of the nonlinear structure that is found in the dry bulk shipping freight market.","Inglada-Perez, Lucia; Coto-Millan, Pablo",2021,10.3390/math9172065,None,wos
32873e86106b0a11,A Class of Non-Gaussian State Space Models With Exact Likelihood Inference,"The likelihood function of a general nonlinear, non-Gaussian state space model is a high-dimensional integral with no closed-form solution. In this article, I show how to calculate the likelihood function exactly for a large class of non-Gaussian state space models that include stochastic intensity, stochastic volatility, and stochastic duration models among others. The state variables in this class follow a nonnegative stochastic process that is popular in econometrics for modeling volatility and intensities. In addition to calculating the likelihood, I also show how to perform filtering and smoothing to estimate the latent variables in the model. The procedures in this article can be used for either Bayesian or frequentist estimation of the model's unknown parameters as well as the latent state variables. Supplementary materials for this article are available online.","Creal, Drew D.",2017,10.1080/07350015.2015.1092977,None,wos
355cffc3dbbe0946,A Comparative Analysis of the Choice of Mother Wavelet Functions Affecting the Accuracy of Forecasts of Daily Balances in the Treasury Single Account,"Improving the accuracy of cash flow forecasting in the TSA is key to fulfilling government payment obligations, minimizing the cost of maintaining the cash reserve, providing the absence of outstanding debt accumulation and ensuring investment in financial instruments to obtain additional income. This study aims to improve the accuracy of traditional methods of forecasting the time series compiled from the daily remaining balances in the TSAbased on prior decomposition using a discrete wavelet transform. The paper compares the influence of selecting a mother wavelet out of 570 mother wavelet functions belonging to 10 wavelet families (Haar;Dabeshies; Symlet; Coiflet; Biorthogonal Spline; Reverse Biorthogonal Spline; Meyer; Shannon; Battle-Lemarie; and Cohen–Daubechies–Feauveau) and the decomposition level (from 1 to 8) on the forecast accuracy of time series compiled from the daily remaining balances in the TSA in comparison with the traditional forecasting method without prior timeseries decomposition. The model with prior time series decomposition based on the Reverse Biorthogonal Spline Wavelet [5.5] mother wavelet function, upon the eighth iteration, features the highest accuracy, significantly higher than that of the traditional forecasting models. The choice of the mother wavelet and the decomposition level play an important role in increasing the accuracy of forecasting the daily remaining balances in the TSA.","Karaev, Alan K; Gorlova, Oksana S; Ponkratov, Vadim V; Sedova, Marina L; Shmigol, Nataliya S; Vasyunina, Margarita L",2022,10.3390/economies10090213,None,proquest
ff08816516693672,"A Comparison of LSTM, GRU, and XGBoost for forecasting Morocco’s yield curve","The field of time series forecasting has grown significantly over the past several years and is now highly active. In numerous application domains, deep neural networks are exact and powerful. They are among the most popular machine learning techniques for resolving big data issues because of these factors. Historically, there have been numerous methods for accurately predicting the subsequent change in time series data. The time series forecasting problem and its mathematical underpinnings are first articulated in this study. Following that, a description of the most popular deep learning architectures used to date with success in time series forecasting is provided, emphasizing both their benefits and drawbacks. Feedforward networks, recurrent neural networks (such as Elman networks), long-and short-term memory (LSTM), and gated recurrent units (GRU) are given special consideration. Furthermore, the advantages of the XGBoost boosting tree method have shown its superiority in numerous data mining competitions in recent years. The high coefficients of the metric measures indicate that the proposed XGBoost model provides good predictive performance, according to the results. © 2024 Elsevier B.V., All rights reserved.","Jeaab, K.; Saoudi, Y.; Falloul, M.E.M.",2024,10.23939/mmc2024.03.674,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205025967&doi=10.23939%2Fmmc2024.03.674&partnerID=40&md5=a547ef809381a9bbc475c0545010746d,scopus
c939b92fc4ff0bb3,"A Comparison of Neural Network, Statistical Methods, and Variable Choice for Life Insurers' Financial Distress Prediction","This study examines the effect of the statistical-mathematical model selected and the variable set considered on the ability to identify financially troubled life insurers. Models considered are two artificial neural network methods (back-propagation and learning vector quantization (LVQ)) and two more standard statistical methods (multiple discriminant analysis and logistic regression analysis). The variable sets considered are the insurance regulatory information system (IRIS) variables, the financial analysis solvency tracking (FAST) variables, and Texas early warning information system (EWIS) variables, and a data set consisting of twenty-two variables selected by us in conjunction with the research staff at TDI and a review of the insolvency prediction literature. The results show that the back-propagation (BP) and LVQ outperform the traditional statistical approaches for all four variable sets with a consistent superiority across the two different evaluation criteria (total misclassification cost and resubstitution risk criteria), and that the twenty-two variables and the Texas EWIS variable sets are more efficient than the IRIS and the FAST variable sets for identification of financially troubled life insurers in most comparisons.","Brockett, Patrick L; Golden, Linda L; Jang, Jaeho; Yang, Chuanhou",2006,10.1111/j.1539-6975.2006.00181.x,None,proquest
a2291dc0a2cab336,A Comprehensive Approach to Residual Value Analysis in the Luxury Automotive Market,"Global automotive markets have introduced new complexities, from the surge in powertrain diversity to evolving consumer purchasing habits. In the luxury car segment, residual value (RV), the car’s actual value at the end of ownership, is particularly significant. A high RV translates into lower overall ownership costs, as the car retains more of its value over time, which can boost demand as well as leasing margin. For this reason, the analysis of RV offers key insights for strategic decision-making. The present study leverages a large-scale global dataset spanning a 10-year period, capturing both internal vehicle features and three available external market conditions (CPI, unemployment rate, and 10-year bond yield). Our approach employs machine learning techniques, particularly CatBoost, achieving a mean absolute percentage error of around 5%, deemed highly acceptable within the industry. Moreover, a novel method to enhance the reliability and interpretability of RV estimations is proposed by quantifying depreciation thresholds and mitigating distortions related to sample composition via a “Standard Vehicle” concept. The approach has been validated by Ferrari S.p.A., the provider of the data, serving as a robust tool for automotive industry stakeholders.",A. Ghibellini; A. Scioletti; M. Coletto; L. Bononi; M. Gabbrielli,2025,10.1109/access.2025.3591765,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11091377,ieeexplore
aaa155be6197dbf8,A Cox model for gradually disappearing events,"Innovations in medicine provide us longer and healthier life, leading lower mortality. Sooner rather than later, much greater longevity would be possible for us due to artificial intelligence advances in health care. Similarly, Advanced Driver Assistance Systems (ADAS) in highly automated vehicles may reduce or even eventually eliminate accidents by perceiving dangerous situations, which would minimize the number of accidents and lead to fewer loss claims for insurance companies. To model the survivor function capturing greater longevity as well as the number of claims reflecting less accidents in the long run, in this paper, we study a Cox process whose intensity process is piecewise-constant and decreasing. We derive its ultimate distributional properties, such as the Laplace transform of intensity integral process, the probability generating function of point process, their associated moments and cumulants, and the probability of no more claims for a given time point. In general, this simple model may be applicable in many other areas for modeling the evolution of gradually disappearing events, such as corporate defaults, dividend payments, trade arrivals, employment of a certain job type (e.g., typists) in the labor market, and release of particles. In particular, we discuss some potential applications to insurance.","Jang, Jiwook; Qu, Yan; Zhao, Hongbiao; Dassios, Angelos",2023,10.1017/s0269964821000553,None,wos
b5415c8117608d9f,A Discussion of Non-Gaussian Price Processes for Energy and Commodity Operations,"Energy sources and commodities exhibit high price risk. This risk is thus an important feature of operational models of the value chains for these goods. These models typically employ Gaussian-based representations of the evolution of this uncertainty. This approach facilitates the optimization of operational policies but is at odds with empirical facts about energy and commodity prices, which are better captured by non-Gaussian processes. We discuss this alternative modeling strategy, focusing on Lévy processes. As an illustration, we show that it substantially increases the optimal policy value in a simplified merchant natural gas storage setting. Further, we highlight potential implications of using this approach to formulate realistic energy and commodity operations models. Our work has broader relevance for modeling the dynamics of both other market variables and operational quantities, such as exchange rates and demand forecasts. The study of how the adoption of non-Gaussian processes may impact energy and commodity operations is an appealing area for future research. © 2021 Elsevier B.V., All rights reserved.","Gambaro, A.M.; Secomandi, N.",2021,10.1111/poms.13250,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096644292&doi=10.1111%2Fpoms.13250&partnerID=40&md5=5666d8014dd126fe7d35d4bc4040ac34,scopus
f9836cc4dd014711,A Gaussian Process of Yield Rates Calibrated with Strips,"This paper presents a Gaussian multivariate factor model of the term structure of interest rates. It shows that there exists a martingale valuation law of the factors so that the price function of a zero-coupon bond is an exponential spline. The model’s linear and Gaussian structure yields a simple model where estimation and calibration are relatively easy to do. Using yield data on stripped bonds, the spline model gives a very good approximation of the yield curve at all times. Moreover, the crucial Gaussian assumption is reasonable when modeling the dynamics for short periods like one year. © 2001 Taylor & Francis Group, LLC. © 2017 Elsevier B.V., All rights reserved.","Carrière, J.F.",2001,10.1080/10920277.2001.10595995,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011238970&doi=10.1080%2F10920277.2001.10595995&partnerID=40&md5=b9fd767ad96ca600385575d9c079e5fb,scopus
3eef9b78b9335605,A Hybrid Methodology Using Machine Learning Techniques and Feature Engineering Applied to Time Series for Medium- and Long-Term Energy Market Price Forecasting,"In the electricity market, the issue of contract negotiation prices between generators/traders and buyers is of particular relevance, as an accurate contract modeling leads to increased financial returns and business sustainability for the various participating agents, encouraging investments in specialized sectors for price forecasting and risk analysis. This paper presents a methodology applied in experiments on energy forward curve scenarios using a set of techniques, including Long Short-Term Memory (LSTM), Extreme Gradient Boosting (XGBoost), Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors (SARIMAX), and Feature Engineering to generate a 10-year projection of the Conventional Long-Term Price. The model validation proved to be effective, with errors of only 4.5% by Root Mean Square Error (RMSE) and slightly less than 2% by Mean Absolute Error (MAE), for a time series spanning from 7 January 2012 to 31 August 2024, in the Brazilian energy market.","Flávia Pessoa Monteiro; Flávia Pessoa Monteiro; Monteiro, Suzane; Rodrigues, Carlos; Reis, Josivan; Bezerra, Ubiratan; Tostes, Maria Emília; Almeida, Frederico A F",2025,10.3390/en18061387,None,proquest
c4c8f4469053f753,A Hybrid Vector Autoregressive Model for Accurate Macroeconomic Forecasting: An Application to the U.S. Economy,"Forecasting macroeconomic variables is essential to macroeconomics, financial economics, and monetary policy analysis. Due to the high dimensionality of the macroeconomic dataset, it is challenging to forecast efficiently and accurately. Thus, this study provides a comprehensive analysis of predicting macroeconomic variables by comparing various vector autoregressive models followed by different estimation techniques. To address this, this paper proposes a novel hybrid model based on a smoothly clipped absolute deviation estimation method and a vector autoregression model that combats the curse of dimensionality and simultaneously produces reliable forecasts. The proposed hybrid model is applied to the U.S. quarterly macroeconomic data from the first quarter of 1959 to the fourth quarter of 2023, yielding multi-step-ahead forecasts (one-, three-, and six-step ahead). The multi-step-ahead out-of-sample forecast results (root mean square error and mean absolute error) for the considered data suggest that the proposed hybrid model yields a highly accurate and efficient gain. Additionally, it is demonstrated that the proposed models outperform the baseline models. Finally, the authors believe the proposed hybrid model may be expanded to other countries to assess its efficacy and accuracy.","Khan Faridoon; Hasnain, Iftikhar; Khan, Imran; Rodrigues, Paulo Canas; Alharbi, Abdulmajeed Atiah; Jeza, Allohibi",2025,10.3390/math13111706,None,proquest
f1779cf7208a0e34,A MODEL-SELECTION APPROACH TO ASSESSING THE INFORMATION IN THE TERM STRUCTURE USING LINEAR-MODELS AND ARTIFICIAL NEURAL NETWORKS,"We take a model-selection approach to the question of whether forward-interest rates are useful in predicting future spot rates, using a variety of out-of-sample forecast-based model-selection criteria-forecast mean squared error, forecast direction accuracy, and forecast-based trading-system profitability. We also examine the usefulness of a class of novel prediction models called artificial neural networks and investigate the issue of appropriate window sizes for rolling-window-based prediction methods. Results indicate that the premium of the forward rate over the spot rate helps to predict the sign of future changes in the interest rate. Furthermore, model selection based on an in-sample Schwarz information criterion (SIC) does not appear to be a reliable guide to out-of-sample performance in the case of short-term interest rates. Thus, the in-sample SIC apparently fails to offer a convenient shortcut to true out-of-sample performance measures.","SWANSON, NR; WHITE, H",1995,10.2307/1392186,None,wos
fd4f0e95b6a42d4c,A Machine Learning Approach to Forecast Economic Recessions-An Italian Case Study,"In economic activity, recessions represent a period of failure in Gross Domestic Product (GDP) and usually are presented as episodic and non-linear. For this reason, they are difficult to predict and appear as one of the main problems in macroeconomics forecasts. A classic example turns out to be the great recession that occurred between 2008 and 2009 that was not predicted. In this paper, the goal is to give a different, although complementary, approach concerning the classical econometric techniques, and to show how Machine Learning (ML) techniques may improve short-term forecasting accuracy. As a case study, we use Italian data on GDP and a few related variables. In particular, we evaluate the goodness of fit of the forecasting proposed model in a case study of the Italian GDP. The algorithm is trained on Italian macroeconomic variables over the period 1995:Q1-2019:Q2. We also compare the results using the same dataset through Classic Linear Regression Model. As a result, both statistical and ML approaches are able to predict economic downturns but higher accuracy is obtained using Nonlinear Autoregressive with exogenous variables (NARX) model.","Cicceri, Giovanni; Inserra, Giuseppe; Limosani, Michele",2020,10.3390/math8020241,None,wos
6c328af0321b7d5d,A Machine-Learning-Based Approach for Natural Gas Futures Curve Modeling,"This work studies the term structure dynamics in the natural gas futures market, focusing on the Dutch Title Transfer Facility (TTF) daily futures prices. At first, using the whole dataset, we compared the in-sample fitting performance of three models: the four-factor dynamic Nelson–Siegel–Svensson (4F-DNSS) model, the five-factor dynamic De Rezende–Ferreira (5F-DRF) model, and the B-spline model. Our findings suggest that B-spline is the method that achieves the best in-line fitting results. Then, we turned our attention to forecasting, using data from 20 January 2011 to 13 May 2022 as the training set and the remaining data, from 16 May to 13 June 2022, for day-ahead predictions. In this second part of the work we combined the above mentioned models (4F-DNSS, 5F-DRF and B-spline) with a Nonlinear Autoregressive Neural Network (NAR-NN), asking the NAR-NN to provide parameter tuning. All the models provided accurate out-of-sample prediction; nevertheless, based on extensive statistical tests, we conclude that, as in the previous case, B-spline (combined with an NAR-NN) ensured the best out-of-sample prediction.","Castello, Oleksandr; Castello, Oleksandr; Resta, Marina",2023,10.3390/en16124746,None,proquest
99d0e8a05fcc941c,A Markov regime-switching model for the semiconductor industry cycles,"Because of the huge fluctuation in the semiconductor business, it has been a challenging work for the industry researchers to predict the turning points of the semiconductor industry cycles. To catch the cyclical behavior of the semiconductor business, we propose a Markov Regime-Switching model with two regimes representing expansion and contraction. The simple nonlinear, two states, regime-switching model shows a successful in-sample prediction on the contraction of semiconductor industry sales during the period of 1990:01-2003:08. (c) 2006 Elsevier B.V. All rights reserved.","Liu, Wen-Hsien; Chyi, Yih-Luan",2006,10.1016/j.econmod.2006.02.007,None,wos
7af7d2c3acf27b2d,A Markov-modulated tree-based gradient boosting model for auto-insurance risk premium pricing,"In most sub Saharan African countries,the mechanism for pricing auto-insurance policies is tariff based. This means that the key factor that influences price changes is usually based on regulation and legislative dynamics. Additionally, where ratemaking is risk based, analysis has in most cases focused on internal historical data or claims history, particularly in the sub Saharran Africa. These policy regimes have led to unfair price distortions among policyholders and have increased risk of portfolios for most insurance companies. In this study we consider geographical location risk that influence auto-insurance claim process for an insurance company. The study develops a Markov-modulated tree-based gradient boosting (MMGB) model for pricing auto-insurance premiums. The Markov-modulated tree-based gradient boosting model is a Tweedie general linear model (GLM) based pricing algorithm with a compound Poisson-Gamma distribution whose rate varies according to accident risk in a Markovian process. Thus, the study extends the existing premium pricing framework by integrating a geographical location risk factor into the main pricing framework. The study applies the model to a motor insurance data set from Ghana. The results show that the proposed method is superior to other competing models because it generates relatively fair premium predictions for the non-life auto-insurance companies, helping to mitigate more the insured risk for the firm and the industry. © 2020 Elsevier B.V., All rights reserved.","Arku, D.; Doku-Amponsah, K.; Howard, N.K.",2020,10.3233/rda-180050,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085768703&doi=10.3233%2FRDA-180050&partnerID=40&md5=43274c399c2abe9303985a4ed9506140,scopus
94f2194dac2bf593,A Multi-Objective Portfolio Selection Model With Fuzzy Value-at-Risk Ratio,"Considering nonstatistical uncertainties and/or insufficient historical data in security return forecasts, fuzzy set theory has been applied in the past decades to build portfolio selection models. Meanwhile, various risk measurements such as variance, entropy, and Value-at-Risk have been proposed in fuzzy environments to evaluate investment risks from different perspectives. Sharpe ratio, also known as the reward-to-variability ratio, which measures the risk premium per unit of the nonsystematic risk (asset deviation), has received great attention in modern portfolio theory. In this study, the Sharpe ratio in fuzzy environments is introduced, whereafter, a fuzzy Value-at-Risk ratio is proposed. Compared with Sharpe ratio, Value-at-Risk ratio is an index with dimensional knowledge that reflects the risk premium per unit of the systematic risk (the greatest loss under a given confidence level). On the basis of the two ratios, a multi-objective model is built to evaluate their joint impact on portfolio selection. Then, the proposed model is solved by a fuzzy simulation based multi-objective particle swarm optimization algorithm, where the global best of each iteration is determined by an improved dominance times based method. Finally, the algorithm superiority is justified via comparing with existing solvers on benchmark problems, and the model effectiveness is exemplified by using three case studies on portfolio selection.",B. Wang; Y. Li; S. Wang; J. Watada,2018,10.1109/tfuzz.2018.2842752,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8370687,ieeexplore
512099f188d82d66,"A Network and Machine Learning Approach to Factor, Asset, and Blended Allocation","The main idea of this article is to approach and compare factor and asset allocation portÂfolios using both traditional and alternative allocation techniques: Inverse variance optimization, minimum-variance optimization, and centrality-based techniques from network science. Analysis of the interconnectedÂness between assets and factors shows that their relaÂtionship is strong. The authors compare the allocation techniques, considering centrality and hierarchal-based networks. They demonstrate the advantages of graph theory to explain the advantages to portfolio manageÂment and the dynamic nature of assets and factors with their ""importance score."" They find that asset allocaÂtion can be efficiently derived using directed networks, dynamically driven by both US Treasuries and curÂrency returns with significant centrality scores. AlterÂnatively, the inverse variance weight estimation and correlation-based networks generate factor allocation with favorable risk-return parameters. Furthermore, factor allocation is driven mostly by the importance scores of the Fama-French-Carhart factors: SMB, HML, CMA, RMW, and MOM. The authors confirm previous results and argue that both factors and assets are interconnected with different value and momentum factors. Therefore, a blended strategy comprising factors and assets can be defensible for investors. As argued in previous research, factors are much more overcrowded than assets. Therefore, the centrality scores help to identify the crowded expoÂsure and build diversified allocation. The authors run LASSO regressions and show how the network-based allocation can be implemented using machine learning. © 2020 Elsevier B.V., All rights reserved.","Konstantinov, G.; Chorus, A.; Rebmann, J.",2020,10.3905/jpm.2020.1.147,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088367857&doi=10.3905%2Fjpm.2020.1.147&partnerID=40&md5=6e1dee8ae9c04309ccd1b8d63a1dbd71,scopus
3c7ed3cc4ae5de19,A Neural Network Architecture for Maximizing Alpha in a Market Timing Investment Strategy,"In finance, assuming more risk often corresponds to the expectation of higher, compensating returns. In this setting, alpha stands out as one of the most prevalent and refined measures of risk-adjusted return ever postulated, allowing for the estimation of the excess return that cannot be explained by the risk factors impacting an asset. This article introduces a neural network architecture designed to formulate an investment strategy with the explicit goal of maximizing alpha. The strategy, centered around market timing, determines on a daily basis, based on past returns of the risky asset, whether to fully invest in the risky asset or opt for the risk-free alternative. The neural network architecture comprises two components: a policy network for strategy implementation and an evaluation network for long-term alpha computation during parameter optimization. Employing value-weighted US size decile portfolios as risky assets, the study achieves significant out-of-sample alphas ranging from 3.6% to 8.2% per year under the  $q^{5}$  asset pricing model (with a transaction cost assumption of one basis point). By construction, these alphas are not generated by risky asset growth. Robustness tests yield similar results with equal-weighted decile portfolios or under the Fama and French six-factor asset pricing model. Variations in transaction cost, number of past returns used as inputs, policy network design, or training sample size produce similar outcomes. This study underscores the effectiveness of reinforcement learning-inspired techniques in uncovering alpha in financial markets.",J. H. Ospina-Holguín; A. M. Padilla-Ospina,2024,10.1109/access.2024.3446708,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10640102,ieeexplore
d4273ad348021037,A New Credit Spread to Predict Economic Activities in China,"In recent years, the relationship between bond spreads and macro economy has been studied extensively by economists in western countries. However, few attentions were paid on this topic in China. This essay regards Chinese bond market as a complex system and constructs bond indices for China with the bottom-up approach. The authors use the data of 3,205 non-financial corporate bonds from February 2010 to October 2017 and construct a new spread noted as the PE_SOE spread. The authors find that the PE_SOE spread has a negative impact on economic activities and has the best predictive ability at short-run forecasting horizons, owing to the institutional superiority of the state-owned enterprises in China. The Treasury bond yields are found to have the best predictive ability at long-run horizons. Both spread shock and Treasury yield shock could lead to deflation and declines in economic activities, and the Treasury yield shock has a more severe and persistent impact on the economy due to the financial accelerator mechanism. PE_SOE spread is proved to be a better indicator for Chinese corporate bond market and can be widely used not only in future Chinese economic studies, but also for Chinese government’s macroeconomic monitoring and warning.","Wang, Lei; Nie, Changhong; Wang, Shouyang",2019,10.1007/s11424-019-8033-3,None,proquest
d476fa9fc94bed8b,A New Linear Estimator for Gaussian Dynamic Term Structure Models,"This article proposes a novel regression-based approach to the estimation of Gaussian dynamic term structure models. This new estimator is an asymptotic least-square estimator defined by the no-arbitrage conditions upon which these models are built. Further, we note that our estimator remains easy-to-compute and asymptotically efficient in a variety of situations in which other recently proposed approaches might lose their tractability. We provide an empirical application in the context of the Canadian bond market.","de los Rios, Antonio Diez",2015,10.1080/07350015.2014.948176,None,wos
607804f1e76890ab,A Nonlinear Factor Analysis of S&P 500 Index Option Returns,"Growing evidence suggests that extraordinary average returns may be obtained by trading equity index options, and that at least part of this abnormal performance is attributable to volatility and jump risk premia. This paper asks whether such priced risk factors are alone sufficient to explain these average returns. To provide an answer in as general as possible a setting, I estimate a flexible class of nonlinear models using all S&P 500 Index futures options traded between 1986 and 2000. The results show that priced factors contribute to these expected returns but are insufficient to explain their magnitudes, particularly for short-term out-of-the-money puts.","Jones, Christopher S",2006,10.1111/j.1540-6261.2006.01059.x,None,proquest
e87df0ce8abe00f6,A Novel Particle Swarm Optimizer and Its Application to the Yield Curve Estimation Problem,"Particle swarm optimization (PSO) has been considered as one of the main swarm intelligence algorithms for solving single-objective optimization problem. How to update the velocities and positions of a swarm of particles is key to its optimization performance. In this paper, we propose to use the moving average of the local best positions visited so far as a key information to update the velocities and positions. Further, a central learning strategy is proposed in which the center of the local best positions is computed and used to update the global best position. Combining these two strategies with the updating formulas which are inspired by the free electron model in metal conductors placed in an external electric field, we name the proposed PSO algorithm as PSO with moving average and central learning strategies (dubbed as MAPSO). We test the performance of MAPSO on the CEC 2017 test problems with 10 and 30 dimensions. Experimental results show that MAPSO significantly outperforms some well-known PSOs in general. We then apply MAPSO on a very challenging real-world problem, i.e. the yield curve estimation problem, in macroeconomics. Our experimental study on the yield curve estimation problem with Shanghai interbank offered rates shows that MAPSO can effectively solve the problem and achieve the state-of-the-art performance.",J. Zhang; B. Shi,2022,10.1109/access.2022.3220792,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9943541,ieeexplore
d02c3ba10caea169,A Public Administration Moment: Forging an Agenda for Financial Regulatory Reform,"The numbers are staggering. As the financial crisis deepens, American financial companies will lose an estimated $3.6 trillion in non-performing loans and lost asset value (Lohr 2009). Nationally, home prices have fallen more than 18% from peak levels -- as much as 40% in some states -- and in 2008, lenders initiated more than 2.25 million home foreclosures (Duke 2009). The biggest financial crisis since the Great Depression, as the Treasury Department describes it, is a crisis of confidence, of capital, of credit, and of consumer and business demand. Just as staggering, however, is the lack of attention given to the government administrative capacities that failed going into the crisis, and that require fervent attention as they grope toward a reengineered financial system and regulatory structure. Public administration scholars and practitioners play a vital role in forging the future of finance.","Khademian, Anne M",2009,10.1111/j.1540-6210.2009.02008.x,None,proquest
cd8418d04eb88856,"A Public, Open, and Independently-Curated Database of Happiness Coefficients","We present a nascent database of happiness coefficients. This is a synthesis of evidence on the size of improvements to human life experience that can be expected from changing objective, policy-amenable circumstances. The wealth of data on people’s self-reported satisfaction with life in a wide variety of circumstances, from around the world, including respondents undergoing a diversity of changes and life events and subject to a variety of public policies and policy changes, has provided a rich base of knowledge about what makes life good. This growing research literature has in recent years been met with interest from central governments looking for accountable but more human-centred approaches to measuring progress, as well as for communicating objectives, making policy, and allocating resources. Meanwhile, frameworks for benefit-cost accounting using inference from life satisfaction data have been devised. In some cases central government finance departments and treasuries are incorporating this approach into their formal methodology for budgeting. The body of causal inference about these effects is still somewhat diffuse. Collating, reviewing, and synthesizing such evidence should be led initially by academia and ultimately by a broad academic, civil society, and government collaboration. We report on the assembly of a database of summary estimates for Canada, supplemented where needed by evidence from around the world. The categorized domains of individual experience and circumstances include Education, Environment, Work, Finances, Health, Social Capital, and Crime. The paper also explains the context for and limitations of the use of a database of happiness coefficients.","Barrington-Leigh, C. P.; Lemermeyer, Katja",2023,10.1007/s10902-023-00652-4,None,proquest
44371c6c7e52b37e,A Quantitative Investment Model Based on Random Forest and Sentiment Analysis,"In recent years, under the influence of economic globalization and anti-globalization, the stock market has experienced great fluctuations in China. Quantitative investment has attracted a lot of attention because of its characteristics of maintaining stable returns. Existing research is unilaterally based on quantitative data or qualitative data for analysis to construct a quantitative investment model. This paper considers both quantitative and qualitative data to construct a more comprehensive model than that in the past. Based on the optimized database, we present a combinational model named RF-SA, which is composed of random forest and sentiment analysis model. First of all, this paper uses the SBS algorithm to select the characteristics of stock transaction historical data, optimizes the prediction database, reduces data redundancy, and improves the accuracy of the model. Secondly, we analyze the characteristics of the Chinese stock market and study the advantages and disadvantages of many data mining algorithms, and select random forest model, the most suitable model, to build the first step of stock selection model. Then, through the analysis of public opinion, the confidence index of the stockholders is calculated; on this basis, the results of the RF model and the confidence index are combined to make a second choice for the stock, and the quantitative investment portfolio is obtained, and excess returns can be obtained. The results of empirical data show that, the RF-SA model obtains a higher rate of return than the investment model of the Shanghai Stock Index.","Chen, Mingqin; Zhang, Zhenhua; Shen, Jiawen; Deng, Zhijian; He, Jiaxing; Huang, Shiting",2020,10.1088/1742-6596/1575/1/012083,None,proquest
b91ed97fec43aa60,A Rational Theory of Mutual Funds' Attention Allocation,"The question of whether and how mutual fund managers provide valuable services for their clients motivates one of the largest literatures in finance. One candidate explanation is that funds process information about future asset values and use that information to invest in high-valued assets. But formal theories are scarce because information choice models with many assets are difficult to solve as well as difficult to test. This paper tackles both problems by developing a new attention allocation model that uses the state of the business cycle to predict information choices, which in turn, predict observable patterns of portfolio investments and returns. The predictions about fund portfolios' covariance with payoff shocks, cross-fund portfolio and return dispersion, and their excess returns are all supported by the data. These findings offer new evidence that some investment managers have skill and that attention is allocated rationally. © 2016 Elsevier B.V., All rights reserved.","Kacperczyk, M.; Van Nieuwerburgh, S.; Veldkamp, L.",2016,10.3982/ecta11412,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961238568&doi=10.3982%2FECTA11412&partnerID=40&md5=7c9b7cee943ebb7a5cb2bd4e745f8a5f,scopus
b1dd51e86fcc91e6,A Rigorous Statistical Comparison of Deep Learning Models for US Treasury Yield Prediction,"The intrinsic nonlinearity and dynamic relationships in interest rate fluctuations present a substantial challenge when forecasting financial time series, particularly US Treasury yields. These intricate relationships are sometimes not adequately captured by traditional econometric models. In recent years, deep learning (DL) methodologies have gained prominence in the financial market, offering advanced predictive capabilities by modeling high-dimensional dependencies and nonlinear interactions inside yield curves. To enhance the predictive accuracy of short-term (13-week) and long-term (5-year) US Treasury yields, this study leverages advanced deep learning models, including convolutional neural networks (CNNs), long short-term memory (LSTM) networks, and gated recurrent units (GRUs). A comprehensive statistical evaluation is performed to assess model performance through key error metrics such as root mean squared error (RMSE), mean squared error (MSE), mean absolute error (MAE), the coefficient of determination (R2), maximum error, and minimum error, as well as SAFE metrics (Sustainability, Accuracy, Fairness, Explainability) for a holistic assessment. To ensure a robust comparison, we employed the paired t-test to determine if the differences in model predictions are statistically significant. Additionally, we analyzed correlation metrics using Pearson and Spearman coefficients, which evaluate the models’ ability to capture both linear dependencies and ranking trends in yield fluctuations. This rigorous framework not only benchmarks the predictive power of each model but also provides deeper insights into their effectiveness in forecasting treasury yields across different time horizons.","Rani, Indu; Verma, Neetu; Verma, Chandan Kumar",2025,10.1007/s43069-025-00497-y,None,proquest
d4e4962a4745e30c,A Risk-Free Discount Rate Prediction Model for Mineral Project Evaluation Using a Hybrid Discrete Wavelet Transform and Artificial Neural Network,"The discount rate input parameter of Net Present Value (NPV) in mineral project evaluation is a function of a risk-free rate and risk premium component. To obtain a reliable NPV, it is important to estimate each of these components. This study employs a hybrid approach to predict risk-free rate using Discrete Wavelet Transform and Artificial Neural Network (DWT-ANN). The DWT-ANN model was tested using London Interbank Offered Rate (LIBOR) dataset from 1986 to 2020. The results showed that Discrete Wavelet Transform-Radial Basis Function Neural Network (DWT-RBFNN) of the three different hybrid algorithms developed and applied performed best in predicting the risk-free rate. This is because it achieved the lowest root mean square error of 0.0376 and the highest correlation coefficient of 0.9995. The DWT-RBFNN model can be a useful alternative tool for predicting risk-free rate, which is a key input parameter for the determination of discount rate. © 2022 Elsevier B.V., All rights reserved.","Gyebuni, R.; Ziggah, Y.Y.; Mireku-Gyimah, D.",2022,10.1155/2022/9984679,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139564882&doi=10.1155%2F2022%2F9984679&partnerID=40&md5=1dc2d0577c07a01ce69bdf0d8deb8b22,scopus
339df4defc6a0a72,A Semi-Static Replication Method for Bermudan Swaptions under an Affine Multi-Factor Model,"We present a semi-static replication algorithm for Bermudan swaptions under an affine, multi-factor term structure model. In contrast to dynamic replication, which needs to be continuously updated as the market moves, a semi-static replication needs to be rebalanced on just a finite number of instances. We show that the exotic derivative can be decomposed into a portfolio of vanilla discount bond options, which mirrors its value as the market moves and can be priced in closed form. This paves the way toward the efficient numerical simulation of xVA, market, and credit risk metrics for which forward valuation is the key ingredient. The static portfolio composition is obtained by regressing the target option’s value using an interpretable, artificial neural network. Leveraging the universal approximation power of neural networks, we prove that the replication error can be arbitrarily small for a sufficiently large portfolio. A direct, a lower bound, and an upper bound estimator for the Bermudan swaption price are inferred from the replication algorithm. Additionally, closed-form error margins to the price statistics are determined. We practically study the accuracy and convergence of the method through several numerical experiments. The results indicate that the semi-static replication approaches the LSM benchmark with basis point accuracy and provides tight, efficient error bounds. For in-model simulations, the semi-static replication outperforms a traditional dynamic hedge. © 2023 Elsevier B.V., All rights reserved.","Hoencamp, J.H.; Jain, S.; Kandhai, D.",2023,10.3390/risks11100168,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175481739&doi=10.3390%2Frisks11100168&partnerID=40&md5=8b7a20248b55d866fc0a12d7eb46c0ab,scopus
e5bc9c76cee36aba,A Simulation and Empirical Study of the Maximum Likelihood Estimator for Stochastic Volatility Jump-Diffusion Models,"We investigate the behaviour of the maximum likelihood estimator (MLE) for stochastic volatility jump-diffusion models commonly used in financial risk management. A simulation study shows the practical conditions under which the MLE behaves according to theory. In an extensive empirical study based on nine indices and more than 6000 individual stocks, we nonetheless find that the MLE is unable to replicate key higher moments. We then introduce a moment-targeted MLE - robust to model misspecification - and revisit both simulation and empirical studies. We find it performs better than the MLE, improving the management of financial risk.","Begin, Jean-Francois; Boudreault, Mathieu",2025,10.1515/snde-2023-0028,None,wos
a44cc2b7da758f7b,A Stock Market Decision-Making Framework Based on CMR-DQN,"In the dynamic and uncertain stock market, precise forecasting and decision-making are crucial for profitability. Traditional deep neural networks (DNN) often struggle with capturing long-term dependencies and multi-scale features in complex financial time series data. To address these challenges, we introduce CMR-DQN, an innovative framework that integrates discrete wavelet transform (DWT) for multi-scale data analysis, temporal convolutional network (TCN) for extracting deep temporal features, and a GRU–LSTM–Attention mechanism to enhance the model’s focus and memory. Additionally, CMR-DQN employs the Rainbow DQN reinforcement learning strategy to learn optimal trading strategies in a simulated environment. CMR-DQN significantly improved the total return rate on six selected stocks, with increases ranging from 20.37% to 55.32%. It also demonstrated substantial improvements over the baseline model in terms of Sharpe ratio and maximum drawdown, indicating increased excess returns per unit of total risk and reduced investment risk. These results underscore the efficiency and effectiveness of CMR-DQN in handling multi-scale time series data and optimizing stock market decisions.","Chen, Xun; Wang, Qin; Hu, Chao; Hu, Chao; Wang, Chengqi",2024,10.3390/app14166881,None,proquest
a55c6c4dbb980926,A Structural Credit Risk Model with Jumps Based on Uncertainty Theory,"This study, within the framework of uncertainty theory, employs an uncertain differential equation with jumps to model the asset value process of a company, establishing a structured model of uncertain credit risk that incorporates jumps. This model is applied to the pricing of two types of credit derivatives, yielding pricing formulas for corporate zero-coupon bonds and Credit Default Swap (CDS). Through numerical analysis, we examine the impact of asset value volatility and jump magnitude on corporate default uncertainty, as well as the influence of jump magnitude on the pricing of zero-coupon bonds and CDS. The results indicate that an increase in volatility levels significantly enhances default uncertainty, and an expansion in the magnitude of negative jumps not only directly elevates default risk but also leads to a significant increase in the value of zero-coupon bonds and the price of CDS through a risk premium adjustment mechanism. Therefore, when assessing corporate default risk and pricing credit derivatives, the disturbance of asset value jumps must be considered a crucial factor.","Huang, Hong; Huang, Hong; Jiang, Meihua; Yufu Ning; Wang, Shuai",2025,10.3390/math13060897,None,proquest
21d86b47059741ab,A Study of Stock Market Predictability Based on Financial Time Series Models,"In today’s era of economic globalization and financial integration, the stock market is constantly complex, showing many deviations that cannot be explained by classical financial analysis, but at the same time, some classic financial statistical features have striking similarities. This suggests that although the stock market is intricate, there are universal laws that can be found through data mining to find its underlying operating rules. In this paper, we construct financial time series models such as ARIMA, ARCH, and GARCH to predict the stock market price fluctuations and trends. The ARIMA model is used to fit the linear financial time series, and the GARCH model is used to fit the nonlinear time series residuals. The results show that the integrated tree model based on the idea of weight voting has high accuracy in predicting stock market bulls and bears, with XGBoost prediction accuracy up to 96%, and the neural network model is also very effective, with an accuracy rate of over 90%.","Yu, Yan",2022,10.1155/2022/8077277,None,proquest
2e9eec71c0351724,A Study on Project Portfolio Models with Skewness Risk and Staffing,"When it comes to business operation, the institutions have to choose some appropriate projects from numerous projects to invest. To this end, they should consider to establish a project portfolio to make decisions. When building such a portfolio, the project selection and the staff assignment are the most essential parts, which greatly affect the profit of project portfolios. As for the project selection, market returns tend to be asymmetric and investors are often concerned about the skewness risk which is ignored by the traditional project portfolio. Meanwhile, as for the staff assignment, the institutional investors aim at achieving the highest returns by adopting a proper assignment of project managers. In addition, since the exact possibility distributions of uncertain parameters in practical project portfolio problems are often unavailable, we adopt variable parametric credibility measure to characterize uncertain model parameters. In view of these problems, this article proposes a project portfolio model with skewness risk constraints and a project portfolio model with staffing based on credibility measure theory and fuzzy theory in uncertain circumstances. Our two models are associated with risk-free assets so that the remaining funds can be utilized effectively. Finally, we use genetic algorithms to solve our proposed models and present some numerical examples to demonstrate the effectiveness of the proposed models. © 2023 Elsevier B.V., All rights reserved.","Xu, W.; Liu, G.; Li, H.; Luo, W.",2017,10.1007/s40815-017-0295-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037379412&doi=10.1007%2Fs40815-017-0295-0&partnerID=40&md5=5d175108a94ab2d9fd4c70c6ba35eaf2,scopus
fdd8722f03a9cd48,A Synthetic Data Generation Technique for Enhancement of Prediction Accuracy of Electric Vehicles Demand,"In terms of electric vehicles (EVs), electric kickboards are crucial elements of smart transportation networks for short-distance travel that is risk-free, economical, and environmentally friendly. Forecasting the daily demand can improve the local service provider’s access to information and help them manage their short-term supply more effectively. This study developed the forecasting model using real-time data and weather information from Jeju Island, South Korea. Cluster analysis under the rental pattern of the electric kickboard is a component of the forecasting processes. We cannot achieve noticeable results at first because of the low amount of training data. We require a lot of data to produce a solid prediction result. For the sake of the subsequent experimental procedure, we created synthetic time-series data using a generative adversarial networks (GAN) approach and combined the synthetic data with the original data. The outcomes have shown how the GAN-based synthetic data generation approach has the potential to enhance prediction accuracy. We employ an ensemble model to improve prediction results that cannot be achieved using a single regressor model. It is a weighted combination of several base regression models to one meta-regressor. To anticipate the daily demand in this study, we create an ensemble model by merging three separate base machine learning algorithms, namely CatBoost, Random Forest (RF), and Extreme Gradient Boosting (XGBoost). The effectiveness of the suggested strategies was assessed using some evaluation indicators. The forecasting outcomes demonstrate that mixing synthetic data with original data improves the robustness of daily demand forecasting and outperforms other models by generating more agreeable values for suggested assessment measures. The outcomes further show that applying ensemble techniques can reasonably increase the forecasting model’s accuracy for daily electric kickboard demand.","Chatterjee, Subhajit; Yung-Cheol Byun; Yung-Cheol Byun",2023,10.3390/s23020594,None,proquest
4229103779a54ec5,A TVM-Copula-MIDAS-GARCH model with applications to VaR-based portfolio selection,"This paper develops a novel time-varying multivariate Copula-MIDAS-GARCH (TVM-Copula-MIDAS-GARCH) model with exogenous explanatory variables to model the joint distribution of returns. The model accounts for mixed frequency factors that affect the time-varying dependence structure of financial assets. Furthermore, we examine the effectiveness of the proposed model in VaR-based portfolio selection. We conduct an empirical analysis on estimating the 90%, 95%, 99% VaRs of the portfolio constituted of the Shanghai Composite Index, Shanghai SE Fund Index, and Shanghai SE Treasury Bond Index. The empirical results show that the proposed TVM-Copula-MIDAS-GARCH model is effective to investigate the nonlinear time-varying dependence among those three indices and performs better in portfolio selection. © 2020 Elsevier B.V., All rights reserved.","Jiang, C.; Ding, X.; Xu, Q.; Tong, Y.",2020,10.1016/j.najef.2019.101074,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072602228&doi=10.1016%2Fj.najef.2019.101074&partnerID=40&md5=73863b38a88325f20a4b8f7eddc0f364,scopus
209637058300c847,A Unified Framework for Fast Large-Scale Portfolio Optimization,"We introduce a unified framework for rapid, large-scale portfolio optimization that incorporates both shrinkage and regularization techniques. This framework addresses multiple objectives, including minimum variance, mean-variance, and the maximum Sharpe ratio, and also adapts to various portfolio weight constraints. For each optimization scenario, we detail the translation into the corresponding quadratic programming (QP) problem and then integrate these solutions into a new open-source Python library. Using 50 years of return data from US mid to large-sized companies, and 33 distinct firm-specific characteristics, we utilize our framework to assess the out-of-sample monthly rebalanced portfolio performance of widely-adopted covariance matrix estimators and factor models, examining both daily and monthly returns. These estimators include the sample covariance matrix, linear and nonlinear shrinkage estimators, and factor portfolios based on Asset Pricing (AP) Trees, Principal Component Analysis (PCA), Risk Premium PCA (RP-PCA), and Instrumented PCA (IPCA). Our findings emphasize that AP-Trees and PCA-based factor models consistently outperform all other approaches in out-of-sample portfolio performance. Finally, we develop new (Formula presented.) and (Formula presented.) regularizations of factor portfolio norms which not only elevate the portfolio performance of AP-Trees and PCA-based factor models but they have a potential to reduce an excessive turnover and transaction costs often associated with these models. © 2025 Elsevier B.V., All rights reserved.","Deng, W.; Polak, P.; Safikhani, A.; Shah, R.",2024,10.1080/26941899.2023.2295539,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003413482&doi=10.1080%2F26941899.2023.2295539&partnerID=40&md5=09ebcd357e426caf6aa3db4d044e82bc,scopus
f187ea8de5111e6f,A VECM analysis of Bitcoin price using time-varying cointegration approach,"This study proposed an optimal model to examine the relationship between the Bitcoin price and six macroeconomic variables – the Bitcoin price, Standard and Poor's 500 volatility index, US treasury 10-year yield, US consumer price index, gold price and dollar index. It also examined the effectiveness of the vector error correction model (VECM) in analyzing the interrelationship among these variables. The authors employed the following approach: first, the authors sampled the period August 2010–February 2022. This is because Bitcoin achieved a market capitalization of more than US$1 tn over this period, gaining market attention and acceptance from retail, corporate and institutional investors. Second, the authors employed a VECM with the six macroeconomic variables. Finally, the authors expanded the long-run equilibrium relationship (time-invariant cointegration)-based VECM to develop a time-varying cointegration (TVC) VECM. The authors estimated the TVC VECM using the Chebyshev polynomial specification based on various information criteria. The results showed that the Bitcoin price can be modeled with the VECM (p = 1, r = 1). The TVC approach generated more explanatory power for Bitcoin pricing, indicating the effectiveness of the approach for modeling the long-run relationship between Bitcoin price and macroeconomic variables. © 2023 Elsevier B.V., All rights reserved.","Lee, Y.; Rhee, J.H.",2022,10.1108/jdqs-01-2022-0001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150338859&doi=10.1108%2FJDQS-01-2022-0001&partnerID=40&md5=14ed575c3c7ffa374c533ddd0c3a53b7,scopus
8467d8f718f5b82c,A class of Gaussian hybrid processes for modeling financial markets,"This paper proposes a one-factor model of financial markets using a class of Gaussian process that can be decomposed into a Brownian motion and an Ornstein-Uhlenbeck process. It is shown that this ""hybrid"" process is obtained as a continuous-time scaling limit of the differenced first-order autoregressive integrated moving average (ARIMA(1,1,1)) process. Parameter estimations using an ARIMA(1,1,1) framework and its variance ratio test show the accuracy of the proposed model. Construction of the one-factor commodity futures price model is presented as an application. A multidimensional extension of the hybrid process is also presented in the Appendix. © 2008 Springer Science+Business Media, LLC. © 2008 Elsevier B.V., All rights reserved.","Itoh, Y.",2007,10.1007/s10690-007-9058-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-41149159008&doi=10.1007%2Fs10690-007-9058-5&partnerID=40&md5=d41636f4abc62db5bad174cc42210d9d,scopus
644a6f98cf40c70c,A comparison of linear and nonlinear statistical techniques in performance attribution,"Performance attribution is usually conducted under the linear framework of multifactor models. Although commonly used by practitioners in finance, linear multifactor models are known to be less than satisfactory in many situations. After a brief survey of nonlinear methods, nonlinear statistical techniques are applied to performance attribution of a portfolio constructed from a fixed universe of stocks using factors derived from some commonly used cross sectional linear multifactor models. By rebalancing this portfolio monthly, the cumulative returns for procedures based on standard linear multifactor model and three nonlinear techniques-model selection, additive models, and neural networks-are calculated and compared. It is found that the first two nonlinear techniques, especially in combination, outperform the standard linear model. The results in the neural-network case are inconclusive because of the great variety of possible models. Although these methods are more complicated and may require some tuning, toolboxes are developed and suggestions on calibration are proposed. This paper demonstrates the usefulness of modern nonlinear statistical techniques in performance attribution.",Ngai Hang Chan; C. R. Genovese,2001,10.1109/72.935100,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=935100,ieeexplore
23dde43cefbb3d8b,A comparison of linear regression and neural network methods for predicting excess returns on large stocks,"Recent studies have shown that there is predictable variation in returns of financial assets over time. We investigate whether the predictive power of the economic and financial variables employed in the above studies can be enhanced if the statistical method of linear regression is replaced by feedforward neural networks with backpropagation of error. A shortcoming of backpropagation networks is that too many free parameters allow the neural network to fit the training data arbitrarily closely resulting in an ""overfitted"" network. Overfitted networks have poor generalization capabilities. We explore two methods that attempt to overcome this shortcoming by reducing the complexity of the network. The results of our experiments confirm that an ""overfitted"" network, while making better predictions for within-sample data, makes poor predictions for out-of-sample data. The methods for reducing the complexity of the network, explored in this paper, clearly help improve out-of-sample forecasts. We show that one cannot say that the linear regression forecasts are conditionally efficient with respect to the neural networks forecasts with any degree of confidence. However, one can say that the neural networks forecasts are conditionally efficient with respect to the linear regression forecasts with some confidence. © 2020 Elsevier B.V., All rights reserved.","Desai, V.S.; Bharati, R.",1998,10.1023/a:1018993831870,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032376229&doi=10.1023%2Fa%3A1018993831870&partnerID=40&md5=9522b8d59588be335e6542c062a56e6f,scopus
f1af81ea3d55fdf8,A comparison of machine learning and econometric models for pricing perpetual Bitcoin futures and their application to algorithmic trading,"Bitcoin (BTC) perpetual futures contracts are highly leveraged speculative trading instruments with daily market trading of $45 Billion. BTC perpetual futures are derivative contracts, which depend upon the underlying BTC SPOT (current) price. Pricing perpetual futures fairly is hard, using traditional arbitrage arguments, because of the volatile nature of the so called funding rate, which is used as the replacement of risk free rate in the Cryptocurrency market. This work presents a novel technique for pricing BTC futures contracts using conditional volatility and mean models. Intra‐day high‐frequency futures' return volatility and mean are modelled using different ML and econometric techniques. A comparison is made using statistical measures to find the model that best captures the intra‐day conditional mean and volatility. Exponential generalized autoregressive conditional heteroskedasticity is shown to be an almost unbiased predictor of intra‐day volatility, while a constant autoregressive moving average (0, 0) model best captures the conditional mean of the returns. A market directional high frequency trading algorithm is developed using the volatility and mean models. The algorithm first prices the futures contract at some future point of time using the volatility and mean regression models. Next, the slope between the current futures price and the expected price are used to predict the market direction. A long or short position is taken depending upon the expected market direction movement. Extensive back‐testing results show absolute returns of 1500%–8000% depending upon the transaction fees and leverage used. On average, the market direction is predicted correctly 85% of the time by the best model. Finally, the trading technique is market neutral, in that it gives large positive returns, with low SD, in both bull and bear markets.","Malik, Avinash",2023,10.1111/exsy.13414,None,proquest
3e17cebdb57d3bca,A comparison of multitask and single task learning with artificial neural networks for yield curve forecasting,"The yield curve is the centrepiece in bond markets, a massive asset class with an overall size of USD 100 trillion that remains relatively under-investigated using machine learning. This paper is the first comprehensive study using artificial neural networks in the context of yield curve forecasting. Specifically, two models were used for forecasting the European yield curve: multivariate linear regression and multilayer perceptron (MLP), at five forecasting horizons, from next day to 20 days ahead. Five variants of the MLP were analysed with different sets of features: target to predict (univariate); the most relevant features; all generated features; and the former two incorporating synthetic data generated by the linear regression model. Additionally, two different techniques of multitask learning were employed: simultaneous modelling and transformation into multiple single task learning. The results show that considering all forecasting horizons, the MLP using the most relevant features achieved the best results and the addition of synthetic data tends to improve accuracy. Furthermore, different targets and forecasting horizons resulted in different relevant features, reinforcing the importance of custom-built models. In the two multitask learning methodologies no clear differentiation could be demonstrated, and several explaining factors are identified. Overall, the outcome is very encouraging for the development of better forecasting systems for fixed income markets.","Nunes, Manuel; Gerding, Enrico; McGroarty, Frank; Niranjan, Mahesan",2019,10.1016/j.eswa.2018.11.012,None,proquest
bac703195941f32a,A comparison of nonlinear methods for predicting earnings surprises and returns,"We compare four nonlinear methods on their ability to learn models from data. The problem requires predicting whether a company will deliver an earnings surprise a specific number of days prior to announcement. This problem has been well studied in the literature using linear models. A basic question is whether machine learning-based nonlinear models such as tree induction algorithms, neural networks, naive Bayesian learning, and genetic algorithms perform better in terms of predictive accuracy and in uncovering interesting relationships among problem variables. Equally importantly, if these alternative approaches perform better, why? And how do they stack up relative to each other? The answers to these questions are significant for predictive modeling in the financial arena, and in general for problem domains characterized by significant nonlinearities. In this paper, we compare the four above-mentioned nonlinear methods along a number of criteria. The genetic algorithm turns out to have some advantages in finding multiple ""small disjunct"" patterns that can be accurate and collectively capable of making predictions more often than its competitors. We use some of the nonlinearities we discovered about the problem domain to explain these results.",V. Dhar; D. Chou,2001,10.1109/72.935099,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=935099,ieeexplore
8a149439aecedfa5,A comparison of risk-premium forecasts implied by parametric versus nonparametric conditional mean estimators,"This paper computes parametric estimates of a time-varying risk premium model and compares the one-step-ahead forecasts implied by that model with those given by a nonparametric kernel estimator of the conditional mean function. The conditioning information used for the nonparametric analysis is that implied by the theoretical model of time-varying risk. Thus, the kernel estimator is used, in conjunction with a nonparametric diagnostic test for in-sample residual nonlinear structure, to assess the adequacy of the parametric model in capturing any structure in the excess returns. Our results support the parametric specification of an asset pricing model in which the conditional beta is the ratio of the relevant components of the conditional covariance matrix of returns modelled as a bivariate generalized ARCH process. Although the predictable component of the conditional moments is relatively small, the parametric estimator of the risk premia has somewhat more out-of-sample forecasting ability than does the kernel estimator. Hence, the superior in-sample performance of the latter may be attributed to overfitting. © 1992. © 2014 Elsevier B.V., All rights reserved.","McCurdy, T.H.; Stengos, T.",1992,10.1016/0304-4076(92)90071-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0011463942&doi=10.1016%2F0304-4076%2892%2990071-X&partnerID=40&md5=5201c426cd455c9821ffe152c1cd7b83,scopus
6260d09b870d4639,A comparison of tests of nonlinear cointegration with application to the predictability of US interest rates using the term structure,"We test whether there are nonlinearities in the response of short- and long-term interest rates to the spread in interest rates, and assess the out-of-sample predictability of interest rates using linear and nonlinear models. We find strong evidence of nonlinearities in the response of interest rates to the spread. Nonlinearities are shown to result in more accurate short-horizon forecasts, especially of the spread. © 2004 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved. © 2008 Elsevier B.V., All rights reserved.","Clements, M.P.; Galvão, A.B.",2004,10.1016/j.ijforecast.2003.09.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-1842659918&doi=10.1016%2Fj.ijforecast.2003.09.001&partnerID=40&md5=0815b049531bbb3f1e71069935d68952,scopus
7736932495ba615c,A comprehensive investigation on the predictive power of economic policy uncertainty from non-US countries for US stock market returns,"This study uses economic policy uncertainty (EPU) indices for ten developed countries, three diffusion models, and five combination methods to forecast excess returns in the U.S. stock market. It shows empirically that, over the period January 1997 to January 2022, non-U.S. EPU indices have better predictive power for U.S. equity market excess returns than the U.S. EPU index itself. This illustrates how economic information from interna-tional markets can affect the U.S. stock market. This finding challenges the extensively recognized view that the U.S. is where important market signals are initially transmitted to other markets, suggesting that this belief is incomplete. Our outcomes are robust to a battery of tests covering model selection, model specification, forecast horizons, and the pandemic period, and their economic values are assessed. The findings are essential for the financial field to confront future fierce situations and crises.","Huang, Yisu; Ma, Feng; Bouri, Elie; Huang, Dengshi",2023,10.1016/j.irfa.2023.102656,None,wos
1d5944dc1f483123,"A constrained least square method for estimating a smooth, nonnegative forward rate sequence","We will develop an efficient method for estimating a smooth nonnegative forward rate sequence using the market price of riskless bonds. This method is an improvement of the classical Carleton-Cooper's method based on standard least square method, which often generates a non-smooth forward rate sequence and hence is not used in practice. The method to be proposed in this paper is intended to resolve this difficulty. We will impose a smoothness condition while maintaining the fitting error within an acceptable level. The resulting optimization problem is shown to be convex in the region of interest. Therefore, we can calculate a globally optimal solution very fast by standard nonlinear programming algorithms. We will demonstrate that this method generates a smooth forward rate sequence at the expense of a very small increase of fitting error. © World Scientific Publishing Company. © 2008 Elsevier B.V., All rights reserved.","Konno, H.; Ito, S.",2005,10.1142/s0219024905003293,https://www.scopus.com/inward/record.uri?eid=2-s2.0-27544457345&doi=10.1142%2FS0219024905003293&partnerID=40&md5=d4b267dbfd7198ed1b95a3f81c3e5184,scopus
d3acea4f9be74018,A daily view of the term structure dynamics: Some international evidence,"The paper employs daily interest rates from the short-end of the Eurocurrency market in order to test the validity of the Expectations Hypothesis (EH). In particular, exploiting the stochastic trends embedded in the time series the EH implications are tested in a multivariate cointegration framework. The empirical findings indicate that once daily rates are used the estimated coefficients are very close to their theoretical values as predicted by the EH. Furthermore, we cannot reject the hypothesis that the EH is an adequate description of the US yield curve. Similarly, for the German and UK yield curves the number of common stochastic trends present in their yield curves is consistent with the EH. However, the restrictions imposed by the theory on parameters of the cointegration space are rejected.","Drakos, K",2002,10.1023/a:1014851101861,None,wos
6b84e9b3a4dbcbf6,A differential evolution algorithm for yield curve estimation,"Modeling the term structure of government bond yields is of great interest to macroeconomists and financial market practitioners. It is crucial for bonds and derivatives pricing, risk management, and reveals market expectations, which is essential for monetary policy decisions. This paper suggests the use of a differential evolutionary algorithm to estimate yield curves for US Treasury bonds. It considers parsimonious modeling to avoid non-convergence and high instability of traditional optimization algorithms when estimating model parameters caused by the choice of their initial values during curve fitting. In this approach, the whole yield curve for different maturities is obtained by models parameters estimates. Computational experiments show that the differential evolutionary algorithm provides more accurate yield curves than the ones derived by nonlinear least squares and genetic algorithm approaches. © 2016 Elsevier B.V., All rights reserved.","Maciel, L.; Gomide, F.; Ballini, R.",2016,10.1016/j.matcom.2016.04.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971623035&doi=10.1016%2Fj.matcom.2016.04.004&partnerID=40&md5=b9d939ee042f35134b929a881b51fb90,scopus
bb18143d023a488b,A dynamic asset allocation approach under technical analysis and machine learning classification,"This research evaluates the effectiveness of machine learning models by comparing the performance of seven models in predicting the return movement of four asset types over different return periods. The assets include S&P 500 Futures, Gold Futures, US 10Y Treasury Bond Futures, and a risk-free investment. The study considers 1-week, 4-week, and 12-week forward return periods. The analysis assesses model accuracy and portfolio performance using data spanning two decades. ML-based portfolios modestly outperform an equal-weighted benchmark in terms of risk-adjusted metrics over longer horizons, even though the differences are generally insignificant. However, the study emphasizes the importance of considering diverse economic cycles to understand asset behaviour comprehensively. Nevertheless, the study did not find significant evidence that combining machine learning prediction with dynamic asset allocation can outperform passive portfolio investment. The study underscores the potential of non-linear models in short-term trading but also notes limitations in adaptiveness, threshold design, and model generalization under atypical conditions. © 2025 Elsevier B.V., All rights reserved.","Luc, G.B.; Wu, C.-C.",2025,10.1080/00036846.2025.2526177,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010230429&doi=10.1080%2F00036846.2025.2526177&partnerID=40&md5=1bfee009edd82f459adff74af01afe83,scopus
24e4d383bd202c0a,A dynamic factor model of the yield curve components as a predictor of the economy,"In this paper, we propose an econometric model of the joint dynamic relationship between the Treasury yield curve components and the economy, for predicting business cycle turning points. The nonlinear multivariate dynamic factor model takes into account not only the popular slope, but also information extracted from the level and curvature of the yield curve, and from macroeconomic variables. We investigate the interrelationship between the phases of cyclical fluctuations in yield curve components and the phases of the business cycle. The results indicate a strong interrelationship between the yield curve and the economy. The proposed model has substantial incremental predictive value relative to alternative specifications. This result holds both in-sample and out-of-sample, using revised and real time unrevised data. © 2016 Elsevier B.V., All rights reserved.","Chauvet, M.; Senyuz, Z.",2016,10.1016/j.ijforecast.2015.05.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955313253&doi=10.1016%2Fj.ijforecast.2015.05.007&partnerID=40&md5=a41c2d9e062771db7347649b91b21ab4,scopus
5db21e3fdea8a7c2,A dynamic target volatility strategy for asset allocation using artificial neural networks,"A challenge to developing data-driven approaches in finance and trading is the limited availability of data because periods of instability, such as during financial market crises, are relatively rare. This study applies a stability-oriented approach (SOA) based on statistical tests to compare data for the current period to a past set of data for a stable period, providing higher reliability due to a more abundant source of data. Based on an SOA, this study uses an artificial neural network (ANN), which is one of the commonly applied machine learning algorithms, for simultaneously forecasting the volatility and classifying the level of market stability. In addition, this study develops a dynamic target volatility strategy for asset allocation using an ANN to enhance the ability of a target volatility strategy that is established for automatically allocating capital between a risky asset and a risk-free cash position. In order to examine the impact of the proposed strategy, the results are compared to the buy-and-hold strategy, the static asset allocation strategy, and the conventional target volatility strategy using different volatility forecasting methodologies. An empirical case study of the proposed strategy is simulated in both the Korean and U.S. stock markets.","Kim, Youngmin; Enke, David",2018,10.1080/0013791x.2018.1461287,None,proquest
0e5f8a823c00b204,A factor pricing model based on machine learning algorithm,"We adopt Discrete Wavelet Transform (DWT) and Support Vector Regression (SVR) algorithm to predict stock returns and form a time-varying Machine Learning (ML) factor based on the predicted returns for improving the classical asset pricing in the Chinese stock market from 2000 to 2020. The results show that the sorted portfolios formed by the predicted return rates can obtain significant excess returns in the Chinese market. Furthermore, our research shows that incorporating the ML factor into the CH4 and FF5 model can improve the pricing power significantly. It indicates that the ML factor can complement the traditional pricing models. We also find the performance of factor models depend on macroeconomy and market sentiment, that is, the better the macroeconomic and stock market performance, the stronger the pricing power of the factor models in the Chinese market. Additionally, we explore whether ML factor falls under short-term, median-term, and long-term momentum and reversal factors, and our analysis demonstrates that the ML factor is more effective than momentum and reversal factors. © 2023 Elsevier B.V., All rights reserved.","Fang, Y.; Chen, Y.; Ren, H.",2023,10.1016/j.iref.2023.06.012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165250152&doi=10.1016%2Fj.iref.2023.06.012&partnerID=40&md5=5d7b8619f3b34ab111872af48b27b9aa,scopus
58faaf67a8d7f201,A framework to measure integrated risk,A framework underlying various models that measure the credit risk of a portfolio is extended in this paper to allow the integration of credit risk with a range of market risks using Monte Carlo simulation. A structural model is proposed that allows interest rates to be stochastic and provides closed-form expressions for the market value of a firm's equity and its probability of default. This model is embedded within the integrated framework and the general approach illustrated by measuring the risk of a foreign exchange forward when there is a significant probability of default by the counterparty. For this example moving from a market risk calculation to an integrated risk calculation reduces the expected future value of the instrument by an amount that Could not be calculated using the common pre-settlement exposure technique for estimating the credit risk of a derivative.,"Medova, EA; Smith, RG",2005,10.1080/14697680500117583,None,wos
c25e22f6b2dd0dd1,A further analysis of robust regression modeling and data mining corrections testing in global stocks,"In this analysis of the risk and return of stocks in global markets, we build a reasonably large number of stock selection models and create optimized portfolios to outperform a global benchmark. We apply robust regression techniques, LAR regression, and LASSO regression modeling to estimate stock selection models. Markowitz-based optimization techniques is used in portfolio construction within a global stock universe. We apply the Markowitz–Xu data mining corrections test to a global stock universe. We find that (1) robust regression applications are appropriate for modeling stock returns in global markets; (2) weighted latent root regression robust regression techniques work as well as LAR and LASSO-Regressions in building effective stock selection models; (3) mean–variance techniques continue to produce portfolios capable of generating excess returns above transactions costs; and (4) our models pass several data mining tests such that regression models produce statistically significant asset selection for global stocks. Recent Sturdy-Regression modeling technique may offer the greatest potential for further research for statistically based stock selection modeling. © 2021 Elsevier B.V., All rights reserved.","Guerard, J.B.; Xu, G.; Markowitz, H.",2021,10.1007/s10479-020-03521-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079228702&doi=10.1007%2Fs10479-020-03521-y&partnerID=40&md5=e087ffa22478c084792e3b0edf880973,scopus
9d117d54bee8c73e,A general equilibrium (GE) model of the term structure applied to Australian securities,"The Double Square Root (DSR) GE model of the term structure is fitted to Australian security yield data over the period 2 January 1984 to 15 December 1995 - a data set of 3041 yields on four securities: 30 and 90-day BAB: and 5 and 10-year bonds. Applying both the OLS and GMM estimators we find a nonlinear, reduced form relationship between these yields and the risk free rate. So we conclude that GE models explain a diverse range of Australian yield curve shapes and that Australian bond prices are not necessarily inversely related to interest rates. © 199S Roulledge. © 2017 Elsevier B.V., All rights reserved.","Felmingham, B.S.; Norton Grey, W.",1998,10.1080/135048598354122,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33744459271&doi=10.1080%2F135048598354122&partnerID=40&md5=14ea2b3eb6434db4e77834f89eebf639,scopus
1c4239d6298f5cb3,A generalized bootstrap method to determine the yield curve,"A new technique is described for operationalizing the bootstrap methodology to estimate the yield curve given any available data set of bond yields. The problem of missing data points is dealt with using symbolic cubic spline interpolation. To make such an approach tractable the computer algebra system Maple is employed to symbolically generate the interpolation equations for the missing data points and to solve the nonlinear equation system in order to obtain the points on the yield curve. Several examples with real data demonstrate the usefulness of the methodology. © 2000, Taylor & Francis Group, LLC. © 2019 Elsevier B.V., All rights reserved.","Deaves, R.; Parlar, M.",2000,10.1080/13504860010021162,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066185898&doi=10.1080%2F13504860010021162&partnerID=40&md5=af033d7b30bfd2da8123b454f987e7d0,scopus
3a8fd6c9625412a8,A genetic algorithm estimation of the term structure of interest rates,"The term structure of interest rates is a key instrument for financial research. It provides relevant information for pricing deterministic financial cash flows, it measures economic market expectations and it is extremely useful when assessing the effectiveness of monetary policy decisions. However, it is not directly observable and needs to be estimated by smoothing asset pricing data through statistical techniques. The most popular techniques adjust parsimonious functional forms based on bond yields to maturity. Unfortunately, these functions, which need to be optimised, are highly non-linear which make them very sensitive to the initial conditions. In this context, this paper proposes the use of genetic algorithms to find the values for the initial conditions and to reduce the risk of false convergence, showing that stable parameters are obtained without imposing arbitrary restrictions.","Gimeno, Ricardo; Nave, Juan M",2009,10.1016/j.csda.2008.10.030,None,proquest
75b384fd743b0d2a,A hybrid EMD-AR model for nonlinear and non-stationary wave forecasting,"Accurate wave forecasting with a couple of hours of warning time offers improvements in safety for maritime operation-related activities. Autoregressive (AR) model is an efficient and highly adaptive approach for wave forecasting. However, it is based on linear and stationary theory and hence has limitations in forecasting nonlinear and non-stationary waves. Inspired by the capability of empirical mode decomposition (EMD) technique in handling nonlinear and non-stationary signals, this paper describes the development of a hybrid EMD-AR model for nonlinear and non-stationary wave forecasting. The EMDAR model was developed by coupling an AR model with the EMD technique. Nonlinearity and non-stationarity were overcome by decomposing the wave time series into several simple components for which the AR model is suitable. The EMD-AR model was implemented using measured significant wave height data from the National Data Buoy Center, USA. Prediction results from various locations consistently show that the hybrid EMD-AR model is superior to the AR model. This demonstrates that the EMD technique is effective in processing nonlinear and non-stationary waves.","Wen-yang, Duan; Li-min, Huang; Yang, Han; De-tai, Huang",2016,10.1631/jzus.a1500164,None,proquest
288e3fa01209bb59,A hybrid approach for portfolio construction: Combing two‐stage ensemble forecasting model with portfolio optimization,"Combining the stock prediction with portfolio optimization can improve the performance of the portfolio construction. In this article, we propose a novel portfolio construction approach by utilizing a two‐stage ensemble model to forecast stock prices and combining the forecasting results with the portfolio optimization. To be specific, there are two phases in the approach: stock prediction and portfolio optimization. The stock prediction has two stages. In the first stage, three neural networks, that is, multilayer perceptron (MLP), gated recurrent unit (GRU), and long short‐term memory (LSTM) are used to integrate the forecasting results of four individual models, that is, LSTM, GRU, deep multilayer perceptron (DMLP), and random forest (RF). In the second stage, the time‐varying weight ordinary least square model (OLS) is utilized to combine the first‐stage forecasting results to obtain the ultimate forecasting results, and then the stocks having a better potential return on investment are chosen. In the portfolio optimization, a diversified mean‐variance with forecasting model named DMVF is proposed, in which an average predictive error term is considered to obtain excess returns, and a 2‐norm cost function is introduced to diversify the portfolio. Using the historical data from the Shanghai stock exchange as the study sample, the results of the experiments indicate the DMVF model with two‐stage ensemble prediction outperforms benchmarks in terms of return and return‐risk characteristics.","Chen, Wei; Liu, Zinuo; Jia, Lifen",2024,10.1111/coin.12617,None,proquest
06dce1e4e6c88e26,A hybrid convolutional neural network with long short-term memory for statistical arbitrage,"We propose a CNN-LSTM deep learning model, which has been trained to classify profitable from unprofitable spread sequences of cointegrated stocks, for a large scale market backtest ranging from January 1991 to December 2017. We show that the proposed model can achieve high levels of accuracy and successfully derives features from the market data. We formalize and implement a trading strategy based on the model output which generates significant risk-adjusted excess returns that are orthogonal to market risks. The generated out-of-sample Sharpe ratio and alpha coefficient significantly outperform the reference model, which is based on a standard deviation rule, even after accounting for transaction costs.","Eggebrecht, P.; Luetkebohmert, E.",2023,10.1080/14697688.2023.2181707,None,wos
28c83a8bcd39edfd,A hybrid model integrating artificial neural network with multiple GARCH-type models and EWMA for performing the optimal volatility forecasting of market risk factors,"The 2008 financial crisis has highlighted the lack of precision in the market risk metrics that financial institutions must report to the regulator. The use of Machine Learning techniques in stock markets and the treasury (Front–Back Office) of financial institutions is a key tool for optimizing its own resources, internal processes and risk measures. We propose a hybrid methodology to better capture the volatility of market risk factors with Value-at-risk models in periods of stress, but also in periods of stability compared to traditional metrics. This hybrid model uses different types of artificial neural networks and traditional metrics to perform the optimal forecast of volatility applied to the main market risk nodes of the Spanish stock market. We use data from the following main market risk factors: returns on Santander Bank shares, the Spanish Stock Market Index, Euro/Dollar exchange rates and the index that measures the total return performance of a funded long credit position in the on-the-run iTraxx Crossover 5-Year-Index. Our contribution is a hybrid model that combines correct sequential pattern learnings with an improved prediction performance in the volatility of market risk factors. Our findings show that the Support Vector Machine and the Long-Short-Term Memory Model present better prediction results in all factors in the stability periods. Therefore, the proposed method is promising for application in risk management systems. © 2023 Elsevier B.V., All rights reserved.","Pérez-Hernández, F.; Arévalo-De-Pablos, A.; Camacho-Miñano, M.-D.-M.",2024,10.1016/j.eswa.2023.122896,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180444826&doi=10.1016%2Fj.eswa.2023.122896&partnerID=40&md5=35a9237d6bbd45c16c7e293c52c5f62e,scopus
942cfdbce2efdb9a,A hybrid novel framework for flood disaster risk control in developing countries based on smart prediction systems and prioritized scenarios,"A Decision Support System (DSS) is a highly efficient concept for managing complex objects in nature or human-made phenomena. The main purpose of the present study is related to designing and implementation of real-time monitoring, prediction, and control system for flood disaster management as a DSS. Likewise, the problem of statement in the research is correlated to implementation of a system for different climates of Iran as a unique flood control system. For the first time, this study coupled hydrological data mining, Machine Learning (ML), and Multi-Criteria Decision Making (MCDM) as smart alarm and prevention systems. Likewise, it created the platform for conditional management of floods in Iran's different clusters of climates. According to the KMeans clustering system, which determines homogeneity of the hydrology of a specific region, Iran's rainfall is heterogeneous with 0.61 score, which is approved high efficiency of clustering in a vast country such as Iran with four seasons and different climates. In contrast, the relation of rainfall and flood disaster is evaluated by Nearest Neighbors Classification (NNC), Stochastic Gradient Descent (SGD), Gaussian Process Classifier (GPC), and Neural Network (NN) algorithms which have an acceptable correlation coefficient with a mean of 0.7. The machine learning outputs demonstrated that based on valid data existence problems in developing countries, just with verified precipitation records, the flood disaster can be estimated with high efficiency. In the following, Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) method as a Game Theory (GT) technique ranked the preventive flood damages strategies through three social (Se 1), environmental (Se 2), and economic (Se 3) crises scenarios. The solutions of flood disaster management are collected from literature review, and the opinion approves them of 9 senior experts who are retired from a high level of water resource management positions of Iran. The outcomes of the TOPSIS method proved that National announcement for public-institutional participation for rapid response and funding (G1-2), Establishment of delay structures to increase flood focus time to give the animals in the ecosystem the opportunity to escape to the upstream points and to preserve the habitat (G 2–8), and Granting free national financial resources by government agencies in order to rebuild sensitive infrastructure such as railways, hospitals, schools, etc. to the provincial treasury (G3-10) are selected as the best solution of flood management in Social, Environmental, and Economic crises, respectively. Finally, the collected data are categorized in Social, Environmental, and Economic aspects as three dimensions of Sustainable Development Goals (SDGs) and ranked based on the opinion of 32 experts in the five provinces of present case studies.","Akbarian, Hadi; Gheibi, Mohammad https://orcid.org/0000-0003-1987-5790; Hajiaghaei-Keshteli, Mostafa https://orcid.org/0000-0002-9988-2626; Rahmani, Mojtaba https://orcid.org/0000-0002-7979-5904",2022,10.1016/j.jenvman.2022.114939,None,proquest
dc813e77ef51d733,A long-short dual-mode knowledge distillation framework for empirical asset pricing models in digital financial networks,"The continuous combination of digital network technology and traditional financial services has given birth to digital financial networks, which explore massive economic data under the AI-driven models to achieve intelligent connections among financial institutions, markets, transactions, and instruments. Empirical asset pricing is a challenging task in financial analysis, which has attracted research attention. However, existing studies only focus on tackling the challenges of equity risk premium in the single stock market. Considering multiple economic linkages between the two countries, the transaction history of the US stock market as empirical knowledge is a powerful supplement to improve the prediction of equity risk premium in the China market. In this paper, we aim to fully leverage the prior information in two stock markets for empirical asset pricing models. Due to the rich financial domain knowledge, there may be various characteristic signals that partially overlap in different periods. To address these issues, we propose a framework based on long-short dual-mode knowledge distillation, termed as LSDM-KD, which incorporates US and China stock market models, and a shared characteristic signals model. The method effectively understands the relationships between assets and market behaviour, reducing reliance on expensive correlation databases and professional knowledge. Extensive experiments conducted on US and China stock market datasets demonstrate that our LSDM-KD can significantly improve the performance of empirical asset pricing.","Yi, Yuanyuan; Cui, Kai; Xu, Minghua; Yi, Lingzhi; Yi, Kun; Zhou, Xinlei; Liu, Shenghao; Zhou, Gefei",2024,10.1080/09540091.2024.2306970,None,proquest
a2db605c319cbc0f,A machine learning based asset pricing factor model comparison on anomaly portfolios,"We frame asset pricing linear factor models in a machine learning context and consider related comparisons of their predictive performance against ordinary least squares linear regression over a dataset of anomaly portfolios. Specific regression models involved in the comparison include regularized linear, support vector machines, neural networks, and tree based models among others. Performance metrics are presented on a model, portfolio group, and sequential basis, and the strongest predictors are recommended as alternative techniques for the problem of excess return forecasting.","Fang, Ming; Taylor, Stephen",2021,10.1016/j.econlet.2021.109919,None,proquest
0c90039e02d794b5,A machine learning portfolio allocation system for IPOs in Korean markets using GA-rough set theory,"An initial public offering (IPO) is a type of public offering in which a company's shares are sold to institutional and individual investors. While the majority of studies on IPOs have focused on the efficiency of raising capital and price adequacy in IPOs, studies on portfolio allocation strategies for IPO stocks are relatively scarce. This paper develops a machine learning investment strategy for IPO stocks based on rough set theory and a genetic algorithm (GA-rough set theory). To reduce issues of information asymmetry, we use nonfinancial data that are publicly available to individual and institutional investors in the IPO process. Based on the rule sets generated from the training sets, we conduct 120 tests with various conditions involving the target days and the partition of the training and testing sets, and we find excess returns of the constructed portfolios compared to the benchmark portfolios. Investors in IPO stocks can formulate more efficient investment strategies using our system. In this sense, the system developed in this paper contributes to the efficiency of financial markets and helps achieve sustained economic growth. © 2021 Elsevier B.V., All rights reserved.","Kim, J.; Shin, S.; Lee, H.S.; Oh, K.J.",2019,10.3390/su11236803,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076596987&doi=10.3390%2Fsu11236803&partnerID=40&md5=13ff053dd22d5b0ae2fb194bf4f0dde3,scopus
7e93c19fba02abbf,A measure of Turkey's sovereign and banking sector credit risk: Asset swap spreads,"The existence of the credit derivatives written on the eurobonds such as credit default swaps or asset swaps allows policymakers and investors to monitor the evolvement of credit risk. However, these instruments are mostly available in advanced economies, whereas the market for credit derivatives in emerging market countries, including Turkey, is limited in terms of liquidity and maturity. In this regard, this study aims to construct a proxy for the credit risk of the Turkish Treasury and banking sector in international markets by calculating asset swap spread for US dollar-denominated fixed coupon eurobonds, which requires a robust estimation of the relevant yield curves. The study firstly presents the estimation of the sovereign and banking sector yield curves and then constructs a synthetic asset swap structure to obtain embedded credit risk premia in the eurobond curves. Our findings show that the proposed credit risk indicator is vastly correlated with credit default swap premium. In addition to this, estimated eurobond curves are also useful for monitoring borrowing cost dynamics of the Turkish Treasury and banking sector in international markets. (C) 2021 Production and hosting by Elsevier B.V. on behalf of Central Bank of The Republic of Turkey.","Kucuksarac, Doruk; Kazdal, Abdullah; Korkmaz, Halil Ibrahim; Onay, Yigit",2021,10.1016/j.cbrev.2021.05.001,None,wos
d87bd95a61553bb9,A micro data approach to the identification of credit crunches,"This article presents a micro data approach to the identification of credit crunches. Using a survey among German firms which regularly queries the firms' assessment of the current willingness of banks to extend credit, we estimate the probability of a restrictive loan supply policy by time taking into account the creditworthiness of borrowers. Creditworthiness is approximated by firm-specific factors, e.g. the firms' assessment of their current business situation and their business expectations. After controlling for the return on the banks' risk-free investment alternative, which is also likely to affect the supply of loans, we derive a credit crunch indicator, which measures that part of the shift in the loan supply that is neither explained by firm-specific factors nor by the opportunity costs of providing risky loans. © 2012 Taylor and Francis Group, LLC. © 2012 Elsevier B.V., All rights reserved.","Rottmann, H.; Wollmershäuser, T.",2013,10.1080/00036846.2012.665604,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859759058&doi=10.1080%2F00036846.2012.665604&partnerID=40&md5=f41992b5331f82089cdad15d091c36c9,scopus
8fa57119b90ec594,A model-selection approach to assessing the information in the term structure using linear models and artificial neural networks,"We take a model-selection approach to the question of whether forward-interest rates are useful in predicting future spot rates, using a variety of out-of-sample forecast-based model-selection criteria—forecast mean squared error, forecast direction accuracy, and forecast-based trading- system profitability. We also examine the usefulness of a class of novel prediction models called artificial neural networks and investigate the issue of appropriate window sizes for rolling-window- based prediction methods. Results indicate that the premium of the forward rate over the spot rate helps to predict the sign of future changes in the interest rate. Furthermore, model selection based on an in-sample Schwarz information criterion (SIC) does not appear to be a reliable guide to out-of-sample performance in the case of short-term interest rates. Thus, the in-sample SIC apparently fails to offer a convenient shortcut to true out-of-sample performance measures. © 1995 Taylor & Francis Group, LLC. © 2016 Elsevier B.V., All rights reserved.","Swanson, N.R.; White, H.",1995,10.1080/07350015.1995.10524600,https://www.scopus.com/inward/record.uri?eid=2-s2.0-21844518145&doi=10.1080%2F07350015.1995.10524600&partnerID=40&md5=3fb7e2b2653ab9f836c914042957ea00,scopus
6a29710c06b32305,A neural-network analyzer for mortality forecast,"This article proposes a neural-network approach to predict and simulate human mortality rates. This semi-parametric model is capable to detect and duplicate non-linearities observed in the evolution of log-forces of mortality. The method proceeds in two steps. During the first stage, a neural-network-based generalization of the principal component analysis summarizes the information carried by the surface of log-mortality rates in a small number of latent factors. In the second step, these latent factors are forecast with an econometric model. The term structure of log-forces of mortality is next reconstructed by an inverse transformation. The neural analyzer is adjusted to French, UK and US mortality rates, over the period 1946-2000 and validated with data from 2001 to 2014. Numerical experiments reveal that the neural approach has an excellent predictive power, compared to the Lee-Carter model with and without cohort effects. © 2018 Elsevier B.V., All rights reserved.","Hainaut, D.",2018,10.1017/asb.2017.45,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041374415&doi=10.1017%2Fasb.2017.45&partnerID=40&md5=95ab9244ef17be4d7010801baa451b81,scopus
34e04b398fa30214,A new game-theoretical multi-objective evolutionary approach for cash-in-transit vehicle routing problem with time windows (A Real life Case),"Cash transfer from a central treasury to bank branches, which is with high security, is one of the crucial processes in the banking system. In this paper, a new multi-objective game theory-based model is developed to increase the security of cash-in-transit. For this purpose and in order to reduce the transportation costs, a bi-objective vehicle routing problem with time window is developed where the risk of transfers (including armed robbers attack and theft) and the distance traveled by vehicles are minimized. In order to better estimate the robber's performance, the probability of robber's ambush is calculated by the game theory approach, in such a way that a two-player, zero-sum game is played between the robber and the cash carrier. The probability of theft success is also estimated in the proposed approach through a multiple-criteria decision-making and in order to be further representative of real-life situations. A periodic review is also added to the proposed model to increase the cash transport security in which the previously used links would enjoy less chance of choosing in the current period. Moreover, a new multi-objective hybrid genetic algorithm incorporated with a number of new heuristics and operators is developed to tackle the proposed model. The efficiency and effectiveness of the algorithm are examined through several standard data sets, and the results indicate the effectiveness of the proposed solution algorithm. The wide applicability of our proposed approach in real-life situations is examined with a real case study as well. © 2020 Elsevier B.V., All rights reserved.","Ghannadpour, S.F.; Zandiyeh, F.",2020,10.1016/j.asoc.2020.106378,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084485975&doi=10.1016%2Fj.asoc.2020.106378&partnerID=40&md5=b4c39d98a905071477c2592dc16d0b26,scopus
54789511d2462a92,A new optimisation approach to assess optimal asset allocation in European non-life insurance companies,"This study addresses the allocation of optimal assets in non-life insurance companies' environment with a new vision. Most previous studies are based on the maximisation of the utility function. However, in this paper, we focused on the maximisation of technical efficiency (TE). In order to validate our objective, we select a set of European non-life insurance companies (ENIC) over the period 2008-2014. In the first step, we estimate the production function characterised by the directional output distance function (DODF). In the second one, we use two metaheuristics (PSO and GA) to assess the optimal asset allocation (OAA). The empirical results show that the proportion allocated to the 'alternative investment with high-risk high-return' (AIhh) is on average lower than those found in previous studies. However, the percentage allocated to the 'risk-free assets' (RFA) is on average different from zero. This can be explained by the attention given to the competitiveness, survival and long-term profitability respecting the maximisation of TE. So, any insurance company must give more attention to the presence of different stakeholders and resolve the conflicts of interest between them.","Jarraya, Bilel",2021,10.1504/ijads.2021.116004,None,proquest
6094397f5a71118e,A new portmanteau test for predictive regression models with possible embedded endogeneity,"In the widely used predictive regression model, any possible serial correlation in innovations leads to estimation bias and statistical inference distortions. Hence, it is important to pretest the existence of such serial correlation. Nevertheless, in the presence of embedded endogeneity, which is a common problem in the predictive regression setting, traditional serial correlation tests such as Box-Pierce (BP) and Ljung-Box (LB) tests are found to perform poorly. Motivated by this, we develop a new portmanteau test in this article as a pretest for serial correlation in predictive regression under possible embedded endogeneity. This test is based on the sample splitting idea and the jackknife empirical likelihood method. The asymptotic distribution of the proposed test has been derived, and the Monte Carlo simulations confirm good finite sample performances. As an illustration, we apply our proposed test in pretesting the serial correlation in predictive regression, where financial variables are used to predict the excess return of S&P 500.","Rao, Yao; Fan, Yawen; Ao, Huimin; Liu, Xiaohui",2024,10.1111/jtsa.12745,None,wos
ef406ebb291c642e,A non-Gaussian Ornstein-Uhlenbeck model for pricing wind power futures,"The recent introduction of wind power futures written on the German wind power production index has brought with it new interesting challenges in terms of modelling and pricing. Some particularities of this product are the strong seasonal component embedded in the underlying, the fact that the wind index is bounded from both above and below and also that the futures are settled against a synthetically generated spot index. Here, we consider the non-Gaussian Ornstein-Uhlenbeck type processes proposed by Barndorff-Nielsen and Shephard in the context of modelling the wind power production index. We discuss the properties of the model and estimation of the model parameters. Further, the model allows for an analytical formula for pricing wind power futures. We provide an empirical study, where the model is calibrated to 37 years of German wind power production index that is synthetically generated assuming a constant level of installed capacity. Also, based on 1 year of observed prices for wind power futures with different delivery periods, we study the market price of risk. Generally, we find a negative risk premium whose magnitude decreases as the length of the delivery period increases. To further demonstrate the benefits of our proposed model, we address the pricing of European options written on wind power futures, which can be achieved through Fourier techniques.","Benth, Fred Espen; Pircalabu, Anca",2018,10.1080/1350486x.2018.1438904,None,proquest
6667b3b24aa57a2c,A non-knotty inflation risk premium model,"In this article, I estimate the inflation risk premium (IRP) using a low-dimensional arbitrage-free dynamic model through a novel strategy. Instead of modelling the nominal and real yields jointly, I make assumptions about the short-term inflation rate. More specifically, I assume it follows a Gaussian process. This framework has a closed-form expression for IRP. Since inflation yields are not observed, to estimate the model parameters I approximate them by the break-even inflation rate. This approximation works well because the convexity correction is very small. I find that the estimated IRP is strongly correlated with those obtained using surveys or more complex models. Therefore, I provide an easier procedure to obtain IRP, avoiding the cumbersome estimation process of high-order models.","Machado Vicente, José Valentim",2023,10.1080/00036846.2022.2111023,None,proquest
eb966554fc893e72,A non-linear dynamic model of the variance risk premium,We propose a new class of non-linear diffusion processes for modeling financial markets data. Our non-linear diffusions are obtained as transformations of affine processes. We show that asset-pricing and estimation is possible and likelihood estimation is straightforward. We estimate a non-linear diffusion model for the VIX index under both the objective measure and the risk-neutral measure where the latter is obtained from futures prices. We find evidence of significant non-linearity under both measures. We define the difference between the P and Q drift as a measure of the variance risk premium and show that it has strong predictive power for stock returns.,"Eraker, Bjørn; Wang, Jiakou",2015,10.1016/j.jeconom.2015.02.038,None,proquest
f1226e3a19defec0,A nonlinear Bayesian filtering approach to estimating adaptive market efficiency,"The adaptive market hypothesis (AMII) supplies a convincing motivation for why market efficiency should not be regarded as a stable property in time. This paper explores a Bayesian methodology for estimating weak-form market efficiency under the AMII using a test of evolving efficiency (TEE). More precisely, a generalized TEE (GTEE) approach is proposed in which the conditional first moment of a time series is assumed to be a nonlinear function of its conditional second moment, i.e., a nonlinear feedback term is present in the conditional mean equation. We then discuss a maximum likelihood estimation procedure for the resulting nonlinear model using the state-space approach and extended Kalman filtering. This methodology is used to estimate time-varying, weak-form market efficiency in four, specifically chosen, markets over a time period that includes the global financial crisis of 2007/2008.","Kulikov, Gennady Yu.; Taylor, David R.; Kulikova, Maria V.",2019,10.1515/rnam-2019-0003,None,wos
cf9f62572b2d6956,A nonlinear general equilibrium model of the term structure of interest rates,"We derive and test an alternative closed-form general equilibrium model of the term structure within the Cox, Ingersoll, and Ross theoretical framework in which yields are nonlinear functions of the risk-free rate. We show that equilibrium bond prices and the risk-free rate are not always inversely related and that bond risk need not be strictly increasing in maturity. Using Hansen's generalized method of moments to obtain parameter estimates, this nonlinear model outperforms the Cox, Ingersoll, and Ross square root model in describing actual Treasury bill yields for the 1964-1986 period. © 1989. © 2014 Elsevier B.V., All rights reserved.","Longstaff, F.A.",1989,10.1016/0304-405x(89)90056-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0344971168&doi=10.1016%2F0304-405X%2889%2990056-1&partnerID=40&md5=da37d31c6e2c300ffdead5c18b5cebfc,scopus
0f09673e5b50a64e,A nonlinear model of the term structure of interest rates,"We present an economically motivated two-factor term structure model that generalizes existing stochastic mean term structure models. By allowing a certain parameter to acquire dynamical behavior we extend the two-factor model to obtain a nonlinear three-factor model that is shown, in a deterministic version, to be equivalent to the Lorenz system of differential equations. With reasonable parameter values the model exhibits chaotic behavior. It successfully emulates certain properties of interest rates including cyclical behavior on a business cycle time scale. Estimation and pricing issues are discussed. Standard PCA techniques used to estimate HJM type models are observed to be equivalent to dimensional estimates commonly applied to 'spatial data' in nonlinear systems analysis. It is concluded that techniques commonly used in the analysis of nonlinear systems may be directly applicable to interest rate models, offering new insights in the development of these models. Tests of nonlinearity in interest rate behavior may need to focus on long cycle times. © 2018 Elsevier B.V., All rights reserved.","Tice, J.; Webber, N.",1997,10.1111/1467-9965.00030,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0040657144&doi=10.1111%2F1467-9965.00030&partnerID=40&md5=c5199d870e62e9702b95e8b3acf50c5b,scopus
ead79b7f6088813e,A nonparametric data mining approach for risk prediction in car insurance: A case study from the Montenegrin market,"For prediction of risk in car insurance we used the nonparametric data mining techniques such as clustering, support vector regression (SVR) and kernel logistic regression (KLR). The goal of these techniques is to classify risk and predict claim size based on data, thus helping the insurer to assess the risk and calculate actual premiums. We proved that used data mining techniques can predict claim sizes and their occurrence, based on the case study data, with better accuracy than the standard methods. This represents the basis for calculation of net risk premium. Also, the article discusses advantages of data mining methods compared to standard methods for risk assessment in car insurance, as well as the specificities of the obtained results due to small insurance market, such as Montenegrin. © 2017 Elsevier B.V., All rights reserved.","Kašćelan, V.; Kašćelan, L.; Novovic Buric, M.N.",2016,10.1080/1331677x.2016.1175729,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009997041&doi=10.1080%2F1331677X.2016.1175729&partnerID=40&md5=7f3a8611352e0c53d21f363d9b290835,scopus
836eb9e2c451e5c5,A nonparametric estimator for the covariance function of functional data,"Many quantities of interest in economics and finance can be represented as partially observed functional data. Examples include structural business cycle estimation, implied volatility smile, the yield curve. Having embedded these quantities into continuous random curves, estimation of the covariance function is needed to extract factors, perform dimensionality reduction, and conduct inference on the factor scores. A series expansion for the covariance function is considered. Under summability restrictions on the absolute values of the coefficients in the series expansion, an estimation procedure that is resilient to overfitting is proposed. Under certain conditions, the rate of consistency for the resulting estimator achieves the minimax rate, allowing the observations to be weakly dependent. When the domain of the functional data is K(>1) dimensional, the absolute summability restriction of the coefficients avoids the so called curse of dimensionality. As an application, a Box-Pierce statistic to test independence of partially observed functional data is derived. Simulation results and an empirical investigation of the efficiency of the Eurodollar futures contracts on the Chicago Mercantile Exchange are included. © 2015 Elsevier B.V., All rights reserved.","Sancetta, A.",2014,10.1017/s0266466614000784,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949744301&doi=10.1017%2FS0266466614000784&partnerID=40&md5=235cb272bbf1152c694cf9b9858eb102,scopus
c3bd093b2f2483fb,"A note on the impact of the United States federal budget deficit on the intermediate-term interest rate, 1960-94","There is an extensive literature investigating the impact of federal budget deficits in the US on interest rate yields. This literature focuses almost entirely on short-term rates (under one year to maturity) and long-term rates (ten years or more to maturity). However, almost no attention has been directed at intermediate-term interest rate yields, that is yields on bonds maturing more than one year and less than ten years in the future. Also, this literature essentially ignores the second half of the 1980s and the 1990s. Accordingly, this note empirically investigates the impact of budget deficits in the US on the interest rate yield on three-year US Treasury notes for the period 1960 through the end of 1994. Based on OLS and IV estimates, two of which include net international capital inflows, it is found that budget deficits do raise intermediate-term rates, which may strengthen arguments that budget deficits lead to crowding out. © 2017 Elsevier B.V., All rights reserved.","Cebula, R.J.",1997,10.1080/758530655,https://www.scopus.com/inward/record.uri?eid=2-s2.0-5844313200&doi=10.1080%2F758530655&partnerID=40&md5=c8a1fd58caaa68d76aef4209a45c7f92,scopus
904ecc8c3e03282b,A novel approach to Predict WTI crude spot oil price: LSTM-based feature extraction with Xgboost Regressor,"This paper presents a novel model based on LSTM to predict future prices of WTI crude oil. The WTI price forecasting utilizes data on spot gold price, US 10-year bond yield, global economic activity, and US dollar index from January 1986 to May 2023. The model's performance is assessed using measures such as MAE, MSE, RMSE, MAPE, and R2 metrics. The results generated by the proposed new model are compared to those of the existing machine and deep learning methods, and it is observed that the new model performs better than the existing models in all statistical tests. The study further examined the decision-making processes of the model using SHAP analysis and assessed the individual contribution of each feature to the model's predictions. The correlation between the US Dollar Index and Gold prices and WTI crude oil prices is evident. The SHAP research has demonstrated that the model effectively captures complicated economic linkages and enhances the accuracy of forecasts. The results of this study enhance the development of models that are capable of predicting results, even in times of significant instability, such as economic crises. Using sophisticated data analytics and AI methods would improve the efficiency of energy market oversight. © 2024 Elsevier B.V., All rights reserved.","Simsek, A.I.; Bulut, E.; Gur, Y.E.; Gültekin Tarla, E.",2024,10.1016/j.energy.2024.133102,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203530978&doi=10.1016%2Fj.energy.2024.133102&partnerID=40&md5=d9cf0148dabf51a718ea46ae4789d646,scopus
d63fadf05abeb819,A novel decomposition integration model for power coal price forecasting,"Accurate prediction of steam coal prices is important for stabilizing the coal trading market and formulating coal use strategies scientifically. In this paper, a new decomposition integration model (VADM) is proposed to predict coal prices by combining the variational modal decomposition (VMD), arithmetic optimization algorithm (AOA), deep temporal convolutional network (DeepTCN), and mean impact value algorithm (MIV). Firstly, the AOA optimization algorithm is used to improve the VMD, AOA-VMD was obtained. It is used to decompose the steam coal price series. Then, the decomposed subsequences are predicted for the prediction of steam coal prices by using DeepTCN. Finally, the MIV algorithm is applied to analyze the impact of different factors on the price of steam coal. It is found that: the steam coal price sub-series decomposed by AOA-VMD are smoother and more linear compared with the original series; the errors in forecasting steam coal prices are significantly reduced after considering newly proposed factors, interest rates, such as the overnight Shanghai interbank offered rate and the six-month treasury bond yield; the MAPE, MASE and SMAPE of the VADM model all show different degrees of decline compared with benchmark models. The forecasting effect of VADM model is better than the benchmark model in terms of stability and accuracy, and can be used for short-term forecasting of coal prices. © 2023 Elsevier B.V., All rights reserved.","Wu, S.; Xia, G.; Liu, L.",2023,10.1016/j.resourpol.2022.103259,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145655492&doi=10.1016%2Fj.resourpol.2022.103259&partnerID=40&md5=227fae8fd06a4f24cab6e80ac1324e5c,scopus
99ce25282168bdae,A novel term structure stochastic model with adaptive correlation for trend analysis,"The prediction of underlying price continues to draw extensive attention in academic research. Based on a review of the advantages and disadvantages of different volatility models, we find that the Heston stochastic volatility model with an adaptive correlation coefficient is most suitable for analysing the Hong Kong options market. We subsequently propose a model-free implied volatility term structure formulated using options with different strikes and different maturities. The implied volatility is calculated by integrating the option price and strike price from the current time to the expiry date. Discrete points of term structure data are used to fit a term structure curve. Finally, we use the model-free implied volatility term structure as the long-run mean level of the Heston model to fully exploit the information content contained in the implied volatility term structure. We simulate the distribution of the underlying asset price based on the Heston model and constant elasticity of variance (CEV) model. The adaptive correlation Heston model provides superior results in terms of one-day-ahead prediction performance and the 79-day distribution of the underlying asset price compared with the CEV model. © 2021 Elsevier B.V., All rights reserved.","Du, J.; Lai, S.; Lai, K.K.; Zhou, S.",2021,10.1002/ijfe.2076,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089457308&doi=10.1002%2Fijfe.2076&partnerID=40&md5=0bd330a48e1a5066903ad5d67db64590,scopus
08245f9f6de44032,"A novel, rule-based technical pattern identification mechanism: Identifying and evaluating saucers and resistant levels in the US stock market","This paper has two main purposes. The first one is the development of a rigorous rule-based mechanism for identifying the rounding bottoms (also known as saucers) pattern and resistant levels. The design of this model is based solely on principles of technical analysis, and thus making it a proper system for evaluating the efficacy of the aforementioned technical trading patterns. The second aim of this paper is measuring the predictive power of buy-signals generated by these technical patterns. Empirical results obtained from seven US tech stocks indicate that simple resistant levels outperform saucers patterns. Furthermore, positive statistical significant excess returns are being generated only in first sub-periods of examination. These returns decline or even vanish as the experiment proceeds to recent years. Our findings are aligned with the results reported by various former studies. The proposed identification mechanism can be used as a component of an expert system to assist academic community in evaluating trading strategies where technical patterns are embedded. (C) 2011 Elsevier Ltd. All rights reserved.","Zapranis, Achilleas; Tsinaslanidis, Prodromos E.",2012,10.1016/j.eswa.2011.11.079,None,wos
75bf2bd602a393cf,A parametric factor model of the term structure of mortality,"The prototypical Lee–Carter mortality model is characterized by a single common time factor that loads differently across age groups. In this paper, we propose a parametric factor model for the term structure of mortality where multiple factors are designed to influence the age groups differently via parametric loading functions. We identify four different factors: a factor common for all age groups, factors for infant and adult mortality, and a factor for the “accident hump” that primarily affects mortality of relatively young adults and late teenagers. Since the factors are identified via restrictions on the loading functions, the factors are not designed to be orthogonal but can be dependent and can possibly cointegrate when the factors have unit roots. We suggest two estimation procedures similar to the estimation of the dynamic Nelson–Siegel term structure model. First, a two-step nonlinear least squares procedure based on cross-section regressions together with a separate model to estimate the dynamics of the factors. Second, we suggest a fully specified model estimated by maximum likelihood via the Kalman filter recursions after the model is put on state space form. We demonstrate the methodology for US and French mortality data. We find that the model provides a good fit of the relevant factors and, in a forecast comparison with a range of benchmark models, it is found that, especially for longer horizons, variants of the parametric factor model have excellent forecast performance. © 2019 Elsevier B.V., All rights reserved.","Haldrup, N.; Rosenskjold, C.P.T.",2019,10.3390/econometrics7010009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069524567&doi=10.3390%2Feconometrics7010009&partnerID=40&md5=25f49d47a3a9211b38babce433e20709,scopus
27cdb45de7c97a28,A parametric nonlinear model of term structure dynamics,"Recent nonparametric estimation studies pioneered by Aït-Sahalia document that the diffusion of the short rate is similar to the parametric function, r1.5, estimated by Chan et al., whereas the drift is substantially nonlinear in the short rate. These empirical properties call into question the efficacy of the existing affine term structure models and beg for alternative models which admit the observed behavior. This article presents such a model. Our model delivers closed-form solutions for bond prices and a concave relationship between the interest rate and the yields. We show that in empirical analyses, our model outperforms the one-factor affine models in both time-series as well as cross-sectional tests. © 2016 Elsevier B.V., All rights reserved.","Ahn, D.-H.; Gao, B.",1999,10.1093/rfs/12.4.721,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033410115&doi=10.1093%2Frfs%2F12.4.721&partnerID=40&md5=1194eb86b455e11c6bbe2174bdea396f,scopus
5e7b8c965b7c7487,A penalized two-pass regression to predict stock returns with time-varying risk premia,"We develop a penalized two-pass regression with time-varying factor loadings. The penalization in the first pass enforces sparsity for the time-variation drivers while also maintaining compatibility with the no-arbitrage restrictions by regularizing appropriate groups of coefficients. The second pass delivers risk premia estimates to predict equity excess returns. Our Monte Carlo results and our empirical results on a large cross-sectional data set of US individual stocks show that penalization without grouping can yield to nearly all estimated time-varying models violating the no-arbitrage restrictions. Moreover, our results demonstrate that the proposed method reduces the prediction errors compared to a penalized approach without appropriate grouping or a time-invariant factor model. © 2023 Elsevier B.V., All rights reserved.","Bakalli, G.; Guerrier, S.; Scaillet, O.",2023,10.1016/j.jeconom.2022.12.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146471323&doi=10.1016%2Fj.jeconom.2022.12.004&partnerID=40&md5=3da444594d98ac1c1f1f5ec4e044ee7b,scopus
8008c2b14a83b123,A prediction model for the secure issuance scale of Chinese local government bonds,"PurposeThe purpose of this paper is to calculate the local guaranteed fiscal revenue with the local fiscal revenue of 31 provinces, and predict their guaranteed fiscal revenue in 2018 with the artificial neural network (ANN).Design/methodology/approachThe principal components analysis (PCA), particle swarm optimization (PSO) and extreme learning machine (ELM) model was designed to produce the inputs of KMV model. Then the KMV model was used for obtaining the default probabilities under different issuance scales. Data were collected from Wind Database. MATLAB 2018b and SPSS 22 were used in the field of modeling and results analysis.FindingsThis study’s findings show that PCA–PSO–ELM proposed in this research has the highest accuracy in terms of the prediction compared with ELM, back propagation neural network and auto regression. And PCA–PSO–ELM–KMV model can calculate the secure issuance scale of local government bonds effectively.Practical implicationsThe sustainability forecast in this study can help local governments effectively control the scale of debt issuance, strengthen the budget management of local debt and establish the corresponding risk warning mechanism, which could make local governments maintain good credit ratings.Originality/valueThis study sheds new light on helping local governments avoid financial risks effectively, and it is conducive to establish a debt repayment reserve system for local governments and the proper arrangement for stock debt.","Bowen, Jia; Wu, Jiaying; Du, Juan; Ji, Yun; Zhu, Lina",2021,10.1108/k-10-2019-0699,None,proquest
5c800f91626cad4f,A production function analysis of commercial dairy farms in the Highlands of Eritrea using ridge regression,"This study presents a production function analysis of fresh milk production in the Highlands of Eritrea, where most dairy farmers in Eritrea are located. To ensure representative production functions, this region was divided into three relatively homogenous study areas, namely Central Zone, Mendefera and Dekemhare. Most data for the study were collected in a survey of 120 respondents using a structured questionnaire. To obviate the problem of multicollinearity among explanatory variables, ridge regression was used to estimate milk production functions for each study area. Production elasticities of variable inputs, marginal products (MPx), values of marginal products (VMPx), marginal rates of input substitution (MRS) and leastcost combinations of purchased concentrates and forage were estimated for the three regions. The VMPs of all inputs for Central Zone dairy farmer respondents were estimated to be greater than their input prices, implying that the resources were under-utilized from a profit-maximising perspective (i.e. where VMPx = Px). However, respondents in Mendefera and Dekemhare used concentrates in excess of optimum levels (i.e. VMPx < Px). Analysis of the least-cost combination of purchased concentrates and forage suggests that dairy farmer respondents were also not allocating these resources on a minimum-cost basis. However, the profit maximizing and least-cost criteria assume perfect knowledge, a risk-free environment and competitive markets. Improved information, farmer training and better infrastructure (roads and telecommunications) to promote competitive markets could help to enhance resource allocation decisions by dairy producers. © 2013 Elsevier B.V., All rights reserved.","Ghebremariam, W.K.; Ortmann, G.F.; Nsahlai, I.V.",2006,10.1080/03031853.2006.9523745,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887173439&doi=10.1080%2F03031853.2006.9523745&partnerID=40&md5=47b75f133719f2c7f00f4ae602b92772,scopus
9cd458c37bf8d94f,A quasi-maximum likelihood method for estimating the parameters of multivariate diffusions,"A quasi-maximum likelihood procedure for estimating the parameters of multi-dimensional diffusions is developed in which the transitional density is a multivariate Gaussian density with first and second moments approximating the true moments of the unknown density. For affine drift and diffusion functions, the moments are exactly those of the true transitional density and for nonlinear drift and diffusion functions the approximation is extremely good and is as effective as alternative methods based on likelihood approximations. The estimation procedure generalises to models with latent factors. A conditioning procedure is developed that allows parameter estimation in the absence of proxies. (C) 2012 Elsevier B.V. All rights reserved.","Hurn, A. S.; Lindsay, K. A.; McClelland, A. J.",2013,10.1016/j.jeconom.2012.09.002,None,wos
78921cc3f5612ddb,A re-evaluation of the term spread as a leading indicator,"Forecasting the evolution path of macroeconomic variables has always been of keen interest to policy makers and market participants. A common tool used in the relevant forecasting literature is the term spread of Treasury bond yields. In this paper, we decompose the term spread into an expectation and a term premium component and evaluate the informational content of each component in forecasting the GDP growth rate and inflation in various forecasting horizons. In doing so, we employ alternative decomposition procedures and introduce the Support Vector Regression (SVR) methodology from the field of Machine Learning, coupled with linear and non-linear kernels as a novel forecasting method in the field. Using rolling windows in producing point and conditional probability distribution forecasts we find that neither the term spread, nor its decomposition components possess the ability to accurately forecast output growth or inflation. Our findings extend the existing literature, since they are focused on an explicit out-of-sample evaluation in contrast to most existing empirical studies that produce only in-sample forecasts. To strengthen our findings, we also consider several control variables suggested in the relevant literature without significant qualitative differences from the initial results. The main innovation of our approach stems from the use of the non-linear Support Vectors Machine methodology, that is introduced for the first time in this line of research for forecasting out-of-sample. © 2019 Elsevier B.V., All rights reserved.","Plakandaras, V.; Gogas, P.; Papadimitriou, T.; Gupta, R.",2019,10.1016/j.iref.2019.07.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071871619&doi=10.1016%2Fj.iref.2019.07.002&partnerID=40&md5=b1cce98b67b0a1da2aeeb00c223c6d90,scopus
d572e7def663dd99,A risk index model for uncertain portfolio selection with background risk,"This study proposes a new uncertain risk index model with background risk and presents its deterministic equivalents. The security returns and background asset returns are assumed as uncertain variables and estimated by experts. To discuss the influence of background risk on investment decisions, we compare the proposed model with a variant without background risk and find that the portfolio with background risk produces an equal or lower return than the one without background risk. The effects of changes in the standard deviation of background asset and the risk-free interest rate on optimal expected value are discussed. Two different risk measures for portfolio optimization model with background risk are compared, viz., the risk index model with background risk is further compared with the mean chance model with background risk. The nonlinear risk index model is solved by using a genetic algorithm. The efficiency of the genetic algorithm and the applications of the proposed models are illustrated through numerical experiments.","Huang, Xiaoxia; Jiang, Guowei; Gupta, Pankaj; Mehlawat, Mukesh Kumar",2021,10.1016/j.cor.2021.105331,None,proquest
d8fcd5f38dfdb0e4,A semiparametric approach for modelling multivariate nonlinear time series,"AbstractIn this article, a semiparametric time‐varying nonlinear vector autoregressive (NVAR) model is proposed to model nonlinear vector time series data. We consider a combination of parametric and nonparametric estimation approaches to estimate the NVAR function for both independent and dependent errors. We use the multivariate Taylor series expansion of the link function up to the second order which has a parametric framework as a representation of the nonlinear vector regression function. After the unknown parameters are estimated by the maximum likelihood estimation procedure, the obtained NVAR function is adjusted by a nonparametric diagonal matrix, where the proposed adjusted matrix is estimated by the nonparametric kernel estimator. The asymptotic consistency properties of the proposed estimators are established. Simulation studies are conducted to evaluate the performance of the proposed semiparametric method. A real data example on short‐run interest rates and long‐run interest rates of United States Treasury securities is analyzed to demonstrate the application of the proposed approach. The Canadian Journal of Statistics 47: 668–687; 2019 © 2019 Statistical Society of Canada","Samadi, S Yaser; Hajebi, Mahtab; Rahman Farnoosh",2019,10.1002/cjs.11518,None,proquest
a1edbbf24e2cefe3,A semiparametric model for the systematic factors of portfolio credit risk premia,"The aim of this paper is to investigate the empirical relationship between daily fluctuations in the risk premium for holding a large diversified credit portfolio, which we approximate by a benchmark credit index, and some tradeable market factors which capture systematic risk. The analysis is based on an adaptive nonparametric modelling approach which allows for the data-driven estimation of the nonlinear dynamic relationship between portfolio credit risk premia and their hypothetical components. Our main finding is that the empirical weights of the systematic factors display sudden jumps during market crises and a less intense time-dependent behaviour during normal market conditions. In addition, we find that during market crises the directions of the empirical relationships are often inconsistent with ordinary economic intuition, as they are influenced by the specific circumstances of financial markets distress. All rights reserved, Elsevier","Giammarino, Flavia; Barrieu, P",2009,10.1016/j.jempfin.2009.05.001,None,proquest
1cef435702aea303,A simple test of momentum in foreign exchange markets,"This study proposes a new method for testing for the presence of momentum in nominal exchange rates, using a probabilistic approach. We illustrate our methodology estimating a binary response model using information on local currency / US dollar exchange rates of eight emerging economies. After controlling for important variables affecting the behavior of exchange rates in the short-run, we show evidence of exchange rate inertia; in other words, we find that exchange rate momentum is a common feature in this group of emerging economies, and thus foreign exchange traders participating in these markets are able to make excess returns by following technical analysis strategies. We find that the presence of momentum is asymmetric, being stronger in moments of currency depreciation than of appreciation. This behavior may be associated with central bank intervention. © 2014 Elsevier B.V., All rights reserved.","García-Suaza, A.F.; Gomez-Gonzalez, J.E.",2012,10.2753/ree1540-496x480504,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905081033&doi=10.2753%2FREE1540-496X480504&partnerID=40&md5=8cc1c4643bfbf2bfda3ee8a5e71341b6,scopus
1a908a762a3a843e,A sparse enhanced indexation model with chance and cardinality constraints,"Enhanced indexation aims to construct a portfolio to track and outperform the performance of a stock market index by employing both passive and active fund management strategies. This paper presents a novel sparse enhanced indexation model with chance and cardinality constraints. Its goal is to maximize the excess return that can be attained with a high probability, while the model allows a fund manger to limit the number of stocks in the portfolio and specify the maximum tolerable relative market risk. In particular, we model the asset returns as random variables and estimate their probability distributions by the Capital Asset Pricing Model or Fama-French 3-factor model, and measure the relative market risk with the coherent semideviation risk function. We deal with the chance constraint via distributionally robust approach and present a second-order cone programming and a semidefinite programming safe approximation for the model under different sets of potential distribution functions. A hybrid genetic algorithm is applied to solve the NP-hard problem. Numerical tests are conducted on the real data sets from major international stock markets, including USA, UK, Germany and China. The results demonstrate that the proposed model and the method can efficiently solve the enhanced indexation problem and our approach can generally achieve sparse tracking portfolios with good out-of-sample excess returns and high robustness.","Xu, Fengmin; Wang, Meihua; Yu-Hong, Dai; Xu, Dachuan",2018,10.1007/s10898-017-0513-1,None,proquest
6eebbf4ce06ab357,A static replication approach for callable interest rate derivatives: mathematical foundations and efficient estimation of SIMM–MVA,"The computation of credit risk measures such as exposure and Credit Value Adjustments (CVA) requires the simulation of future portfolio prices. Recent metrics, such as dynamic Initial Margin (IM) and Margin Value Adjustments (MVA) additionally require the simulation of future conditional sensitivities. For portfolios with non-linear instruments that do not admit closed-form valuation formulas, this poses a significant computational challenge. This problem is addressed by proposing a static replication algorithm for interest rate options with early-exercise features under an affine term-structure model. Under the appropriate conditions, we can find an equivalent portfolio of vanilla options that replicate these products. Specifically, we decompose the product into a portfolio of European swaptions. The weights and strikes of the portfolio are obtained by regressing the target option value with interpretable, feed-forward neural networks. Once an equivalent portfolio of European swaptions is determined, we can leverage on closed-form expressions to obtain the conditional prices and sensitivities, which serve as an input to exposure and SIMM-driven MVA quantification. For a consistent forward sensitivity estimation, this involves the differentiation of the portfolio-weights. The accuracy and convergence of the method is demonstrated through several representative numerical examples, benchmarked against the established least-square Monte Carlo method. © 2024 Elsevier B.V., All rights reserved.","Hoencamp, J.H.; Jain, S.; Kandhai, B.D.",2024,10.1080/14697688.2024.2312523,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185970359&doi=10.1080%2F14697688.2024.2312523&partnerID=40&md5=e658f86122a239c289b291ec3fe810ae,scopus
dce460c566e97ef3,A stock selection algorithm hybridizing grey wolf optimizer and support vector regression,"Artificial intelligence remarkably facilitates quantitative investment. A latest intelligent search algorithm, grey wolf optimizer, is well integrated with support vector regression machine to obtain the optimal portfolio. The performance of the hybrid algorithm is empirically investigated through transactional and financial data from stock markets of America and China. The experimental results indicate that (i) the proposed algorithm is able to stably achieve excess returns; (ii) compared with genetic algorithm, particle swarm optimization, gravitational search algorithm and harmony search, the enhanced grey wolf optimizer significantly boots the predictive performance of support vector regression machine; (iii) the proposed algorithm can achieve the better profitability and the higher reliability in Chinese A-share market.","Liu, Meng; Luo, Kaiping; Zhang, Junhuan; Chen, Shengli",2021,10.1016/j.eswa.2021.115078,None,proquest
c39f49834e05eba2,A structural econometric model of price discrimination in the French mortgage lending industry,"We propose a model of discrimination in the market for mortgages. The model explains accepted loan applications and simultaneously determines loan sizes and interest rates. A competitive and a discriminating monopoly version of the model are proposed. Offered interest rates and loan sizes are a function of observable borrower characteristics. The competitive model rests on a marginal condition, reflecting contract optimality, to which a zero-profit condition is added. In contrast, the discriminating monopoly maximizes profits under a borrower participation constraint, reflecting the availability of a rental market as an outside option. Each version of the model is a bivariate, nonlinear model, and is estimated by standard maximum likelihood methods. The data used for estimation is a sample of clients of a French network of mortgage lenders. We show the presence of ""social discrimination"" in the data, the loan conditions depending not only on the borrower's wage and down payment, but also on the borrower's occupational status. Abnormally high risk premia in the competitive version of the model suggest the presence of market power, justifying an attempt at estimating its monopolistic version. The discriminating monopoly model estimates show that the borrowers' price-elasticity of demand for housing varies with occupational status, and is inversely related with the lender's interest rate markups. This confirms that the lender exploits structural differences in the preferences to discriminate, as predicted by standard theories. © 2003 Elsevier B.V. All rights reserved. © 2008 Elsevier B.V., All rights reserved.","Gary-Bobo, R.J.; Larribeau, S.",2004,10.1016/j.ijindorg.2003.07.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0346962780&doi=10.1016%2Fj.ijindorg.2003.07.002&partnerID=40&md5=10ab500b28b6878f5d1a556e8a2af88b,scopus
232cb3a8af099a6f,A study of cross-industry return predictability in the Chinese stock market,"We investigate cross-industry return predictability for the Shanghai and Shenzhen stock exchanges, by constructing 6- and 26- industry portfolios. The dominance of retail investors in these markets, in conjunction with the gradual diffusion of information hypothesis provide the theoretical background that allows us to employ machine learning methods to test for cross-industry predictability. We find that Oil, Telecommunications and Finance industry portfolio returns are significant predictors of other industries. Our out-of-sample forecasting exercise shows that the OLS post-LASSO estimation outperforms a variety of benchmarks and a long–short trading strategy generates an average annual excess return of 13%. © 2022 Elsevier B.V., All rights reserved.","Ellington, M.; Stamatogiannis, M.P.; Zheng, Y.",2022,10.1016/j.irfa.2022.102249,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133314818&doi=10.1016%2Fj.irfa.2022.102249&partnerID=40&md5=f14048287a71b77d7730f86dffa447ab,scopus
7cf9c33d0b85ec48,A tale of two coffees? Analysing interaction and futures market efficiency,"PurposeThe purpose of this paper is to assess the informational efficiency of Arabica (other milds) and Robusta coffee futures markets in terms of predicting future coffee spot prices.Design/methodology/approachFutures market efficiency is associated with the existence of a long-run equilibrium relationship between spot and future prices such that coffee futures prices are unbiased predictors of future spot prices. This study applies unit root testing to daily data for futures-spot price differentials. A range of maturities for futures contracts are considered, and the study also uses a recursive approach to consider time variation in futures market efficiency.FindingsThe other milds and Robusta futures prices tend to be unbiased predictors for their own respective spot prices. The paper further finds that other milds and Robusta futures prices are unbiased predictors of the respective Robusta and other milds spot prices. Recursive estimation suggests that the futures market efficiency associated with these cross cases has increased, though with no clear link to the implementation of the 2007 International Coffee Agreement.Originality/valueThe paper draws new insights into futures market efficiency by examining the two key types of coffee and analyses the potential interactions between them. Hitherto, no attention has been paid to futures contracts of the Robusta variety. The employment of unit root testing of spot futures coffee price differentials can be viewed as more stringent than an approach based on non-cointegration testing.","Holmes, Mark J; Otero, Jesús",2020,10.1108/sef-09-2019-0356,None,proquest
2aa4181eccce522e,A three-level nested portfolio optimization model with position allocation,"Existing portfolio optimization models cannot well capture the real position allocation requirement, leading to limited impact in practice. To overcome this challenge, we propose a three-level nested portfolio optimization model with position allocation. Within this model, the inner and middle levels collaboratively determine the optimal portfolio, while the outer level focuses on optimizing the holding proportion of each stock in the optimal portfolio. Compared with existing models with portfolio weights, the proposed model imposes the position allocation constraint that precisely characterizes the limitations on holding each stock. This constraint is crucial for investors to obey securities trading regulations involving position limitations and to mitigate the potential impact of market risks. To address the nonlinear and nonconvex nature of the novel model, we develop an intelligent optimization algorithm by effectively hybridizing the support vector regression and the enhanced grey wolf optimizer. We comprehensively evaluate its performance using eight metrics, including accumulative return, annual return, Sharpe ratio, maximum drawdown, absolute and relative win ratios, predictive precision and accuracy. The experimental results indicate that (i) the proposed model can achieve more excess returns than those stock selection models not considering position allocation, especially for the large-cap stocks; (ii) compared with other state-of-the-art meta-heuristics, the enhanced grey wolf optimizer can yield better portfolio in conjunction with the support vector regression; (iii) in the context of the Chinese A-share stock market, specific financial indicators such as return on equity, inventory turnover rate, net income growth rate, and debt-to-equity ratio should be given greater consideration compared to other financial metrics. © 2024 Elsevier B.V., All rights reserved.","Ma, J.; Yang, K.; Luo, K.; Li, P.; He, A.",2024,10.1016/j.asoc.2024.112054,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200798925&doi=10.1016%2Fj.asoc.2024.112054&partnerID=40&md5=7b415008c2dba69527715c4c4b28a8f5,scopus
5b8c2d356e2c63ed,A threshold model for the spread,"Using annual data from two panels, one of 11 Eurozone countries and another of 31 OECD countries, we estimate a two-regime log-linear as well as a nonlinear model for the spread as a function of macroeconomic and quality-of-institutions variables. The two regimes, a high-spread and a low-spread regime, are distinguished by using a threshold, in accordance with the perceived ""fair""value of the spread as a reference point. Our results suggest that government-bond spreads are regime-dependent, as most of the regression coefficients of the determinants of the spread are larger (in absolute value) in the high-spread regime than in the low-spread regime. That is, an improvement in the macroeconomic environment (e.g., lower unemployment, lower inflation, lower growth of the debt-to-GDP ratio, less macroeconomic uncertainty, higher growth of real GDP), and/or an improvement in the quality of institutions (e.g., less corruption) reduce the spread facing a country (by enhancing its creditworthiness) to a greater extent in high-spread situations than in low-spread situations. A possible explanation is that the demand for and the supply of loans are inelastic at higher than ""fair""interest rates and elastic at lower rates. © 2023 Elsevier B.V., All rights reserved.","Hatzinikolaou, D.; Sarigiannidis, G.",2023,10.1515/snde-2020-0007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131677707&doi=10.1515%2Fsnde-2020-0007&partnerID=40&md5=13323e4318936c45cc6c14e3e03f58f0,scopus
8fb4c155f69de669,A transformer-based model for default prediction in mid-cap corporate markets,"In this paper, we study mid-cap companies, i.e. publicly traded companies with less than US$10 billion in market capitalisation. Using a large dataset of US mid-cap companies observed over 30 years, we look to predict the default probability term structure over the short to medium term and understand which data sources (i.e. fundamental, market or pricing data) contribute most to the default risk. Whereas existing methods typically require that data from different time periods are first aggregated and turned into cross-sectional features, we frame the problem as a multi-label panel data classification problem. To tackle it, we then employ transformer models, a state-of-the-art deep learning model emanating from the natural language processing domain. To make this approach suitable to the given credit risk setting, we use a loss function for multi-label classification, to deal with the term structure, and propose a multi-channel architecture with differential training that allows the model to use all input data efficiently. Our results show that the proposed deep learning architecture produces superior performance, resulting in a sizeable improvement in AUC (Area Under the receiver operating characteristic Curve) over traditional models. In order to interpret the model, we also demonstrate how to produce an importance ranking for the different data sources and their temporal relationships, using a Shapley approach for feature groups. © 2023 Elsevier B.V., All rights reserved.","Korangi, K.; Mues, C.; Bravo, C.",2023,10.1016/j.ejor.2022.10.032,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143550150&doi=10.1016%2Fj.ejor.2022.10.032&partnerID=40&md5=629f9a4355496d502e429e10a7d84773,scopus
7fe86973d0f86928,A two-regime threshold model with conditional skewed Student t distributions for stock returns,"This paper proposes a two-regime threshold model for the conditional distribution of stock returns in which returns follow a distinct skewed Student t distribution within each regime: the model allows capturing time variation in the conditional distribution of returns, as well as higher order moments. An application of the model to daily U.S. stock returns illustrates the advantages of the proposed model in comparison to alternative specifications: the model performs well in terms of in-sample fit; it more accurately estimates the conditional volatility; and it produces useful risk assessment as measured by the term structure of value at risk. (C) 2014 Elsevier B.V. All rights reserved.","Massacci, Daniele",2014,10.1016/j.econmod.2014.07.032,None,wos
313f1f457f10765c,ABS inflows to the United States and the global financial crisis,"Relative to the 'global savings glut' (GSG) hypothesis, we present a more complete picture of how capital flows contributed to the financial crisis, drawing attention to the sizable inflows from European investors into U.S. private-label asset-backed securities (ABS), including mortgage-backed securities and other structured investment products. The GSG hypothesis argues that the surge in capital inflows from emerging market economies to the United States led to significant declines in long-term interest rates in the United States and other industrial economies. In turn, these lower interest rates, when combined with both innovations and deficiencies of the U.S. credit market, are believed to have contributed to the U.S. housing bubble and to the buildup in financial vulnerabilities that led to the financial crisis. Because the GSG countries for the most part restricted their U.S. purchases to Treasuries and Agency debt, their provision of savings to ultimately risky subprime mortgage borrowers was necessarily indirect, pushing down yields on safe assets and increasing the appetite for alternative investments on the part of other investors. Foreign acquisitions of private-label ABS, primarily by Europeans, provided credit more directly and, by adding to domestic demand for these securities, contributed to the decline in their spreads over Treasury yields. Through a combination of empirical estimation and model simulation, we verify that both GSG inflows into Treasuries and Agencies, as well as European acquisitions of ABS, played a role in contributing to downward pressures on U.S. interest rates. All rights reserved, Elsevier","Bertaut, C; DeMarco, L P; Kamin, S; Tryon, R",2012,10.1016/j.jinteco.2012.04.001,None,proquest
09e7ecec6845d7fd,ADAPTIVE LASSO-TYPE ESTIMATION FOR MULTIVARIATE DIFFUSION PROCESSES,"The least absolute shrinkage and selection operator (LASSO) is a widely used statistical methodology for simultaneous estimation and variable selection. It is a shrinkage estimation method that allows one to select parsimonious models. In other words, this method estimates the redundant parameters as zero in the large samples and reduces variance of estimates. In recent years, many authors analyzed this technique from a theoretical and applied point of view. We introduce and study the adaptive LASSO problem for discretely observed multivariate diffusion processes. We prove oracle properties and also derive the asymptotic distribution of the LASSO estimator. This is a nontrivial extension of previous results by Wang and Leng (2007, Journal of the American Statistical Association, 102(479), 1039-1048) on LASSO estimation because of different rates of convergence of the estimators in the drift and diffusion coefficients. We perform simulations and real data analysis to provide some evidence on the applicability of this method.","De Gregorio, Alessandro; Iacus, Stefano M.",2012,10.1017/s0266466611000806,None,wos
9b03378b08a85c98,AI-Driven Dental Caries Management Strategies: From Clinical Practice to Professional Education and Public Self Care,"Dental caries is one of the most prevalent chronic diseases among both children and adults, despite being largely preventable. This condition has significant negative impacts on human health and imposes a substantial economic burden. In recent years, scientists and dentists have increasingly started to utilize artificial intelligence (AI), particularly machine learning, to improve the efficiency of dental caries management. This study aims to provide an overview of the current knowledge about the AI-enabled approaches for dental caries management within the framework of personalized patient care. Generally, AI works as a promising tool that can be used by both dental professionals and patients. For dental professionals, it predicts the risk of dental caries by analyzing dental caries risk and protective factors, enabling to formulate personalized preventive measures. AI, especially those based on machine learning and deep learning, can also analyze images to detect signs of dental caries, assist in developing treatment plans, and help to make a risk assessment for pulp exposure during treatment. AI-powered tools can also be used to train dental students through simulations and virtual case studies, allowing them to practice and refine their clinical skills in a risk-free environment. Additionally, AI tracks brushing patterns and provides feedback to improve oral hygiene practices of the patients and the general population, thereby improving their understanding and compliance. This capability of AI can inform future research and the development of new strategies for dental caries management and control.Dental caries is one of the most prevalent chronic diseases among both children and adults, despite being largely preventable. This condition has significant negative impacts on human health and imposes a substantial economic burden. In recent years, scientists and dentists have increasingly started to utilize artificial intelligence (AI), particularly machine learning, to improve the efficiency of dental caries management. This study aims to provide an overview of the current knowledge about the AI-enabled approaches for dental caries management within the framework of personalized patient care. Generally, AI works as a promising tool that can be used by both dental professionals and patients. For dental professionals, it predicts the risk of dental caries by analyzing dental caries risk and protective factors, enabling to formulate personalized preventive measures. AI, especially those based on machine learning and deep learning, can also analyze images to detect signs of dental caries, assist in developing treatment plans, and help to make a risk assessment for pulp exposure during treatment. AI-powered tools can also be used to train dental students through simulations and virtual case studies, allowing them to practice and refine their clinical skills in a risk-free environment. Additionally, AI tracks brushing patterns and provides feedback to improve oral hygiene practices of the patients and the general population, thereby improving their understanding and compliance. This capability of AI can inform future research and the development of new strategies for dental caries management and control.","Liang, Yutong; Li, Dongling; Deng, Dongmei; Chu, Chun Hung; Mei, May Lei; Li, Yunpeng; Yu, Na; He, Jinzhi; Cheng, Lei",2025,10.1016/j.identj.2025.04.007,None,proquest
412fc4122a3c36ac,AN ARBITRAGE-FREE ESTIMATE OF PREPAYMENT OPTION PRICES IN FIXED-RATE GNMA MORTGAGE-BACKED SECURITIES,"In an efficient market, the no-arbitrage condition implies that the price difference between any two assets must be the market value of ail differences in their cash flows. We use this logic to deduce the price of the prepayment option embedded in fixed-rate Government National Mortgage Association (GNMA) mortgage-backed securities. The option price equals the difference between an observed GNMA price and the cost of a synthetic, nonprepayable GNMA constructed from the least expensive portfolio of Treasury securities that exactly replicates the promised GNMA cash flow stream, assuming prepayment is precluded. We regress the option prices on variables found significant in previous prepayment studies, finding that five key regressors explain more than 90% of the prepayment option value in pooled time-series cross-sectional analysis. We also show that the time value of the prepayment option calculated by our method displays a pattern similar to that produced by the Black-Scholes (1973) option pricing model. An additional empirical result is the existence of negative option prices and negative time value of the option prices. We attribute these to the fact that homeowners sometimes exercise their prepayment options when they are out-of-the-money, and to refinancing transaction costs. Our method is independent of assumptions regarding interest rate processes and the homeowner's prepayment behavior, and it provides a benchmark for testing theoretical prepayment models.","RONN, EI; RUBINSTEIN, PD; PAN, FS",1995,10.1111/1540-6229.00655,None,wos
efd37e8cd45dfd0b,ASYMMETRICAL EFFECTS OF REAL EFFECTIVE EXCHANGE RATE OF KUNA ON FOREIGN TRADE BALANCE IN REPUBLIC OF CROATIA,"This paper strives on giving an answer to whether assymetrical effects of real effective ex-change rate of kuna, J-curve and Marshall-Lerner condition exist in the Republic of Croatia. Price rigidity, capacity constraints, and adjustment costs are just some reasons why depreciation and appreciation of the real effective exchange rate do not necessarily have equally strong effect of the opposite direction on net exports. Econometric estimation by nonlinear autoregressive distributed lags method (NARDL) enables separation of positive (appreciation) from negative (depreciation) changes in the real effective exchange rate, showing that its changes do not affect net exports sym-metrically and linearly. Existence of J-curve and positive impact of the real effective exchange rate depreciation on trade balance (Marshall-Lerner condition) are confirmed, while appreciation has no significant effect. Results obtained in this paper point out that Croatia `s foreign trade bal-ance can be improved by real effective exchange rate depreciation. However, this should be taken with caution given that nominal depreciation leads to growing external indebtedness of domestic economy, affects expectations, especially those related to inflation, import prices (therefore domes-tic prices), risk premium, returns on financial assets, and there are indications that depreciation of nominal and real exchange rate in Croatia have a contractional effect on domestic economic activity, so costs of such a policy may far outweigh the benefits of currency weakening. In addition, research limitations include low variability of the real effective exchange rate (which might make it difficult to obtain econometric relevant estimates), the problem of choosing representative exchange rate measures, and the choice of proxy variables for domestic and foreign income. In the observed period, appreciation and depreciation of the real effective exchange rate were relatively mild, so the conclusions are not necessarily valid in the case of a sudden and large fluctuations in it. Compared to previous research, asymmetric effect of the real effective exchange rate is confirmed on the bal-ance of goods and services (not only balance of goods), and possible causes of nonlinearity in the response of foreign trade balance to changes in the real effective exchange rate are discussed.","Novinc, Filip",2023,10.32910/ep.74.4.4,None,wos
b4063c4f4752f0dc,Accounting for correlations: Price adjustments in unit-cost construction contracts,"Macroeconomic conditions, such as commodity prices, affect the cost of construction projects. In a volatile market environment, contractors respond by adding premiums in bid prices when highway agencies pass such risk on to contractors by using fixed-price contracts. How much of the commodity cost risk should highway agencies pass on to contractors? More specifically, this study aims to investigate the impact of correlation among commodity prices on optimal risk-hedging decisions. A weighted least-squares regression model is used to estimate the risk premium; both univariate time series and vector time series models are estimated and applied to simulate changes in commodity prices over time, including the effect of correlation. A genetic algorithm is used as a solution approach to a multiobjective optimization problem (cost versus future risk exposure). In a case study, project cost risks are shown to be significantly underestimated if correlations are not accounted for. © 2023 Elsevier B.V., All rights reserved.","Zhou, X.; Damnjanović, I.D.",2012,10.3141/2297-17,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026873013&doi=10.3141%2F2297-17&partnerID=40&md5=e436631f1dfbd0d2ab0a0a1fa0768ffd,scopus
b773c6aa167ceace,"Accounting-based probabilistic prediction of ROE, the residual income valuation model and the assessment of mispricing in the Swedish stock market","Using Swedish stock market data, this study investigates whether an investment strategy based on publicly available accounting information can generate abnormal investment returns. The strategy involves two steps. First, an accounting-based probabilistic prediction model of changes in the medium-term book return on owners' equity (ROE) is estimated. Second, market expectations of changes in medium-term ROE are assessed through observed stock prices and the residual income valuation model. Stock market positions over thirty-six-month holding periods are taken when the accounting-based predictions of ROE and the market expectations differ. Over the period 1983-2003, the investment strategy generated values of Jensen's alpha corresponding to an average monthly excess return for a hedge position of up to 0.8% for a sample of manufacturing companies. In the main this hedge return was caused by strong positive returns to the long positions, and additional analyses show that the returns appear to have been affected by a positive market sentiment bias (i.e. positive ROE surprises being associated with stronger price reactions than negative ROE surprises) making out-of-sample inferences somewhat dubious. Furthermore, most of the investment returns accrued over holding periods up to around 1995, with no indications of market mispricing over the last third (1995-2003) of the investment period. The empirical results are consistent with market investors having become more sophisticated in their use of publicly available accounting information over time. Reprinted by permission of Blackwell Publishers","Skogsvik, Kenth; Skogsvik, Stina",2010,10.1111/j.1467-6281.2010.00325.x,None,proquest
1b82b421c3fc63d2,Adaptive Algorithm for Selecting the Optimal Trading Strategy Based on Reinforcement Learning for Managing a Hedge Fund,"In hedge fund management, the ability to dynamically select optimal trading strategies is paramount for maximizing returns and mitigating risk. This paper presents a pioneering approach that integrates Reinforcement Learning (RL), specifically the Proximal Policy Optimization (PPO) algorithm, into the strategy selection process for hedge fund management. Our model considers a diverse array of strategies, including Mean Reversion and Momentum, and employs advanced mathematical frameworks to evaluate and select the strategies. By leveraging RL, our algorithm learns to adaptively adjusts strategy allocations to maximize cumulative returns while adhering to the risk constraints. We demonstrate the effectiveness of our approach through extensive backtesting and validation of historical market data, demonstrating superior performance compared to traditional methods. Nevertheless, it is important to understand that training trading agents requires a considerable amount of time, computing power, and other resources. Our research offers a novel perspective on leveraging RL to optimize strategy selection in hedge fund management and underscores the potential of AI-driven approaches in finance.",B. Belyakov; D. Sizykh,2024,10.1109/access.2024.3515039,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10792442,ieeexplore
d0e42311667ba639,Adaptive investment strategies for periodic environments,"In this paper, an adaptive investment strategy for environments with periodic returns on investment is presented. In this approach, an investment model is considered where the agent decides at every time step the proportion of wealth to invest in a risky asset, keeping the rest of the budget in a risk-free asset. Every investment is evaluated in the market via stylized return on investment function (RoI), which is modeled by a stochastic process with unknown periodicities and levels of noise. For comparison, two reference strategies are presented which represent the case of agents with zero knowledge and complete knowledge of the dynamics of the returns. An investment strategy based on technical analysis to forecast the next return is also considered. To account for the performance of the different strategies, some computer experiments are performed to calculate the average budget that can be obtained with them over a certain number of time steps. To assure fair comparisons, the parameters of each strategy are first tuned for budget maximization. Afterward, the performance of these strategies is compared for RoI's with different periodicities and levels of noise. © 2008 World Scientific Publishing Company. © 2017 Elsevier B.V., All rights reserved.","Navarro-Barrientos, J.-E.",2008,10.1142/s0219525908001933,https://www.scopus.com/inward/record.uri?eid=2-s2.0-57249084067&doi=10.1142%2FS0219525908001933&partnerID=40&md5=b1124d852118bf010bb60d870df16faa,scopus
8527a7f34521c485,Adaptive online portfolio selection with transaction costs,"As an application of machine learning techniques in financial fields, online portfolio selection has been attracting great attention from practitioners and researchers, which makes timely sequential decision making available when market information is constantly updated. For online portfolio selection, transaction costs incurred by changes of investment proportions on risky assets have a significant impact on the investment strategy and the return in long-term investment horizon. However, in many online portfolio selection studies, transaction costs are usually neglected in the decision making process. In this paper, we consider an adaptive online portfolio selection problem with transaction costs. We first propose an adaptive online moving average method (AOLMA) to predict the future returns of risky assets by incorporating an adaptive decaying factor into the moving average method, which improves the accuracy of return prediction. The net profit maximization model (NPM) is then constructed where transaction costs are considered in each decision making process. The adaptive online net profit maximization algorithm (AOLNPM) is designed to maximize the cumulative return by integrating AOLMA and NPM together. Numerical experiments show that AOLNPM dominates several state-of-the-art online portfolio selection algorithms in terms of various performance metrics, i.e., cumulative return, mean excess return, Sharpe ratio, Information ratio and Calmar ratio. © 2021 Elsevier B.V., All rights reserved.","Guo, S.; Gu, J.-W.; Ching, W.-K.",2021,10.1016/j.ejor.2021.03.023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103966971&doi=10.1016%2Fj.ejor.2021.03.023&partnerID=40&md5=09d67e9398dc3fb20f5fd921477927f0,scopus
e869368c4a48ce29,Advanced Option Pricing and Hedging with Q-Learning: Performance Evaluation of the QLBS Algorithm,"This article provides an overview of the recent advances in reinforcement learning (RL) for pricing and hedging financial instruments, focusing on the Q-Learning Black-Scholes (QLBS) approach. This RL approach bridges the traditional Black-Scholes-Merton (BSM) model with artificial intelligence algorithms, enabling option pricing and hedging in a completely model-free and data-driven way. The study evaluates the QLBS algorithm’s performance across different state variables and scenarios for a European put option, showing that the model accurately estimates option prices under varying volatility levels, hedging frequencies, risk-free rates, and when dividends are included. Additionally, the QLBS method shows robust performance in pricing and hedging options across different moneyness levels, with more pronounced deviations from the BSM model for deep in-the-money options under higher risk aversion. The empirical analysis also incorporates proportional transaction costs using at-the-money S&P 500 call options, revealing varied implications for profitability and risk mitigation, influenced by the choice of state variables. The article sheds light on the QLBS model’s explainability by providing detailed technical notes and a numerical example, and additionally, the results reveal its high practical relevance. © 2025 Elsevier B.V., All rights reserved.","Stoiljkovic, Z.",2025,10.3905/jod.2025.1.222,https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000150110&doi=10.3905%2Fjod.2025.1.222&partnerID=40&md5=2458dcaba8e795c55b724323df4ee627,scopus
5b1ba23957effe90,Affine arbitrage-free yield net models with application to the euro debt crisis,"We develop a parsimonious class of affine arbitrage-free yield net models for consistent bond pricing across maturities and issuers of different risk levels. Containing a core curve and multiple peripheral curves, the yield net is spanned by three layers of factors: base factors spanning all curves, and common and individual spread factors. Under the arbitrage-free assumption, we prove a parsimonious solution to the risk-neutral process that guarantees joint identification of parameters and latent states. By using a Bayesian estimation method with a marginal Metropolis–Hastings algorithm and specification tests based on MCMC output, we apply the model to weekly treasury yields of Germany, Italy, Spain, and Greece from 2009 to 2016. The results show that the extracted common credit risk is a level factor in spread, and market liquidity risk is a slope factor. Further, the net structure helps reconstruct the Greek yield curve even with only its 10-year yield available throughout the sample. © 2022 Elsevier B.V., All rights reserved.","Hong, Z.; Niu, L.; Zhang, C.",2022,10.1016/j.jeconom.2021.11.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122961603&doi=10.1016%2Fj.jeconom.2021.11.002&partnerID=40&md5=01905cc014d6ef66741afd239638d650,scopus
373e6a23aca8fb8c,"Air pollution, weather factors, and realized volatility forecasts of agricultural commodity futures","This study investigates the potential effects of environmental factors on fluctuations in agricultural commodity futures markets, by constructing a new category of daily exogenous predictors related to air pollution, weather, climate change, and investor attention. The empirical results from out‐of‐sample analyses suggest that the heterogeneous autoregressive (HAR) model incorporating all these exogenous predictors is more likely to outperform other HAR‐type models. Additionally, economic evaluations demonstrate the superior performance of models incorporating investors' attention to climate change or extreme weather as predictors. While not all exogenous predictors are equally important for volatility forecasts, adopting appropriate variable selection methods to handle different sets of exogenous predictors can lead to better performance than the HAR benchmark. With the inclusion of air pollution or weather factors in the HAR model, a portfolio with an annualized average excess return of 16.2068% or a Sharpe ratio of 10.0431 can be achieved for the wheat futures, respectively.","Luo, Jiawen; Zhang, Qun",2024,10.1002/fut.22467,None,proquest
b812228bd22517dc,Algorithmic estimation of risk factors in financial markets with stochastic drift,"We assume a financial market governed by a diffusion process reverting to a stochastic mean which is itself governed by an unobservable ergodic diffusion, similar to those observed in electricity and other energy markets. We develop a moment method algorithm for the estimation of the parameters of both the observable process and the unobservable stochastic mean. Our approach is contrasted with other methods for parameter estimation of partially observed diffusions, and applications to the modelling of interest rates and commodity prices are discussed. (C) 2010 Elsevier Ltd. All rights reserved.","Hernandez, Janko; Saunders, David; Seco, Luis",2012,10.1016/j.cor.2010.09.007,None,wos
302c792dbf247468,Algorithmic sign prediction and covariate selection across eleven international stock markets,"I investigate whether an expert system can be used for profitable long-term asset management. The trading strategy of the expert system needs to be based on market predictions. To this end, I generate binary predictions of the market returns by using statistical and machine-learning algorithms. The methods used include logistic regressions, regularized logistic regressions and similarity-based classification. I test the methods in a contemporary data set involving data from eleven developed markets. Both statistical and economic significance of the results are considered. As an ensemble, the results seem to indicate that there is some degree of mild predictability in the stock markets. Some of the results obtained are highly significant in the economic sense, featuring annualized excess returns of 3.1% (France), 2.9% (Netherlands) and 0.8% (United States). However, statistically significant results are seldom found. Consequently, the results do not completely invalidate the efficient-market hypothesis. © 2018 Elsevier B.V., All rights reserved.","Karhunen, M.",2019,10.1016/j.eswa.2018.07.061,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051398572&doi=10.1016%2Fj.eswa.2018.07.061&partnerID=40&md5=553aa1a74c3267f31622ea2e5a12741a,scopus
3dfd04e4fb4d9063,Alternative Maximum Likelihood Estimation of Structural Vector Autoregressive Models Partially Identified with Short-Run Restrictions,"This paper presents an alternative maximum likelihood estimation method for partially identified vector autoregressive models. This method might be especially useful to handle very large systems of variables by reducing the dimension of the likelihood space. As an application, we consider an open economy model to investigate the effects of monetary policy on exchange rates and term structures. We find that exchange rates tend to overshoot and term structures have hump-shaped responses to monetary policy shocks. © 2013 The Ohio State University. © 2013 Elsevier B.V., All rights reserved.","Jang, K.",2013,10.1111/jmcb.12010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875290853&doi=10.1111%2Fjmcb.12010&partnerID=40&md5=21a61ad4420d752980f482e339f0aa47,scopus
bcfa69807c6a868e,Alternative models for stock price dynamics,"This paper evaluates the role of various volatility specifications, such as multiple stochastic volatility (SV) factors and jump components, in appropriate modeling of equity return distributions. We use estimation technology that facilitates nonnested model comparisons and use a long data set which provides rich information about the conditional and unconditional distribution of returns. We consider two broad families of models: (I) the multifactor loglinear family, and (2) the affine-jump family. Both classes of models have attracted much attention in the derivatives and econometrics literatures. There are various tradeoffs in considering such diverse specifications. If pure diffusion SV models are chosen over jump diffusions, it has important implications for hedging strategies. If logarithmic models are chosen over affine ones, it may seriously complicate option pricing. Comparing many different specifications of pure diffusion multifactor models and jump diffusion models, we find that (I) log linear models have to be extended to two factors with feedback in the mean reverting factor, (2) affine models have to have a jump in returns, stochastic volatility or probably both. Models (I) and (2) are observationally equivalent on the data set in hand. In either (I) or (2) the key is that the volatility can move violently. As we obtain models with comparable empirical fit, one must make a choice based on arguments other than statistical goodness-of-fit criteria. The considerations include facility to price options, to hedge and parsimony. The affine specification with jumps in volatility might therefore be preferred because of the closed-form derivatives prices. (C) 2003 Elsevier B.V. All rights reserved.","Chernov, M; Gallant, AR; Ghysels, E; Tauchen, G",2003,10.1016/s0304-4076(03)00108-8,None,wos
6935cf79559f8c33,"Ambiguity reduction by objective model selection, with an application to the costs of the EU 2030 climate targets","I estimate the cost of meeting the EU 2030 targets for greenhouse gas emission reduction, using statistical emulators of ten alternative models. Assuming a first-best policy implementation, I find that total and marginal costs are modest. The statistical emulators allow me to compute the risk premiums, which are small, because the EU is rich and the policy impact is small. The ensemble of ten models allows me to compute the ambiguity premium, which is small for the same reason. I construct a counterfactual estimate of recent emissions without the climate policy and use that to test the predictive skill of the ten models. The models that show the lowest cost of emission reduction also have the lowest skill for Europe in recent times. © 2018 Elsevier B.V., All rights reserved.","Tol, R.S.J.",2014,10.3390/en7116886,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912033606&doi=10.3390%2Fen7116886&partnerID=40&md5=885f426cc74a9fa09f0696aff6b5bf0b,scopus
a68df8aeccec0afd,An Analysis of Some Effects of Rating Information using an Artificial Market,"Standard & Poor' s (S & P) downgraded American government bonds from AAA to AA+ last year. The effects of the downgrade on financial markets have been studied in financial engineering, economics and computational finance, but not in agent-based simulation studies. In this paper, we investigate the effect of the rating system (e.g.: S & P) on asset price fluctuations in the artificial market, which is the agent-based simulation model of the financial market. The rating information is defined as a discrete version of the fundamental value. Four strategies : the noise trader, the fundamentalist, the trend predictor, and the contrarian trader, were assumed in previous studies of the artificial market, plus we assume a new agent called “rating user” which uses the rating value, defined as the discrete value of the fundamental value of an asset. We investigate if the rating user makes the artificial market unstable. First, the simulation results show that kurtosis of an asset price return in the market, without fundamentalists, is higher than without rating users. This suggests the usage of rating information makes the artificial market unstable. The simulation outcomes also suggest volatility continuity of asset price return is stronger in the market without fundamentalists than without rating users. Second, we investigate how two parameters, the update interval and rating length, which control the rating value, makes the market stable. The simulation outcomes show that both standard deviation of asset price return and kurtosis of asset price return becomes smaller as the update interval increases. The standard deviation gets larger and kurtosis of that gets larger with the increasing length of rating. These results imply that the rating information should be updated at short intervals and the length of rating should be moderate to make the artificial market stable. keywords: raing-information, financial market, artificial market, agent-based simulation. © 2012, The Japanese Society for Artificial Intelligence. All rights reserved. © 2017 Elsevier B.V., All rights reserved.","Katsumi, S.; Shimao, H.; Nishiyama, N.",2012,10.1527/tjsai.27.384,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024750711&doi=10.1527%2Ftjsai.27.384&partnerID=40&md5=14a23a707402b1332239499f679a1415,scopus
e040435996e03d39,An Application of Damped Diffusion for Modeling Volatility Dynamics,"This paper proposes a damped constant elasticity variance (CEV) stochastic volatility (DCEV) model, which remedies the possible explosive behavior of the CEV model and also accommodates the mean-reverting dynamics more appropriately than the nonlinear drift (NLD) stochastic volatility model. As the DCEV model maintains the linear drift, an analytic formula is available to efficiently infer latent variances from VIX levels, after which both its physical and risk-neutral parameters can be simultaneously estimated with the maximum-likelihood approach given S&P 500 returns and inferred variances. The DCEV model outperforms the CEV and NLD models in in-sample fitting performance and in out-of-sample variance forecasting under the physical measure. It also exhibits superior ability in out-of-sample option pricing over the CEV and models under the risk-neutral measure. This satisfactory performance demonstrates the suitability of describing volatility dynamics with the DCEV model and the potential of applying this to study other issues.","Hung, Mao-Wei; Ko, Yi-Chen; Wang, Jr-Yan",2023,10.1093/jjfinec/nbab018,None,wos
7ac4d584ce43caa8,An Automated Framework for Incorporating News into Stock Trading Strategies,"In this paper we present a framework for automatic exploitation of news in stock trading strategies. Events are extracted from news messages presented in free text without annotations. We test the introduced framework by deriving trading strategies based on technical indicators and impacts of the extracted events. The strategies take the form of rules that combine technical trading indicators with a news variable, and are revealed through the use of genetic programming. We find that the news variable is often included in the optimal trading rules, indicating the added value of news for predictive purposes and validating our proposed framework for automatically incorporating news in stock trading strategies.",W. Nuij; V. Milea; F. Hogenboom; F. Frasincar; U. Kaymak,2014,10.1109/tkde.2013.133,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6574843,ieeexplore
dde2fd0b63571dc0,An Efficient Deep Learning Based Model to Predict Interest Rate Using Twitter Sentiment,"In macroeconomics, decision making is highly sensitive and significantly influences the financial and business world, where the interest rate is a crucial factor. In addition, the interest rate is used by the governments to manage the monetary policy. There is a need to design an efficient algorithm for interest rate prediction. The analysis of the social media sentiment impact on financial decision making is also an open research area. In this study, we deploy a deep learning model for the accurate forecasting of the interest rate for the UK, Turkey, China, Hong Kong, and Mexico. For this purpose, daily data of the interest rate and exchange rate covering the period from Jan 2010 to Oct 2019 is used for all the mentioned countries. We also incorporate the input of the twitter sentiments of six mega-events, namely the US election 2012, Mexican election 2012, Gaza under attack 2014, Hong Kong protest 2014, Refugee Welcome 2015, and Brexit 2016. Our results provide evidence that the error of the deep learning model significantly decreases when event sentiment is incorporated. A notable improvement has been observed in the case of the Hong Kong interest rate, i.e., a 266% decline in the error after incorporating event sentiments as an input in the deep learning model.","Yasir, Muhammad; Afzal, Sitara; Latif, Khalid; Chaudhary, Ghulam Mujtaba; Malik, Nazish Yameen; Shahzad, Farhan; Song, Oh-young",2020,10.3390/su12041660,None,wos
f3ace5f4c4fc6584,An Empirical Investigation of the Level Effect in Australian Interest Rates,"An extensive literature examines the dynamics of interest rates, with particular attention given to the positive relationship between interest-rate volatility and the level of interest rates—the so-called level effect. This paper examines the interaction between the estimated level effect and competing parameterisations of interest-rate volatility for the Australian yield curve. We adopt a new methodology that estimates elasticity in a multivariate setting that explicitly accommodates the correlations that exist between various yield factors. Results show that significant correlations exist between the residuals of yield factors and that such correlations do indeed impact on model estimates. Within the multivariate setting, the level of the short rate is shown to be a crucial determinant of the conditional volatility of all three yield factors. Measures of model fit suggest that, in addition to the usual level effect, the incorporation of GARCH effects and possible regime shifts is important. © 2008, SAGE Publications. All rights reserved. © 2019 Elsevier B.V., All rights reserved.","Gray, P.; Smith, D.R.",2008,10.1177/031289620803300103,https://www.scopus.com/inward/record.uri?eid=2-s2.0-54849404302&doi=10.1177%2F031289620803300103&partnerID=40&md5=dd13438b705d6c7e42bc5b6e7c4e98a3,scopus
abe1221edb4c5afc,An Evaluation of Machine Learning Models for Forecasting Short-Term U.S. Treasury Yields,"This study explores the historical evolution and short-term predictive modeling of the U.S. 10-year Treasury bond yield, a critical indicator in global financial markets. Recognizing its sensitivity to macroeconomic conditions, the research integrates economic variables, including the federal funds rate, core Consumer Price Index (CPI), real Gross Domestic Product (GDP) growth rate, and the U.S. federal debt growth rate, to assess their influence on yield movements. Four forecasting models are employed for comparative analysis: linear regression (LR), decision tree (DT), random forest (RF), and multilayer perceptron (MLP) neural networks. Using historical data from the Federal Reserve Economic Data (FRED), this study finds that the RF model offers the most accurate short-term predictions, achieving the lowest mean squared error (MSE) and mean absolute error (MAE), with an R2 value of 0.5760. The results highlight the superiority of ensemble-based nonlinear models in capturing complex interactions between economic indicators and yield dynamics. This research not only provides empirical support for using machine learning in economic forecasting but also offers practical implications for bond traders, system developers, and financial institutions aiming to enhance predictive accuracy and risk management.","Yi-Fan, Wang; Wang, Max Yue-Feng; Li-Ying, Tu",2025,10.3390/app15126903,None,proquest
60d9d62ef78644a0,An adaptively managed dynamic portfolio selection model using a time-varying investment target according to the market forecast,"In this paper, we propose an adaptive investment strategy (AIS) based on a dynamic portfolio selection model (DPSM) that uses a time-varying investment target according to the market forecast. The DPSM allows for flexible investments, setting relatively aggressive investment targets when market growth is expected and relatively conservative targets when the market is expected to be less attractive. The model further allows investments to be liquidated into risk-free assets when the market forecast is pessimistic. By dynamically determining the investment target, the DPSM allows construction of portfolios that are more responsive to market changes, while eliminating the possibility of the model becoming infeasible under certain market conditions. When the proposed DPSM is implemented in real-life investment scenarios using the AIS, the portfolio is rebalanced according to a predefined rebalancing cycle and the model's input parameters are estimated on each rebalancing date using an exponentially weighted moving average (EWMA) estimator. To evaluate the performance of the proposed approach, a 7-year investment experiment was conducted using historical stock returns data from 10 different stock markets around the world. Performance was assessed and compared using diverse measures. Superior performance was achieved using the AIS proposed herein compared with various benchmark approaches for all performance measures. In addition, we identified a converse relationship between the average trading volume of a market and the value of the weighting parameter prescribed to the EWMA estimator, which maximizes cumulative returns in each market. © 2020 Elsevier B.V., All rights reserved.","Jung, J.; Kim, S.",2015,10.1057/jors.2014.72,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937210799&doi=10.1057%2Fjors.2014.72&partnerID=40&md5=8aa29123405930fe4848e304ee973f23,scopus
08de1ecc4154ae9b,An analysis of nonlinearities in term premiums and forward rates,"Previous studies often assume a linear relation between term premiums on Treasury securities and forward interest rates even though a nonlinear relation is a theoretical and an empirical possibility. To examine the relation, this paper uses a nonparametric kernel approach that permits both linear and nonlinear associations. The linear specification yields conditional expectations of term premiums that are similar to those predicted by the kernel approach only at the mean forward premiums. Generally, kernel estimation shows that the responses of expected term premiums to changes in forward premiums are time-varying and are significantly different from the constant slope coefficients produced by linear estimations. The evidence also shows that forward premiums contain much more information content for predicting future term premiums than has been found with linear estimation procedures. © 2005 Elsevier Science B.V., Amsterdam. All rights reserved.","Huang, R.D.; Lin, C.S.Y.",1996,10.1016/s0927-5398(96)00008-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030527175&doi=10.1016%2FS0927-5398%2896%2900008-4&partnerID=40&md5=2762a85a3dc870c284cd425c9e590525,scopus
bdbdd3c5ab5a5647,An application of comonotonicity theory in a stochastic life annuity framework,"A life annuity contract is an insurance instrument which pays pre-scheduled living benefits conditional on the survival of the annuitant. In order to manage the risk borne by annuity providers, one needs to take into account all sources of uncertainty that affect the value of future obligations under the contract. In this paper, we define the concept of annuity rate as the conditional expected present value random variable of future payments of the annuity, given the future dynamics of its risk factors. The annuity rate deals with the non-diversifiable systematic risk contained in the life annuity contract, and it involves mortality risk as well as investment risk. While it is plausible to assume that there is no correlation between the two risks, each affects the annuity rate through a combination of dependent random variables. In order to understand the probabilistic profile of the annuity rate, we apply comonotonicity theory to approximate its quantile function. We also derive accurate upper and lower bounds for prediction intervals for annuity rates. We use the Lee-Carter model for mortality risk and the Vasicek model for the term structure of interest rates with an annually renewable fixed-income investment policy. Different investment strategies can be handled using this framework.","Liu, Xiaoming; Jang, Jisoo; Kim, Sun Mee",2011,10.1016/j.insmatheco.2010.11.008,None,proquest
257e4f256aa2e115,An automated financial indices-processing scheme for classifying market liquidity regimes,"A multivariate hidden Markov model (HMM)-based approach is developed to capture simultaneously the regime-switching dynamics of four financial market indicators: Treasury-Euro Dollar rate spread, US dollar index, volatility index and S&P 500 bid-ask spread. These indicators exhibit stochasticity, mean reversion, spikes and state memory, and they are deemed to drive the main characteristics of liquidity risk and regarded to mirror financial markets' liquidity levels. In this paper, an online system is proposed in which observed indicators are processed and the results are then interfaced with an advanced alert mechanism that gives out appropriate measures. In particular, two stochastic models, with HMM-modulated parameters switching between liquidity regimes, are integrated to capture the evolutions of the four time series or their transformations. Parameter estimation is accomplished by deriving adaptive multivariate filters. Indicators' joint empirical characteristics are captured well and useful early warnings are obtained for occurrence prediction of illiquidity episodes.","Gu, Xing; Mamon, Rogemar; Davison, Matt; Yu, Hao",2021,10.1080/00207179.2019.1616225,None,proquest
516f97e519503054,An effective hybrid approach for forecasting currency exchange rates,"Accurately forecasting the movement of exchange rates is of interest in a variety of fields, such as international business, financial management, and monetary policy, though this is not an easy task due to dramatic fluctuations caused by political and economic events. In this study, we develop a new forecasting approach referred to as FSPSOSVR, which is able to accurately predict exchange rates by combining particle swarm optimization (PSO), random forest feature selection, and support vector regression (SVR). PSO is used to obtain the optimal SVR parameters for predicting exchange rates. Our analysis involves the monthly exchange rates from January 1971 to December 2017 of seven countries including Australia, Canada, China, the European Union, Japan, Taiwan, and the United Kingdom. The out-of-sample forecast performance of the FSPSOSVR algorithm is compared with six competing forecasting models using the mean absolute percentage error (MAPE) and root mean square error (RMSE), including random walk, exponential smoothing, autoregres-sive integrated moving average (ARIMA), seasonal ARIMA, SVR, and PSOSVR. Our empirical results show that the FSPSOSVR algorithm consistently yields excellent predictive accuracy, which compares favorably with competing models for all currencies. These findings suggest that the proposed algorithm is a promising method for the empirical forecasting of exchange rates. Finally, we show the empirical relevance of exchange rate forecasts arising from FSPSOSVR by use of foreign exchange carry trades and find that the proposed trading strategies can deliver positive excess returns of more than 3% per annum for most currencies, except for AUD and NTD. © 2021 Elsevier B.V., All rights reserved.","Shen, M.-L.; Lee, C.-F.; Liu, H.-H.; Chang, P.-Y.; Yang, C.-H.",2021,10.3390/su13052761,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102711580&doi=10.3390%2Fsu13052761&partnerID=40&md5=a7f81af1c0335702887643e103e0ea2c,scopus
8071539ff0d58c9e,An empirical comparison of transformed diffusion models for VIX and VIX futures,"Transformed diffusions (TDs) are nonlinear functions of continuous-time affine diffusion processes. Since they are flexible models with tractable analytic properties, financial modelling with TDs has become increasing popular in recent years. We first provide a formal classification of TD models into drift-driven, diffusion-driven, and distribution-driven according to their empirical emphases and specification strategies. Motivated by the stylized distributional features of VIX such as skewness and excess kurtosis, we then propose a pair of new distribution-driven TDs for modelling VIX dynamics and pricing VIX futures by directly incorporating such information into the specification of the transformation. We conduct a comprehensive empirical investigation into the relative performance of the three classes of models against several empirically relevant criteria. Our focus is on the in-sample goodness-of-fit measure and the out-of-sample forecast accuracy for modelling VIX and pricing VIX futures, as well as the stock return predictability of the implied Variance Risk Premium. Our findings demonstrate that the newly proposed distribution-driven models have clear advantages over well-established alternatives in most of our exercises. © 2017 Elsevier B.V., All rights reserved.","Bu, R.; Jawadi, F.; Li, Y.",2017,10.1016/j.intfin.2016.08.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994910609&doi=10.1016%2Fj.intfin.2016.08.003&partnerID=40&md5=67c5023992ba98b3ea71cdfb9652d735,scopus
fde376f05af6d7b7,"An empirical investigation into the impact of US federal government budget deficits on the real interest rate yield on intermediate-term treasury issues, 1972-2012","This study provides new empirical evidence on the impact of the federal budget deficit on the real interest rate yields on intermediate-term debt issues of the US Treasury, represented herein by the ex post real interest rate yields on 3-year Treasury notes and 7-year Treasury notes, two interest rate measures that have received essentially no attention in the economics and finance literature in recent years. This study is couched within a loanable funds model that includes two ex post real interest rate yields, the monetary base as a per cent of GDP, the change in per capita real GDP, net financial capital inflows as a per cent of GDP and the budget deficit as a per cent of GDP. This study uses annual data for the study period 1972 to 2012, a time period that includes 'quantitative easing' monetary policies by the Federal Reserve. Two-stage least squares estimations reveal that the federal budget deficit, expressed as a per cent of GDP, exercised a positive and statistically significant impact on the ex post real interest rate yields on both 3-year and 7-year Treasury notes, even after allowing for quantitative easing and other factors. The study also considers the time period 1980 to 2012 and offers simple robustness testing. Reprinted by permission of Routledge, Taylor and Francis Ltd.","Cebula, Richard J",2014,10.1080/00036846.2014.932050,None,proquest
9a0f00b75445a4f1,An end-to-end deep learning framework for the portfolio optimization with stop-loss orders,"Incorporating stop-loss orders into portfolio optimization is an effective strategy for mitigating tail risk. However, traditional methods often rely on static stop-loss rules paired with separate price prediction models, leading to amplified error propagation in the application of stop-loss orders. We propose a novel end-to-end (E2E) data-driven deep learning framework that simultaneously determines portfolio allocations and stop-loss orders for risky assets, with each asset triggering sales when its prices reach the stop-loss order. The E2E approach uses a two-branch neural network architecture that integrates historical transaction data with additional inputs such as predicted returns and price volatility. A recurrent neural network extracts feature representation vectors for each risky asset from its time series data, and two fully connected layers process the aggregated information to generate the optimal joint action of portfolio allocations and corresponding stop-loss orders. The effectiveness of the E2E solution is demonstrated by numerical experiments on four stock market datasets. The results show that the E2E strategy outperforms alternative benchmarks across multiple metrics, including cumulative returns, alpha returns, and risk-adjusted returns. The strategy exhibits superior ability to maintain robust returns and control tail risk, achieving an average excess return of 0.33% and an average Calmar ratio of 4.50 over four datasets. In addition, the introduction of stop-loss orders yields significantly positive excess returns, and the strategy maintains its advantage even when a transaction cost rate of 0.3% is included. © 2025 Elsevier B.V., All rights reserved.","Zhang, Y.; Liu, Y.; Liu, W.; Yang, X.",2025,10.1016/j.asoc.2025.113465,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009613641&doi=10.1016%2Fj.asoc.2025.113465&partnerID=40&md5=4a06f7897a7b12fe2e864719fa90d7f0,scopus
01f7b4f943c3d0b7,An estimation model for the term structure of yield spread,"An estimation model for term structure of yield spread has become an extremely important subject to evaluate securities with default risk. By Duffie and Singleton model, yield spread was explained by two factors, namely collection rate and default probability. An estimation of the collection rate is given from historical earnings data, but estimation of default probability is known to be a remaining problem. There are some approaches to express default probability. One of them is to describe it through hazard process, and the other is to represent it by risk neutral transition probability matrix of credit-rating class. Some models that use Gaussian type hazard process or Vasicek type hazard process have already constructed. An advantage of evaluation using a rating transition probability matrix is that it is easy to obtain an image of movement of the credit-rating class. We do not need to show the calculation basis of the threshold or an assumption for distribution of prospective yield spread. But the model that uses the risk neutral transition probability matrix has not established yet, because of the computational difficulty required to estimate large number of the parameters. At first, for the purposes of this article, we will estimate the term structure of credit spreads results from the possibility of future defaults. It is assumed that credit risk is specified as a discrete-state Markov chain. And we construct a model which can be used to estimate the baseline transition matrix of the credit-rating class, risk-adjusting factors, industrial drift factors, corporate drift factors and recovery ratio, from yield spreads for individual bond. This enables us to compute the implied term structure from market data. We are capable of computing the implied term structure from market date by this process. Next, we will provide a valuation model for the term structure of yield spread. © 2001 Kluwer Academic Publishers. © 2018 Elsevier B.V., All rights reserved.","Aonuma, K.; Tanabe, T.",2001,10.1023/a:1011967507050,https://www.scopus.com/inward/record.uri?eid=2-s2.0-52549092985&doi=10.1023%2FA%3A1011967507050&partnerID=40&md5=a0e6e9585c1ad15f528cb05bd29ea952,scopus
4b946252a5b5a44e,An indicator of future inflation extracted from the steepness of the interest rate yield curve along its entire length,"The term-structure slope contains information about expected future inflation. Mishkin shows that the spread between the twelve-month and three-month interest rates helps predict the difference between twelve-month and three-month inflation. We apply a simple existing framework, which lets the real interest rate vary in the short run but converge to a constant in the long run, to this problem. The appropriate indicator of expected inflation uses the entire length of the yield curve, estimating the steepness of a specific nonlinear transformation, rather than being restricted to a spread between two points. The resulting indicator better predicts inflation, over 1960–1991. © 1994 by the President and Fellows of Harvard College and the Massachusetts Institute of Technology. © 2016 Elsevier B.V., All rights reserved.","Frankel, J.A.; Lown, C.S.",1994,10.2307/2118472,https://www.scopus.com/inward/record.uri?eid=2-s2.0-21344483312&doi=10.2307%2F2118472&partnerID=40&md5=f5ed43ec582dfc6b2cde18634449f72f,scopus
99367e520d9af0be,An infinite hidden Markov model for short-term interest rates,"The time-series dynamics of short-term interest rates are important as they are a key input into pricing models of the term structure of interest rates. In this paper we extend popular discrete time short-rate models to include Markov switching of infinite dimension. This is a Bayesian nonparametric model that allows for changes in the unknown conditional distribution over time. Applied to weekly U.S. data we find significant parameter change over time and strong evidence of non-Gaussian conditional distributions. Our new model with a hierarchical prior provides significant improvements in density forecasts as well as point forecasts. We find evidence of recurring regimes as well as structural breaks in the empirical application. © 2016 Elsevier B.V., All rights reserved.","Maheu, J.M.; Yang, Q.",2016,10.1016/j.jempfin.2016.06.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976337100&doi=10.1016%2Fj.jempfin.2016.06.006&partnerID=40&md5=afcfc5a06eb822eff1844bc60ca17c66,scopus
b4caec0083b6f9ca,An infinite hidden Markov model with GARCH for short-term interest rates,"This paper introduces a novel Bayesian time series model that combines the nonparametric features of an infinite hidden Markov model with the volatility persistence captured by the GARCH framework, to effectively model and forecast short-term interest rates. When applied to US 3-month Treasury bill rates, the GARCH-IHMM reveals both structural and persistent changes in volatility, thereby enhancing the accuracy of density forecasts compared to existing benchmark models. Out-of-sample evaluations demonstrate the superior performance of our model in density forecasts and in capturing volatility dynamics due to its adaptivity to different macroeconomic environments. © 2025 Elsevier B.V., All rights reserved.","Li, C.; Yang, Q.",2025,10.1016/j.frl.2025.107294,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002424722&doi=10.1016%2Fj.frl.2025.107294&partnerID=40&md5=5636e92e21eac3c3d6ffe3b06d97955c,scopus
a8f66bfcf423531f,An interval constraint-based trading strategy with social sentiment for the stock market,"Developing effective strategies to earn excess returns in the stock market is a cutting-edge topic in the field of economics. At the same time, stock price forecasting that supports trading strategies is considered one of the most challenging tasks. Therefore, this study analyzes and extracts news media data, expert comments, social opinion data, and pandemic text data using natural language processing, and then combines the data with a deep learning model to forecast future stock price patterns based on historical stock prices. An interval constraint-based trading strategy is constructed. Using data from several typical stocks in the Chinese stock market during the COVID-19 period, the empirical studies and trading simulations show, first, that the sentiment composite index and the deep learning model can improve the accuracy of stock price forecasting. Second, the interval constraint-based trading strategy based on the proposed approach can effectively enhance returns and thus, can assist investors in decision-making.","Li, Mingchen; Yang, Kun; Lin, Wencan; Wei, Yunjie; Wang, Shouyang",2024,10.1186/s40854-023-00567-2,None,proquest
84d299eae50d47d6,An online estimation scheme for a Hull-White model with HMM-driven parameters,"This paper considers the implementation of a mean-reverting interest rate model with Markov-modulated parameters. Hidden Markov model filtering techniques in Elliott (1994, Automatica, 30:1399-1408) and Elliott et al. (1995, Hidden Markov Models: Estimation and Control. Springer, New York) are employed to obtain optimal estimates of the model parameters via recursive filters of auxiliary quantities of the observation process. Algorithms are developed and implemented on a financial dataset of 30-day Canadian Treasury bill yields. We also provide standard errors for the model parameter estimates. Our analysis shows that within the dataset and period studied, a model with two regimes is sufficient to describe the interest rate dynamics on the basis of very small prediction errors and the Akaike information criterion. © 2007 Springer-Verlag. © 2009 Elsevier B.V., All rights reserved.","Erlwein-Sayer, C.; Mamon, R.",2009,10.1007/s10260-007-0082-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-58849132965&doi=10.1007%2Fs10260-007-0082-4&partnerID=40&md5=7f659b37a7d8a0412dc1e1436f438fff,scopus
0f172ab615288205,An overview of maintenance management strategies for corroded steel structures in extreme marine environments,"Maintenance is playing an important role in integrity management of marine assets such as ship structures, offshore renewable energy platforms and subsea oil and gas facilities. The service life of marine assets is heavily influenced by the involvement of numerous material degradation processes (such as fatigue cracking, corrosion and pitting) as well as environmental stresses that vary with geographic locations and climatic factors. The composition of seawater constituents (e.g. dissolved oxygen, salinity, temperature content, etc.) is one of the major influencing factors in degradation of marine assets. Improving the efficiency and effectiveness of maintenance management strategies can have a significant impact on operational availability and reliability of marine assets. Many research studies have been conducted over the past few decades to predict the degradation behaviour of marine structures operating under different environmental conditions. The utilisation of structural degradation data – particularly on marine corrosion – can be very useful in developing a reliable, risk-free and cost-effective maintenance strategy. This paper presents an overview of the state-of-the-art and future trends in asset maintenance management strategies applied to corroded steel structures in extreme marine environments. The corrosion prediction models as well as industry best practices on maintenance of marine steel structures are extensively reviewed and analysed. Furthermore, some applications of advanced technologies such as computerized maintenance management system (CMMS), artificial intelligence (AI) and Bayesian network (BN) are discussed. Our review reveals that there are significant variations in corrosion behaviour of marine steel structures and their industrial maintenance practices from one climatic condition to another. This has been found to be largely attributed to variation in seawater composition/characteristics and their complex mutual relationships. © 2020 Elsevier B.V., All rights reserved.","Abbas, M.; Shafiee, M.",2020,10.1016/j.marstruc.2020.102718,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078962228&doi=10.1016%2Fj.marstruc.2020.102718&partnerID=40&md5=06e8029f84c8b4e4d649d53d85207f63,scopus
90fdb546691bd626,Analysis of herding behavior in individual investor portfolios using machine learning algorithms,"This paper examines the determinants of herding at both stock and individual investor levels and studies the portfolio performance of herd vs. non-herd portfolios using machine learning algorithms. The disposition effect and the attention effect seem to explain herding behavior at the stock level. At the individual investor level, the cumulative number of buys and portfolio values reduce the prediction of herding behavior, while high values of portfolio return lead to a small increase in herding. Individuals who herd do not outperform either market or non-herd portfolios, suggesting that herding is a behavioral bias. Thus, such behavior seems to destabilize stock markets, creating temporary discrepancies in stock prices followed by reversals back to fundamentals. The most predictive factor in the performance tests of individual portfolios is the market risk premium and using equally-weighted factors rather than value-weighted factors seem to provide more consistent results in the portfolio performance analyses. © 2022 Elsevier B.V., All rights reserved.","Mavruk, T.",2022,10.1016/j.ribaf.2022.101740,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136526119&doi=10.1016%2Fj.ribaf.2022.101740&partnerID=40&md5=9a05e65026a399027b17b7c424c6c9fc,scopus
1b54463d1a0cc54d,Analysis of multifactor affine yield curve models,"In finance and economics much work has been done on the theoretical modeling and statistical estimation of the yield curve, defined as the relationship between -1/τ logp <inf>t</inf>.(τ) and τ,where p <inf>t</inf>(τ) is the time t price of a zero - coupon bond with payoff 1 at maturity date t + τ. Of considerable current interest are models of the yield curve in which a collection of observed and latent factors determine the market price of factor risks, the stochastic discount factor, and the arbitrage - free bond prices. The model is particularly interesting from a statistical perspective, because the yields are complicated nonlinear functions of the underlying parameters (e.g., those appearing in the evolution dynamics of the factors and those appearing in the model of the factor risks). This nonlinearity tends to produce a likelihood function that is multimodal. In this article we revisit the question of how such models should be fit from the Bayesian viewpoint. Key aspects of the inferential framework include (a) a prior on the parameters of the model that is motivated by economic considerations, in particular, those involving the slope of the implied yield curve; (b) posterior simulation of the parameters in ways to improve the efficiency of the MCMC output, for example, through sampling of the parameters marginalized over the factors and tailoring of the proposal densities in the Metropolis - Hastings steps using information about the mode and curvature of the current target based on the output of a simulating annealing algorithm; and (c) measures to mitigate numerical instabilities in the fitting through reparameterizations and square root filtering recursions. We apply the techniques to explain the monthly yields on nine U.S. Treasury Bills (with maturities ranging from 1 month to 120 months) over the period January 1986 - December 2005. The model contains three factors, one latent and two observed. We also consider the problem of predicting the nine yields for each month of 2006. We show that the (multi-step-ahead) prediction regions properly bracket the actual yields in those months, thus highlighting the practical value of the fitted model. © 2009 American Statistical Association. © 2012 Elsevier B.V., All rights reserved.","Chib, S.; Ergashev, B.",2009,10.1198/jasa.2009.ap08029,https://www.scopus.com/inward/record.uri?eid=2-s2.0-74049132711&doi=10.1198%2Fjasa.2009.ap08029&partnerID=40&md5=e3022f035f007aa8736ec76106515f58,scopus
f9ea0fbfd77a9f06,Analysis of the relevance of sentiment data for the prediction of excess returns in a multiasset framework,"In this study, we look at the relevance of sentiment data for the prediction of excess returns in a multiasset analysis. We start by initial exploratory data analysis in order to assess the pertinence of the sentiment data. We then compare the performance of rule-based algorithms with and without the sentiment data. The data considered are provided by RavenPack. Finally, we explore the economic relevance of the forecast model in a long-only and long-short context. Inclusion of sentiment data leads to encouraging results.","Desforges, Perceval; Geissler, Christophe; Liu, Fei",2023,10.1002/for.2967,None,wos
4b4d931ddca887fb,Analyst Reports and Stock Performance: Evidence From the Chinese Market,"This article applies natural language processing (NLP) to extract and quantify textual information for predicting stock performance. Utilizing an extensive dataset of Chinese analyst reports and employing a customized BERT deep learning model for Chinese text, the study categorizes the sentiment of these reports as positive, neutral, or negative. The findings highlight the predictive power of this sentiment indicator for stock volatility, excess returns, and trading volume. Specifically, analyst reports with strong positive sentiment are associated with increased excess returns and intraday volatility. Conversely, reports with strong negative sentiment also heighten volatility and trading volume but lead to a decline in future excess returns. Notably, the magnitude of the effect is more pronounced for positive sentiment reports compared to negative ones. This article contributes to the empirical literature on sentiment analysis and the stock market’s response to news, particularly within the context of the Chinese stock market. © 2025 Elsevier B.V., All rights reserved.","Liu, R.; Liang, J.; Chen, H.; Hu, Y.",2025,10.1007/s10690-025-09522-w,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001866318&doi=10.1007%2Fs10690-025-09522-w&partnerID=40&md5=899a1a91422d5f7e03aad92258d8bf4b,scopus
a9d18ef3b66653ed,Analyzing the green bond index: A novel quantile-based high-dimensional approach,"The development of green bond markets is important for advancing energy efficiency, supporting renewable energy, encouraging sustainable investments, and safeguarding the environment. However, the inherent complexity and uncertainty of these markets pose significant challenges for both investors and researchers. In this study, we focus on analyzing the S&P Green Bond Index, a leading benchmark for monitoring the global green bond market. We introduce a new high-dimensional statistical method, the Quantile Group Adaptive Lasso, designed to accurately predict the returns of this index. Our empirical results demonstrate that this model surpasses several established forecasting techniques in both accuracy and stability. Furthermore, our analysis of economic significance highlights the critical influence of traditional energy-related predictors from G7 and BRICS countries on the global green bond markets. We also find that monetary policies and macroeconomic factors, such as M2 money supply, CPI, and government bond yields, play vital roles. Additionally, the robustness of our proposed method is confirmed. Overall, our study provides a powerful tool that not only significantly enhances forecasting performance but also deepens the understanding of the interplay between trends in green bond markets and information from energy sectors and broader economic conditions. © 2024 Elsevier B.V., All rights reserved.","Tao, L.; Jiang, W.; Ren, X.",2024,10.1016/j.irfa.2024.103659,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206793875&doi=10.1016%2Fj.irfa.2024.103659&partnerID=40&md5=2a3ac17fe37094fba78ff153a1937058,scopus
ef29280b50c0dfb2,Anchoring Bias in Consensus Forecasts and Its Effect on Market Prices,"Previous empirical studies on the rationality of economic. and financial forecasts generally test for generic properties such as bias or autocorrelated errors but provide only limited insight into the behavior behind inefficient forecasts. This paper tests for a specific form of forecast bias. In particular, we examine whether expert consensus forecasts of monthly economic releases are systematically biased toward the value of previous months' releases. Such a bias would be consistent with the anchoring and adjustment heuristic described by Tversky and Kahneman (1974) or could arise from professional forecasters' strategic incentives. We find broad-based and significant evidence for this form of bias, which in some cases results in sizable predictable forecast errors. To investigate whether market participants' expectations are influenced by this bias, we examine interest rate reactions to economic news. We find that bond yields react only to the residual, or unpredictable, component of the forecast error and not to the component induced by anchoring, suggesting that expectations of market participants anticipate this bias embedded in expert forecasts.","Campbell, Sean D.; Sharpe, Steven A.",2009,10.1017/s0022109009090127,None,wos
926b79a7e254334f,Anomalies and the Expected Market Return,"We provide the first systematic evidence on the link between long‐short anomaly portfolio returns—a cornerstone of the cross‐sectional literature—and the time‐series predictability of the aggregate market excess return. Using 100 representative anomalies from the literature, we employ a variety of shrinkage techniques (including machine learning, forecast combination, and dimension reduction) to efficiently extract predictive signals in a high‐dimensional setting. We find that long‐short anomaly portfolio returns evince statistically and economically significant out‐of‐sample predictive ability for the market excess return. The predictive ability of anomaly portfolio returns appears to stem from asymmetric limits of arbitrage and overpricing correction persistence.","Dong, Xi; Li, Yan; Rapach, David E; Zhou, Guofu",2022,10.1111/jofi.13099,None,proquest
df151b31988d8992,Application of QGA-BP Neural Network in Debt Risk Assessment of Government Platforms,"How to correctly understand the existence of local government debt, study its risk classification and impact, give full play to the “dual nature” of debt with a full-caliber indicator system, and avoid debt risks to the greatest extent. That is the research direction of this article. In order to improve the accuracy and efficiency of risk assessment and effectively reduce the debt risk of government platform companies, a risk assessment method based on optimized back-propagation (BP) neural network is proposed. First, the method uses quantum genetic algorithm (quantum genetic algorithm, QGA) to adjust and determine the initial weight and threshold of BP neural network and realize the optimization of BP neural network model parameter setting. Then, the QGA-BP debt risk assessment of government platforms is verified that it performs well in the debt risk prediction of government platform companies, and its prediction accuracy and prediction speed are improved.","Li, Qingping; Liu, Ming; Zhang, Yao",2024,10.4018/ijitwe.335124,None,proquest
73bbac9a2ecd9493,Application of evolutionary computation for rule discovery in stock algorithmic trading: A literature review,"Despite the wide application of evolutionary computation (EC) techniques to rule discovery in stock algorithmic trading (AT), a comprehensive literature review on this topic is unavailable. Therefore, this paper aims to provide the first systematic literature review on the state-of-the-art application of EC techniques for rule discovery in stock AT. Out of 650 articles published before 2013 (inclusive), 51 relevant articles from 24 journals were confirmed. These papers were reviewed and grouped into three analytical method categories (fundamental analysis, technical analysis, and blending analysis) and three EC technique categories (evolutionary algorithm, swarm intelligence, and hybrid EC techniques). A significant bias toward the applications of genetic algorithm-based (GA) and genetic programming-based (GP) techniques in technical trading rule discovery is observed. Other EC techniques and fundamental analysis lack sufficient study. Furthermore, we summarize the information on the evaluation scheme of selected papers and particularly analyze the researches which compare their models with buy and hold strategy (B&H). We observe an interesting phenomenon where most of the existing techniques perform effectively in the downtrend and poorly in the uptrend, and considering the distribution of research in the classification framework, we suggest that this phenomenon can be attributed to the inclination of factor selections and problem in transaction cost selections. We also observe the significant influence of the transaction cost change on the margins of excess return. Other influenced factors are also presented in detail. The absence of ways for market trend prediction and the selection of transaction cost are two major limitations of the studies reviewed. In addition, the combination of trading rule discovery techniques and portfolio selection is a major research gap. Our review reveals the research focus and gaps in applying EC techniques for rule discovery in stock AT and suggests a roadmap for future research. © 2015 Elsevier B.V., All rights reserved.","Hu, Y.; Liu, K.; Zhang, X.; Su, L.; Ngai, E.W.T.; Liu, M.",2015,10.1016/j.asoc.2015.07.008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939799429&doi=10.1016%2Fj.asoc.2015.07.008&partnerID=40&md5=7ea181ab6877b4d9d39c04fed89bad36,scopus
c5a0693edf0851ee,Application of statistical mechanics methodology to term-structure bond-pricing models,"Recent work in statistical mechanics has developed new analytical and numerical techniques to solve coupled stochastic equations. This paper applies the very fast simulated re-annealing and path-integral methodologies to the estimation of the Brennan and Schwartz two-factor term structure model. It is shown that these methodologies can be utilized to estimate more complicated n-factor nonlinear models. © 1991. © 2014 Elsevier B.V., All rights reserved.","Ingber, L.; Wehner, M.F.; Jabbour, G.M.; Barnhill, T.M.",1991,10.1016/0895-7177(91)90107-i,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4344609903&doi=10.1016%2F0895-7177%2891%2990107-I&partnerID=40&md5=a10cc26f8f9082733f9325f7b75f0961,scopus
ce0e67a56a1db07c,Applications of machine learning for corporate bond yield spread forecasting,"This article considers nine different predictive techniques, including state-of-the-art machine learning methods for forecasting corporate bond yield spreads with other input variables. We examine each method's out-of-sample forecasting performance using two different forecast horizons: (1) the in-sample dataset over 2003–2007 is used for one-year-ahead and two-year-ahead forecasts of non-callable corporate bond yield spreads; and (2) the in-sample dataset over 2003–2008 is considered to forecast the yield spreads in 2009. Evaluations of forecasting accuracy have shown that neural network forecasts are superior to the other methods considered here in both the short and longer horizon. Furthermore, we visualize the determinants of yield spreads and find that a firm's equity volatility is a critical factor in yield spreads. © 2021 Elsevier B.V., All rights reserved.","Kim, J.-M.; Kim, D.H.; Jung, H.",2021,10.1016/j.najef.2021.101540,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113399304&doi=10.1016%2Fj.najef.2021.101540&partnerID=40&md5=5ba74f57fb59d060a2c1775e12c696df,scopus
30d5228daba342c6,Arbitrage bounds in markets with noisy prices and the puzzle of negative option prices implicit in bonds,"The term structure of interest rates has occupied economists for many years. This is testimony to the importance of the term structure (or, equivalently, valuation operator) and to the difficulty of obtaining reliable estimates of it. Until recently, it was not possible to reconcile the theoretical existence of a multiplicity of valuation operators in an incomplete bond market and the empirical nonexistence of even a single one. MacKay and Prisman [Estimating valuation operators in incomplete market with noises: Can noise complete the market. Working paper, 1996] tackle this problem. In this paper, an amendment to and a generalization of their methodology is presented. The amendment preserves the linearity of valuation operators and allows use of efficient linear programming techniques. Further, it facilitates an admissible consideration of the puzzle of negative option prices embedded in bonds. The empirical results presented in this paper were obtained using data on extendable Government of Canada bonds. The results indicate that although the gap between the lowest and the highest prices assigned to a cash flow by different valuation operators is significant, it is not sufficient to resolve the above-mentioned puzzle. (C) 2002 Elsevier Science B.V. All rights reserved.","Ioffe, LD",2002,10.1016/s0378-4266(01)00172-8,None,wos
9c2770375eb64f35,Are bond returns predictable with real-time macro data?,"We investigate the predictability of bond returns using real-time macro variables and consider the possibility of a nonlinear predictive relationship and the presence of weak factors. To address these issues, we propose a scaled sufficient forecasting (sSUFF) method and analyze its asymptotic properties. Using both the existing and the new method, we find empirically that real-time macro variables have significant forecasting power both in-sample and out-of-sample. Moreover, they generate sizable economic values, and their predictability is not spanned by the yield curve. We also observe that the forecasted bond returns are countercyclical, and the magnitude of predictability is stronger during economic recessions, which lends empirical support to well-known macro finance theories.","Huang, Dashan; Jiang, Fuwei; Li, Kunpeng; Tong, Guoshi; Zhou, Guofu",2023,10.1016/j.jeconom.2022.09.008,None,proquest
6cc4da4926303f66,Are corporate bond market returns predictable?,"This paper examines the predictability of corporate bond returns using the transaction-based index data for the period from October 1, 2002 to December 31, 2010. We find evidence of significant serial and cross-serial dependence in daily investment-grade and high-yield bond returns. The serial dependence exhibits a complex nonlinear structure. Both investment-grade and high-yield bond returns can be predicted by past stock market returns in-sample and out-of-sample, and the predictive relation is much stronger between stocks and high-yield bonds. By contrast, there is little evidence that stock returns can be predicted by past bond returns. These findings are robust to various model specifications and test methods, and provide important implications for modeling the term structure of defaultable bonds. All rights reserved, Elsevier","Hong, Y; Lin, H; Wu, C.",2012,10.1016/j.jbankfin.2012.04.001,None,proquest
302ced4755753438,Are embedded calls valuable? Evidence from agency bonds,"This paper examines the call option values embedded in callable agency bonds. For FHLB, FNMA, and SLMA bonds, call value estimates range from 1.23% of par to 1.47% on average, which are between those for the treasury and corporate debt securities. FHLMC bonds, on the other hand, have an average call value estimate of 2.85%. Call values are significantly larger for bonds with a longer remaining maturity and greater default risk. Most interestingly, call values in the call protection period are significantly larger than those in the callable period except for the SLMA bonds, whereas previous studies on corporate debt find no significant difference in call values between these two periods.In general, call value exhibits a downward trend over time as the callable bond approaches maturity. Also, call value is inversely related to the level of interest rates. Interest rate drops are usually accompanied by an increase in Call values. An analysis of the determinants of call values suggests the following conclusions. First, call values are negatively related to short-term interest rates and the slope of the yield curve, and positively related to coupon rate and remaining maturity. Second, bonds with a greater amount of call protection have smaller call values, which is in contrast with the finding in a previous study on corporate debt that call protection period has little effect on call value. (c) 2006 Elsevier B.V. All rights reserved.","King, Tao-Hsien Dolly",2007,10.1016/j.jbankfin.2006.02.001,None,wos
4414f9a04e60c0a8,Are multi-factor Gaussian term structure models still useful? An empirical analysis on Italian BTPs,"In this paper, we empirically study models for pricing Italian sovereign bonds under a reduced form framework, by assuming different dynamics for the short-rate process. We analyze classical Cox-Ingersoll-Ross and Vasicek multi-factor models, with a focus on optimization algorithms applied in the calibration exercise. The Kalman filter algorithm together with a maximum likelihood estimation method are considered to fit the Italian term-structure over a 17-year horizon, including the global financial crisis, the euro area sovereign debt crisis and the Italian political turmoil in 2018. Analytic formulas for the gradient vector and the Hessian matrix of the likelihood function are provided. © 2022 Elsevier B.V., All rights reserved.","Bianchi, M.L.",2022,10.1080/03610918.2020.1721540,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078925539&doi=10.1080%2F03610918.2020.1721540&partnerID=40&md5=48175a83feef6a419ccf98cb26d0831d,scopus
c88844adcd257543,Are quantitative easing effects transitory? Evidence from out-of-sample forecasts,"Purpose>Advocates of quantitative easing (QE) policies have emphasized some evidence that structural models do not predict long-term asset yields as well as naive forecasts, implying that predictions of price reversals cannot be profitable and that QE effects are not transitory. The purpose of this study is to reconsider the out-of-sample forecasting performance of structural time series processes relative to that of a random walk with or without drift.Design/methodology/approach>This study uses bivariate vector autoregression and Markov switching representations to generate out-of-sample forecasts of ten-year sovereign bond yields, when the information set is augmented by including the growth rate of the monetary base, and the estimation relies on monthly data from countries that have pursued unconventional policies over the last decade.Findings>The results show that naive forecasts are not better than those of structural time series models, based on root mean squared errors, while the Markov model provides additional information on price reversals, through probabilistic inferences regarding policy regime switches, which can induce agents to counteract QE interventions and reduce their effectiveness.Originality/value>The novel features of this work are the use of a large information set including the instrument of unconventional monetary policy, the use of a structural model (Markov process) that can really inform about potential asset price reversals and the use of a large sample over which QE policies have been pursued.","Kirikos, Dimitris G",2022,10.1108/jfep-04-2022-0099,None,proquest
31af06ccc96e13d2,Are there nonlinear speculative bubbles in commodities prices?,"Daily price movements of seventeen commodities are tested for the possible presence of nonlinear speculative bubbles during 1991-2012. A VAR model for logarithmic first differences of each is estimated with one-year Treasury bill rates, U.S. dollar value, a world stock market index, and an overall commodities price index using Hamilton regime switching and Hurst rescaled range tests. Residuals after removing ARCH for all seventeen commodity price series are tested for remaining nonlinearity using the BDS test. These tests fail to reject the presence of bubble-like trends and nonlinearity beyond ARCH for all seventeen commodity series. However, we note that we are unable to overcome the misspecified fundamentals problem, which means we cannot argue that we have definitely found speculative bubbles. At most we can argue that our results indicate that these markets appear to exhibit excess volatility and unexplained trends. © 2014 M.E. Sharpe, Inc. All rights reserved. © 2020 Elsevier B.V., All rights reserved.","Ahmed, E.; Rosser, J.B.; Uppal, J.Y.",2014,10.2753/pke0160-3477360302,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898645711&doi=10.2753%2FPKE0160-3477360302&partnerID=40&md5=34a271069a89937d6ad612232df95cda,scopus
a956a31e47fe7cee,Artificial Intelligence and Firm Performance: Does Machine Intelligence Shield Firms from Risks?,"We estimate and compare the impact of the coronavirus pandemic (COVID-19) on the performance of Artificial Intelligence (AI) and conventional listed firms using stock market indices. The single-group and multiple-group Interrupted Time-Series Analyses (ITSA) with panel data were used with four interventions: when the news of COVID-19 spread and the pandemic entered the first, second, third, and fourth months (24 February 2020, 23 March 2020, 20 April 2020, and 18 May 2020, respectively). The results show that the negative impact of COVID-19 on the AI stock market was less severe than on the conventional stock market in the first month of the pandemic. The performance of the AI stock market recovered quicker than the conventional stock market when the pandemic went into its third month. The results suggest that the AI stocks were more resilient than conventional stocks when the financial market was exposed to uncertainty caused by the COVID-19 pandemic. The deployment of AI in firms serves as a resilient, crucial driver for sustainable performance in challenging environments. Observing the performance of AI-adopted firms is an interesting direction for technical and fundamental analysts. Investors and portfolio managers should consider an AI market index to minimize risk or invest in stocks of AI-adopted listed firms to maximize excess returns.","Linh Tu Ho; Linh Tu Ho; Gan, Christopher; Jin, Shan; Le, Bryan",2022,10.3390/jrfm15070302,None,proquest
c7505f1ac2274c1a,Artificial Intelligence in Economics Research: What Have We Learned? What Do We Need to Learn?,"Motivated by the recent boom in artificial intelligence (AI) playing a significant role in the economics of individuals, firms, and government bodies, we investigate the role of AI in economics by reviewing the literature (2231 articles) during the last 34 years (1990 to November 2024). We identify five research streams: (1) AI and economic modeling, (2) AI and macroeconomics (eight sub-streams), (3) AI and equity and debt market, (4) AI and prediction modeling (three sub-streams), and (5) AI and economics of innovation. Further, we offer suggestions for future research (20 questions). Additionally, we outline a framework to consider changes in economics before and after AI adoption. Further, the critical AI-based methods are identified and discussed.","Bahoo, Salman; Goodell, John W.; Rhattat, Rachid; Shahid, Subhan",2025,10.1111/joes.12694,None,wos
289cad8e7325e40a,Artificial Intelligence in Manufacturing Industry Worker Safety: A New Paradigm for Hazard Prevention and Mitigation,"The phenomenal rise of artificial intelligence (AI) in the last decade, and its evolution as a versatile addition to various fields, necessitates its usage for novel purposes in multidimensional fields like the manufacturing industry. Even though AI has been rigorously studied for process optimization, wastage reduction, and other quintessential aspects of the manufacturing industry, there has been limited focus on worker safety as a theme in the current literature. Safety standards contribute to worker safety, but there is no one-size-fits-all approach in these standards or policies, which warrants evaluation and integration of new ideas and technologies to reach the closest to ideal standards. This includes but is not limited to health, regulation of operations, predictive maintenance, and automation and control. The rise of Industry 4.0 and the migration towards Industry 5.0 facilitate easy integration of advanced technologies like AI into the manufacturing industry with real-time predictive capabilities, and this can help reduce human errors and mitigate hazards in processes where sensitivity is crucial or hazards are frequent. Keeping the future outlook in focus, AI can contribute to training workers in risk-free environments, promote engineering education for easy adaptation to new technology, and reduce resistance to changes in the industry. Furthermore, there is an urgent need for standards and regulations to govern and integrate AI technologies judiciously into the manufacturing industry, which holds AI models and their creators accountable for their decisions. This could further extend to preventing the adversarial use of new technology. This study exhaustively discusses the potential and ongoing contributions of this technology to the safety of workers in the manufacturing industry. © 2025 Elsevier B.V., All rights reserved.","Khurram, M.; Zhang, C.; Muhammad, S.; Kishnani, H.; An, K.; Abeywardena, K.; Chadha, U.; Behdinan, K.",2025,10.3390/pr13051312,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006749937&doi=10.3390%2Fpr13051312&partnerID=40&md5=62881fa545a36f4d695feaaad90cb4af,scopus
e387f15db5d09f82,Artificial intelligence combined with nonlinear optimization techniques and their application for yield curve optimization,"This study makes use of the artificial intelligence approaches combined with some nonlinear optimization techniques for optimization of a well-known problem in financial engineering called yield curve. Yield curve estimation plays an important role on making strategic investment decisions. In this paper, we use two well-known parsimonious estimation models, Nelson-Siegel and Extended Nelson-Siegel, for the yield curve estimation. The proposed models of this paper are formulated as continuous nonlinear optimization problems. The resulted models are then solved using some nonlinear optimization and meta-heuristic approaches. The optimization techniques include hybrid GPSO parallel trust region-dog leg, Hybrid GPSO parallel trust region-nearly exact, Hybrid GPSO parallel Levenberg-Marquardt and Hybrid genetic electromagnetism like algorithm. The proposed models of this paper are examined using some real-world data from the bank of England and the results are analyzed. © 2017 Elsevier B.V., All rights reserved.","Soltani, R.; Sadjadi, S.J.; Rahnama, M.",2017,10.3934/jimo.2017014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030552095&doi=10.3934%2Fjimo.2017014&partnerID=40&md5=9e10a6ec52920ca48e87b2e5a37a3950,scopus
be5b87f1c882c528,Asian holding of US Treasury securities: trade integration as a threshold,"This paper empirically investigates if there have been any shifts in regimes with Asian holding of US long-term Treasury securities with particular attention paid to the role of growing regional integration in trade. A panel regression estimation of eight Asian countries for 1998-2004 confirms the striking persistency of the portfolio weight of US Treasury securities. It also reveals, without a surprise, that the traditionally strong trade link with US as well as exchange rate regime and volatility of local currency bond index explain observed overinvestment in US Treasury securities deviating from what can be warranted by the market share of the US Treasury securities. What is interesting, however, is the estimated regime switches as found when examined with a threshold estimation (Hansen, 1999). We find three thresholds which divide the sample into four regimes-a decreasing persistency as intraregional trade link becomes tighter. All rights reserved, Elsevier","Terada-Hagiwara, Akiko",2011,10.1016/j.jjie.2011.07.001,None,proquest
7dddef039290f6a0,Ask BERT: How Regulatory Disclosure of Transition and Physical Climate Risks Affects the CDS Term Structure,"We use BERT, an AI-based algorithm for language understanding, to quantify regulatory climate risk disclosures and analyze their impact on the term structure in the credit default swap (CDS) market. Risk disclosures can either increase or decrease CDS spreads, depending on whether the disclosure reveals new risks or reduces uncertainty. Training BERT to differentiate between transition and physical climate risks, we find that disclosing transition risks increases CDS spreads after the Paris Climate Agreement of 2015, while disclosing physical risks decreases the spreads. In addition, we also find that the election of Trump had a negative impact on CDS spreads for firms exposed to transition risk. These impacts are consistent with theoretical predictions and economically and statistically significant. © 2024 Elsevier B.V., All rights reserved.","Kölbel, J.F.; Leippold, M.; Rillaerts, J.; Wang, Q.",2024,10.1093/jjfinec/nbac027,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182901564&doi=10.1093%2Fjjfinec%2Fnbac027&partnerID=40&md5=23e2756786ad479db12b6ac26122ffba,scopus
cecdcfa68c964887,Assessing the relevance of sell-side analyst recommendations,"This paper evaluates the informational value and alpha-generating potential of sell-side analyst recommendations. We explore this by employing a monthly portfolio-sorted long-short strategy based on consensus analyst recommendations. Our findings indicate that the long-short equal-weighted and value-weighted portfolios yield significant excess returns. However, the value-weighted excess returns are primarily driven by the predictive power of the lowest decile (sell recommendations). The long-short strategy for the value-weighted portfolios yields a monthly excess return ranging from 1.36% to 1.57%, above the risk-free rate. Our analysis further examines variations in recommendation effectiveness across economic cycles, industries, investment banks/brokers, and firm sizes, providing further insights into the value of analyst recommendations.","Aguegboh, Ekene S.; Onuoha, Uchenna C.; Patel, Poojan",2025,10.1002/rfe.70015,None,wos
1aa5adffb2e84661,Asset Pricing When 'This Time Is Different',"Recent evidence suggests that younger people update beliefs in response to aggregate shocks more than older people. We embed this generational learning bias in an equilibrium model in which agents have recursive preferences and are uncertain about exogenous aggregate dynamics. The departure from rational expectations is statistically modest, but generates high average risk premiums varying at generational frequencies, a positive relation between past returns and agents' future return forecasts, and substantial and persistent over-and undervaluation. Consistent with the model, the price-dividend ratio is empirically more sensitive to macroeconomic shocks when the fraction of young in the population is higher.","Collin-Dufresne, Pierre; Johannes, Michael; Lochstoer, Lars A.",2017,10.1093/rfs/hhw084,None,wos
6512de4ac6889893,Asset Pricing and Machine Learning: A critical review,"The latest development in empirical Asset Pricing is the use of Machine Learning methods to address the problem of the factor zoo. These techniques offer great flexibility and prediction accuracy but require special care as they strongly depart from traditional Econometrics. We review and critically assess the most recent and relevant contributions in the literature grouping them into five categories defined by the Machine Learning (ML) approach they employ: regularization, dimension reduction, regression trees/random forest (RF), neural networks (NNs), and comparative analyses. We summarize the empirical findings with particular attention to their economic interpretation providing hints for future developments. © 2024 Elsevier B.V., All rights reserved.","Bagnara, M.",2024,10.1111/joes.12532,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137459905&doi=10.1111%2Fjoes.12532&partnerID=40&md5=d514f0cebadfe1ab035f5fdd14a1fc49,scopus
2bf195f032f9a152,"Asset Returns Under Model Uncertainty: Evidence from the Euro Area, the US and the UK","We analyze predictability of risk premium in the context of model uncertainty. Using data for the euro area, the US and the UK, we show that there is a large amount of model uncertainty and one can improve the forecasts of stock returns with a Bayesian Model Averaging (BMA) approach. The empirical evidence for the euro area suggests that several macroeconomic, financial and macro-financial variables are consistently among the most prominent determinants of risk premium. As for the US, only a few number of predictors play an important role. In the case of the UK, future stock returns are better forecasted by financial variables. These results are corroborated for both the M-open and the M-closed perspectives, different model priors and in the context of “in-sample” and “out-of-sample” forecasting. Finally, we highlight that the predictive ability of the BMA framework is stronger at longer periods, and clearly outperforms the constant expected returns and the autoregressive benchmark models.","Sousa, João M; Sousa, Ricardo M",2019,10.1007/s10614-017-9696-2,None,proquest
d2fd8eca9a065eb4,Asset Returns: Reimagining Generative ESG Indexes and Market Interconnectedness,"Financial economists have long studied factors related to risk premiums, pricing biases, and diversification impediments. This study examines the relationship between a firm’s commitment to environmental, social, and governance principles (ESGs) and asset market returns. We incorporate an algorithmic protocol to identify three nonobservable but pervasive E, S, and G time-series factors to meet the study’s objectives. The novel factors were tested for information content by constructing a six-factor Fama and French model following the imposition of the isolation and disentanglement algorithm. Realizing that nonlinear relationships characterize models incorporating both observable and nonobservable factors, the Fama and French model statement was estimated using an enhanced shallow-learning neural network. Finally, as a post hoc measure, we integrated explainable AI (XAI) to simplify the machine learning outputs. Our study extends the literature on the disentanglement of investment factors across two dimensions. We first identify new time-series-based E, S, and G factors. Second, we demonstrate how machine learning can be used to model asset returns, considering the complex interconnectedness of sustainability factors. Our approach is further supported by comparing neural-network-estimated E, S, and G weights with London Stock Exchange ESG ratings.","Dash, Gordon; Dash, Gordon; Kajiji, Nina; Kamdem, Bruno G",2024,10.3390/jrfm17100463,None,proquest
5b66361e6bd351e7,Asset market equilibrium under rational inattention,"We propose a noisy rational expectations equilibrium model of asset markets with rationally inattentive investors. We incorporate any finite number of assets with arbitrary correlation. We also do not restrict the signal form and show that investors optimally choose a single signal, which is a noisy linear combination of all risky assets. This generates comovement of asset prices and contagion of shocks, even when asset payoffs are negatively correlated. The model also provides testable predictions of the impact of risk aversion, aggregate risk, and information capacity on the security market line, the portfolio dispersion, and the abnormal return.","Miao, Jianjun; Su, Dongling",2023,10.1007/s00199-021-01396-z,None,proquest
db174cb1df2093f1,Asset prices in a production network,"The relative importance of sectoral and aggregate productivity shocks in asset pricing is examined using a nonlinear dynamic equilibrium model where heterogeneous sectors interact in a production network. The model accounts for the heterogeneity in sectoral stock returns and endogenously generates conditional heteroskedasticity and fat tails. The equity risk premium is shown to be driven by sectoral shocks – specially to investment good producers and mining – with a limited contribution from the aggregate shock. SMM estimates of the elasticities of substitution between material inputs and between investment goods support the assumption of gross complementarity employed by previous network literature. © 2024 Elsevier B.V., All rights reserved.","Ruge-Murciá, F.",2024,10.1016/j.euroecorev.2024.104751,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193980037&doi=10.1016%2Fj.euroecorev.2024.104751&partnerID=40&md5=09a671fb1dc467fc6c86b4a434bc87f1,scopus
7be43e8757080b63,Asset pricing and foreign exchange risk,"According to the International Capital Asset Pricing Model (ICAPM), the covariance of assets with foreign exchange currency returns should be a risk factor that must be priced when the purchasing power parity is violated. The goal of this study is to re-examine the relationship between stock returns and foreign exchange risk. The novelties of this work are: (a) a data set that makes use of daily observations for the measurement of the foreign exchange exposure and volatility of the sample firms and (b) data from a Eurozone country. The methodology we make use in reference to the estimation of the sensitivity of each stock to exchange rate movements is that it allows regressing stock returns against factors controlling for market risk, size, value, momentum, foreign exchange exposure and foreign exchange volatility. Stocks are then classified according to their foreign exchange sensitivity portfolios and the return of a hedge (zero-investment) portfolio is calculated. Next, the abnormal returns of the hedge portfolio are regressed against the return of the factors. Finally, we construct a foreign exchange risk factor in such manner as to obtain a monotonic relation between foreign exchange risk and expected returns. The empirical findings show that the foreign exchange risk is priced in the cross section of the German stock returns over the period 2000-2008. Furthermore, they show that the relationship between returns and foreign exchange sensitivity is nonlinear, but it takes an inverse U-shape and that foreign exchange sensitivity is larger for small size firms and value stocks. © 2011 Elsevier B.V. © 2011 Elsevier B.V., All rights reserved.","Apergis, N.; Artikis, P.; Sorros, J.",2011,10.1016/j.ribaf.2011.02.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953279666&doi=10.1016%2Fj.ribaf.2011.02.005&partnerID=40&md5=711719c805262e6682f85c3b8ccd3aaf,scopus
34b352d3f2e22998,Asset pricing with financial bubble risk,"This paper characterizes systematic risk stemming from the possible occurrence of price bubbles and measures the impact of this additional risk factor on asset prices. Historical stock market behavior and recent empirical experience have led economists and policy makers to acknowledge that price bubbles in financial markets do occur and need to be accounted for in risk analysis. New econometric tools for analyzing mildly explosive behavior (Phillips and Magdalinos, 2007; Phillips et al., 2011) have made it possible to detect the presence of bubbles in data and to date stamp their origination and collapse, providing empirical confirmation of such episodes in recent data. The potential for price bubbles and market collapse provides another source of stock market risk and adds to the risk premium. We provide an analytic and empirical investigation of this additional risk factor. The standard present value model is extended to allow for possible price bubbles and the effects of integrating bubble behavior into a consumption-based asset pricing model are analyzed. The theory involves attention to the investor time horizon and a study of the validity of conventional log linear approximations in the presence of nonstationary and mildly explosive data. Finite decision horizons accommodate myopic investors and are a component of speculative behavior that focuses on short run market gains rather than long run effects of fundamentals. An econometric approach to estimate bubble risk effects is developed and the methods are applied to composite stock market index data, giving new model-based equity premium and market volatility estimates that more closely match the data than traditional consumption based asset pricing models. © 2016 Elsevier B.V., All rights reserved.","Lee, J.H.; Phillips, P.C.B.",2016,10.1016/j.jempfin.2015.11.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954285389&doi=10.1016%2Fj.jempfin.2015.11.004&partnerID=40&md5=ee8c418940be84168dc9bdae30a188ed,scopus
3c7234e3f11f883f,Asset pricing with neural networks: Significance tests,"This study proposes a novel hypothesis test for evaluating the statistical significance of input variables in multi-layer perceptron (MLP) regression models. Theoretical foundations are established through consistency results and estimation rate analysis using the sieves method. To validate the test's performance in complex and realistic settings, an extensive Monte Carlo simulation is conducted. Results of the simulation reveal that the test has a high power and low rate of false positives, making it a powerful tool for detecting true effects in data. The test is further applied to identify the most influential predictors of equity risk premiums, with results indicating that only a small number of characteristics have statistical significance and all macroeconomic predictors are insignificant at the 1% level. These findings are consistent across a variety of neural network architectures. © 2023 Elsevier B.V., All rights reserved.","Fallahgoul, H.; Franstianto, V.; Lin, X.",2024,10.1016/j.jeconom.2023.105574,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175615182&doi=10.1016%2Fj.jeconom.2023.105574&partnerID=40&md5=266d86eec03bf13321f13fad852108df,scopus
0c787f997c47e0be,Asset-pricing implications of biologically based non-expected utility,"Results in population ecology suggest that evolutionary successful species should have an adaptive (reference-based) S-shaped utility function that is intrinsically more sensitive to aggregate than uninsured idiosyncratic shocks the former cannot be diversified demographically. To test the asset-pricing relevance of these ideas, I embed the non-expected utility specification implied by evolutionary theory into an economy with partial risk sharing due to limited commitment. For the benchmark specification (CARA = 6 over gains), Monte Carlo simulations of a Markov growth economy produce the following results: (i) matching the degree of consumption-smoothing in the cross section, the Sharpe ratio for a Lucas tree is 0.33, an increase of 44 percent relative to expected utility; (ii) the risk-free rate is low, stable and counter-cyclical, hence equity returns, unlike in the expected utility case, have the correct pattern of predictability; (iii) in the cross section, excess returns across equity classes exhibit both a value premium and a size discount with risk adjusted returns that are at least two times higher than their expected utility counterparts. (C) 2012 Elsevier Inc. All rights reserved.","Iantchev, Emil P.",2013,10.1016/j.red.2012.08.002,None,wos
cb2acc4b493b7729,"Association between isolation of staphylococcus aureus one week after calving and milk yield, somatic cell count, clinical mastitis, and culling through the remaining lactation","Cows with isolation of Staphylococcus aureus approximately 1 week after calving and milk yield, somatic cell count (SCC), clinical mastitis (CM), and culling risk through the remaining lactation were assessed in 178 Norwegian dairy herds. Mixed models with repeated measures were used to compare milk yield and SCC, and survival analyses were used to estimate the hazard ratio for CM and culling. On average, cows with an isolate of Staph. aureus had a significantly higher SCC than culture-negative cows. If no post-milking teat disinfection (PMTD) was used, the mean values of SCC were 42 000, 61 000, 68 000 and 77 000 cells/ml for cows with no Staph. aureus isolate, with Staph. aureus isolated in 1 quarter, in 2 quarters and more than 2 quarters respectively. If iodine PMTD was used, SCC means were 36 000; 63 000; 70 000 and 122 000, respectively. Primiparous cows testing positive for Staph. aureus had the same milk yield curve as culture-negative cows, except for those with Staph. aureus isolated in more than 2 quarters. They produced 229 kg less during a 305-d lactation. Multiparous cows with isolation of Staph. aureus in at least 1 quarter produced 94161 kg less milk in 2nd and >3rd parity, respectively, and those with isolation in more than 2 quarters produced 303390 kg less than multiparous culture-negative animals during a 305-d lactation. Compared with culture-negative cows, the hazard ratio for CM and culling in cows with isolation of Staph. aureus in at least 1 quarter was 20 (1624) and 17 (1519), respectively. There was a decrease in the SCC and in the CM risk in culture-negative cows where iodine PMTD had been used, indicating that iodine PMTD has a preventive effect on already healthy cows. For cows testing positive for Staph. aureus in more than 2 quarters at calving, iodine PMTD had a negative effect on the CM risk and on the SCC through the remaining lactation. © 2008 Proprietors of Journal of Dairy Research 2008. © 2009 Elsevier B.V., All rights reserved.","Whist, A.C.; Osterås, O.; Sølverød, L.",2009,10.1017/s0022029908003592,https://www.scopus.com/inward/record.uri?eid=2-s2.0-61849171892&doi=10.1017%2FS0022029908003592&partnerID=40&md5=a117643932e2df01d89e6acaacd31332,scopus
4b22c1332c433aaa,Asymmetric impacts of individual investor sentiment on the time-varying risk-return relation in stock market,"This study investigates the impacts of investor sentiments, including individual sentiment and market-wide sentiments, on time-varying risk-return tradeoffs in the U.S. stock market using quantile regressions. Empirical results show that the individual sentiment has a significant negative effect on the time-varying risk-return tradeoff across all quantiles, indicating the heterogeneity of the individual sentiment effect. Specifically, the positive individual sentiment weakens the time-varying risk-return tradeoff while the negative individual sentiment enhances it. Besides, there are asymmetric effects of the individual sentiment at quantiles (0.25, 0.75), that is, a negative individual sentiment associated with bad news has a stronger impact than a positive individual sentiment associated with good news. These findings are robust for alternative estimate methods and individual sentiments. However, the study finds that the time-varying riskreturn tradeoff is less sensitive to the market-wide sentiment than to the individual sentiment, indicating that the individual sentiment is more useful and important in determining the stock price and variation.","He, Zhifang",2022,10.1016/j.iref.2021.11.018,None,wos
1b83d207f7348a04,Asymmetries in exchange rate pass-through and monetary policy principle: Some Caribbean empirical evidence,"The study shows that nonlinear models yield superior unbiased estimates which are free of serial correlation, heteroscedasticity and functional form instability problems which often affect linear models. All six countries have partial exchange rate pass-through, with only The Bahamas recording the lowest pass-through comparable with developed countries which target inflation. The rest of countries, and to a lesser extent Barbados, have high exchange rate pass-through which signifies their vulnerabilities to external inflation. Depreciation results in higher pass-through than appreciation, especially during rising prices/inflation. Nonlinear/threshold cointegration exists in all six countries. TAR results show asymmetric adjustment towards long-run equilibrium in The Bahamas, Guyana and to a lesser extent Jamaica, and symmetric adjustment in Barbados, Belize and Trinidad-Tobago. M-TAR results show asymmetric adjustment in four countries, while Guyana and Trinidad-Tobago experience symmetric adjustment. Taylor's rule is effective in The Bahamas, insignificant in Trinidad-Tobago; and ineffective in the rest of the countries. Appreciation is the most effective operating target for central banks to reduce inflation in The Bahamas, Barbados, Guyana and Jamaica. © 2019 Elsevier B.V., All rights reserved.","Ghartey, E.E.",2019,10.1016/j.najef.2018.05.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047390611&doi=10.1016%2Fj.najef.2018.05.001&partnerID=40&md5=031863a6cf182b0e8952be0d6eeb64d3,scopus
cc2d45a53ccb3e61,Asymmetry in the link between the yield spread and industrial production: Threshold effects and forecasting,"We analyse the nonlinear behaviour of the information content in the spread for future real economic activity. The spread linearly predicts one-year-ahead real growth in nine industrial production sectors of the USA and four of the UK over the last 40 years. However, recent investigations on the spread-real activity relation have questioned both its linear nature and its time-invariant framework. Our in-sample empirical evidence suggests that the spread-real activity relationship exhibits asymmetries that allow for different predictive power of the spread when past spread values were above or below some threshold value. We then measure the out-of-sample forecast performance of the nonlinear model using predictive accuracy tests. The results show that significant improvement in forecasting accuracy, at least for one-step-ahead forecasts, can be obtained over the linear model. Copyright (C) 2004 John Wiley Sons, Ltd.","Paya, I; Venetis, IA; Peel, DA",2004,10.1002/for.921,None,wos
996de93213bec4cf,Audit firm tenure and the equity risk premium,"Although investor perceptions of audit quality play a critical role in maintaining systemic confidence in the integrity of financial accounting reports (Levitt [2000]), prior research on the effects of auditor tenure from an investor perspective is relatively sparse. In this study, we investigate whether investors price audit firm tenure for Big Five audits by examining the relation between tenure and the ex ante equity risk premium, that is, the excess of the company-specific ex ante cost of equity capital over the risk-free interest rate. Based on prior research, whereas the ""auditor learning"" argument predicts that audit quality will change in only one direction (i.e., improve) with tenure, the ""auditor-client closeness"" argument suggests that audit quality may decrease beyond some (albeit unspecified) length of tenure because of impaired auditor independence and objectivity. Consistent with prior theoretical arguments, we find some evidence of a nonlinear relation between audit firm tenure and the ex ante equity risk premium, that is, we find that the equity risk premium decreases in the early years of tenure but increases with additional years of tenure. These findings persist after we control for well-known risk factors and company characteristics that have been shown in prior research to be related to the cost of equity capital. The implications of our findings are discussed. © 2018 Elsevier B.V., All rights reserved.","Boone, J.P.; Khurana, I.K.; Raman, K.K.",2008,10.1177/0148558x0802300107,https://www.scopus.com/inward/record.uri?eid=2-s2.0-39049110814&doi=10.1177%2F0148558X0802300107&partnerID=40&md5=afbbdddf8ba8026c99f86443de6bb403,scopus
c082017acc820446,Autoencoder-Based Three-Factor Model for the Yield Curve of Japanese Government Bonds and a Trading Strategy,"Interest rates are representative indicators that reflect the degree of economic activity. The yield curve, which combines government bond interest rates by maturity, fluctuates to reflect various macroeconomic factors. Central bank monetary policy is one of the significant factors influencing interest rate markets. Generally, when the economy slows down, the central bank tries to stimulate the economy by lowering the policy rate to establish an environment in which companies and individuals can easily raise funds. In Japan, the shape of the yield curve has changed significantly in recent years following major changes in monetary policy. Therefore, an increasing need exists for a model that can flexibly respond to the various shapes of yield curves. In this research, we construct a three-factor model to represent the Japanese yield curve using the machine learning approach of an autoencoder. In addition, we focus on the model parameters of the intermediate layer of the neural network that constitute the autoencoder and confirm that the three automatically generated factors represent the “Level,” “Curvature,” and “Slope” of the yield curve. Furthermore, we develop a long–short strategy for Japanese government bonds by setting their valuation with the autoencoder, and we confirm good performance compared with the trend-follow investment strategy.","Suimon, Yoshiyuki; Sakaji, Hiroki; Izumi, Kiyoshi; Matsushima, Hiroyasu",2020,10.3390/jrfm13040082,None,proquest
28706c3e7bae92e6,BEKKs: An R Package for Estimation of Conditional Volatility of Multivariate Time Series,"We describe the R package BEKKs, which implements the estimation and diagnostic analysis of a prominent family of multivariate generalized autoregressive conditionally heteroskedastic (MGARCH) processes, the so-called BEKK models. Unlike existing software packages, we make use of analytical derivatives implemented in efficient C++ code for nonlinear log-likelihood optimization. This allows fast parameter estimation even in higher model dimensions N > 3. The baseline BEKK model is complemented with an asymmetric parameterization that allows for a flexible modeling of conditional (co)variances. Furthermore, we provide the user with the simplified scalar and diagonal BEKK models to deal with high dimensionality of heteroskedastic time series. The package is designed in an object-oriented way featuring a comprehensive toolbox of methods to investigate and interpret, for instance, volatility impulse response functions, risk estimation and forecasting (VaR) and a backtesting algorithm to compare the forecasting performance of alternative BEKK models. For illustrative purposes, we analyze a bivariate ETF return series (S&P, US treasury bonds) and a four-dimensional system comprising, in addition, a gold ETF and changes of a log oil price by means of the suggested package. We find that the BEKKs package is more than 100 times faster for time series systems of dimension N > 3 than other existing packages. © 2024 Elsevier B.V., All rights reserved.","Fülle, M.J.; Lange, A.; Hafner, C.M.; Herwartz, H.",2024,10.18637/jss.v111.i04,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211314976&doi=10.18637%2Fjss.v111.i04&partnerID=40&md5=64e7416bf0ca62d1bfe6d56bc4055e20,scopus
d4426d9a9ebcd78f,Baltic Dry Index Estimation With NARX Neural Network Model,"Abstract. BDI is a global trade indicator followed by those interested in maritime trade. But it has volatility, seasonality, and uncertain cyclicality. For this reason, in this study, the BDI has been estimated to provide preliminary information to those interested in maritime trade. NARX Neural Network which performs successfully in complex and nonlinear real-life problems is used. In addition, the NARX neural network model has not been found in a previous study used for BDI estimation. Eleven independent variables are used in this study, what increases the predictive power. Independent variables are Bloomberg Commodities Index (BCOM), Twitter-Based Economic Uncertainty Index (TEU), Twitter-Based Market Uncertainty Index (TMU), S&P 500 Index, MSCI World Index, €/$ Parity, VIX (CBOE), US 10-Year Bond Yield (%), Brent Oil (USD/Barrel), Economic Uncertainty Index and World Trade Volume (USD Billion). The Twitter-Based Economic Uncertainty Index (TEU) and Twitter-Based Market Uncertainty Index (TMU), which were not used before in BDI estimation studies, were included in the analysis and contributed to the literature. The data set contains daily data for the period 9.07.2012-31.08.2020. 11-day estimate values covering 1.09.2020-15.09.2020 are calculated. MAPE, MAE and RMSE performance criteria were calculated for the estimation values. Value of MAPE (2.96%), value of MAE (36.6%) and value of RMSE (46.68) were obtained. As a result, the estimate values were compared with the actual values.","Kılınç, Gamze; Kocabıyık, Turan; Karaatlı, Meltem",2023,10.15388/ekon.2023.102.1.4,None,proquest
dc9164700f08b9ff,Bank portfolio exposure to emerging markets and its effects on bank market value,"This study estimates a model of banking company equity returns taking into consideration book value and market value measures of their exposure to emerging markets debt. In this estimation, general systematic market factors, such as the rate of return on the S&P500 stock index and yields on a constant maturity 5-year Treasury note, are held constant such that the exposure variables are accounting for effects due to banks' exposure to emerging market debt. The results, although not uniform among banking companies, support the hypothesis that the extent of exposure to emerging market debt are factored into the valuation of banking company equity contemporaneously. The inclusion of a market value indicator adds to the explanation of equity returns of some banks. It is also clear that knowing the extent of the exposure on a book value basis is important information alone that may allow investors to take account of or evaluate the effects of changes in banking company equity valuation from LDC debt exposures. We also perform an event study for three major debt crises to determine whether the market recognizes the effects of these events on bank valuation. The event study results show that there is little information from identifying the time period of the crises on banking company equity returns. Explanations for this are that the information of these possible crises has been embedded in bank changes in exposure and that the market valuation of the emerging market debt is already accounted for by our model. (c) 2005 Elsevier B.V. All rights reserved.","Fissel, GS; Goldberg, L; Hanweck, GA",2006,10.1016/j.jbankfin.2005.05.013,None,wos
dfcbbfd4ce4c41f2,"Bank risks, capital and loan supply: evidence from Sierra Leone","Purpose -- The study aims to investigate the factors that influence banks' loan supply in Sierra Leone. More specifically, it seeks to look into the effects of risk premium, leverage ratio and credit risk on banks' loan supply in Sierra Leone. Design/methodology/approach -- Using annual bank level data on an unbalanced panel of 13 commercial banks data observed over a period of ten years (2002 to 2011), the study employs time and bank-specific fixed effects model for estimation. Findings -- The findings indicate that risk premium, the share of non-performing loans in the banks' loan portfolio, tier 1 capital ratio (leverage ratio) and local currency deposit levels positively and significantly affect the share of loan supply to the private sector in banks' earning assets. On the other hand, advances to local currency deposit ratio and bank size have significant negative effects on the share of loans in banks assets. The study also finds bank type and the growth rate of real GDP (a proxy for economic activity) to be important determinants of the share of loans in banks' earning assets. Practical implications -- The study recommends that the monetary authorities, banking practitioners and the government should pay keen attention to the key risk factors such as non-performing loans and risk premium in the operation of the banking sector to boost commercial banks' loan supply. Originality/value -- Sierra Leone's banking sector presents a unique opportunity to study bank loan supply in relation to bank-specific features in the context of post-war financial reconstruction. Adapted from the source document.","Osei-Assibey, Eric; Bockarie, Baimba Augustine",2013,10.1108/jfep-09-2012-0041,None,proquest
b917561dfec7c669,Banking and Currency Crises: Differential Diagnostics for Developed Countries,"We identify a set of ‘rules of thumb’ that characterize economic, financial and structural conditions preceding the onset of banking and currency crises in 36 advanced economies over 1970–2010. We use the classification and regression tree methodology and its random forest extension, which permits the detection of key variables driving binary crisis outcomes, allows for interactions among key variables and determines critical tipping points. We distinguish between basic country conditions, country structural characteristics and international developments. We find that crises are more varied than they are similar. For banking crises, we find that low net interest rate spreads in the banking sector and a shallow, or inverted, yield curve is their most important forerunners in the short term. In the longer term, it is high house price inflation. For currency crises, high domestic short-term rates coupled with overvalued exchange rates are the most powerful short-term predictors. We find that both country structural characteristics and international developments are relevant banking-crisis predictors. Currency crises, however, seem to be driven more by country idiosyncratic, short-term developments. We find that some variables, such as the domestic credit gap, provide important unconditional signals, but it is difficult to use them as conditional signals and, more importantly, to find relevant threshold values. Copyright © 2016 John Wiley & Sons, Ltd. © 2017 Elsevier B.V., All rights reserved.","Joy, M.; Rusnák, M.; Šmídková, K.; Vašíček, B.",2017,10.1002/ijfe.1570,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997815830&doi=10.1002%2Fijfe.1570&partnerID=40&md5=ad5779af0086673cb5576a2c30dc058f,scopus
91cd7e8cbfa567ea,Bayesian Factor-adjusted Sparse Regression,"Many sparse regression methods are based on the assumption that covariates are weakly correlated, which unfortunately do not hold in many economic and financial datasets. To address this challenge, we model the strongly-correlated covariates by a factor structure: strong correlations among covariates are explained by common factors and the remaining variations are interpreted as idiosyncratic components. We then propose a factor-adjusted sparse regression model with both common factors and idiosyncratic components as decorrelated covariates and develop a semi-Bayesian method. Parameter estimation rate-optimality and model selection consistency are established by non-asymptotic analyses. We show on simulated data that the semi-Bayesian method outperforms its Lasso analogue, manifests insensitivity to the overestimates of the number of common factors, pays a negligible price when covariates are not correlated, scales up well with increasing sample size, dimensionality and sparsity, and converges fast to the equilibrium of the posterior distribution. Numerical results on a real dataset of U.S. bond risk premia and macroeconomic indicators also lend strong supports to the proposed method.Many sparse regression methods are based on the assumption that covariates are weakly correlated, which unfortunately do not hold in many economic and financial datasets. To address this challenge, we model the strongly-correlated covariates by a factor structure: strong correlations among covariates are explained by common factors and the remaining variations are interpreted as idiosyncratic components. We then propose a factor-adjusted sparse regression model with both common factors and idiosyncratic components as decorrelated covariates and develop a semi-Bayesian method. Parameter estimation rate-optimality and model selection consistency are established by non-asymptotic analyses. We show on simulated data that the semi-Bayesian method outperforms its Lasso analogue, manifests insensitivity to the overestimates of the number of common factors, pays a negligible price when covariates are not correlated, scales up well with increasing sample size, dimensionality and sparsity, and converges fast to the equilibrium of the posterior distribution. Numerical results on a real dataset of U.S. bond risk premia and macroeconomic indicators also lend strong supports to the proposed method.","Fan, Jianqing; Jiang, Bai; Sun, Qiang",2022,10.1016/j.jeconom.2020.06.012,None,proquest
331b25330b0d6585,Bayesian estimation of generalized hyperbolic skewed student GARCH models,"Efficient posterior simulators for two GARCH models with generalized hyperbolic disturbances are presented. The first model, GHt-GARCH, is a threshold GARCH with a skewed and heavy-tailed error distribution; in this model, the latent variables that account for skewness and heavy tails are identically and independently distributed. The second model, ODLV-GARCH, is formulated in terms of observation-driven latent variables; it automatically incorporates a risk premium effect. Both models nest the ordinary threshold t-GARCH as a limiting case. The GHt-GARCH and ODLV-GARCH models are compared with each other and with the threshold t-GARCH using five publicly available asset return data sets, by means of Bayes factors, information criteria, and classical forecast evaluation tools. The GHt-GARCH and ODLV-GARCH models both strongly dominate the threshold t-GARCH, and the Bayes factors generally favor GHt-GARCH over ODLV-GARCH. A Markov switching extension of GHt-GARCH is also presented. This extension is found to be an empirical improvement over the single-regime model for one of the five data sets. © 2010 Elsevier B.V. All rights reserved. © 2012 Elsevier B.V., All rights reserved.","Deschamps, P.J.",2012,10.1016/j.csda.2011.10.021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862002336&doi=10.1016%2Fj.csda.2011.10.021&partnerID=40&md5=8ad3dd3fea5afe72e5ab50f367c7831f,scopus
3b84aee29f05f089,Bayesian estimation of stable CARMA spot models for electricity prices,"We develop a Bayesian estimation procedure for the electricity spot price model in Benth et al. (2014). This model incorporates a trend and seasonality component, a stable CARMA process for the price spikes, and an additional Lévy process for mid-range price level changes. Our MCMC algorithm has two advantages over the existing stepwise estimation procedure presented in Benth et al. (2014): First, since our algorithm produces samples from the full posterior distribution over all parameters, we can estimate the parameters much more accurately, which is shown in simulation studies. Second, we can provide accuracy measures as credibility intervals in addition to the point estimates. The approach is quite general, so that it can be adapted also to other similar pricing models. For illustration, we analyse spot and future prices from the EEX using the new Bayesian method and provide estimates for the risk premium together with credibility regions. © 2019 Elsevier B.V., All rights reserved.","Müller, G.; Seibert, A.",2019,10.1016/j.eneco.2018.10.016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057586272&doi=10.1016%2Fj.eneco.2018.10.016&partnerID=40&md5=c80f6183b56a7b047b29e1f7324535da,scopus
aaff782e22358a7e,Bayesian inference and state number determination for hidden Markov models: an application to the information content of the yield curve about inflation,"This paper is concerned with Bayesian inference in hidden Markov models. Focusing oil switching regression models, we propose a new methodology that delivers a joint estimation of the parameters and the number of regimes that have actually appeared in the studied sample. The only prior information that is required on the latter quantity is an upper bound. We implement a particle filter algorithm to compute the corresponding estimates. Applying this methodology to the information content of the yield curve regarding future inflation in four OECD countries, we show that the predictive content for given country and combination of maturities is subject to regime switching. (C) 2003 Elsevier B.V. All rights reserved.","Chopin, N; Pelgrin, F",2004,10.1016/j.jeconom.2003.12.010,None,wos
6201003eedc6f1e7,Bayesian inference for long memory term structure models,"In this study, we propose a novel adaptation of the Dynamic Nelson–Siegel term structure model, incorporating long memory properties to enhance its forecasting accuracy. Our approach involves modelling the evolution of latent factors using fractional Gaussian noise processes, approximated by a weighted sum of independent first-order autoregressive components. The resulting formulation allows for a Gaussian Markov Random Field representation, facilitating the application of computationally efficient Bayesian techniques through Integrated Nested Laplace Approximations. Extensive simulation and empirical analysis demonstrate that integrating long memory significantly improves the model's forecasting performance, particularly for longer time horizons. By shedding light on the potential benefits of incorporating long memory concepts into traditional term structure models, our research highlights its utility in capturing intricate temporal dependencies and enhancing prediction precision.","Valente, Fernanda; Laurini, Márcio",2024,10.1080/00949655.2023.2299938,None,proquest
dd98079f619d0fee,Bayesian inference for the hazard term structure with functional predictors using Bayesian predictive information criteria,"A Bayesian method for estimation of a hazard term structure is presented in a functional data analysis framework. The hazard terms structure is designed to include the effects of changes in economic conditions, as well as trends in stock prices and accounting variables from financial statements. The hazard function contains time-varying parameters that are modelled using splines. To estimate the model parameters, a Markov-chain Monte Carlo sampling algorithm is developed. The Bayesian predictive information criterion is employed to assess the default predictive power of the estimated model. The method is then applied to a Japanese firm's default data listed on the Japanese Stock Exchange. The results demonstrate that the proposed method performs well. © 2007 Elsevier B.V. All rights reserved. © 2009 Elsevier B.V., All rights reserved.","Ando, T.",2009,10.1016/j.csda.2007.12.014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-61549125754&doi=10.1016%2Fj.csda.2007.12.014&partnerID=40&md5=c8e5911b96b6a03f4d653c0cb4b296cb,scopus
4b816497adef29ec,Bayesian inference in a Stochastic Volatility Nelson-Siegel model,"Bayesian inference is developed and applied for an extended Nelson-Siegel term structure model capturing interest rate risk. The so-called Stochastic Volatility Nelson-Siegel (SVNS) model allows for stochastic volatility in the underlying yield factors. A Markov chain Monte Carlo (MCMC) algorithm is proposed to efficiently estimate the SVNS model using simulation-based inference. The SVNS model is applied to monthly US zero-coupon yields. Significant evidence for time-varying volatility in the yield factors is found. The inclusion of stochastic volatility improves the model's goodness-of-fit and clearly reduces the forecasting uncertainty, particularly in low-volatility periods. The proposed approach is shown to work efficiently and is easily adapted to alternative specifications of dynamic factor models revealing (multivariate) stochastic volatility. © 2010 Elsevier B.V. All rights reserved. © 2012 Elsevier B.V., All rights reserved.","Hautsch, N.; Yang, F.",2012,10.1016/j.csda.2010.07.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862010805&doi=10.1016%2Fj.csda.2010.07.003&partnerID=40&md5=2473ed923e34cceeeb4420f58f6ec03d,scopus
fd600085dd1ac45f,Bayesian inference via filtering equations for ultrahigh frequency data (I): Model and estimation,"We propose a general partially observed framework of Markov processes with marked point process observations for ultrahigh frequency (UHF) data. The model fits well the stylized facts of UHF data in both macro- and micro-movements, subsumes important existing models, and incorporates the influence of other observable economic or market factors. We develop the corresponding Bayes estimation via a filtering equation to quantify parameter uncertainty. Namely, we derive the normalized filtering equation to characterize the evolution of the posterior distribution, present a weak convergence theorem, and construct consistent, easily parallelizable, recursive algorithms to calculate the joint posteriors and the Bayes estimates for streaming UHF data. Moreover, a sufficient condition for the consistency of the Bayes estimators is provided. The general estimation theory is illustrated by four specific models built for U.S. Treasury notes transactions data from GovPX. We show that in this market, both information-based and inventory management-based motives are significant factors in the trade-to-trade price volatility. © 2021 Elsevier B.V., All rights reserved.","Hu, G.X.; Kuipers, D.R.; Zeng, Y.",2018,10.1137/16m1094762,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046007287&doi=10.1137%2F16M1094762&partnerID=40&md5=09a7b04e5b748673463cf6778c6055f0,scopus
fd425a361c8e4fbd,Belgian economic policy uncertainty index: Improvement through text mining,"Recently, the literature has measured economic policy uncertainty using news references, resulting in the frequently-mentioned ‘Economic Policy Uncertainty index’ (EPU). In the original setup, a news article is assumed to address policy uncertainty if it contains certain predefined keywords. We argue that the original setup is prone to measurement error, and propose an alternative methodology using text mining techniques. We compare the original method to modality annotation and support vector machines (SVM) classification in order to create an EPU index for Belgium. Validation on an out-of-sample test set speaks in favour of using an SVM classification model for constructing a news-based policy uncertainty indicator. The indicators are then used to forecast 10 macroeconomic and financial variables. The original method of measuring EPU does not have predictive power for any of these 10 variables. The SVM indicator has a higher predictive power and, notably, changes in the level of policy uncertainty during tumultuous periods of high uncertainty and risk can predict changes in the sovereign bond yield and spread, the credit default swap spread, and consumer confidence. © 2018 Elsevier B.V., All rights reserved.","Tobback, E.; Naudts, H.; Daelemans, W.; Junqué de Fortuny, E.; Martens, D.",2018,10.1016/j.ijforecast.2016.08.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001799528&doi=10.1016%2Fj.ijforecast.2016.08.006&partnerID=40&md5=a3c133019eda083c81645c0cff02d8cb,scopus
eb04dae4c9d8b62c,Benchmark bonds interactions under regime shifts,"In the present paper we examine the interactions among five benchmark ten year government bonds, namely those of the USA, Germany, France, Italy and the Netherlands. Our aim is to illustrate empirically a net of interactions existing among the major bond markets of Europe and the US market taking into account shifts in the underlying stochastic processes. For this purpose, differing from the rest of the relevant empirical literature, after specifying the long run equilibrium relations, we estimate the linkages between the bond markets as subject to hidden Markov chains, by applying the Markov Switching Vector Error Correction framework (MS-VECM). This formulation is found to efficiently reflect the shifts brought about by significant economic events, such as the European monetary unification. As a result we illustrate different short-run relations referring to the periods before and after the monetary union. Overall, our empirical results indicate that stronger interactions among the markets of the system exist in the period after the EMU. Also, by means of a variance decomposition analysis we assess leader-follower relations which indicate that the benchmark status of bonds has changed since the introduction of the common monetary policy framework in Europe. Reprinted by permission of Blackwell Publishers","Georgoutsos, Dimitris A; Migiakis, Petros M",2012,10.1111/j.1468-036x.2009.00535.x,None,proquest
ab700dd24895596c,Berry-Esseen inequalities for the fractional Black-Karasinski model of term structure of interest rates,"The Black-Karasinski model is a one-factor non-affine interest rate model as it describes interest rate movements driven by a single source of randomness and the drift function is a nonlinear function of the interest rate. The drift parameters represent the level and the speed of mean reversion of the interest rate. It belongs to the class of no-arbitrage models. The paper introduces some new approximate minimum contrast estimators of the mean reversion speed parameter in the model based on discretely sampled data which are efficient and studies their asymptotic distributional properties with precise rates of convergence. © 2022 Elsevier B.V., All rights reserved.","Bishwal, J.P.N.",2022,10.1515/mcma-2022-2111,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128529022&doi=10.1515%2Fmcma-2022-2111&partnerID=40&md5=0df5d76b3a1c89a37cef11986d99cff1,scopus
fe830c5db5e38b8f,Beyond Stochastic Volatility and Jumps in Returns and Volatility,"While a great deal of attention has been focused on stochastic volatility in stock returns, there is strong evidence suggesting that return distributions have time-varying skewness and kurtosis as well. Under the risk-neutral measure, for example, this can be observed from variation across time in the shape of Black Scholes implied volatility smiles. This article investigates model characteristics that are consistent with variation in the shape of return distributions using a stochastic volatility model with a regime-switching feature to allow for random changes in the parameters governing volatility of volatility, leverage effect, and jump intensity. The analysis consists of two steps. First, the models are estimated using only information from observed returns and option-implied volatility. Standard model assessment tools indicate a strong preference in favor of the proposed models. Since the information from option-implied skewness and kurtosis is not used in fitting the models, it is available for diagnostic purposes. In the second step of the analysis, regressions of option-implied skewness and kurtosis on the filtered state variables (and some controls) suggest that the models have strong explanatory power for these characteristics.","Durham, Garland; Park, Yang-Ho",2013,10.1080/07350015.2013.747800,None,wos
4353d80b6dc1ec37,Bias in estimating multivariate and univariate diffusions,"Multivariate continuous time models are now widely used in economics and finance. Empirical applications typically rely on some process of discretization so that the system may be estimated with discrete data. This paper introduces a framework for discretizing linear multivariate continuous time systems that includes the commonly used Euler and trapezoidal approximations as special cases and leads to a general class of estimators for the mean reversion matrix. Asymptotic distributions and bias formulae are obtained for estimates of the mean reversion parameter. Explicit expressions are given for the discretization bias and its relationship to estimation bias in both multivariate and in univariate settings. in the univariate context, we compare the performance of the two approximation methods relative to exact maximum likelihood (ML) in terms of bias and variance for the Vasicek process. The bias and the variance of the Euler method are found to be smaller than the trapezoidal method, which are in turn smaller than those of exact ML. Simulations suggest that when the mean reversion is slow, the approximation methods work better than ML, the bias formulae are accurate, and for scalar models the estimates obtained from the two approximate methods have smaller bias and variance than exact ML For the square root process, the Euler method outperforms the Nowman method in terms of both bias and variance. Simulation evidence indicates that the Euler method has smaller bias and variance than exact ML, Nowman's method and the Milstein method. (C) 2010 Elsevier B.V. All rights reserved.","Wang, Xiaohu; Phillips, Peter C. B.; Yu, Jun",2011,10.1016/j.jeconom.2010.12.006,None,wos
f94a815f95694f43,Bias in the estimation of the mean reversion parameter in continuous time models,"It is well known that for continuous time models with a linear drift standard estimation methods yield biased estimators for the mean reversion parameter both in finite discrete samples and in large in-fill samples. In this paper, we obtain two expressions to approximate the bias of the least squares/maximum likelihood estimator of the mean reversion parameter in the Ornstein-Uhlenbeck process with a known long run mean when discretely sampled data are available. The first expression mimics the bias formula of Marriott and Pope (1954) for the discrete time model. Simulations show that this expression does not work satisfactorily when the speed of mean reversion is slow. Slow mean reversion corresponds to the near unit root situation and is empirically realistic for financial time series. An improvement is made in the second expression where a nonlinear correction term is included into the bias formula. It is shown that the nonlinear term is important in the near unit root situation. Simulations indicate that the second expression captures the magnitude, the curvature and the non-monotonicity of the actual bias better than the first expression. (C) 2012 Elsevier B.V. All rights reserved.","Yu, Jun",2012,10.1016/j.jeconom.2012.01.004,None,wos
d7cc9979d5792ab1,Biased Bayesian learning with an application to the risk-free rate puzzle,"Based on the axiomatic framework of Choquet decision theory, we develop a closed-form model of Bayesian learning with ambiguous beliefs about the mean of a normal distribution. In contrast to rational models of Bayesian learning the resulting Choquet Bayesian estimator results in a long-run bias that reflects the agent's ambiguity attitudes. By calibrating the standard equilibrium conditions of the consumption based asset pricing model we illustrate that our approach contributes towards a resolution of the risk-free rate puzzle. For a plausible parameterization we obtain a risk-free rate in the range of 3.5-5%. This is 1-2.5% closer to the empirical risk-free rate than according calibrations of the rational expectations model. (C) 2013 Elsevier B.V. All rights reserved.","Ludwig, Alexander; Zimper, Alexander",2014,10.1016/j.jedc.2013.11.007,None,wos
19bdb59e2615ce25,"Big data analytics in economics: What have we learned so far, and where should we go from here?","Research into predictive accuracy testing remains at the forefront of the forecasting field. One reason for this is that rankings of predictive accuracy across alternative models, which under misspecification are loss function dependent, are universally utilized to assess the usefulness of econometric models. A second reason, which corresponds to the objective of this paper, is that researchers are currently focusing considerable attention on so‐called big data and on new (and old) tools that are available for the analysis of this data. One of the objectives in this field is the assessment of whether big data leads to improvement in forecast accuracy. In this survey paper, we discuss some of the latest (and most interesting) methods currently available for analyzing and utilizing big data when the objective is improved prediction. Our discussion includes a summary of various so‐called dimension reduction, shrinkage and machine learning methods as well as a summary of recent tools that are useful for ranking prediction models associated with the implementation of these methods. We also provide a brief empirical illustration of big data in action, in which we show that big data are indeed useful when predicting the term structure of interest rates.","Swanson, Norman R; Xiong, Weiqi",2018,10.1111/caje.12336,None,proquest
60a879db8106ce03,Bilateral multiple gamma returns: Their risks and rewards,"The bilateral gamma model for returns is naturally derived from the lognormal model. Maximizing entropy in a random time change delivers the symmetric variance gamma model. The asymmetric variance gamma follows on incorporating skewness. Differential speeds for the upward and downward motions lead to the bilateral gamma. A further generalizations results in the bilateral double gamma model when the speed parameter of the bilateral gamma model is itself taken to be gamma distributed on entropy maximization. A rich five to seven parameter specification of preferences renders possible the extraction of physical densities from option prices. The quality of such extraction is measured by examining the uniformity of the estimated distribution functions evaluated at realized forward returns. The economic value of risky returns is seen to embed three/five risk premia for the bilateral gamma/bilateral double gamma. For the bilateral gamma they are up and down side volatilities compensated in up and down side drifts, and the down side drift compensated in the up side drift. For the bilateral double gamma one adds in addition compensations for skewness. Results reveal a drop in the down side risk premiumsince the crisis with an increase in the recent period.","Madan, Dilip B.; Schoutens, Wim; Wang, King",2020,10.1142/s2424786320500085,None,wos
3cf97d4770aaca9e,Binomial Markov-Switching Multifractal model with Skewed t innovations and applications to Chinese SSEC Index,"This paper presents the Binomial Markov-switching Multifractal (BMSM) model of asset returns with Skewed t innovations (BMSM-Skewed t for short), which considers the fat tails, skewness and multifractality in asset returns simultaneously. The parameters of BMSM-Skewed t model can be estimated by Maximum Likelihood (ML) methods, and volatility forecasting can be accomplished via Bayesian updating. In order to evaluate the performance of BMSM-Skewed t model, BMSM model with Normal innovations (BMSM-N), BMSM model with Student-t innovations (BMSM-t) and GARCH(1,1) models (GARCH-N, GARCH-t and GARCH-Skewed t) are chosen for comparison. Through empirical studies on Shanghai Stock Exchange Composite Index (SSEC), we find that for sample estimation, BMSM models outperform the GARCH(1,1) models through BIC and AIC rules, and BMSM-Skewed t performs the best among all the models due to its fat tails, skewness and multifractality. In addition, BMSM-Skewed t model dominates other models at most forecasting horizons for out-of-sample volatility forecasts in terms of MSE, MAE and SPA test. (C) 2016 Elsevier B.V. All rights reserved.","Liu, Yufang; Zhang, Weiguo; Fu, Junhui",2016,10.1016/j.physa.2016.06.014,None,wos
72beeece03449e4d,Bitcoin transaction strategy construction based on deep reinforcement learning,"The emerging cryptocurrency market has lately received great attention for asset allocation due to its decentralization uniqueness. However, its volatility and brand new trading mode has made it challenging to devising an acceptable automatically-generating strategy. This study proposes a framework for automatic high-frequency bitcoin transactions based on a deep reinforcement learning algorithm — proximal policy optimization (PPO). The framework creatively regards the transaction process as actions, returns as awards and prices as states to align with the idea of reinforcement learning. It compares advanced machine learning-based models for static price predictions including support vector machine (SVM), multi-layer perceptron (MLP), long short-term memory (LSTM), temporal convolutional network (TCN), and Transformer by applying them to the real-time bitcoin price and the experimental results demonstrate that LSTM outperforms. Then an automatically-generating transaction strategy is constructed building on PPO with LSTM as the basis to construct the policy. Extensive empirical studies validate that the proposed method perform superiorly to various common trading strategy benchmarks for a single financial product. The approach is able to trade bitcoins in a simulated environment with synchronous data and obtains a 31.67% more return than that of the best benchmark, improving the benchmark by 12.75%. The proposed framework can earn excess returns through both the period of volatility and surge, which opens the door to research on building a single cryptocurrency trading strategy based on deep learning. Visualizations of trading the process show how the model handles high-frequency transactions to provide inspiration and demonstrate that it can be expanded to other financial products. © 2021 Elsevier B.V., All rights reserved.","Liu, F.; Li, Y.; Li, B.; Li, J.; Xie, H.",2021,10.1016/j.asoc.2021.107952,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117191473&doi=10.1016%2Fj.asoc.2021.107952&partnerID=40&md5=3f33a1f33bc09779c5d4f95e042f6975,scopus
351b5218c7102054,Black-Scholes Fuzzy Numbers as Indexes of Performance,"We use the set of propositions of some previous papers to define a fuzzy version of the Black-Scholes value where the risk free instantaneous interest intensity, the volatility and the initial stock price are fuzzy numbers whose parameters are built with statistical financial data. With our Black-Scholes fuzzy numbers we define indexes of performance varing in time. As an example, with data of the Italian Stock Exchange on MIB30, we see that in 2004 and 2006 our indexes are negative, that is, they are indexes of the refuse to invest and this refuse increased. So, on November 11, 2006 we could forecast that the market will become with more risk: the risk of loss will increase. Now, on January 25, 2010, we know that this forecast has happened. Obviously, the parameters of our Black-Scholes fuzzy numbers can be valued also with incomplete, possibilistic data. With respect to the probabilistic one, our fuzzy method is more simple and immediate to have a forecast on the financial market.","Simonelli, M R",2010,10.1155/2010/607214,None,proquest
3f98ba9b92b7d6ec,Black-litterman model with views prediction using elman recurrent neural network,"The Black-Litterman model is a portfolio model that considers investor views. The purpose of this study is to develop the Black-Litterman (BL) portfolio model with views prediction using Elman Recurrent Neural Network (ERNN) on LQ-45 stocks. The ERNN model is one of the neural network models that adjusts the input using the output feedback from the hidden layer. The BL portfolio is generated based on the capital assets pricing model (CAPM) excess return equilibrium. The data used in CAPM model must fulfill the normality assumption which is checked by using Jarque Bera test. The selected stocks for the portfolio are the member of LQ-45 stocks which meet the normality assumption and have the highest expected excess return CAPM value, those are AKRA, BBNI, INCO, and JSMR stocks. The ERNN model is employed to those stocks to obtain the views prediction. Then, the Black-Litterman portfolio is constructed by combining the ERNN views of the stock returns and the expected equilibrium return yielded by the capital assets pricing model. Three designs of relative views are considered, each design is distinguished from the percentage of each stock return prediction. The simulation shows that the best portfolio is constructed based on the design of the first views due to the most accurate views prediction. © 2021 Elsevier B.V., All rights reserved.","Wutsqa, D.U.; Pamungkas, M.A.; Subekti, R.",2021,10.13189/ujaf.2021.090609,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120813748&doi=10.13189%2Fujaf.2021.090609&partnerID=40&md5=79efd1877b35d6a272814a5d81943845,scopus
8624241783a1b415,Blockchain Innovation for Sustainability: Unraveling Its Market Impact Through Public Attention and Financial Performance,"This study investigates the dynamic interplay between blockchain innovation, public attention, and financial performance, with a focus on sustainability applications. Using a state-space model and the Kalman filter, it analyzes data from blockchain-related patents and Google Trends to assess their influence on the excess returns of blockchain-focused exchange-traded funds (ETFs). The findings highlight that innovation activity significantly enhances financial performance, underscoring blockchain’s role as a general-purpose technology with transformative sustainability potential. Public attention, measured through search interest, independently drives investor sentiment and market outcomes, while the interaction between innovation and public attention does not exhibit significant synergistic effects, suggesting distinct channels of influence. This study contributes to the growing stream of literature in sustainable finance, innovation management, and behavioral finance by introducing a real-time measure of blockchain innovation for sustainability into an asset pricing model, by showing that patent activity and public attention operate as separate predictors of financial returns, and by advancing methodological practice through the use of a state-space approach to capture latent innovation dynamics. The findings suggest actionable strategies: investors can track patent-based innovation and search trends as early signals of thematic-ETF performance; industry leaders can align blockchain projects with sustainability goals to unlock valuation gains; and policymakers can foster environmental, social, and governance innovation ecosystems by encouraging transparent patent disclosure and public awareness.",C. Toscano Hernandez; F. P. Appio; F. Platania,2025,10.1109/tem.2025.3598382,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11123793,ieeexplore
a5caed190c8d52f6,Bond Market Prediction using an Ensemble of Neural Networks,"The characteristics of a successful financial forecasting system are the exploitation of inefficiencies of a given market and the precise application to that market. Overwhelming evidence indicates that opportunities exist for consistent positive returns over a given period of time. This project aims to provide means for the yield curve projection of government bonds. An ensemble of networks such as back propagation, radial basis function, linear regression, is used to predict the yield. The yield is forecasted using technical analysis using historical data and the output is tested for accuracy and accordingly assigned weights. Using the ensemble of neural networks, accuracy has been tried to be maximized and offer near to actual prediction. Using the yield curve, the investor can assess not only the yield of that bond, but can also the interest rates, and hence, has a very useful tool in his hand for investment purpose, thus making decisions about whether to invest or not , and if invest then when to invest. The yield curve prediction not only provides the investor a tool to make investment decisions in bond market, but it also serves as a tool to gauge the macroeconomic conditions of the country and hence predict the movement in various other markets as well, and hence make investment decisions accordingly.","Parekh, Bhagya; Shah, Naineel; Mehta, Rushabh; Shah, Harshil",2013,10.5120/14105-2144,None,proquest
f602c4f1e8740b8d,Bond Risk Premiums with Machine Learning,"We show that machine learning methods, in particular, extreme trees and neural networks (NNs), provide strong statistical evidence in favor of bond return predictability. NN forecasts based on macroeconomic and yield information translate into economic gains that are larger than those obtained using yields alone. Interestingly, the nature of unspanned factors changes along the yield curve: stock- and labor-market-related variables are more relevant for short-term maturities, whereas output and income variables matter more for longer maturities. Finally, NN forecasts correlate with proxies for time-varying risk aversion and uncertainty, lending support to models featuring both channels.","Bianchi, Daniele; Büchner, Matthias; Tamoni, Andrea",2021,10.1093/rfs/hhaa062,None,proquest
da6ebcbcc20f2fd2,Bond return predictability: Macro factors and machine learning methods,"We investigate the impact of macroeconomic variables on bond risk premia prediction via machine learning techniques. On the basis of Chinese treasury bonds from March 2006 to December 2022, we show that adding macroeconomic factors improves bond return forecasts and generates higher economic benefits to investors. This is achieved when the nonlinear relationship between macroeconomic variables and bond returns is modelled via machine learning methods. Furthermore, the importance of macroeconomic determinants changes along the yield curve. Our study sheds new light on the information contained in macroeconomic variables for treasury bond valuation and highlights the importance of utilizing appropriate machine learning methods.","Jiang, Ying; Liu, Xiaoquan; Liu, Yirong; Zhu, Fumin",2024,10.1111/eufm.12483,None,proquest
46572bea2afbeb26,Bond risk premia in a small open economy with volatile capital flows: The case of Korea,"This paper investigates bond risk premia embedded in Korean government bonds. Unlike the U.S., Korea is a small open economy characterized by highly volatile capital flows and non-reserve currency country. My empirical findings show that among alternative predictive variables (including the macro and global liquidity factors) for one-year-ahead excess bond returns, the global liquidity factors, extracted from the panel data set of various global liquidity variables, are the only predictors that perform well across both in- and out-of-sample forecast analysis. In a similar vein, the regression analysis for the determinants of the estimated bond risk premia (with both monthly and quarterly frequencies) reveals that similar to the case of U.S. bond market, the risk premia in Korean government bonds are affected by domestic expected inflation, but more importantly, that they are affected heavily by the global liquidity variables, such as VIX, bank capital flows and the leverage of global banks. (C) 2019 Elsevier Ltd. All rights reserved.","Yun, Jaeho",2019,10.1016/j.jimonfin.2019.01.007,None,wos
72088005c119975b,Bond risk premiums at the zero lower bound,"We document that the spread between long- and short-term government bond yields is a stronger predictor of excess bond returns when the U.S. economy is at the zero lower bound (ZLB) than away from this bound. The Gaussian shadow rate model with a linear or quadratic shadow rate is unable to explain this change in return predictability. The same holds for the quadratic term structure model and the autoregressive gamma-zero model that also enforce the ZLB. In contrast, the linear-rational square-root model explains our new empirical finding because the model allows for unspanned stochastic volatility as seen in bond yields.","Andreasen, Martin M.; Jorgensen, Kasper; Meldrum, Andrew",2025,10.1016/j.jeconom.2024.105939,None,wos
067ccda7c63409f5,Brand Alliances and Stock Reactions,"Purpose: This paper examines the performance and risk of brand alliances by investigating the market value of brand alliances through the analysis of investors’ response, and look into the different reactions of the stock market to brand alliance-type in terms of co-branding and joint-promotion, as well as into the potential different effects in the contexts of B to B versus B to C. Brand alliances, whereby two or more brands are jointly presented to the consumer, have been investigated extensively. The importance of brand alliances is emphasized by two factors: (1) brands are considered critical elements in business-to-business marketing settings; and (2) firms use brand alliances due to the trading costs and investment necessary to buy brands, the increasingly higher costs of launching a new brand onto the market, the high failure rates in new brand launches and brand extensions, the competitive pressures around product launches and diffusion, and the limitations imposed on the extension of a brand by its own identity. Consequently, brand alliances have exploded over recent years. As indicated later, by accomplishing the purpose of this research we fill a gap in the literature as most of the research on brand alliances revolves around consumers’ perspective. Methodology/Approach: The methodology followed is based on the event study method. First, the event study estimates the excess returns of share prices generated by events that were unanticipated by the market. To this end, we estimate the market model and the subsequent abnormal returns. To examine the impact of the publication of a brand alliance announcement on the share prices of the company, we use the cumulative abnormal returns calculated over k days of the event window for 55 announcements. In the second step, we analyze the returns of the different brand alliances. In particular, the abnormal returns are used as dependent variable in a regression analysis, wherein the central explanatory variable is brand alliance type (co-branding vs joint promotion). Finally, the third stage of the methodology analyzes the change in the variance of returns between the periods before and after the brand alliance announcements. Findings: The results show that brand alliance announcements generate positive abnormal returns, which support the hypothesis that brand alliance announcements are positively related to company stock returns. In particular, we observe that the reactions to brand alliances are spread over the event window. In fact, the window (−5,+5) produces returns that stand at 1.6%, which is the greatest abnormal return over the five days around the publication date. The economic impact of a cumulative return of 1.6% in eleven days is tantamount to annual returns of 69.33%. Considering that the average market value of the sample is €17,494 million, it represents an increase of €279 million for the sample stocks on the period (−5,+5). The regression analysis shows that the coefficients of the variable “co-branding” are positive and significant, which supports the hypothesis that co-branding presents higher abnormal returns than joint promotion. However, no differential effect are found between B to B versus B to C paradigms. The results obtained present an increase in the variance of the share prices after the alliance announcement date, which supports the hypothesis that the variance of the company stock returns is positively associated to announcements of brand alliances. Research Implications: The key implication of the measurement of the market value of brand alliances is that research should be reoriented toward a better understanding of the role of marketing in the value creation of a company. Instead of just concentrating on marketing research into consumer behavior, more emphasis should be given to the core company processes that create shareholder value. Practical Implications: The managerial implications of the specific results obtained are the following: the result that companies increase their market value when they implement brand alliance strategies, leads to a better ken of the way alliance activities can be managed when dealing with other organizations. In this way, finding a partner to form a brand alliance with could be a useful objective in terms of firm performance. Moreover, the results show that co-branding presents higher abnormal returns than joint promotion, which suggests that co-branding is the most valuable strategic decision (or long-term decision) for companies, as it implies the simultaneous participation of two or more brands in a single product. In this way, deciding on whether a short- or long-term branding strategy is pursued turns to be fundamental. Originality/Value/Contribution of the paper: The literature has analyzed the consequences of brand alliance, which looks at each partner’s brand attitude after the alliance, the brand equity of the constituent brands after the alliance, and the impact of the allied brand on the evaluation of the host brand. These studies have focused on the area of consumer behavior; that is, by measuring consumers´ attitudes and evaluation. Still, the measurement of dimensions reflecting the other side of the relationship, i.e. the firm, via brand image and equity is critical. Nevertheless, the examination of the impact of brand alliances on the partner company performance and risk has received little attention, despite the fact that “brand perceptions of companies’ products spill over to investment decisions in the market for companies’ stock”. © 2021 Elsevier B.V., All rights reserved.","Mas-Ruiz, F.J.; Nicolau, J.L.; Calderón-Martínez, A.",2021,10.1080/1051712x.2021.1893029,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106229558&doi=10.1080%2F1051712X.2021.1893029&partnerID=40&md5=b86e75377e394e1b65e18c69efb1907f,scopus
7c6e73c3fc3236c1,Buffered vector error-correction models: An application to the U.S. Treasury bond rates,"This paper extends the buffered autoregressive model to the buffered vector error-correction model (VECM). Least squares estimation and a reduced-rank estimation are discussed, and the consistency of the estimators on the delay parameter and threshold parameters is derived. We also propose a supWald test for the presence of buffer-type threshold effect. Under the null hypothesis of no threshold, the supWald test statistic converges to a function of Gaussian process. A bootstrap method is proposed to obtain the p-value for the supWald test. We investigate the effectiveness of our methods by simulation studies. We apply our model to study the monthly Federal bond rates of United States. We find the evidences of buffering regimes and the asymmetric error-correction effect. © 2022 Elsevier B.V., All rights reserved.","Lu, R.; Yu, P.L.H.",2021,10.1515/snde-2019-0047,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094603557&doi=10.1515%2Fsnde-2019-0047&partnerID=40&md5=79cc2936dd1fb0d52d32acd43219b341,scopus
cbc5ab117794f5d0,Building Risk into the Mitigation/Adaptation Decisions simulated by Integrated Assessment Models,"This paper proposes an operationally simple and easily generalizable methodology to incorporate climate change damage uncertainty into Integrated Assessment Models (IAMs). First uncertainty is transformed into a risk measure by extracting damage distribution means and variances from an ensemble of socio economic and climate change scenarios. Then a risk premium is computed under different degrees of risk aversion, quantifying what society would be willing to pay to insure against the uncertainty of the damages. Our estimates show that the premium for the risk is a potentially significant addition to the “standard average damage”, but highly sensitive to the attitudes toward risk. In the last research phase, the risk premium is incorporated into the climate change damage function of a widely used IAM which shows, consequently, a substantial increase in both mitigation and adaptation efforts, reflecting a more precautionary attitude by the social planner. Interestingly, adaptation is stimulated more than mitigation in the first half of this century, while the situation reverses afterwards.","Markandya, Anil; De Cian, Enrica; Drouet, Laurent; Polanco-Martínez, Josué M; Bosello, Francesco",2019,10.1007/s10640-019-00384-1,None,proquest
2aa1f42bb57aced5,Building portfolios based on machine learning predictions,"This paper demonstrates that portfolio optimization techniques represented by Markowitz mean-variance and Hierarchical Risk Parity (HRP) optimizers increase the risk-adjusted return of portfolios built with stocks preselected with a machine learning tool. We apply the random forest method to predict the cross-section of expected excess returns and choose n stocks with the highest monthly predictions. We compare three different techniques—mean-variance, HRP, and 1/N— for portfolio weight creation using returns of stocks from the S&P500 and STOXX600 for robustness. The out-of-sample results show that both mean-variance and HRP optimizers outperform the 1/N rule. This conclusion is in the opposition to a common criticism of optimizers’ efficiency and presents a new light on their potential practical usage. © 2022 Elsevier B.V., All rights reserved.","Kaczmarek, T.; Perez, K.",2022,10.1080/1331677x.2021.1875865,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100727648&doi=10.1080%2F1331677X.2021.1875865&partnerID=40&md5=e01a1a40410b7343778ed004d9e97d84,scopus
aa51b3156f3ce072,"Business cycles, stock market wealth, and gambling at the racetracks","Purpose: As digital technologies expand access to new forms of legalized gambling, including sports betting and online gaming, it is important to assess the impact of macroeconomic and equity market outcomes on fund flows into gambling. The authors’ findings will be of interest to policymakers and the gambling industry, as various forms of gambling, including day trading, gain broad public acceptance. Design/methodology/approach: The authors examine the impact of macroeconomic forces, business cycles, and financial market wealth on gambling. The authors propose a nonlinear model linking aggregate gambling expenditures to macroeconomic, stock market, and gambling industry variables. The authors estimate the proposed model using nonlinear estimation procedures. Findings: The authors find that price of wagering, incomes, and supply of gambling opportunities are the primary determinants of wagering demand. Aggregate wagering is negatively impacted by realized stock returns and market volatility, but rises during recessions. Originality/value: To the best of the authors’ knowledge, the questions posed and addressed in this manuscript have not been addressed in prior literature. © 2024 Elsevier B.V., All rights reserved.","Ramezani, C.A.; Ahern, J.J.",2024,10.1108/jes-03-2023-0120,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164109195&doi=10.1108%2FJES-03-2023-0120&partnerID=40&md5=f3427f470bd95119b06fc28721e86dd2,scopus
0ec6af0b1079b24e,Business performance assessment of small and medium-sized enterprises: Evidence from the Czech Republic,"Business performance assessment is one of the basic tasks of management. Business performance can be assessed using a number of methods. The basic ones include financial analysis, Balanced Scorecard or Economic Value Added (EVA). The paper is focused on SME business performance assessment based on Economic Value Added, calculated using the INFA build-up model. According to this method, companies were divided into four categories. The first category included companies with a positive EVA value. The second category included companies with negative EVA, but with the economic result above the risk-free rate. The third category included companies with a positive economic result above the risk-free rate. The fourth category included companies with a negative economic result. The model did not include companies with negative equity. The input represented 15 predictors based on their financial statements. The data were normalized and all extreme values, likely caused by a data rewriting error, were removed. Company performance is visualized by comparing Principal Component Analysis and Kohonen neural networks. Compared to similar research, the methods are compared using the data that analyzes the performance of companies. Both methods made it possible to visualize the given task. With regard to the purpose of facilitating the interpretation of the results, for the given case, the use of PC seems to be more appropriate.","Stehel, Vojtech; Horak, Jakub; Krulicky, Tomas",2021,10.21511/ppm.19(3).2021.35,None,proquest
acc0253aba3ad46f,CAPM model for the valuation of shares of companies in the construction market during the period 2015 - 2020; Modelo CAPM para la valoración de acciones de las empresas en el mercado de la construcción durante el periodo 2015 - 2020,"This article consisted of the application of the CAPM model on companies listed on the stock exchange of and related to the construction sector in Colombia during the period from January 1, 2015 to December 31, 2020. This research has a quantitative approach with a type of descriptive and longitudinal research. Its methodology consisted in the application of ordinary least squares to the daily volatilities of the asset based on the estimation of the betas, which mostly complied with the probabilistic values and the intercepts were not different from 0, which is consistent with the model hypothesis. As for the variables that accompany the model, the risk-free rate TFIT16240724 was chosen and the ICOLCAP index was chosen as the variable that measures the market risk. Finally obtained the results, these were evaluated, concluding that the beta coefficient is an acceptable indicator in the risk-return assessment of the asset during the period in question, however, as an estimator it is not effective, which reflects the ineffectiveness of the model. © 2023 Elsevier B.V., All rights reserved.","González, G.A.O.; Domínguez, M.R.",2023,10.46661/revmetodoscuanteconempresa.7350,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162148528&doi=10.46661%2Frevmetodoscuanteconempresa.7350&partnerID=40&md5=f21ca467e8fee4b68a7af008bd550b76,scopus
374c0b6ef5ceccd7,CDS risk premia forecasting with multi-featured deep RNNs: An application on BR[I]CS countries,"Using state-of-the-art recurrent neural network architectures, this study attempts to predict credit default swap risk premia for BR[I]CS countries as accurately as possible. In the time series setting, these recurrent neural networks are ELMAN, NARX, GRU, and LSTM RNNs, considering local and global features. The predictive power of each architecture is compared, and the results differ depending on the country. NARX RNN was the best predictor for Brazil and South Africa in various settings. Meanwhile, ELMAN RNN produces more accurate results in China, whereas Russia's long short-term memory RNN achieves the best predictors among other countries’ RNNs. © 2023 Elsevier B.V., All rights reserved.","Kutuk, Y.",2023,10.1016/j.bir.2023.10.013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175864895&doi=10.1016%2Fj.bir.2023.10.013&partnerID=40&md5=a144e84f118885624d72b08a1f1e2dfa,scopus
21724fc90a15e265,CONDITIONAL HETEROSKEDASTICITY IN ASSET RETURNS - A NEW APPROACH,"GARCH models have been applied in modelling the relation between conditional variance and asset risk premia. These models, however, have at least three major drawbacks in asset pricing applications: (i) Researchers beginning with Black (1976) have found a negative correlation between current returns and future returns volatility. GARCH models rule this out by assumption. (ii) GARCH models impose parameter restrictions that are often violated by estimated coefficients and that may unduly restrict the dynamics of the conditional variance process. (iii) Interpreting whether shocks to conditional variance persist or not is difficult in GARCH models, because the usual norms measuring persistence often do not agree. A new form of ARCH is proposed that meets these objections. The method is used to estimate a model of the risk premium on the CRSP Value-Weighted Market Index from 1962 to 1987.","NELSON, DB",1991,10.2307/2938260,None,wos
d8e65611644bacb9,Calendar anomolies and stock market volatility in selected Arab stock exchanges,"While seasonal effects for both advanced and emerging markets have been investigated extensively in mean and variance equations, Arab region asset markets have received much less attention. The objective of this article is to fill this gap in the literature by investigating the day-of-the-week effect in 12 major Arab stock markets using Arab Monetary Fund (AMF) daily index returns from May 2002 to December 2005. Our estimation strategy utilizes Autoregressive (AR) and Generalized Autoregressive Conditional Heteroscedastic (GARCH)-type specifications to allow for a time-varying variance. Among the most important results of this article are, first, is one-third of these markets exhibit significant day-of-the-week effect in returns. Second, two-third of these markets exhibit significant day-of-the-week effect on volatility. Third, most of these day-of-the-week effects are focused within the beginning and the end of the trading week. Finally, the existence of a significant risk premium was confirmed in five of the 12 studied markets.","Kamaly, A; Tooma, E A",2009,10.1080/09603100802359976,None,proquest
0c6ee05d8b799ba1,Can Brazilian Central Bank communication help to predict the yield curve?,"This paper investigates whether Brazilian Central Bank communication helps to forecast the yield curve. Our forecast strategy involves two steps: First, we analyze textual Central Bank documents to extract sentiment variables that describe its communication, and then, we include those sentiment variables as additional factors into the dynamic Nelson–Siegel term structure model. We found that sentiment variables contain predictive information for yield curve forecasting. Specifically, when combined with macroeconomic variables, the sentiment variables improve the accuracy of the forecast for short maturities and forecast horizons. In addition, sentiment variables are useful in forecasting for medium and long forecast horizons for all maturities. Besides finding a new source of information to forecast the yield curve, the results indicate that the information provided by Central Bank affects market participants, proving to be a useful tool for monetary policy. © 2023 Elsevier B.V., All rights reserved.","de Andrade Alves, C.R.; Joseph Abraham, K.; Laurini, M.",2023,10.1002/for.2964,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148706166&doi=10.1002%2Ffor.2964&partnerID=40&md5=b789cdf18b904f4f1c913cf6b72bf13b,scopus
5c1357ad22be14f6,Can Deep-Learning Models Predict Behavior of Treasury Bond Yields,"Treasury market dominates the fixed-income segment, especially in emerging economies such as India. The Treasury rates affect the investment decisions, portfolio management, capital structure, as well as corporate debt structure decisions of the firms. Even after this huge impact, the Treasury rate prediction problems are less explored. This paper investigates the efficacy of ensemble-based machine learning and deep learning models in predicting the behavior of Treasury bond yields. The work has employed six models on six Treasury index datasets with different maturity periods. The result suggests that the Recurrent Neural Network and its variants are best-suited models to work on Treasury bonds. The Gated Recurrent Unit gives the best result among all Recurrent Network variants. The deep learning models give higher accuracy for the Treasury yield with a greater maturity period. In contrast, the ensemble models perform better on the Treasury yield with a smaller maturity period. The findings call for incorporating machine learning-based prediction in the pricing and valuation of securities, investment plans, and debt structure decisions. © 2025 Elsevier B.V., All rights reserved.","Podder, D.; Mukherjee, R.; Hiremath, G.S.",2025,10.1007/s10614-025-10947-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007230849&doi=10.1007%2Fs10614-025-10947-8&partnerID=40&md5=0d918fe85ff3646830e1f74d6664d2bf,scopus
b2577b00d1f7a76c,Can Ensemble Machine Learning Methods Predict Stock Returns for Indian Banks Using Technical Indicators?,"This paper develops ensemble machine learning models (XGBoost, Gradient Boosting, and AdaBoost in addition to Random Forest) for predicting stock returns of Indian banks using technical indicators. These indicators are based on three broad categories of technical analysis: Price, Volume, and Turnover. Various error metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), Mean Absolute Percentage Error (MAPE), Root-Mean-Squared-Error (RMSE) have been used to check the performance of the models. Results show that the XGBoost algorithm performs best among the four ensemble models. The mean of absolute error and the root-mean-square -error vary around 3–5%. The feature importance plots generated by the models depict the importance of the variables in predicting the output. The proposed machine learning models help traders, investors, as well as portfolio managers, better predict the stock market trends and, in turn, the returns, particularly in banking stocks minimizing their sole dependency on macroeconomic factors. The techniques further assist the market participants in pre-empting any price-volume action across stocks irrespective of their size, liquidity, or past turnover. Finally, the techniques are incredibly robust and display a strong capability in predicting trend forecasts, particularly with any large deviations.","Mohapatra, Sabyasachi; Mohapatra, Sabyasachi; Mukherjee, Rohan; Roy, Arindam; Sengupta, Anirban; Puniyani, Amit",2022,10.3390/jrfm15080350,None,proquest
e50a5412de437bec,Can Voluntary Insurance ensure risk-free digital-banking in Chinese-economy: seeking attentions?,"In today’s business-world, services are carried out in a competitive manner country-wise such as China. Banking services are no different, which has resulted digital-banking. Bank Laws regulated by Central-Bank of China are characterized by evolving many factors that are often unpredictable. It faces serious pitfalls being it riskiness. Most cases, customers don’t read terms & conditions of services. Customers don’t save contract-copy. These weaknesses cause abuses. Customer faces perceived-risk. Dealing with challenges in Chinese-economy, application of Akim’s model - Voluntary Insurance (VI) can be impetus for policy-design, which can increase number of users. Welfare Analyses are used for guidance on setting insurance-price ensuring customer’s efficiency-cost so that the VI becomes appealing to parties involved. It can lead to higher number-of-users. In scenario, bank itself is an insurance-seller, the existence of adverse-selection is detected. Here estimated welfare-cost associated with inefficient-pricing created by adverse-selection is quantitatively small; however, advantageous-selection results opposite. Welfare assessment under alternative policy intervention in Chinese-economy will be vital for future-study.","Rahman, Akim M; Islam, Saadi",2022,10.1080/14765284.2021.1929792,None,proquest
7dabbf5c345dc1a3,Can climate change attention predict energy stock returns?,"We propose a climate change attention (CCA) index based on Google search volume index (GSVI) from 2004 to 2021 and show that it is an economically and statistically significant negative predictor for next month’s energy stock returns. The index is extracted using principal component analysis (PCA), but the results are similar by using the equal-weighted average method. Compared with 14 traditional macroeconomic predictors, CCA performs the best and provides complementary information when added into bivariate and multivariate macro predictive models. When further considering the effect of CCA’s forecasting power over different periods, strong evidence is shown that this outperformance is especially prominent in economic depressions and down market conditions. From the asset allocation perspective, CCA can provide a mean-variance investor with significant economic gains under alternative risk aversions. Our empirical results prove that investors’ attention to climate change contains predictive information for excess returns of global traditional energy stock index.","Jia, Shanghui; Liu, Yingke; Jin, Jiayu",2023,10.1007/s11356-023-28731-2,None,proquest
1b5cd364557d4228,Can deep neural networks outperform Fama-MacBeth regression and other supervised learning approaches in stock returns prediction with asset-pricing factors?,"In asset pricing, most studies focus on finding new factors, such as macroeconomic factors or firm characteristics, to explain risk premiums. Investigating whether these factors help forecast stock returns remains active research in finance and computer science. This paper conducts an extensive comparative analysis using a large set of pricing factors. It compares out-of-sample stock-level and portfolio-level prediction performance among neural networks, the traditional Fama-MacBeth regression, and other supervised learning algorithms such as regression and tree-based algorithms. Our analysis shows the benefit of employing neural networks, and deeper neural networks enjoy marginal improvements in terms of prediction. © 2024 Elsevier B.V., All rights reserved.","Teng, H.-W.; Li, Y.-H.",2023,10.1007/s42521-023-00076-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207820403&doi=10.1007%2Fs42521-023-00076-y&partnerID=40&md5=06ef991afc31574f19f4f932a3174936,scopus
38d168134a26a921,Can forward rates be used to improve interest rate forecasts?,"This paper evaluates the extent to which the explanatory power detected in the term structure in different markets and countries can actually be used to produce sensible forecasts of future short-term interest rates. Specifically, in spite of the forecasting connotation of the unbiasedness property of forward rates, actual evaluation of their forecasting performance has received scant attention in the literature on the term structure. This study uses monthly data for 1978-1998 on interest rates on Euro-deposits on the US dollar, yen, Deutsche mark, British pound, Spanish peseta, French franc, Italian lira and Swiss franc, comparing forecasts obtained from forward rates to those obtained from univariate autoregressions. By themselves, forward rates produce better one-step ahead forecasts, as well as better once-and-for all forecasts of 1-month interest rates over a full year horizon than those obtained from the own past of interest rates. The gain in one-step ahead forecasting disappears for longer maturities, although forward rates still produce better once-and-for all predictions of 3- and 6-month interest rates than univariate autoregressions for a number of currencies. © 2008 Elsevier B.V., All rights reserved.","Domínguez, E.; Novales, A.",2002,10.1080/09603100010007346,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036296125&doi=10.1080%2F09603100010007346&partnerID=40&md5=1ab9a64dfbdfbb88d297fb81367184c4,scopus
accc2a0866415987,Can gold or silver be used as a hedge against policy uncertainty and COVID-19 in the Chinese market?,"Purpose: The purpose of this study is to present evidence as to whether the use of gold or silver can be justified as an asset to hedge against policy uncertainty and COVID-19 in the Chinese market. Design/methodology/approach: By using a GARCH model with a generalized error distribution (GED), this study specifies that the gold (or silver) return is a function of a set of economic and uncertainty variables, which include volatility from interest rate innovation, a change in economic policy uncertainty (EPU), a change in geopolitical risk (GPR) and volatility due to pandemic diseases, while controlling for stock market returns, inflation rates, economic growth and the Chinese currency value. Findings: This study employs monthly data of gold and silver prices over the period from January 2002 to August 2021 to examine hedging behavior. Estimated results show that the gold return is positively correlated to the stock return and a rise in uncertainty from economic policy innovation, geopolitical risk, volatility due to US interest rate innovation as well as COVID-19 infection. This result suggests that gold cannot be used to hedge against a stock market decline, but can be used to hedge against uncertainty in general. However, the silver return only responds positively to a rise in uncertainty from the inflation rate and geopolitical risk. Evidence shows that silver returns are negatively correlated with stock returns, and display hedging characteristics. However, the evidence lacks statistically significance during the COVID-19 period, suggesting that the role of silver as a safe-haven asset against stock market turmoil is weak for this time period. Research limitations/implications: More general nonlinear specifications can be developed. The tests may include different measures of uncertainty that interact with each other or with the lagged error terms. An implication of the model is that gold can be used to hedge against a broad range of uncertainties for economic policy change, political risk and/or a pandemic. However, the use of gold as an asset to hedge against a stock downturn in Chinese market should be done with caution. Practical implications: This study has important policy implications as regards a choice in assets in formatting a portfolio to hedge against uncertainty. Specifically, this study presents empirical evidence on gold and silver return behavior and finds that gold returns respond positively to heightened uncertainty. Thus, gold is a good asset to hedge against uncertainty arising from policy innovations and infectious disease uncertainty. Social implications: This paper provides insightful information on the choice of assets toward hedging against risk in the uncertainty market conditions. It provides information to investors and policy makers to use gold price movements as a signal for detecting the arrival of uncertainty. This study also provides information for demanding a risk premium for infectious disease. Originality/value: This study empirically analyzes and verifies the role that gold serves as a safe haven asset to hedge against uncertainty in the Chinese market. This paper contributes to the literature by presenting evidence of risk/uncertainty premiums for holding gold against various sources of uncertainty such as economic policy uncertainty, geopolitical risk and equity market volatility due to US interest rate innovation and/or COVID-19. This study finds evidence that supports the use of a nonlinear specification, which demonstrates the interaction of uncertainty with the lagged change of infectious disease and helps to explain the gold/silver return behavior. Further, evidence shows that the gold return is positively correlated to the stock return. This finding contrasts with evidence in the US market. However, silver returns are negatively correlated with stock returns, but this correlation becomes insignificant during the period of COVID-19. © 2022 Elsevier B.V., All rights reserved.","Chiang, T.C.",2022,10.1108/cfri-12-2021-0232,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132296653&doi=10.1108%2FCFRI-12-2021-0232&partnerID=40&md5=4ea23791a60965a70d67bf3e4f586df2,scopus
7b18cb3891e648c3,Can google search volume index predict the returns and trading volumes of stocks in a retail investor dominant market,"This research examines whether Google search volume index (GSVI), a proxy of investor attention, can predict the excess returns and abnormal trading volumes of TPEx 50 index constituents. It also explores the motive underlying GSVI based on positive or negative shocks to stock prices. The empirical data include 48 companies from TPEx 50 index constituents and cover a period from 1 September 2016 to 31 August 2019. The empirical results present that (1) lagged GSVI negatively affects current excess returns, perhaps due to the characteristics of TPEx, in which there are a higher proportion of retail investors, smaller listed companies, and a higher information asymmetry problem. (2) Lagged GSVI can positively affect abnormal current trading volumes. (3) If GSVI is driven by positive shocks, then it can predict excess returns and abnormal trading volumes positively.","Lai, Huei-Hwa; Chang, Tzu-Pu; Cheng-Han, Hu; Po-Ching Chou",2022,10.1080/23322039.2021.2014640,None,proquest
3e458c1ef4064bc0,Can investor attention predict oil prices?,"This paper sets out to investigate the predictive power of investor attention onto oil prices. We firstly construct investor attention index by using the Google search volume index (SVI) based on a broad set of words related to oil-related variables and terms that are directly linked to real economy to measure investor attention. Then the empirical work is performed via a novel hybrid approach and WN model (Westerlund and Narayan, 2012, 2014) that account for characteristics of persistency, endogeneity, and heteroskedasticity. The empirical results show that investor attention does exhibit statistically and economically significant in-sample and out-of-sample forecasting power to directly forecast oil prices for both daily data and weekly data. In addition, the results exhibit the term structure character, which are helpful for understanding the financial phenomena that irrational attentions have more effect in short-term decision-making. © 2017 Elsevier B.V., All rights reserved.","Han, L.; Lv, Q.; Yin, L.",2017,10.1016/j.eneco.2017.04.018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019673191&doi=10.1016%2Fj.eneco.2017.04.018&partnerID=40&md5=ca9f86fe67dec0c5b3eeae9ad04a2a64,scopus
81bda8db83234614,Can investors attention on oil markets predict stock returns?,"This paper sets out to explore the predictability of the U.S. equity risk premium directly based on investor attention to oil. We find that the predictive power of oil attention exhibits statistical and economic significance within different models in both in-sample and out-of-sample tests. Meanwhile, oil attention reveals considerable and robust economic value for asset allocation in the sense of positive utility gains. Furthermore, supportive evidence that oil attention is closely linked to stock market volatility endues it with a macroeconomic meaning, serving as an explanation for its predictive power. Overall, investor attention to oil does have a direct predictive power to forecast the U.S. stock excess returns. © 2019 Elsevier B.V., All rights reserved.","Yin, L.; Feng, J.",2019,10.1016/j.najef.2018.08.017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052227023&doi=10.1016%2Fj.najef.2018.08.017&partnerID=40&md5=571887a6f6c671ca6e8211b013cc00c9,scopus
e47a7f4118f99119,Can negative interest rates really affect option pricing? Empirical evidence from an explicitly solvable stochastic volatility model,"The profound financial crisis generated by the collapse of Lehman Brothers and the European sovereign debt crisis in 2011 have caused negative values of government bond yields both in the USA and in the EURO area. This paper investigates whether the use of models which allow for negative interest rates can improve option pricing and implied volatility forecasting. This is done with special attention to foreign exchange and index options. To this end, we carried out an empirical analysis on the prices of call and put options on the US S&P 500 index and Eurodollar futures using a generalization of the Heston model in the stochastic interest rate framework. Specifically, the dynamics of the option’s underlying asset is described by two factors: a stochastic variance and a stochastic interest rate. The volatility is not allowed to be negative, but the interest rate is. Explicit formulas for the transition probability density function and moments are derived. These formulas are used to estimate the model parameters efficiently. Three empirical analyses are illustrated. The first two show that the use of models which allow for negative interest rates can efficiently reproduce implied volatility and forecast option prices (i.e. S&P index and foreign exchange options). The last studies how the US three-month government bond yield affects the US S&P 500 index. © 2017 Elsevier B.V., All rights reserved.","Recchioni, M.C.; Sun, Y.; Tedeschi, G.",2017,10.1080/14697688.2016.1272763,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014563788&doi=10.1080%2F14697688.2016.1272763&partnerID=40&md5=fb231c8d70605cedda83b18b1ebc4c8b,scopus
460cc07cd2824358,Can the Sharia-based Islamic Stock Market returns be forecasted using large number of predictors and models?,"This study employs 14 global economic and financial variables to predict the return of the Islamic stock market as identified by the Dow Jones Islamic Stock Market (DJIM). It implements alternative forecasting methods and allows for nonlinearity in the multivariate predictive regressions by estimating time-varying parameter models. All the methods fail to forecast the returns of the Sharia-based DJIM index over the out- of-sample period. The forecasts are weak at best, with only four predictors, the 3-month Treasury bill rate, inflation, oil price and return on the SandP500 Index, outperforming the benchmark autoregressive model of order one. The study suggests that the DJIM return is best predicted by an autocorrelation(1) model, and that future research should aim at analysing whether the performance of the linear autoregressive model can be improved by using nonlinear methods. Reprinted by permission of Routledge, Taylor and Francis Ltd.","Gupta, Rangan; Hammoudeh, Shawkat; Simo-Kengne, Beatrice D; Sarafrazi, Soodabeh",2014,10.1080/09603107.2014.924296,None,proquest
0171b0a089a6ffef,Can tree-structured classifiers add value to the investor?,"We analyse the investor welfare gain of including tree-structured classifiers’ predictions about the relative performance of stock vs. cash. The CART, bagging, and random forest methods select the VIX level and momentum, the earning bond yield level and momentum, and the detrended risk-free rate as the most important state variables to predict the outperformance of the S&P 500 vs. cash out-of-sample. These tree-structured classifiers’ predictions are used as a binary state variable to estimate optimal investor portfolios that also deliver out-of-sample higher Sharpe ratios and certainty equivalent return gains than competing portfolio strategies that exclude them. © 2019 Elsevier B.V., All rights reserved.","Laborda, R.; Laborda, J.",2017,10.1016/j.frl.2017.06.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020478167&doi=10.1016%2Fj.frl.2017.06.002&partnerID=40&md5=c5cc5c546ee15a2cf5366bb636d8e4ef,scopus
56598c57394f26e9,Can we measure inflation expectations using Twitter?,"Drawing on Italian tweets, we employ textual data and machine learning techniques to build new real-time measures of consumers' inflation expectations. First, we select keywords to identify tweets related to prices and expectations thereof. Second, we build a set of daily measures of inflation expectations around the selected tweets, combining the Latent Dirichlet Allocation (LDA) with a dictionary-based approach, using manually labeled bi-grams and tri-grams. Finally, we show that Twitter-based indicators are highly correlated with both monthly survey-based and daily market-based inflation expectations. Our new indicators anticipate consumers' expectations, proving to be a good real-time proxy, and provide additional information beyond market based expectations, professional forecasts, and realized inflation. The results suggest that Twitter can be a new timely source for eliciting beliefs. (C) 2022 Elsevier B.V. All rights reserved.","Angelico, Cristina; Marcucci, Juri; Miccoli, Marcello; Quarta, Filippo",2022,10.1016/j.jeconom.2021.12.008,None,wos
7a8f143dc92d2032,"Capital accumulation, external indebtedness, and macroeconomic performance of emerging countries","This paper aims at presenting a nonlinear post Keynesian growth model to evaluate at the theoretical and empirical levels the relationship between external indebtedness and economic growth in emerging countries. To this end, a post Keynesian endogenous growth model is presented, in which: (1) the desired rate of capital accumulation is assumed to be a nonlinear function of external indebtedness as a share of capital stock; (2) an endogenous country risk premium is assumed to be an increasing (linear) function of external indebtedness (as a share of capital stock); (3) there is a fixed exchange rate regime and perfect capital mobility in the sense of Mundell and Fleming. The main theoretical result of the model is the existence of two long-run equilibrium positions, one of which has a high level of external indebtedness (as a ratio of capital stock) and a low profit rate and the other has a low level of external indebtedness and a high profit rate. This means that ""excessive"" external indebtedness can result in stagnant growth due to its negative effect on the rate of profit. To test the effects of external indebtedness on the rate of economic growth in emerging economies, a dynamic panel is estimated to evaluate whether external debt has an effective negative influence on economic growth in emerging countries. An empirical test of demand-led growth equations with a dynamic panel for fifty-five emerging countries confirms the potential negative effects of external debt on long-term growth rates in the sample countries. © 2013 M.E. Sharpe, Inc. All rights reserved. © 2013 Elsevier B.V., All rights reserved.","Rocha, M.; Oreiro, J.L.",2013,10.2753/pke0160-3477350405,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880320477&doi=10.2753%2FPKE0160-3477350405&partnerID=40&md5=fb91bb6c33303ec63cde6a40b6bd6773,scopus
5eb44d63138a04b7,Capitalisation rates for commercial real estate investments: evidence from Australia,"Purpose: The paper is motivated by the paucity of empirical research on the determinants of capitalisation rates/yield in the commercial property market. Compared to property price determinants, the capitalisation rate has received significantly less attention. This is somewhat surprising given that the capitalisation rate is a more insightful indicator for investors on commercial property market performance than merely price changes or trends. The capitalisation rate, measured as the ratio of net operating income to the property’s capital value, captures the asset’s overall ability to generate income which is crucial for investors who typically invest in property for their income-generating capacity. The purpose of this paper is to address these issues. Design/methodology/approach: To evaluate the determinants of capitalisation rates, time series analysis was used. The data capture performance in the Australian commercial property market between 2005 and 2018. All macroeconomic and financial data are freely available from official sources such as the Australian Bureau of Statistics and the nation’s central bank. Methodology wise, given the problematic nature of the data such as a mixed order of integration and the possibility of cointegration amongst some of the I (1) variables, the autoregressive distributed lag model was selected given its flexibility and relative lack of assumptions. Findings: Bond rates, market risk premiums, stock market excess returns and other macroeconomic variables were found to drive capitalisation rates of Australian commercial properties. A 1% increase in the bond rate results in approximately 0.3–2.4% increase in capitalisation rates depending on the sub-market. Further, a 1% increase in excess market returns results in a 0.01–0.02% increase in capitalisation rates. Regarding risk premiums, a 100 basis point increase in the BBB spread results in approximately 0.92–1.27% reduction in cap rates in certain markets. Practical implications: Asset managers will find these results useful in asset allocation strategies. Commercial properties offer attractive investment qualities such as yield stability in periods of economic uncertainty while allowing for the possibility of capital growth through appreciation of the underlying asset. By understanding the factors that affect the capitalisation rate, practitioners may predict emerging trends and identify threats to portfolio return and stability. This allows better integration of commercial property in the construction of portfolios that remain robust in a variety of market conditions. Originality/value: The contribution to literature is significant given the lack of similar studies in the Australian market. The performance of real estate assets using cap rates as a comparative measure to equities and bonds influences decisions in asset allocation strategies. It provides crucial information for investors to estimate the performance of commercial property. This research supports the notion that both space and capital market indicators jointly affect capitalisation rates. The findings expand the knowledge base relating to commercial properties and validate the assessments of investors, developers and valuers who utilise yield as a performance benchmark for asset allocation strategies. © 2023 Elsevier B.V., All rights reserved.","Wong, W.W.; Mintah, K.; Baako, K.; Wong, P.Y.",2023,10.1108/jpif-09-2022-0063,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146597624&doi=10.1108%2FJPIF-09-2022-0063&partnerID=40&md5=a7597a55a32cf9357caad38cd9cdc398,scopus
46aaeaa8f110a015,Capturing the Regime-Switching and Memory Properties of Interest Rates,"We propose a mean-reverting interest rate model whose mean-reverting level, speed of mean-reversion and volatility are all modulated by a weak Markov chain (WMC). This model features a simple way to capture the regime-switching evolution of the parameters as well as the memory property of the data. Concentrating on the second-order WMC framework, we derive the filters of the WMC and other auxiliary processes through a change of reference probability measure. Optimal estimates of model parameters are provided by employing the EM algorithm. The h-step ahead forecasts under our proposed set-up are examined and compared with those under the usual Markovian regime-switching framework. We obtain better goodness-of-fit performance based on our numerical results generated from the implementation of WMC-based filters to a 10-year dataset of weekly short-term-maturity Canadian yield rates. Some statistical inference issues of the proposed modelling approach are also discussed.","Xi, Xiaojing; Mamon, Rogemar",2014,10.1007/s10614-013-9396-5,None,wos
d47ebdc5ea5914d1,Carbon risk and return prediction: Evidence from the multi-CNN method,"This paper investigates the carbon risk and its role in stocks’ return prediction by identifying the carbon risk information implied in feature engineering. We predict the stock returns with different neural networks, construct the investment portfolio according to the predicted returns and reflect the returns of stocks with different carbon risks through the relevant evaluation of the investment portfolio. Our Multi-CNN method can best collect information on different relationship types and make full use of graph structure data to identify carbon risks. With or without carbon factor, the stock market performance of high-carbon industry is better than that of medium-carbon industry, and the performance of low-carbon industry is the worst. Moreover, our finding is consistent in both Chinese and American markets. Investment should pay attention to carbon risk and requires corresponding carbon risk premium. © 2022 Elsevier B.V., All rights reserved.","Tang, J.; Li, J.",2022,10.3389/fenvs.2022.1035809,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142006137&doi=10.3389%2Ffenvs.2022.1035809&partnerID=40&md5=6eecf37eb1d8a397e2c08fbd38faa6c7,scopus
220322bfc22a7fa8,Cash Flow Forecasting in SAP ERP Enhanced by UiPath Automation: A Predictive Analytics Approach,"Maintaining liquidity, mitigating financial risks, and making strategic business decisions in today’s enterprises require accurate cash flow forecasting. Unfortunately, the native forecasting features of the SAP ERP are often constrained by outdated input streams, static data assumptions, and rigid model structures, severely impeding responsiveness and accuracy. This study proposes and evaluates the results-focused integration of UiPath robotic process automation (RPA) with predictive analytics to improve short and medium-term cash flow forecasting in SAP environments. We automated real-time data extraction from SAP FI, FI-CA, and bank interface modules, then employed machine learning and deep learning models (regression trees, LSTM networks, and ensemble methods) to demonstrate substantial gains in forecasting accuracy, cycle time, and exception handling. The framework was tested on large data sets from multi-currency, multi-business unit enterprises, achieving forecast accuracy improvement estimates of 15% to 28% compared to SAP’s baseline predictions. Aside from significantly reducing manual effort associated with forecast preparation, automation also expedited scenario-based liquidity analysis while enhancing governance through exception-based audit logging. These results provide a proven scaling architecture for intelligent real-time cash forecasting that is reliable and compliant, placing RPA and AI at the core of cash management operations of the future, and integrating deeply within ERP systems. © 2025 Elsevier B.V., All rights reserved.","Jamithireddy, N.S.",2025,10.51983/ijiss-2025.ijiss.15.2.45,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010042509&doi=10.51983%2Fijiss-2025.IJISS.15.2.45&partnerID=40&md5=b869ac625a26cb67b95a63d8895c5ea9,scopus
98032144cda08a39,Central Bank Transparency and Interest Rate Volatility,"Most central banks around the world have increased their transparency in recent decades. These developments have had an impact on financial markets. Several studies have analysed the impact of central bank transparency (CBT) on variables such as inflation volatility, exchange rate volatility, or stock market volatility. One variable that has not received enough attention is interest rate volatility, despite its importance for decision-makers in both financial markets and the real economy. The study uses a panel data set of a maximum of 93 countries over the years 1998–2017. We use panel data estimators (panel fixed effects and fixed effects filter). Our main findings are that CBT helps to reduce the volatility of several interest rates (money market rates, deposit rates, savings rates, Treasury bill yields and government bond yields), while it increases the volatility of monetary policy rates. The results are also significant from an economic point of view, as a small increase in CBT can reduce the variability of treasury bill rates by up to −8.2%, deposit rates by up to −9.1%, money market rates by up to −15.8% and savings rates by up to −20.4%. © 2024 Elsevier B.V., All rights reserved.","Weber, C.S.",2024,10.1002/ijfe.3072,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212859950&doi=10.1002%2Fijfe.3072&partnerID=40&md5=709d6898cc2a2cb5f01e3dd2e10c9f3a,scopus
218b2b4f103b094a,Challenges in macro-finance modeling,"This article discusses various challenges in the specification and implementation of ""macrofinance"" models in which macroeconomic variables and term structure variables are modeled together in a no-arbitrage framework. The author classifies macro-finance models into pure latent factor models (""internal basis models"") and models that have observed macroeconomic variables as state variables (""external basis models"") and examines the underlying assumptions behind these models. Particular attention is paid to the issue of unspanned short-run fluctuations in macroeconomic variables and their potentially adverse effect on the specification of external basis models. The author also discusses the challenge of addressing features such as structural breaks and timevarying inflation uncertainty. Empirical difficulties in the estimation and evaluation of macrofinance models are also discussed in detail. © 2009, The Federal Reserve Bank of St. Louis. © 2020 Elsevier B.V., All rights reserved.","Kim, D.H.",2009,10.20955/r.91.519-544,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350561910&doi=10.20955%2Fr.91.519-544&partnerID=40&md5=c0fb7fe87ee07e159e0eeb472a1beb2c,scopus
925a15bd08c4a54b,Changes in predictive ability with mixed frequency data,"When assessing the predictive power of financial variables for economic activity, researchers usually aggregate higher-frequency data before estimating a forecasting model that assumes the relationship between the financial variable and the dependent variable to be linear. This paper proposes a model called smooth transition mixed data sampling (STMIDAS) regression, which relaxes both of these assumptions. Simulation exercises indicate that the improvements in forecasting accuracy from the use of mixed data sampling are larger in nonlinear than in linear specifications. When forecasting output growth with financial variables in real time, statistically significant improvements over a linear regression are more likely to arise from forecasting with STMIDAS than with MIDAS regressions. (C) 2012 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.","Galvao, Ana Beatriz",2013,10.1016/j.ijforecast.2012.10.006,None,wos
b127fcd8bbc8c65b,Changing beliefs and the term structure of interest rates: Cross-equation restrictions with drifting parameters,"This paper shows how to estimate a Bayesian VAR with drifting parameters and nonlinear cross-equation restrictions. The restrictions promote parsimony by reducing the dimension of the drifting component in conditional mean parameters. As an application, the paper investigates an anticipated-utility version of the expectations model of the term structure. The estimates suggest that changing beliefs matter for understanding the yield curve and point to an intriguing clue about risk premia. Local approximations to the mean yield spread are highly correlated with the variance of the trend short rate, suggesting a connection between uncertainty about the long-run target of monetary policy and risk premia on long-term bonds. © 2005 Elsevier Inc. All rights reserved. © 2018 Elsevier B.V., All rights reserved.","Cogley, T.",2005,10.1016/j.red.2005.01.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16244390866&doi=10.1016%2Fj.red.2005.01.004&partnerID=40&md5=0033d48127db50efe621f016c846fa59,scopus
e093f0a24b02d3b8,Chasing the deal with the money: Measuring the required risk premium and expected abnormal returns of private equity funds to maximize their internal rate of return,"A number of scholars of private equity (“PE”) have attempted to assess the ex-post returns, or performance, of PEs by adopting an ex-post perspective of asset pricing. In doing so a set of phenomena has been recognized that is thought to be specific to the PE sector, such as “money-chasing deal phenomenon” (Gompers and Lerner, 2000) and “performance persistence” (Lerner and Schoar, 2005). However, based on their continuing use of an ex-post perspective, few scholars have paid attention to the possible extent to which these and other PE phenomena may affect expected returns from PE investments. To address this problem this article draws on an ex-ante perspective of investment decision-making in suggesting how a number of drivers and factors of PE phenomena may produce “abnormal returns”, and that each of those drivers and factors should therefore be considered in accurately assessing the required risk premium and expected abnormal returns of PE investments. In making these contributions we examined a private equity investment of a regional PE in Italy and administered a telephone questionnaire to 40 PEs in Italy and the UK and found principally that while size is the most important driver in producing abnormal returns illiquidity alone cannot explain the expected returns of PE investments (cf. Franzoni et al., 2012). Based on our findings we developed a predictive model of PE decision-making that draws on an ex-ante perspective of asset pricing and takes into account PE phenomena and abnormal returns. This model extends the work of Franzoni et al. (2012), Jegadeesh et al. (2009), and Korteweg and Sorensen (2010) who did not consider the possible influence of PE phenomena in decision-making and will also help PE managers in making better-informed decisions. © 2018 Elsevier B.V., All rights reserved.","Scarpati, F.; Ng, W.",2013,10.22495/rgcv3i3art6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939419937&doi=10.22495%2Frgcv3i3art6&partnerID=40&md5=4a3b001b9d54090bf9a7d53849498f2c,scopus
7b2256e4dbeb757d,ChatGPT and Commodity Return,"This paper investigates the ability of a ChatGPT‐based indicator to forecast excess returns of the commodity futures index. Using ChatGPT to extract information from over 2.5 million articles from nine international newspapers, we demonstrate that our constructed commodity news ratio index significantly predicts future commodity returns, both in‐sample and out‐of‐sample. Furthermore, it outperforms traditional textual analysis methods, including Bidirectional Encoder Representations from Transformers (BERT) and Bag‐of‐Words (BoW), while indicating economic significance within an asset allocation framework. The results highlight the critical role of ChatGPT in forecasting commodity market dynamics and provide valuable insights for both financial market participants and researchers.","Gao, Shen; Wang, Shijie; Wang, Yuanzhi; Zhang, Qunzi",2025,10.1002/fut.22568,None,proquest
6e02db71875332a7,China University Online Public Opinion Risk Dataset,"With the widespread popularity of social software and self-media, online public opinion incidents in colleges and universities occur frequently and present a complicated situation. In the big data era, university students have gained a more relaxed environment in which to receive and disseminate public opinion information, enabling them to spread their opinions and insights to the Internet more rapidly, thus exacerbating the riskiness of public opinion information dissemination. We constructed CUOPO, the first risk classification dataset of China university online public opinion, and screened out 10,255 representative public opinion texts from a large number of university online public opinion information, including 3,641 risk-free and 6,614 risky texts. These risky texts cover many fields, including 1,755 college livelihood risk texts, 767 campus safety risk texts, 1,395 school order risk texts, 906 university reputation risk texts, and 1,793 advertisement risk texts. The dataset contains various information about each network opinion, including authentic labels, text information, time information, and network information. Through an in-depth study of CUOPO, we found that universities have significant risk issues in the areas of livelihood, safety, teaching order, reputation, and advertisement diversion, which require great attention from university administrators. To validate the effectiveness of the CUOPO, we conduct extensive experiments on the dataset using a series of neural network methods to provide benchmark results for predicting online public opinion risk texts. We expect that CUOPO can provide strong data support for the study of the types of online public opinion risks in colleges and universities and thus play a positive role in promoting the progress of college and university public opinion research. The dataset is available at https://github.com/TianShengLee98/CUOPO-Dataset.",S. Wang; T. Li; X. Shen; H. Zhao,2024,10.1109/access.2024.3389974,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10501775,ieeexplore
d649020ccc11a84c,Classification Ratemaking Using Decision Tree in the Insurance Market of Bosnia and Herzegovina,"This paper investigates the impact of risk classification on life insurance ratemaking with particular reference to Bosnia and Herzegovina (BiH). The research is based on a sample of over eighteen thousand insurance policies for passenger vehicles collected over the period 2015-2020. In our empirical investigation we develop a standard risk model based on the application of Poisson Generalized linear models (GLM) for claims frequency estimate and Gamma GLM for claim severity estimate. The analysis reveals that GLM does not provide a reliable parameter estimates for Multi-level factor (MLF) categorical predictors. Although GLM is widely used method to deter insurance premiums, improvements of GLM by using the data mining methods identified in this paper may solve practical challenges for the risk models. The popularity of applying data mining methods in the actuarial community has been growing in recent years due to its efficiency and precision. These models are recommended to be considered in BiH and South East European region in general. © 2021 Elsevier B.V., All rights reserved.","Omerašević, A.; Selimović, J.",2020,10.2478/jeb-2020-0020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099800105&doi=10.2478%2Fjeb-2020-0020&partnerID=40&md5=c11ce006692f8cbd8140a430aeca56e2,scopus
1b1a8cfbbcbec1d6,Climate Change and ESG: Focused on Green Bond Design,"We investigate about climate change, which is now emerging as a hot potato, and realize its seriousness. To respond to climate change, carbon reduction strategies are vitally important. We examine the effect of carbon reduction on ESG score improvement and show the importance of ESG management by using the concept of green spread which is a financial environmental cleanliness measure. An aim of this study is to predict numerically the impact of carbon reduction on national cleanliness and economic benefits using the methodology of CO2 emission-backed securities. In order to get attention from many people to the reduction of GHG gas, we compute risk premiums of the securities and did securitization of CO2 emissions. Then, issuing the securities will stimulate investors about the national CO2 reduction activities. Also, we expect that this study gives countries an incentive to reduce their CO2 emissions and prepare for climate change.","DONGHOON, SHIN; 최윤민; 김창기",2023,10.14251/jscm.2023.3.31,None,wos
1c852fb6a398bfae,Climate response uncertainty and the benefits of greenhouse gas emissions reductions,"Some recent research suggests that uncertainty about the response of the climate system to atmospheric greenhouse gas concentrations can have a disproportionately large influence on benefits estimates for climate change policies, potentially even dominating the effect of the discount rate. In this paper we conduct a series of numerical simulation experiments to investigate the quantitative significance of climate response uncertainty for economic assessments of climate change. First we characterize climate uncertainty by constructing two probability density functions-a Bayesian model-averaged and a Bayesian updated version-based on a combination of uncertainty ranges for climate sensitivity reported in the scientific literature. Next we estimate the willingness to pay of a representative agent for a range of emissions reduction policies using two simplified economic models. Our results illustrate the potential for large risk premiums in benefits estimates as suggested by the recent theoretical work on climate response uncertainty, and they show that the size and even the sign of the risk premium may depend crucially on how the posterior distribution describing the overall climate sensitivity uncertainty is constructed and on the specific shape of the damage function. © United States Environmental Protection Agency 2009. © 2017 Elsevier B.V., All rights reserved.","Newbold, S.C.; Daigneault, A.",2009,10.1007/s10640-009-9290-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-76149142167&doi=10.1007%2Fs10640-009-9290-8&partnerID=40&md5=c5d868d8ee46f868b523eb5a8baa76b1,scopus
f397fe9a3326a4c0,"Climate, race, and the cost of capital in the municipal bond market","Both climate risk and race are factors that may affect municipal bond yields, yet each has received relatively limited empirical research attention. We analyzed > 712,000 municipal bonds representing nearly 2 trillion USD in par outstanding, focusing on credit spread or the difference between a debt issuer's interest cost to borrow and a benchmark ""risk-free"" municipal rate. The relationship between credit spread and physical climate risk is significant and slightly positive, yet the coefficient indicates no meaningful spread penalty for increased physical climate risk. We also find that racial composition (the percent of a community that is Black) explains a statistically significant and meaningful portion of municipal credit spreads, even after controlling for a variety of variables in domains such as geographic location of issuer, bond structure (e.g., bond maturity), credit rating, and non-race economic variables (e.g., per capita income). Assuming 4 trillion USD in annual outstanding par across the entire municipal market, and weighting each issuer by its percent Black, an estimated 19 basis point (bp) penalty for Black Americans sums to approximately 900 million USD annually in aggregate. Our combined findings indicate a systemic mispricing of risk in the municipal bond market, where race impacts the cost of capital, and climate does not.Both climate risk and race are factors that may affect municipal bond yields, yet each has received relatively limited empirical research attention. We analyzed > 712,000 municipal bonds representing nearly 2 trillion USD in par outstanding, focusing on credit spread or the difference between a debt issuer's interest cost to borrow and a benchmark ""risk-free"" municipal rate. The relationship between credit spread and physical climate risk is significant and slightly positive, yet the coefficient indicates no meaningful spread penalty for increased physical climate risk. We also find that racial composition (the percent of a community that is Black) explains a statistically significant and meaningful portion of municipal credit spreads, even after controlling for a variety of variables in domains such as geographic location of issuer, bond structure (e.g., bond maturity), credit rating, and non-race economic variables (e.g., per capita income). Assuming 4 trillion USD in annual outstanding par across the entire municipal market, and weighting each issuer by its percent Black, an estimated 19 basis point (bp) penalty for Black Americans sums to approximately 900 million USD annually in aggregate. Our combined findings indicate a systemic mispricing of risk in the municipal bond market, where race impacts the cost of capital, and climate does not.","Smull, Erika; Kodra, Evan; Stern, Adam; Teras, Andrew; Bonanno, Michael; Doyle, Martin",2023,10.1371/journal.pone.0288979,None,proquest
b39b07bdaf2c9aea,Climate-sensitive hydrological drought insurance for irrigated agriculture under deep uncertainty. Insightful results from the Cega River Basin in Spain,"This paper assesses the feasibility and robustness of an index-based insurance scheme against hydrological droughts under climate change. To this end, we develop a grand ensemble that samples both modeling and scenario uncertainty in the estimation of the insurance risk premium, so to reveal potential unfavorable surprises and minimize regret in the design of the proposed insurance scheme. The grand ensemble combines four microeconomic models and seven GAMLSS models, which are run for three alternative climate change scenarios: stationary climate/no climate change, RCP 2.6, and RCP 8.5. Methods are illustrated with an application to the Cega River Sub-basin (CRS) in central Spain. Results indicate that for a conventional deductible of 30%, the proposed index-based insurance scheme would be actuarially feasible and affordable under all models for the stationary climate scenario (i.e., robust). For climate change scenarios RCP 2.6 and 8.5 and a 30% deductible, the suggested index-based insurance would be actuarially feasible under most models, albeit some outliers point towards potential unfavorable surprises. Lower deductibles decrease feasibility, particularly for deductibles <10%.","Agudo-Domínguez, Alberto; Pérez-Blanco, C Dionisio; Gil-García, Laura; Ortega, José Antonio; Dasgupta, Shouro",2022,10.1016/j.agwat.2022.107938,None,proquest
9cb31eeb7dae5c0a,"Closed-Form Expansion, Conditional Expectation, and Option Valuation","Enlightened by the theory of Watanabe [Watanabe S (1987) Analysis of Wiener functionals (Malliavin calculus) and its applications to heat kernels. Ann. Probab. 15:1-39] for analyzing generalized random variables and its further development in Yoshida [Yoshida N (1992a) Asymptotic expansions for statistics related to small diffusions. J. Japan Statist. Soc. 22: 139-159], Takahashi [Takahashi A (1995) Essays on the valuation problems of contingent claims. Ph.D. thesis, Haas School of Business, University of California, Berkeley, Takahashi A (1999) An asymptotic expansion approach to pricing contingent claims. Asia-Pacific Financial Markets 6:115-151] as well as Kunitomo and Takahashi [Kunitomo N, Takahashi A (2001) The asymptotic expansion approach to the valuation of interest rate contingent claims. Math. Finance 11(1):117-151, Kunitomo N, Takahashi A (2003) On validity of the asymptotic expansion approach in contingent claim analysis. Ann. Appl. Probab. 13(3):914-952] etc., we focus on a wide range of multivariate diffusion models and propose a general probabilistic method of small-time asymptotic expansions for approximating option price in simple closed-form up to an arbitrary order. To explicitly construct correction terms, we introduce an efficient algorithm and novel closed-form formulas for calculating conditional expectation of multiplication of iterated stochastic integrals, which are potentially useful in a wider range of topics in applied probability and stochastic modeling for operations research. The performance of our method is illustrated through various models nested in constant elasticity of variance type processes. With an application in pricing options on VIX under GARCH diffusion and its multifactor generalization to the Gatheral double lognormal stochastic volatility models, we demonstrate the versatility of our method in dealing with analytically intractable non-Levy and non-affine models. The robustness of the method is theoretically supported by justifying uniform convergence of the expansion over the whole set of parameters.","Li, Chenxu",2014,10.1287/moor.2013.0613,None,wos
ae63f674b58debe4,Closed-form likelihood expansions for multivariate time-inhomogeneous diffusions,"The aim of this paper is to find approximate log-transition density functions for multivariate time-nhomogeneous diffusions in closed form. There are many empirical evidences supporting that the data generating process governing dynamics of many economics variables might vary over time because of economic climate changes or time effects. One possible way to explain the time-dependent dynamics of state variables is to model the drift or volatility terms as functions of time t as well as state variables. A way to find closed-form likelihood expansion for a multivariate time-homogeneous diffusion has been developed by Ait-Sahalia (2008). This research is built on his work and extends his results to time-inhomogeneous cases. We conduct Monte Carlo simulation studies to examine performance of the approximate transition density function when it is used to obtain ML estimates. The results reveal that our method yields a very accurate approximate likelihood function, which can be a good candidate when the true likelihood function is unavailable as is often the case. (C) 2013 Elsevier B.V. All rights reserved.","Choi, Seungmoon",2013,10.1016/j.jeconom.2011.12.007,None,wos
4d1b62d1b15ae5dc,Cointegration analysis of hazard rates and CDSs: Applications to pairs trading strategy,"This study examines the cointegration relationship between multiple credit default swap (CDS) spreads by constructing the cointegrated hazard rate model, which assumes the structure of the vector error correction model (VECM) in the drift term of hazard rate processes. We merge the cointegration nature into the framework of arbitrage-free pricing and thereby derive the theoretical spread formula of multiple cointegrated CDSs. For the estimation of hazard rate dynamics, we develop a Bayesian statistical inference method combined with the numerical ordinary differential equation solver because the theoretical CDS spread cannot be expressed in closed form. In the empirical study of Japanese corporate CDSs, we find that the overall term structures of cointegrated CDSs can be explained by a simple two-dimensional VECM of cointegrated hazard rates. Furthermore, we study the pairs trading strategy of CDSs. © 2023 Elsevier B.V., All rights reserved.","Kato, K.; Nakamura, N.",2023,10.1016/j.physa.2023.128489,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147196257&doi=10.1016%2Fj.physa.2023.128489&partnerID=40&md5=6700306a9980b3c616b999d06fa79817,scopus
45a2cb3e694beb29,Cointegration and detectable linear and nonlinear causality: Analysis using the London Metal Exchange lead contract,"This study applies linear and nonlinear Granger causality tests to examine the dynamic relation between London Metal Exchange (LME) cash prices and three possible predictors. The analysis uses matched quarterly inventory, UK Treasury bill interest rates, futures prices and cash prices for the commodity lead traded on the LME. The effects of cointegration on both linear and nonlinear Granger causality tests is also examined. When cointegration is not modelled, evidence is found of both linear and nonlinear causality between cash prices and analysed predictor variables. However, after controlling for cointegration, evidence of significant nonlinear causality is no longer found. These results contribute to the empirical literature on commodity price forecasting by highlighting the relationship between cointegration and detectable linear and nonlinear causality. The importance of interest rate and inventory as well as futures price in forecasting cash prices is also illustrated. Failure to detect significant nonlinearity after controlling for cointegration may also go some way to explaining the reason for the disappointing forecasting performances of many nonlinear models in the general finance literature. It may be that the variables are correct, but the functional form is overly complex and a standard VAR or VECM may often apply. © 2004 Taylor and Francis Ltd. © 2008 Elsevier B.V., All rights reserved.","Chen, A.-S.; Lin, J.W.",2004,10.1080/0003684042000247352,https://www.scopus.com/inward/record.uri?eid=2-s2.0-3543067056&doi=10.1080%2F0003684042000247352&partnerID=40&md5=4a669c06e8048b8dafca13e8c66096a8,scopus
06de698e287ecd19,"Collateralizable wealth, asset returns, and systemic risk: International evidence","Purpose - The purpose of this chapter is to assess the role of collateralizable wealth and systemic risk in explaining future asset returns. Methodology/approach - To test this hypothesis, the chapter uses the residuals of the trend relationship among housing wealth and labor income to predict both stock returns and government bond yields. Specifically, it shows that nonlinear deviations of housing wealth from its cointegrating relationship with labor income, hwy, forecast expected future returns. Findings - Using data for a set of industrialized countries, the chapter finds that when the housing wealth-to-income ratio falls, investors demand a higher risk premium for stocks. As for government bond returns: (i) when they are seen as a component of asset wealth, investors react in the same manner and (ii) if, however, investors perceive the increase in government bond returns as signaling a future rise in taxes or a deterioration of public finances, then they interpret the fall in the housing wealth-to-income ratio as a fall in future bond premia. Finally, this work shows that the occurrence of crisis episodes amplifies the transmission of housing market shocks to financial markets. Originality/value of chapter - These findings are novel. They also open new and challenging avenues for understanding the dynamics of the relationship between the housing sector, stock market and government bond developments, and the banking system. Copyright © 2013 by Emerald Group Publishing Limited. © 2014 Elsevier B.V., All rights reserved.","Sousa, R.M.",2010,10.1108/s1571-0386(2010)0000020006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897585761&doi=10.1108%2FS1571-0386%282010%290000020006&partnerID=40&md5=369313bd78587f6aa5380ba6033b921d,scopus
c5534bf69e592d8c,Combined DEMATEL technique with a novel MCDM model for exploring portfolio selection based on CAPM,"This research proposes a novel MCDM model, including DEMATEL, ANP, and VIKOR for exploring portfolio selection based on CAPM. We probe into the influential factors and relative weights of risk-free rate, expected market return, and beta of the security. The purpose of this research is to establish an investment decision model and provides investors with a reference of portfolio selection most suitable for investing effects to achieve the greatest returns. Taking full consideration of the interrelation effects among criteria/variables of the decision model, this paper examined leading semiconductor companies spanning the hottest sectors of integrated circuit (IC) design, wafer foundry, and IC packaging by experts. Empirical findings revealed that risk-free rate was affected by budget deficit, discount rate, and exchange rate; expected market return was affected by country risk, industrial structure, and macroeconomic factors; and beta of the security was affected by firm-specific risk and financial risk. Also, the factors of the CAPM possessed a self-effect relationship according to the DEMATEL technique. In the eight evaluation criteria, macroeconomic criterion was the most important factor affecting investment decisions, followed by exchange rate and firm-specific risk. In portfolio selection, leading companies in the wafer foundry industry outperformed those in IC design and IC packaging, becoming the optimal portfolio of investors during the time that this study was conducted. (C) 2010 Elsevier Ltd. All rights reserved.","Ho, Wen-Rong Jerry; Tsai, Chih-Lung; Tzeng, Gwo-Hshiung; Fang, Sheng-Kai",2011,10.1016/j.eswa.2010.05.058,None,wos
81fa20cb81e0b280,Combining the wisdom of crowds and technical analysis for financial market prediction using deep random subspace ensembles,"Many researchers and practitioners have attempted to predict financial market trends for excess returns using multiple information sources including social media. Recent studies have investigated the relation between public sentiment and stock price movements and demonstrated that investment decisions are affected by public opinion. In this paper, we design a novel framework that combines the wisdom of crowds and technical analysis for financial market prediction using a new fusion strategy. A machine learning technique called deep random subspace ensembles (DRSE), which integrates deep learning algorithms and ensemble learning methods, is proposed according to the characteristics of the prediction task. Based on collected real-world datasets, the experimental results show that our proposed method outperforms the baseline models in predicting stock market by at least 14.2% in terms of AUC value, indicating the efficacy of DRSE as a viable mechanism for financial market prediction. © 2019 Elsevier B.V., All rights reserved.","Wang, Q.; Xu, W.; Zheng, H.",2018,10.1016/j.neucom.2018.02.095,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045111057&doi=10.1016%2Fj.neucom.2018.02.095&partnerID=40&md5=f9d301ef6362de9274f7f73bb4fbd365,scopus
8ac5d4f4177d3e3a,Common Risk Factors in Cryptocurrency,"We find that three factors-cryptocurrency market, size, and momentum-capture the cross-sectional expected cryptocurrency returns. We consider a comprehensive list of price- and market-related return predictors in the stock market and construct their cryptocurrency counterparts. Ten cryptocurrency characteristics form successful long-short strategies that generate sizable and statistically significant excess returns, and we show that all of these strategies are accounted for by the cryptocurrency three-factor model. Lastly, we examine potential underlying mechanisms of the cryptocurrency size and momentum effects.","Liu, Yukun; Tsyvinski, Aleh; Wu, X., I",2022,10.1111/jofi.13119,None,wos
c75986c18e735da3,Communicating the promise for ocular gene therapies: Challenges and recommendations,"Purpose To identify challenges and pose solutions for communications about ocular gene therapy between patients and clinicians as clinical research progresses. Design Literature review with recommendations. Methods Literature review of science communication best practices to inform recommendations for patient-clinician discussions about ocular gene therapy. Results Clinicians need to employ communications about ocular gene therapy that are both attentive to patient priorities and concerns and responsive to other sources of information, including overly positive news media and the Internet. Coverage often conflates research with therapy - clinical trials are experimental and are not risk free. If proven safe and efficacious, gene therapy may present a treatment but not a cure for patients who have already experienced vision loss. Clinicians can assist patients by providing realistic estimates for lengthy clinical development timelines and positioning current research within models of clinical translation. This enables patients to weigh future therapeutic options when making current disease management decisions. Conclusions Ocular gene therapy clinical trials are raising hopes for treating a myriad of hereditary retinopathies, but most such therapies are many years in the future. Clinicians should be prepared to counter overly positive messaging, found in news media and on the Internet, with optimism tempered by evidence to support the ethical translation of gene therapy and other novel biotherapeutics. © 2018 Elsevier B.V., All rights reserved.","Benjaminy, S.; Kowal, S.P.; MacDonald, I.M.; Bubela, T.",2015,10.1016/j.ajo.2015.05.026,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939258801&doi=10.1016%2Fj.ajo.2015.05.026&partnerID=40&md5=fdaf1a7223d511416c7b84feed4cf280,scopus
8a2720754be4ab08,Comparative analysis of responses of risky and safe haven assets to stock market risk before and after the yield curve inversions in the US,"This study examines the response of safe -haven assets (gold, US dollar) and Bitcoin to market risk before and after yield curve inversions in the U.S. market. Using the VIX volatility index and static and dynamic cross-quantilogram approach, the analysis reveals that gold and the U.S. dollar act as safe havens, showing positive responses to increased VIX values, while Bitcoin behaves as a risky asset, negatively responding to higher VIX values during market turbulence. Changes in the VIX index have an immediate impact on asset price returns, but the effect diminishes over time, suggesting the need for timely updates to investment strategies. Yield curve inversions have altered the VIX-US dollar relationship: pre -inversion changes were influential in calmer markets, but post -inversion, they played a bigger role during turbulent phases, suggesting potential changes in investor behavior and market dynamics. The findings offer practical insights for investors seeking stability and protection during uncertain market conditions.","Sokhanvar, Amin; Hammoudeh, Shawkat",2024,10.1016/j.iref.2024.103376,None,wos
12a420d5f76f8b7d,Comparing Machine Learning Models for Short-Term U.S. Treasury Yield Forecasting,"This study examines historical trends in the U.S. 10-year Treasury yield and evaluates the effectiveness of four machine learning models, linear regression, decision tree, random forest, and multi-layer perceptron (MLP) neural networks, for short-term yield forecasting. As a key benchmark in global financial markets, the 10-year Treasury yield is influenced by multiple economic factors, including core inflation, the federal funds rate, GDP growth, and the U.S. Federal government's debt growth rate. Leveraging historical data from the Federal Reserve Economic Database (FRED), this study develops predictive models to assess the impact of these factors on yield fluctuations. Empirical results indicate that the random forest model outperforms the other approaches, achieving the lowest mean squared error (MSE) and mean absolute error (MAE), alongside an R2 of 0.6073. This suggests its superior ability to capture nonlinear relationships in yield movements. The decision tree model also demonstrates competitive accuracy but is more susceptible to overfitting. Conversely, linear regression provides useful interpretability but struggles to capture complex economic interactions, leading to lower predictive accuracy. Despite its potential for handling nonlinear dependencies, the MLP model underperforms compared to the random forest, yielding an R2 of 0.5058. The findings underscore the advantages of machine learning, particularly ensemble-based methods, in short-term Treasury yield forecasting. © 2025 Elsevier B.V., All rights reserved.","Wang, M.Y.-F.; Wang, Y.-F.",2025,10.1002/cpe.70265,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015141371&doi=10.1002%2Fcpe.70265&partnerID=40&md5=47ea3ed053791be37d1bc13f1326b377,scopus
2fff7c85c30fc367,Comparing forecasting ability of parametric and non-parametric methods: An applications with Canadian monthly interest rates,"The primary objective of this article is to compare the forecasting ability of some recent parametric and non-parametric estimation methods by using monthly Canadian interest rate data between 1964:1-1999:1. The two-factor continous time term structure model of Brennan and Schwartz was estimated where the first factor represents the short rate and the second factor the long rate using the continuous time estimation procedures developed by Bergstrom. The interest rates using the multi-variate GARCH model developed by Engle and Kroner, and two non-parametric estimation methods namely, non-parametric kernel smoothing and the artificial neural networks was modelled. For the short-term rates, it has been found that, the Bergstrom's method and the artificial neural networks model have marginally better forecasting performance than that of the linear benchmark. For the long-term rates, none of the methods produced better forecasting precision than that of the benchmark. © 2004 Elsevier Science B.V., Amsterdam. All rights reserved.","Saltoǧlu, B.",2003,10.1080/09603100110111259,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037359312&doi=10.1080%2F09603100110111259&partnerID=40&md5=0d62d541ef5b9a7cbdf61bb322a0b625,scopus
280680c0ee200d86,Comparison of non-linear optimization algorithms for yield curve estimation,"The yield curve is a very important financial tool used in investment and policy decisions. Its estimation from market data is essentially a non-linear optimization problem. In this paper, we compare a diversity of non-linear optimization algorithms for estimating yield curves based on actual bond market data and conclude that certain classes of algorithms are more effective due to the nature of the problem. (C) 2007 Elsevier B.V. All rights reserved.","Manousopoulos, Polychronis; Michalopoulos, Michalis",2009,10.1016/j.ejor.2007.09.017,None,wos
502c599f9f5a60b2,Comparison procedure of predicting the time to default in behavioural scoring,"The paper deals with the problem of predicting the time to default in credit behavioural scoring. This area opens a possibility of including a dynamic component in behavioural scoring modelling which enables making decisions related to limit, collection and recovery strategies, retention and attrition, as well as providing an insight into the profitability, pricing or term structure of the loan. In this paper, we compare survival analysis and neural networks in terms of modelling and results. The neural network architecture is designed such that its output is comparable to the survival analysis output. Six neural network models were created, one for each period of default. A radial basis neural network algorithm was used to test all six models. The survival model used a Cox modelling procedure. Further, different performance measures of all models were discussed since even in highly accurate scoring models, misclassification patterns appear. A systematic comparison '3 + 2 + 2' procedure is suggested to find the most effective model for a bank. Additionally, the survival analysis model is compared to neural network models according to the relative importance of different variables in predicting the time to default. Although different models can have very similar performance measures they may consist of different variables. The dataset used for the research was collected from a Croatian bank and credit customers were observed during a 12-month period. The paper emphasizes the importance of conducting a detailed comparison procedure while selecting the best model that satisfies the users' interest. © 2008 Elsevier Ltd. All rights reserved. © 2009 Elsevier B.V., All rights reserved.","Šarlija, N.; Benšíc, M.; Zekić-Sušac, M.",2009,10.1016/j.eswa.2008.11.042,https://www.scopus.com/inward/record.uri?eid=2-s2.0-60849137198&doi=10.1016%2Fj.eswa.2008.11.042&partnerID=40&md5=c735efcf3fe984ca06b4c187f150ef0d,scopus
d7114845f2509422,Comparisons of mean-variance analysis and entropy-based approaches to portfolio selection under asymmetric returns in bear and bull markets,"This paper considers dynamic portfolio selection models where uncertainty in the financial market is characterized by business cycles. We consider that the financial market is defined by factors and present a regime switching autoregressive model for macro-economic factors to reflect financial cycles. It is assumed that the regime dynamics are Markovian and the parameters in the autoregressive model depend on regime dynamics. We then define a factor model for asset returns, with returns depending on regimes through the factors. The joint distribution of regimes and asset returns is the input to optimal portfolio selection models. Contrasting approaches to risk measurement of returns on investment are variance and exponential Rényi entropy (Rényi, 1960). We compare portfolio models with minimum variance and minimum entropy objectives. In the empirical analysis, we use the select sector ETFs to test the asset pricing model and examine the portfolio performance. Weekly financial data from 04-March-2016 to 26-June-2020 is employed for the estimation of the hidden Markov model including the asset return parameters, while the out-of-sample period from 26-June-2020 and 14-July-2023 is used for portfolio performance testing. It is found that, under both the empirical Sharpe and excess return to entropy ratios, the dynamic portfolio strategy with the entropy objective is an improvement on mean-variance models. © 2025 Elsevier B.V., All rights reserved.","MacLean, L.; Zhao, Y.; Miao, H.",2025,10.1007/s10479-025-06746-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013467192&doi=10.1007%2Fs10479-025-06746-x&partnerID=40&md5=9f90626e433c0bcb688c46baef7ae42a,scopus
c2f82cd368b736fd,"Complex systems and ‘‘Spatio ‐Temporal Anti‐Compliance Coordination’’ In cyber‐physical networks: A critique of the Hipster Effect, bankruptcy prediction and alternative risk premia","The Hipster Effect is a group of evolutionary ‘‘Diffusive Learning’’ processes of networks of individuals and groups (and their communication devices) that form Cyber‐Physical Systems; and the Hipster Effect theory has potential applications in many fields of research. This study addresses decision‐making parameters in machine‐learning algorithms, and more specifically, critiques the explanations for the Hipster Effect, and discusses the implications for portfolio management and corporate bankruptcy prediction (two areas where AI has been used extensively). The methodological approach in this study is entirely theoretical analysis. The main findings are as follows: (i) the Hipster Effect theory and associated mathematical models are flawed; (ii) some decision‐making and learning models in machine‐learning algorithms are flawed; (iii) but regardless of whether or not the Hipster Effect theory is correct, it can be used to develop portfolio management models, some of which are summarised herein; (iv) the [1] corporate bankruptcy prediction model can also be used for portfolio‐selection (stocks and bonds).","Nwogugu, Michael I. C.",2021,10.1049/ccs2.12029,None,proquest
8b970c6aaf653977,"Complexity, nonlinearity and high frequency financial data modeling: lessons from computational approaches","This editorial introduces the special issue Complexity, Nonlinearity and High Frequency Financial Data Modeling: Lessons from Computational Approaches in Annals of Operations Research, which brings together 19 contributions exploring advanced methods and applications in the analysis of financial markets. The collected works reflect the growing importance of complexity and nonlinear dynamics in understanding modern financial systems, marked by high volatility, interdependence, and structural shifts. The papers are organized thematically into five main areas: (i) complexity and nonlinearity in financial markets, (ii) advanced forecasting and econometric modeling, (iii) network theory, causality, and information flows, (iv) banking, credit risk, and economic growth, and (v) continuous-time and structural model reviews. There is an additional section on methodological innovations, which include time–frequency and multi-scale analysis, recent developments of nonlinear and regime-switching models, machine learning, and complex network approaches. A heartfelt tribute is dedicated to the late Marco Tucci, co-editor of this special issue, whose vision and scholarly contributions significantly shaped its content. Sadly, Marco passed away while we were in the process of compiling this special issue. The editorial concludes by highlighting common methodological threads, synthesizing key insights, and outlining promising avenues for future research in complexity-informed financial modeling.","Amman, Hans; Barnett, William A.; Jawadi, Fredj; Tucci, Marco",2025,10.1007/s10479-025-06809-z,None,proquest
73aef08caa80ac1f,Comprehensive evidence implies a higher social cost of CO2,"The social cost of carbon dioxide (SC-CO2) measures the monetized value of the damages to society caused by an incremental metric tonne of CO2 emissions and is a key metric informing climate policy. Used by governments and other decision-makers in benefit-cost analysis for over a decade, SC-CO2 estimates draw on climate science, economics, demography and other disciplines. However, a 2017 report by the US National Academies of Sciences, Engineering, and Medicine1 (NASEM) highlighted that current SC-CO2 estimates no longer reflect the latest research. The report provided a series ofrecommendations for improving the scientific basis, transparency and uncertainty characterization of SC-CO2 estimates. Here we show that improved probabilistic socioeconomic projections, climate models, damage functions, and discounting methods that collectively reflect theoretically consistent valuation of risk, substantially increase estimates of the SC-CO2. Our preferred mean SC-CO2 estimate is $185 per tonne ofCO2 ($44-$413 per tCO2: 5%-95% range, 2020 US dollars) at a near-term risk-free discount rate of 2%, a value 3.6 times higher than the US government's current value of $51per tCO2. Our estimates incorporate updated scientific understanding throughout all components of SC-CO2 estimation in the new open-source Greenhouse Gas Impact Value Estimator (GIVE) model, in a manner fully responsive to the near-term NASEM recommendations. Our higher SC-CO2 values, compared with estimates currently used in policy evaluation, substantially increase the estimated benefits of greenhouse gas mitigation and thereby increase the expected net benefits of more stringent climate policies.","Rennert, Kevin; Errickson, Frank; Prest, Brian C; Rennels, Lisa; Newell, Richard G; Pizer, William; Kingdon, Cora; Wingenroth, Jordan; Cooke, Roger; Parthum, Bryan; Smith, David; Cromar, Kevin; Diaz, Delavane; Moore, Frances C; Müller, Ulrich K; Plevin, Richard J; Raftery, Adrian E; Ševčíková, Hana; Sheets, Hannah; Stock, James H; Tan, Tammy; Watson, Mark; Wong, Tony E; Anthoff, David",2022,10.1038/s41586-022-05224-9,None,proquest
435757a2aac6a115,Computer-aided resilience: Advanced techniques for disaster management in smart urban environments,"This research paper explores innovative contributions to the field of disaster management in smart urban environments, with a particular focus on integrating advanced computer-aided techniques, specifically GRU-CNN. Three key contributions are highlighted: (1) the development of dynamic risk assessment algorithms utilizing GRU-CNN for real-time analysis and predictive modeling, enabling proactive disaster mitigation; (2) the establishment of an integrated sensor network infrastructure for early warning systems, leveraging various sensors and GRU-CNN-based data analytics to detect and respond to potential disasters at their nascent stages; and (3) the implementation of human-centric resilience planning, utilizing GRU-CNN-based computer-aided tools to simulate disaster scenarios and engage communities in preparedness efforts. The dynamic risk assessment algorithms presented in this paper, powered by GRU-CNN, enable continuous monitoring and analysis of diverse data sources, fostering a proactive approach to disaster preparedness. The integrated sensor network architecture enhances early warning capabilities, allowing for timely responses to emerging threats through the application of GRU-CNN methodologies. Furthermore, the human-centric resilience planning approach introduces virtual simulations using GRU-CNN to model disaster scenarios, facilitating the testing and refinement of strategies in a risk-free environment. This approach not only ensures the adaptability of plans but also engages and educates communities, fostering a culture of preparedness, with GRU-CNN playing a pivotal role in the process. Through these contributions, this research paper seeks to advance the discourse on disaster management in smart urban environments, emphasizing the integration and effectiveness of GRU-CNN in enhancing resilience and response strategies. By leveraging cutting-edge GRU-CNN technologies and prioritizing community involvement, the proposed techniques aim to provide a more robust and adaptive response to the challenges posed by natural and man-made disasters in urban settings. © 2024 Elsevier B.V., All rights reserved.","Li, R.; Di, Y.; Tian, H.",2024,10.1016/j.scs.2024.105437,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192164396&doi=10.1016%2Fj.scs.2024.105437&partnerID=40&md5=5501812a88b27a6182b0b861baf448f2,scopus
d55b2643487b31d3,Computing Arbitrage-Free Yields in Multi-Factor Gaussian Shadow Rate Term Structure Models,"This paper develops an approximation to arbitrage-free bond yields in Gaussian shadow rate term structure models. In this class of models, yields are constrained to be above an effective lower bound, thus rendering standard bond pricing methods inapplicable. I propose approximating the nonlinear relationship between yields and state variables using moments of the censored normal distribution. In an empirical application, this approximation technique is accurate to within a fraction of a basis point. As I show, minimizing the yield approximation error is crucial for model estimation as even seemingly small errors can lead to economically meaningful inference biases. © 2024 Elsevier B.V., All rights reserved.","Priebsch, M.A.",2023,10.1142/s2010139223500131,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181668998&doi=10.1142%2FS2010139223500131&partnerID=40&md5=fcef3acf1d58d664f9d560482b5d0465,scopus
2f9b56551fe50eb8,Condition Prediction for Existing Educational Facilities Using Artificial Neural Networks and Regression Analysis,"Infrastructural assets such as roads, bridges, and buildings make a considerable contribution to national economies. These assets deteriorate due to aging, environmental conditions, and other external factors. Maintaining the performance of an asset in line with rational repair strategies represents a considerable challenge for decision-makers, who may not pay attention to developing adequate maintenance plans or leave the assets unmaintained. Worldwide, organizations are under pressure to ensure the sustainability of their assets. Such organizations may burden their treasury with random maintenance operations, especially with a limited budget. This research aims to develop a generalized condition assessment approach to monitor and evaluate existing facility elements. The proposed approach represents a methodology to determine the element condition index (CI). The methodology is reinforced with an artificial neural network (ANN) model to predict the element deterioration. The performance of this model was evaluated by comparing the obtained predicted CIs with ordinary least squares (OLS) regression model results to choose the most accurate prediction technique. A case study was applied to a group of wooden doors. The ANN model showed reliable results with R2 values of 0.99, 0.98, and 0.99 for training, cross-validation, and testing sets, respectively. In contrast, the OLS model R2 value was 1.00. These results show the high prediction capability of both models with an advantage to the OLS model. Applying this approach to different elements can help decision-makers develop a preventive maintenance schedule and provide the necessary funds.","Hassan, Ahmed M; Hassan, Ahmed M; Kareem Adel; Elhakeem, Ahmed; Elmasry, Mohamed I S",2022,10.3390/buildings12101520,None,proquest
807b76db734ed6fd,Conditional Skewness in Asset Pricing: 25 Years of Out-of-Sample Evidence,"Much attention is paid to portfolio variance, but skewness is also important for both portfolio design and asset pricing. We revisit the empirical research on systematic skewness that we initiated 25 years ago. We analyze the out-of-sample evidence for the skewness risk premium presented in the literature including the recent work of Anghel et al. (2023). We also conduct an out-of-sample test and focus on the sensitivity of the risk premium estimate to different research choices. Overall, we find that the risk premium associated with systematic skewness is similar to the one reported in our original paper. © 2024 Elsevier B.V., All rights reserved.","Harvey, C.R.; Siddique, A.",2023,10.1561/104.00000134,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192779205&doi=10.1561%2F104.00000134&partnerID=40&md5=bf020e243fcc8a2f732bf1780d4d5319,scopus
465418f6b1f7d557,Conditional risk-return relationship in a time-varying beta model,"We investigate the asymmetric risk-return relationship in a time-varying beta CAPM. A state space model is established and estimated by the Adaptive Least Squares with Kalman foundations proposed by McCulloch. Using SP 500 daily data from 1987:11-2003:12, we find a positive risk-return relationship in the up market (positive market excess returns) and a negative relationship in the down market (negative market excess returns). This supports the argument of Pettengill et al., who use a constant beta model. However, our model outperforms theirs by eliminating the unexplained returns and improving the accuracy of the estimated risk price.","Huang, Peng; Hueng, C. James",2008,10.1080/14697680701191361,None,wos
980a360dd8f36999,Conditioning information and variance bounds on pricing kernels,"Gallant, Hansen, and Tauchen (1990) show how to use conditioning information optimally to construct a sharper unconditional variance bound (the GHT bound) on pricing kernels. The literature predominantly resorts to a simple but suboptimal procedure that scales returns with predictive instruments and computes standard bounds using the original and scaled returns. This article provides a formal bridge between the two approaches. We propose an optimally scaled bound that coincides with the GHT bound when the first and second conditional moments are known. When these moments are misspecified, our optimally scaled bound yields a valid lower bound for the standard deviation of pricing kernels, whereas the GHT bound does not. We illustrate the behavior of the bounds using a number of linear and nonlinear models for consumption growth and bond and stock returns. We also illustrate how the optimally scaled bound can be used as a diagnostic for the specification of the first two conditional moments of asset returns.","Bekaert, G; Liu, J",2004,10.1093/rfs/hhg052,None,wos
466b8b36926ebb9e,Connectedness network and dependence structure mechanism in green investments,"We present an empirical study of renewable energy stock returns and their relation to four major investment asset classes—stocks, currency, US Treasury bonds, and oil—and several sources of uncertainty. Applying nonlinear causality and connectedness network analysis on data covering the period 2004–2016, we investigate the directionality and connectedness among different asset classes, as well as between uncertainties. First, from the results of the estimation of directionality and network spillovers, it can be concluded that the European stock market has a strong market dependence on renewable energy stock prices. Second, uncertainties have an economically significant impact on both return and volatility spillover in energy investments. Third, most of the uncertainties are net transmitters of volatility connectedness during the global financial crisis (GFC) and European sovereign debt crisis (ESDC). © 2018 Elsevier B.V., All rights reserved.","Lundgren, A.I.; Milicevic, A.; Uddin, G.S.; Kang, S.H.",2018,10.1016/j.eneco.2018.04.015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045660578&doi=10.1016%2Fj.eneco.2018.04.015&partnerID=40&md5=b1c26dcdb123c802a3c779b455053326,scopus
abab2a97634ef640,Constant Proportion Portfolio Insurance Strategy in Southeast European Markets,"Background: In today's highly volatile and unpredictable market conditions, there are very few investment strategies that may offer a certain form of capital protection. The concept of portfolio insurance strategies presents an attractive investment opportunity.Objectives: The main objective of this article is to test the use of portfolio insurance strategies in Southeast European (SEE) markets. A special attention is given to modelling non-risky assets of the portfolio.Methods/Approach: Monte Carlo simulations are used to test the buy-and-hold, the constant-mix, and the constant proportion portfolio insurance (CPPI) investment strategies. A covariance discretization method is used for parameter estimation of bond returns.Results: According to the risk-adjusted return, a conservative constant mix was the best, the buy-and-hold was the second-best, and the CPPI the worst strategy in bull markets. In bear markets, the CPPI was the best in a high-volatility scenario, whereas the buy-and-hold had the same results in low- and medium-volatility conditions. In no-trend markets, the buy-and-hold was the first, the constant mix the second, and the CPPI the worst strategy. Higher transaction costs in SEE influence the efficiency of the CPPI strategy.Conclusions: Implementing the CPPI strategy in SEE could be done by combining stock markets from the region with government bond markets from Germany due to a lack of liquidity of the government bond market in SEE.","Agic-Sabeta, Elma",2016,10.1515/bsrj-2016-0005,None,proquest
f4767033c2a4eee5,Constrained Factor Models for High-Dimensional Matrix-Variate Time Series,"High-dimensional matrix-variate time series data are becoming widely available in many scientific fields, such as economics, biology, and meteorology. To achieve significant dimension reduction while preserving the intrinsic matrix structure and temporal dynamics in such data, Wang, Liu, and Chen proposed a matrix factor model, that is, shown to be able to provide effective analysis. In this article, we establish a general framework for incorporating domain and prior knowledge in the matrix factor model through linear constraints. The proposed framework is shown to be useful in achieving parsimonious parameterization, facilitating interpretation of the latent matrix factor, and identifying specific factors of interest. Fully utilizing the prior-knowledge-induced constraints results in more efficient and accurate modeling, inference, dimension reduction as well as a clear and better interpretation of the results. Constrained, multi-term, and partially constrained factor models for matrix-variate time series are developed, with efficient estimation procedures and their asymptotic properties. We show that the convergence rates of the constrained factor loading matrices are much faster than those of the conventional matrix factor analysis under many situations. Simulation studies are carried out to demonstrate finite-sample performance of the proposed method and its associated asymptotic properties. We illustrate the proposed model with three applications, where the constrained matrix-factor models outperform their unconstrained counterparts in the power of variance explanation under the out-of-sample 10-fold cross-validation setting. for this article are available online.","Chen, Elynn Y.; Tsay, Ruey S.; Chen, Rong",2020,10.1080/01621459.2019.1584899,None,wos
7246f8dac06ea8d7,Constructing Risk Analysis for Changes in China’s Local Government Bond System Based on SSP,"The local government bond system of China has experienced a series of changes from its initial creation to its abolition and then to a recovery again. During the period, the central government always dominated the changing direction of the local government bond system. However, as fiscal decentralization reform has progressed, the institutional needs of local governments and investors have gradually gained attention. As a result, the size and variety of local government bonds are expanding. Through the introduction of analysis of system change based on situation structure performance (SSP), this paper uses Machine Learning (ML) approaches to predict the risk of government debt of China in the context of changing the local government bond system. Besides, this research work includes the comprehensive weight assignment for government debt hazard, fiscal revenue forecasting, default risk calculation, and finally an analysis of the validity of government debt hazard. The system may provide financial signal advice and strategy reference for dealing with hazards in early payment, organizing debt repayment significance order, optimizing fiscal revenue and cost structure, and so on.","Xie, Ping; Zhang, Chunyan",2022,10.1155/2022/4606905,None,proquest
52cf1b9349ff6fe8,Consumption and equilibrium asset pricing: An empirical assessment,"In the various attempts to solve the equity premium puzzle, the characterization of the utility function has received a lot of attention, along with the postulated nature of the economy. In this paper, we specify and estimate by maximum likelihood over the period 1871 - 1985 a heteroskedastic joint consumption and dividend Markov endowment process in an exchange asset pricing model. To assess the model, we try to replicate both the first and second unconditional moments of the return series, the negative serial correlation present in real and excess returns and the forecasting power of the dividend-price ratio for multiperiod returns. For the real returns, the model captures to some extent the main features of the data for values of the coefficient of risk aversion below 10. The main failure of the model comes from the excess returns. We also assess the model by inferring the consumption growth that rationalizes the observed stock and safe asset returns, but it is too variable to be plausible. © 2022 Elsevier B.V., All rights reserved.","Bonomo, M.; Garcia, R.",1996,10.1016/0927-5398(96)00002-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030243487&doi=10.1016%2F0927-5398%2896%2900002-3&partnerID=40&md5=e7b71931b2764b48a8f6f6888b7ef14b,scopus
cb24b3ef04cba676,"Consumption, aggregate wealth and expected stock returns: a quantile cointegration approach","This paper empirically examines the long-run relationship between consumption, asset wealth and labor income (i.e., cay) in the United States through the lens of a quantile cointegration approach. The advantage of using this approach is that it allows for a nonlinear relationship between these variables depending on the level of consumption. We estimate the coefficients using a Phillips–Hansen type fully modified quantile estimator to correct for the presence of endogeneity in the cointegrating relationship. To test for the null of cointegration at each quantile, we apply a quantile CUSUM test. Results show that: (i) consumption is more sensitive to changes in labor income than to changes in asset wealth for the entire distribution of consumption, (ii) the elasticity of consumption with respect to labor income (asset wealth) is larger at the right (left) tail of the consumption distribution than at the left (right) tail, (iii) the series are cointegrated around the median, but not in the tails of the distribution of consumption, (iv) using the estimated cay obtained for the right (left) tail of the distribution of consumption improves the long-run (short-run) forecast ability on real excess stock returns over a risk-free rate.","Quineche, Ricardo",2022,10.1515/snde-2020-0059,None,proquest
eed3af2446ec0a3a,"Contemporaneous threshold autoregressive models: Estimation, testing and forecasting","This paper proposes a contemporaneous smooth transition threshold autoregressive model (C-STAR) as a modification of the smooth transition threshold autoregressive model surveyed in Terasvirta [1998. Modelling economic relationships with smooth transition regressions. In: Ullah, A., Giles, D.E.A. (Eds.), Handbook of Applied Economic Statistics. Marcel Dekker, New York, pp. 507-552.], in which the regime weights depend on the ex ante probability that a latent regime-specific variable will exceed a threshold value. We argue that the contemporaneous model is well suited to rational expectations applications (and pricing exercises), in that it does not require the initial regimes to be predetermined. We investigate the properties of the model and evaluate its finite-sample maximum likelihood performance. We also propose a method to determine the number of regimes based on a modified Hansen [1992. The likelihood ratio test under nonstandard conditions: testing the Markov switching model of GNP. Journal of Applied Econometrics 7, S61-S82.] procedure. Furthermore, we construct multiple-step ahead forecasts and evaluate the forecasting performance ofthe model. Finally, an empirical application of the short term interest rate yield is presented and discussed. (c) 2006 Elsevier B.V. All rights reserved.","Dueker, Michael J.; Sola, Martin; Spagnolo, Fabio",2007,10.1016/j.jeconom.2006.10.022,None,wos
438204aa4a86c9c1,Corporate Probability of Default: A Single-Index Hazard Model Approach,"Corporate probability of default (PD) prediction is vitally important for risk management and asset pricing. In search of accurate PD prediction, we propose a flexible yet easy-to-interpret default-prediction single-index hazard model (DSI). By applying it to a comprehensive U.S. corporate bankruptcy database we constructed, we discover an interesting V-shaped relationship, indicating a violation of the common linear hazard specification. Most importantly, the single-index hazard model passes the Hosmer-Lemeshow goodness-of-fit calibration test while neither does a state-of-the-art linear hazard model in finance nor a parametric class of Box-Cox transformation survival models. In an economic value analysis, we find that this may translate to as much as three times of profit compared to the linear hazard model. In model estimation, we adopt a penalized-spline approximation for the unknown function and propose an efficient algorithm. With a diverging number of spline knots, we establish consistency and asymptotic theories for the penalized-spline likelihood estimators. Furthermore, we reexamine the distress risk anomaly, that is, higher financially distressed stocks deliver anomalously lower excess returns. Based on the PDs from the proposed single-index hazard model, we find that the distress risk anomaly has weakened or even disappeared during the extended period.","Li, Shaobo; Tian, Shaonan; Yu, Yan; Zhu, Xiaorui; Lian, Heng",2023,10.1080/07350015.2022.2120484,None,wos
1914bca37c18fad2,Corporate bond pricing and the effects of endogenous default and call options,"Acharya and Carpenter [2002] model the value of a defaultable and callable bond. Focusing on the interaction between the call and default options, they note that the existence of one option delays the exercise of the other. This has strong empirical implications for duration and for the determinants of yield spread changes. For duration, when considered separately, both default and call shorten duration. However, when the interaction between the two risks is also accounted for, it is shown to lengthen duration. Since duration is equivalent to the interest-rate elasticity of the bond, the above analysis is also important for the interest-rate sensitivity of the bond yield spread. Sarkar and Hong [2004] also derive a structural model for pricing a fixed-price callable and defaultable bond, and their model has similar implications to that of Acharya and Carpenter [2002]. In this article we test the main implications of these theoretical models. In particular, we test the interest-rate elasticity of the call spread and that of the default spread, allowing for interaction between both spreads. We also examine the impact of both risks and their interaction on the effective duration of corporate bonds. In our tests we examine both bonds carrying a fixed-price call option and those carrying the newer and more popular makewhole option. We find evidence supporting the predictions of the two models. First, our data show a statistically significant interaction between default spreads and call spreads. Second, as the theory predicts, we show that, when considered separately, both default and call risks shorten duration for fixed-price callable bonds. When both risks are considered together, in general we find that the interaction term lengthens the effective duration of callable defaultable bonds. This finding is in agreement with the theory. The implication of our findings is that portfolio managers of callable corporate bonds, who use duration as an immunization tool or practice active rate anticipation strategies, must pay attention to the maturity of the bond. For example, it is clear that no risk adjustment is necessary when one manages A rated make-whole callable bonds with short and medium maturities. However, it is important to consider not only the impacts of default and call risks on estimating duration but also the interaction between these variables when one manages callable debt of all other maturities. We repeat our tests for bond portfolios stratified by ratings. In general, the results for the portfolios are also in agreement with the implications of the Acharya and Carpenter [2002] model. Another prediction made by Acharya and Carpenter is that both the noncallable and callable bonds' sensitivity to firm value decrease. For noncallable bonds, we find that the default spread's sensitivity to equity return is much greater for BBB rated bonds compared with AA and A rated bonds. Acharya and Carpenter [2002] also argue that callable bond's sensitivity to firm value is lower than that of a noncallable bond. In general, our results support this theoretical prediction, especially for make-whole bonds. The models of Acharya and Carpenter [2002] and Sarkar and Hong [2004] focus on pricing fixed-price callable bonds. However, the make-whole call provision became the standard for callable bonds in recent years, both in the U.S. and Canada. Powers and Tsyplakov [2004] derive a structural model for pricing make-whole callable bonds. Their model does not allow the study of duration similar to that of Acharya and Carpenter [2002] and Sarkar and Hong [2004]. Given the popularity of make-whole bonds, a possible direction for future research is the introduction of a structural bond-pricing model that allows studying the duration and yield-spread elasticity of these bonds. © 2010 Elsevier B.V., All rights reserved.","Jacoby, G.; Shiller, I.",2010,10.3905/jfi.2010.20.2.080,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77957848360&doi=10.3905%2Fjfi.2010.20.2.080&partnerID=40&md5=93545e73cc89f0bfc89b6c60f801f529,scopus
6ff1318102cc0b35,Corporate relation extraction for the construction of knowledge-bases against tax fraud,"Tax fraud is a criminal activity that entails significant losses for governments. Due to its clandestine nature, it is difficult to reliably estimate the amount of taxes evaded. To fight tax fraud, this investigation details the construction and evaluation of a corporate relation extraction system designed to access an unstructured knowledge-base and extract corporate relations for further validation. The system was developed in response to a need raised by the Treasury and Finance Department of the Provincial Council of Gipuzkoa (Spain). It follows a waterfall architecture that integrates Natural Language Processing (NLP) and Computer Vision (CV) components, including web scraping, optical character recognition, syntactic parsing, and information extraction. The proposed system produces a relational knowledge-base with structured data representing 23 types of corporate operations published in the Official Gazette of the Commercial Registry (e.g., incorporation of companies, terminations, capital increases and reductions, mergers and takeovers, etc.), allowing for comparison with the fiscal information available in the tax agency. Facilitating such comparison across distinct sources is key to identifying discrepancies that might be indicators of tax fraud. © 2025 Elsevier B.V., All rights reserved.","Lopez-Gazpio, I.; Baselga-Pascual, L.; Garmendia-Lazcano, A.",2025,10.1016/j.knosys.2025.113026,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215966196&doi=10.1016%2Fj.knosys.2025.113026&partnerID=40&md5=7d2cbcf4fc0162b01f57c357e1ef6ac4,scopus
601fcc34e98aa64e,Corrigendum: Bond Risk Premiums with Machine Learning,"In this note we revisit the empirical results in Bianchi, Büchner, and Tamoni (2020) after correcting for using information not available at the time the forecast was made. Although we note a decrease in out-of-sample $R^2$, the revised analysis confirms that bond excess return predictability from neural networks remains statistically and economically significant.","Bianchi, Daniele; Büchner, Matthias; Hoogteijling, Tobias; Tamoni, Andrea",2021,10.1093/rfs/hhaa098,None,proquest
87e1f8b8d00601f6,Cost-benefit analysis in a climate of change: setting social discount rates in the case of Ireland,"The global practice of Cost-Benefit Analysis (CBA), to analyse the welfare impacts of public investments, has undergone profound changes in recent years. The reforms in general practice have primarily been driven by the discussions of the implications of climate change and environmental degradation. Central to the discussion has been the social discount rate, used to value future costs and benefits in the present, and also the dual discount rates for ""environmental goods"", as goods that are of no, or of risky substitution. Official rates, in many nations, are calculated using the ""Ramsey"" formula. The literature has explored the relevant factors in this formula, but with less attention paid to the selection of the rate of future growth in consumption, or to the setting of dual discount rates in national practice guidance. Through considering the case of Ireland, this study demonstrates that the selection of growth rates in consumption, in the context of future uncertainty, requires the use of plausible scenarios, rather than historical trends or forecasts. By employing economic scenarios, alongside established values for the other factors, the main discount rate for Ireland is calculated in a range of 1.7 to 2.8 per cent. Seperately, a dual discount rate, for capital that cannot be replaced, is estimated at ≤1.3 per cent. The main discount rate is validated by comparison against discount rates found in the literature, applied in other comparable nations, and by the rate estimated from the real yield on government bonds. All four independent lines of evidence support the range estimated. This demonstrates that the Irish government's estimated discount rate, of 4.0 per cent, is not credible, and needs reduction, alongside introduction of dual discounting.","O'Mahony, Tadhg",2021,10.3934/gf.2021010,None,proquest
446b6410f6523443,Counting the investor vote: Political business cycle effects on sovereign bond spreads in developing countries,"International business research has paid scant attention to whether and how electoral politics and economic policies affect foreign investment risk assessment, particularly in developing countries, where the last decade has seen both considerable foreign investment and domestic progress toward democratization and electoral competitiveness. We respond with development and testing of a framework using partisan and opportunistic political business cycle (PBC) theory to predict the investment risk perceived by investors holding sovereign bonds during 19 presidential elections in 12 developing countries from 1994 to 2000. Consistent with our framework, we find that bondholders perceive higher (lower) investment risk in the form of higher (lower) credit spreads on their sovereign bonds as right-wing (left-wing) political incumbents appear more likely to be replaced by left-wing (right-wing) challengers. For international business research, our findings illustrate the promise of PBC theory in explaining the election-period behavior of sovereign bondholders and, perhaps, other investors who also 'vote' in developing country elections and can substantially influence the price and availability of capital there. For developing country investors and states, our findings highlight the financial effects of democracy in action, and underscore the importance of state communication with investors during election periods. © 2005 Palgrave Macmillan Ltd. All rights reserved. © 2024 Elsevier B.V., All rights reserved.","Vaaler, P.M.; Schrage, B.N.; Block, S.A.",2005,10.1057/palgrave.jibs.8400111,https://www.scopus.com/inward/record.uri?eid=2-s2.0-14944342935&doi=10.1057%2Fpalgrave.jibs.8400111&partnerID=40&md5=682574fa0a86b86aad256960bf9d9a1c,scopus
c924d5a2b4699539,Creating investment scheme with state space modeling,"This paper proposes a unified approach to creating investment strategies with various desirable properties for investors. Particularly, we provide a new interpretation and the resulting formulations for state space models to attain our investment objectives, which are possibly specified as generating additional returns over benchmark stock indexes or achieving target risk-adjusted returns.Our state space models with particle filtering algorithm are employed to develop expert systems for investment strategies in highly complex financial markets. More concretely, in our state space framework, we apply a system model to representing portfolio weight processes with various constraints, as well as the standard underlying state variables such as volatility processes, Further, we formulate an observation model to stand for target value processes with non-linear functions of observed and latent variables.Numerical experiments demonstrate the effectiveness of our methodology through creating excess returns over S&P 500 and generating investment portfolios with fine risk-return profiles. (C) 2017 Elsevier Ltd. All rights reserved.","Nakano, Masafumi; Takahashi, Akihiko; Takahashi, Soichiro",2017,10.1016/j.eswa.2017.03.045,None,wos
1f799a63b4ffb64c,Credibilistic risk aversion,"In the probabilistic risk aversion approach, risks are presumed as random variables with known probability distributions. However, in some practical cases, for example, due to the absence of historical data, the inherent uncertain characteristic of risks or different subject judgements from the decision-makers, risks may be hard or not appropriate to be estimated with probability distributions. Therefore, the traditional probabilistic risk aversion theory is ineffective. Thus, in order to deal with these cases, we suggest measuring these kinds of risks as fuzzy variables, and accordingly to present an alternative risk aversion approach by employing credibility theory. In the present paper, first, the definition of credibilistic risk premium proposed by Georgescu and Kinnunen [Fuzzy Inf. Eng., 2013, 5, 399–416] is revised by taking the initial wealth into consideration, and then a general method to compute the credibilistic risk premium is provided. Secondly, regarding the risks represented with the commonly used LR fuzzy intervals, a simple calculation formula of the local credibilistic risk premium is put forward. Finally, in a global sense, several equivalent propositions for comparative risk aversion under the credibility measurement are provided. Illustrated examples are presented to show the applicability of the theoretical findings. © 2017 Elsevier B.V., All rights reserved.","Liu, Y.; Zhou, J.; Pantelous, A.A.",2017,10.1080/14697688.2016.1264617,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008225393&doi=10.1080%2F14697688.2016.1264617&partnerID=40&md5=553152a688730680f0ca8955b348c249,scopus
f2efdb3b04670f81,Credit Debt Default Risk Assessment Based on the XGBoost Algorithm: An Empirical Study from China,"The bond market is an important part of China’s capital market. However, defaults have become frequent in the bond market in recent years, and consequently, the default risk of Chinese credit bonds has become increasingly prominent. Therefore, the assessment of default risk is particularly important. In this paper, we utilize 31 indicators at the macroeconomic level and the corporate microlevel for the prediction of bond defaults, and we conduct principal component analysis to extract 10 principal components from them. We use the XGBoost algorithm to analyze the importance of variables and assess the credit debt default risk based on the XGBoost prediction model through the calculation of evaluation indicators such as the area under the ROC curve (AUC), accuracy, precision, recall, and F1-score, in order to evaluate the classification prediction effect of the model. Finally, the grid search algorithm and k-fold cross-validation are used to optimize the parameters of the XGBoost model and determine the final classification prediction model. Existing research has focused on the selection of bond default risk prediction indicators and the application of XGBoost algorithm in default risk prediction. After optimization of the parameters, the optimized XGBoost algorithm is found to be more accurate than the original algorithm. The grid search and k-fold cross-validation algorithms are used to optimize the XGBoost model for predicting the default risk of credit bonds, resulting in higher accuracy of the proposed model. Our research results demonstrate that the optimized XGBoost model has a significantly improved prediction accuracy, compared to the original model, which is beneficial to improving the prediction effect for practical applications.","Wang, Jun; Wei, Rong; Zhang, Zhuo; Dong Mei",2022,10.1155/2022/8005493,None,proquest
c8879786a5202f7a,Credit Pit Detection in Subordinate Securities: A French Perspective,"The purpose of this research is to prepare a predictive model for identifying credit crisis using an artificial neural network. The paper also aims to find out the driver and driven relationship between various financial instruments like CDS, FRA, IRS, and the Volatility index (VCAC) and government securities for France. The model, thus, is directed towards finding a threshold for credit pit events and linking various events corresponding to that dates where the threshold is breached to validate the accuracy and usefulness of the model. From the research, it is found that for France, the CDS-FRA-VCAC model derives the threshold for VCAC to indicate the probability of credit crisis or financial market crash. It is also found that sovereign bonds have a huge impact on France economy including various derivatives. This is probably why the Eurozone debt crisis impacted France much more than the 2008 financial crash.","Jain, Sfoorti",2019,10.12725/ujbm.48.6,None,proquest
fe9ab6866fa2b491,"Credit Spreads, Leverage and Volatility: A Cointegration Approach","This work documents the existence of a cointegration relationship between credit spreads, leverage and equity volatility for a large set of US companies. It is shown that accounting for the long-run equilibrium dynamic between these variables is essential to correctly explain credit spread changes. Using a novel structural model in which equity is modeled as a compound option on the firm's assets, a new methodology for estimating the unobservable market value of the firm's assets and volatility is developed. The proposed model allows to significantly reduce the pricing errors in predicting credit spreads when compared with several structural models. In terms of correlation analysis, it is shown that not accounting for the long-run equilibrium equation embedded in an error correction mechanism (ECM) results into a misspecification problem when regressing a set of explanatory variables onto the spread changes. Once credit spreads, leverage and volatility are correctly modeled, thus allowing for a long-run equilibrium, the fit of the regressions sensibly increases if compared to the results of previous research. It is further shown that most of the cross-sectional variation of the spreads appears to be more driven by firm-specific characteristics rather than systematic factors.","Maglione, Federico",2022,10.3390/computation10090155,None,wos
c93e69f76880bb85,"Credit growth, the yield curve and financial crisis prediction: Evidence from a machine learning approach","We develop early warning models for financial crisis prediction applying machine learning techniques on macrofinancial data for 17 countries over 1870–2016. Most nonlinear machine learning models outperform logistic regression in out-of-sample predictions and forecasting. We identify economic drivers of our machine learning models by applying a novel framework based on Shapley values, uncovering nonlinear relationships between the predictors and crisis risk. Throughout, the most important predictors are credit growth and the slope of the yield curve, both domestically and globally. A flat or inverted yield curve is of most concern when nominal interest rates are low and credit growth is high. © 2023 Elsevier B.V., All rights reserved.","Bluwstein, K.; Buckmann, M.; Joseph, A.; Kapadia, S.; Şimşek, Ö.",2023,10.1016/j.jinteco.2023.103773,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153873224&doi=10.1016%2Fj.jinteco.2023.103773&partnerID=40&md5=abb66d3fa385d12f8957f0e53e487141,scopus
a8284129b0b72d35,Credit rating algorithm of corporate bonds based on Gaussian process mixture model and improved K-means,"The primary challenge in credit analysis revolves around uncovering the correlation between repayment terms and yield to maturity, constituting the interest rate term structure-an essential model for corporate credit term evaluation. Presently, interest rate term structures are predominantly examined through economic theoretical models and quantitative models. However, predicting treasury bond yields remains a challenging task for both approaches. Leveraging the clustering analysis algorithm theory and the attributes of an insurance company’s customer database, this paper enhances the K-means clustering algorithm, specifically addressing the selection of initial cluster centers in extensive sample environments. Utilizing the robust data fitting and analytical capabilities of the Gaussian process mixture model, the study applies this methodology to model and forecast Treasury yields. Additionally, the research incorporates customer credit data from a property insurance company to investigate the application of clustering algorithms in the analysis of insurance customer credit. © 2024 Elsevier B.V., All rights reserved.","Xia, W.",2023,10.61091/jcmcc117-14,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184140053&doi=10.61091%2Fjcmcc117-14&partnerID=40&md5=db4b7e03f54cd2d82f22b94ad0140e56,scopus
893197e230ff363c,Cross-market volatility forecasting with attention-based spatial-temporal graph convolutional networks,"We propose a cross-market volatility forecasting framework by applying attention-based spatial-temporal graph convolutional network model (ASTGCN) to forecast future volatility of stock indices in 18 financial markets. In our work, we construct cross-market volatility networks to integrate interrelations among financial markets and the corresponding features of each market. ASTGCN combines the spatial-temporal attention mechanisms with the spatial-temporal convolutions to simultaneously capture the dynamic spatial-temporal characteristics of global volatility data. Compared with competitive models, ASTGCN exhibits superiority in multivariate predictive accuracies under multiple forecasting horizons. Our proposed framework demonstrates outstanding stability through several robustness checks. We also inspect the training process of ASTGCN by extracting spatial attention matrices and find that interrelations among global financial markets perform differently in tranquil and turmoil periods. Our study levitates empirical findings in financial networks to practical application with a novel forecasting method in the deep learning community.","Gong, Jue; Wang, Gang-Jin; Zhou, Yang; Xie, Chi",2025,10.1016/j.jempfin.2025.101639,None,wos
14c53eff72879cd2,Cross-predictability of industry return in trade network: Using LASSO,"This study tests the predictability power of returns across economically related industries, using monthly data over 1990-2010 and a machine learning model, the Least Absolute Shrinkage and Selection Operator (LASSO). This article presents evidence that LASSO identifies significant predictors of the returns of an individual industry among its interdependent industries. The results indicate cross-predictability of industry return by showing a significant relation between an industry's returns and the lagged returns of its LASSO-selected trade partners. The study finds that industries that are more central in the input-output network have a greater effect in predicting related industry return. It also computes out of sample (2011-2016) the mean return forecasts of the portfolio of industries based on the predictability effect of the lagged returns of trade partners. The self-financing trading strategy of buying (selling) a high (low) portfolio based on related industry lagged returns yields about 10.44 percent annual excess return (0.83 percent monthly), with an annual Sharpe ratio of about 0.86. The study shows that after controlling for the Fama-French (1993) three factors, the monthly returns from the self-financing trading strategies generate a significant alpha of 0.7 percent monthly over the period 2011-2016. © 2020 Elsevier B.V., All rights reserved.","Ashraf, R.",2019,10.3905/joi.2019.1.095,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090195969&doi=10.3905%2Fjoi.2019.1.095&partnerID=40&md5=c7c7979fbc72b7bbed6ea690a19b5740,scopus
c54779c722cfa540,Cross-sectional regression of returns on betas and portfolio grouping procedures,"This paper shows that the deviation of the estimated coefficient of beta from the market risk premium in cross-sectional regression of returns on betas is a direct consequence of the cross-sectional relation between the estimated alphas and betas. Therefore, the portfolio grouping procedure results in systematic cross-sectional relationship between the alphas and betas, causing a deviation in the estimated coefficient of beta in either direction. When firm size is used as the only portfolio grouping variable (Table AI in Fama and French, 1992), the estimated alphas and betas across portfolios are positively related, causing the estimated coefficient of beta to be upwardly biased. However, when beta is used as the only portfolio grouping variable (Table 2 in Kothari et al., 1995), the estimated alphas and betas across portfolios are negatively related, causing the estimated coefficient of beta to be downward biased. We show that forming portfolios on alphas and betas independently can adequately control for this deviation. © 2014 Inderscience Enterprises Ltd. © 2020 Elsevier B.V., All rights reserved.","Hur, J.; Kumar, R.; Singh, V.",2014,10.1504/ijbsr.2014.058005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901001561&doi=10.1504%2FIJBSR.2014.058005&partnerID=40&md5=6c9b7fb0ff1849da3457d63fab3a0b8b,scopus
a4d80f5bda510793,Crude oil price forecasting: a biogeography-based optimization approach,"The importance of crude oil in the world economy has made it imperative for efficient models to be designed for predicting future prices. This paper proposes an alternative approach based on a time series and biogeography-based optimization (BMMR-BBO) for the estimation of the West Texas Intermediate (WTI) crude oil price. To evaluate the forecasting ability of the presented model, we compared its performance with those of time series functions. The results of the experiment showed that BMMR-BBO performed better than the other methods and is a fairly good option for crude oil price prediction. The proposed model can be useful in the formulation of policies related to international crude oil price estimations, development plans, and industrial production.","Dehghani, Hesam; Zangeneh, Mahsa",2018,10.1080/15567249.2018.1501121,None,wos
17468938c29ef9d9,Currency Value,"We assess the properties of currency value strategies based on real exchange rates. We find that real exchange rates have predictive power for the cross-section of currency excess returns. However, adjusting real exchange rates for key country-specific fundamentals (productivity, the quality of export goods, net foreign assets, and output gaps) better isolates information related to the currency risk premium. In turn, the resultant measure of currency value displays considerably stronger predictive power for currency excess returns. Finally, the predictive information content in our currency value measure is distinct from that embedded in popular currency strategies, such as carry and momentum.","Menkhoff, Lukas; Sarno, Lucio; Schmeling, Maik; Schrimpf, Andreas",2017,10.1093/rfs/hhw067,None,wos
d13ded1b300cba91,DEEP NEURAL NETWORKS METHODS FOR ESTIMATING MARKET MICROSTRUCTURE AND SPECULATIVE ATTACKS MODELS: THE CASE OF GOVERNMENT BOND MARKET,"A sovereign bond market offers a wide range of opportunities for public and private sector financing and has drawn the interest of both scholars and professionals as they are the main instrument of most fixed-income asset markets. Numerous works have studied the behavior of sovereign bonds at the microeconomic level, given that a domestic securities market can enhance overall financial stability and improve financial market intermediation. Nevertheless, they do not deepen methods that identify liquidity risks in bond markets. This study introduces a new model for predicting unexpected situations of speculative attacks in the government bond market, applying methods of deep learning neural networks, which proactively identify and quantify financial market risks. Our approach has a strong impact in anticipating possible speculative actions against the sovereign bond market and liquidity risks, so the aspect of the potential effect on the systemic risk is of high importance.","ALAMINOS, DAVID; SALAS, MARÍA BELÉN; FERNÁNDEZ-GÁMEZ, MANUEL A",2025,10.1142/s0217590822480034,None,proquest
8cc0fdcc0a19bb4a,DETECTING BUSINESS CYCLES FOR HUNGARIAN LEADING AND COINCIDENT INDICATORS WITH A MARKOV SWITCHING DYNAMIC MODEL TO IMPROVE SUSTAINABILITY IN ECONOMIC GROWTH,"This paper applies the hidden Markov switching dynamic regression (MSDR) model to estimate transition probabilities of the Hungarian GDP between recessionary and expansionary periods. The transition probabilities are then compared to the OECD Hungarian binary business cycle indicator to assess the predictive power of the model. The paper proposes a linear model with a mean and a homoscedastic component. The level of symmetricity between the GDP and business cycles is explained by the panel data variables (Unemployment rate, IPI index, Inflation, BUX year-on-year change, and 10-3 Year sovereign bond yield spreads). It is assumed in this paper that by extending the model to encompass an exogenous variable listed in the panel data, essentially making the model bivariate, the maximum likelihood function would capture the business cycle more accurately. The results show that by plugging the unemployment rate as the exogenous variable in the regression, our model’s accuracy is 70%. © 2023 Elsevier B.V., All rights reserved.","Molnár, A.; Vasa, L.; Csiszárik-Kocsir, Á.",2023,10.31181/dmame060120032023m,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164272002&doi=10.31181%2Fdmame060120032023m&partnerID=40&md5=47f287a47b3f2d769b9970cd41c0662f,scopus
2bd7bf35284a9fc0,Daily Stock Returns Characteristics and Forecastability,"While stock prices and economic activity are interrelated in a nation, they are not coincident with each other. Stock prices are a leading economic indicator of the United States of America's (U.S.A. 's) economy. An economic variable that influences stock market prices is interest rates through an inverse relationship. The changes in stock prices (or stock returns) are generally caused by the demand for stocks. This paper reports on a study that investigates the underlying spectral and time-frequency characteristics of daily Standard and Poor's (S&P) 500, Dow Jones Industrial Average (DJIA), and National Association of Securities Dealers Automated Quotations (NASDAQ) composite stock returns, and changes in interest rate (namely, inverted 3-month Treasury bill). The study thereafter compared these findings with those obtained in a previous study by Joseph et al, which focused on monthly stock returns and interest rate data. Subsequent to studying stock returns and changes in interest rate that showed relatively similar spectral and frequency-time characteristics, this study investigated the forecastability of stock returns (in S&P 500, DJIA, and NASDAQ composite) by inverted interest rate (in 3-month Treasury bills) over prediction horizons of five and 30 days with the forecasting period covering the last 13 years. The measures of forecast accuracy used were root mean square error and correlation. The forecasts were favorable in all cases even with simpler neural network models. (c) 2017 The Authors. Published by Elsevier B.V.","Joseph, Anthony; Larrain, Maurice; Turner, Claude",2017,10.1016/j.procs.2017.09.033,None,wos
45985ece0e559f1f,Data-Driven and Mechanistic Soil Modeling for Precision Fertilization Management in Cotton,"This study introduces a novel methodology for predicting cotton yield by integrating machine learning (ML) with mechanistic soil modeling. This hybrid approach enhances yield prediction by combining data-driven ML techniques with soil process modeling. Using the developed yield model, yield curves for various nitrogen (N) levels can be constructed to identify the optimal N dose that maximizes yield. Estimating cotton N requirements is crucial, as growers often apply excessive N, exceeding the amount needed for maximum yield. By comparing the Mean Absolute Error (MAE) between predicted and observed cotton yield values across three ML algorithms, i.e., Random Forest (RF), XGBoost, and LightGBM, the RF model achieved the lowest error (422.6 kg/ha), outperforming XGBoost (446 kg/ha) and LightGBM (449 kg/ha). Additionally, the RF model exhibited high sensitivity to N fertilization, ranking N as the most influential variable in feature importance analysis. Furthermore, phosphorus (P) availability in the soil model was found to be a significant factor influencing the RF yield model, highlighting P’s crucial role in cotton growth and productivity. © 2025 Elsevier B.V., All rights reserved.","Iatrou, M.; Tziachris, P.; Bilias, F.; Kekelis, P.; Pavlakis, C.; Theofilidou, A.; Papadopoulos, I.; Strouthopoulos, G.; Giannopoulos, G.; Arampatzis, D.; Vergos, E.; Karydas, C.; Beslemes, D.; Aschonitis, V.",2025,10.3390/nitrogen6020029,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009251145&doi=10.3390%2Fnitrogen6020029&partnerID=40&md5=b1c1d36c3eaba2b309b31ebf8aaad2ca,scopus
cc76b502f40b1012,Day trading profit maximization with multi-task learning and technical analysis,"Stock price movements are claimed to be chaotic and unpredictable, and mainstream theories of finance refute the possibility of realizing risk-free profit through predictive modelling. Despite this, a large body of technical analysis work maintains that price movements can be predicted solely from historical market data, i.e., markets are not completely efficient. In this paper we seek to test this claim empirically by developing a novel stochastic trading algorithm in the form of a linear model with a profit maximization objective. Using this method we show improvements over the competitive buy-and-hold baseline over a decade of stock market data for several companies. We further extend the approach to allow for non-stationarity in time, and using multi-task learning to modulate between individual companies and the overall market. Both approaches further improve the predictive profit. Overall this work shows that market movements do exhibit predictable patterns as captured through technical analysis.","Bitvai, Zsolt; Cohn, Trevor",2015,10.1007/s10994-014-5480-x,None,wos
e1aea4fb54dfddef,De-noising option prices with the wavelet method,"Financial time series are known to carry noise. Hence, techniques to de-noise such data deserve great attention. Wavelet analysis is widely used in science and engineering to de-noise data. In this paper we show, through the use of Monte Carlo simulations, the power of the wavelet method in the de-noising of option price data. We also find that the estimation of risk-neutral density functions and out-of-sample price forecasting is significantly improved after noise is removed using the wavelet method. (C) 2012 Elsevier B.V. All rights reserved.","Haven, Emmanuel; Liu, Xiaoquan; Shen, Liya",2012,10.1016/j.ejor.2012.04.020,None,wos
7ca6c07a43b0a174,Debt Intolerance: Threshold Level and Composition*,"Fiscal vulnerabilities depend on both the level and composition of government debt. This study examines the role of debt thresholds and debt composition in driving the nonlinear behaviour of long-term interest rates through a novel approach, a panel smooth transition regression with a general logistic model. The main findings are threefold. First, the impact of the expected public debt level on interest rates rises exponentially when the share of foreign private holdings exceeds approximately 20% of government debt denominated in local currency. Second, if the public debt level exceeds a certain level, an increase in foreign private holding of government debt could raise interest rates, offsetting the downward pressure from higher market liquidity. Third, out-of-sample forecasts of this novel non-linear model are more accurate than those of previous methods.","Matsuoka, Hideaki",2022,10.1111/obes.12470,None,wos
d9568c102a3985ba,Debt-stabilizing properties of GDP-linked securities: A macro-finance perspective,"We study the debt -stabilizing properties of indexing debt to GDP using a consumption -based macro -finance model. To this end, we derive quasi -analytical pricing formulas for any type of bond/equity by exploiting the discretization of the state -space, making large-scale simulations tractable. We find that GDP -linked security prices would embed time -varying risk premiums of about 40 basis points. For a fixed budget surplus, issuing GDP -linked securities does not imply more beneficial debt -to -GDP ratios in the long -run, while the debt -stabilizing budget surplus is more predictable at the expense of being higher. Our findings call into question the view that such securities tame debt.","Mouabbi, Sarah; Renne, Jean -Paul; Sahuc, Jean -Guillaume",2024,10.1016/j.jbankfin.2024.107131,None,wos
11be73fadb2757bc,Decision analysis under ambiguity,"Abstract In selecting the preferred course of action, decision makers are often uncertain about one or more probabilities of interest. The experimental literature has ascertained that this uncertainty (ambiguity) might affect decision makers' preferences. Then, the decision maker might wish to incorporate ambiguity aversion in the analysis. We investigate the modeling ambiguity attitudes in the solution of decision analysis problems through functionals well-established in the decision theory literature. We obtain the multiple-event problems for subjective expected utility, smooth ambiguity and maximin decision makers. This allows us to establish the conditions under which these alternative decision makers face equivalent problems. Results for certainty equivalents and risk premia in the presence of both risk and ambiguity aversion are obtained. A recent generalization of the classical Arrow-Pratt quadratic approximation allows us to quantify the portions of a premium due to risk-PLXINSERT-, and to ambiguity-aversion. The numerical implementation of the objective functions is addressed, showing that all functionals can be estimated at no additional burden through Monte Carlo simulation. The well known Carter Racing case study is addressed quantitatively to demonstrate the findings. © 2020 Elsevier B.V., All rights reserved.","Borgonovo, E.; Marinacci, M.",2015,10.1016/j.ejor.2015.02.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926408325&doi=10.1016%2Fj.ejor.2015.02.001&partnerID=40&md5=1c2892d7e4971f8f088bace8177405c3,scopus
e83cfb6b1bda5312,Decision-making during the credit crisis: Did the Treasury let commercial banks fail?,"Limited attention has been paid to the comparative fate of banks benefiting from Capital Purchase Program (CPP) funding and less fortunate banks subject to FDIC resolution. We address this omission by investigating two core issues. One is whether commercial banks that ended up being subject to FDIC resolution received CPP funds. The other is whether the non-allocation of CPP funds made FDIC receivership more likely for viable commercial banks. Our findings show almost no overlap between CPP-funded and FDIC-resolved commercial banks, but we provide evidence that a significant number of FDIC-resolved banks could have avoided receivership if they had been allocated CPP funding. By comparing estimated funding and resolution costs we also show that bailing out more banks would have been cost-efficient. While our results do not allow for any policy suggestion on the optimality of bailouts per se, they suggest that once a bailout program is already on the table, it is better to err on the side of rescuing too many rather than too few banks. © 2016 Elsevier B.V., All rights reserved.","Croci, E.; Hertig, G.; Nowak, E.",2016,10.1016/j.jempfin.2016.01.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962173589&doi=10.1016%2Fj.jempfin.2016.01.001&partnerID=40&md5=85c4a94fa1e40a43f82f5e97c5786c32,scopus
3237c5fa565c89c2,Decomposing the yield curve with linear regressions and survey information,"The decomposition of bond yields into term premiums and average expected future short rates is impaired by the limited availability of information about the dynamics of the expectations component. Therefore, many studies require the model-implied average expected future short rates to be close to short rate expectations from surveys. In this paper, I restrict the variance of changes in model-implied average expected future short rates to match the variance of changes in short rate expectations from surveys. The variance of changes in survey expectations is relatively similar across markets and thus provides a reliable source of additional information about the expectation formation of investors. Technically, I impose a nonlinear restriction to the term structure model of Adrian, Crump, and Moench (2013). I show that typical small sample problems of term structure estimations can be mitigated if the restriction on the variance of changes is imposed. However, the analysis also makes a case for unrestricted estimations if they are based on a dataset with a typical sample length in macro finance. © 2023 Elsevier B.V., All rights reserved.","Halberstadt, A.",2023,10.1016/j.qref.2023.07.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166646520&doi=10.1016%2Fj.qref.2023.07.002&partnerID=40&md5=dfd4e947091892f6484d399c6125a8f4,scopus
85bd6d2d916ab727,Deep Learning Model for Stock Excess Return Prediction Based on Nonlinear Random Matrix and Esg Factor,"Aiming at the problem that the traditional model has low accuracy in describing stock excess return, in order to further analyze the change law of stock excess, based on the nonlinear random matrix and esg factor theory, the traditional learning model is analyzed, and the corresponding optimized deep learning model is obtained by introducing the single ring theorem and statistical data. Through the analysis and research of related indexes, the change rules of different indexes are obtained, and the optimization model is used to calculate and forecast the excess return of stocks. The results show that the statistics and spectral radius show typical local linear variation with the increase of eigenvalue. The corresponding statistics show a trend of gradual increase. The corresponding spectral radius has a decreasing variation law, and the two curves have obvious symmetry at some eigenvalues. It can be seen from the change curves under different factors that the change trend of the yield curve is mainly affected by the investment factor, while the change rule of the specific value of the yield curve is controlled by the profit factor. This shows that the two factors have the same influence on the stock excess return. The influence of optimized deep learning model on stock excess index has typical linear characteristics, which can be divided into linear increase and linear decline according to different change rules. The basic type has the greatest influence, while the corresponding pattern analysis type has the least influence. Finally, the method of experimental verification is used to verify the stock excess data, and the results show that the optimized deep learning model can better characterize the experimental results. Therefore, the optimized deep learning model based on nonlinear random matrix and esg factor can carry out targeted analysis of different types of stock returns, thus improving research ideas and calculation methods for the application of deep learning model in different fields.","Meng, Tiantian; Yahya, M H; Chai, Jingmin",2022,10.1155/2022/5239493,None,proquest
bfb98861daf4485c,Deep Learning and Machine Learning Insights Into the Global Economic Drivers of the Bitcoin Price,"This study examines the connection between Bitcoin and global factors, including the VIX, the oil price, the US dollar index, the gold price, and interest rates estimated using the Federal funds rate and treasury securities rate, for forecasting analysis. Deep learning methodologies, including LSTM, GRU, CNN, and TFT, with machine learning algorithms such as XGBoost, LightGBM, and SVR, were employed to identify the optimal prediction model for the Bitcoin price. The findings indicate that the TFT model is the most successful predictive approach, with the gold price identified as the most relevant component in determining the Bitcoin price. After the gold indicator, the US dollar index was a substantial factor in the explanation of the Bitcoin price. The TFT model also included regulatory decisions and global events. It was estimated that the Bitcoin price was significantly influenced by the COVID-19 pandemic. After that, global climate events and China mining ban strongly affected the Bitcoin price. These findings indicate that regulatory decisions and global events determine the Bitcoin price in addition to macroeconomic factors. The VAR analysis was employed as a robustness check. The results indicate that gold and oil prices have a strong negative influence on Bitcoin, particularly in the long term. The paper has significant policy implications for investors, portfolio managers, and scholars.","Kose, Nezir; Gur, Yunus Emre; Unal, Emre",2025,10.1002/for.3258,None,wos
029287686acf7c81,Deep Learning for Bond Yield Forecasting: The LSTM-LagLasso,"We present long short-term memory (LSTM)-LagLasso, a novel explainable deep learning approach applied to bond yield forecasting. Our method involves feature selection from a large universe of potential features and forecasts bond yields using dynamic LSTM networks. It examines the internal gating signals of a trained LSTM and explains their dynamics through exogenous variables that may influence bond price formation. By considering these variables at various lags and using the Lasso technique for feature selection, we demonstrate how different hidden units within the LSTM dynamically adjust to make predictions across different temporal regimes and how their evolution is shaped by various external factors. In an empirical study on government bond yield forecasting, we demonstrate the statistical accuracy of LSTM-LagLasso compared to a multilayer perceptron (MLP) and highlight its explainability. © 2025 Elsevier B.V., All rights reserved.","Nunes, M.; Gerding, E.; McGroarty, F.; Niranjan, M.; Sermpinis, G.",2025,10.1002/ijfe.3116,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215673445&doi=10.1002%2Fijfe.3116&partnerID=40&md5=16a040114703ee0a5003b658cae9572e,scopus
beadf3ba10095213,Deep Sequence Modeling: Development and Applications in Asset Pricing,"The authors predict asset returns and measure risk premiums using a prominent technique from artificial intelligence: deep sequence modeling. Because asset returns often exhibit sequential dependence that may not be effectively captured by conventional time-series models, sequence modeling offers a promising path with its data-driven approach and superior performance. In this article, the authors first overview the development of deep sequence models, introduce their applications in asset pricing, and discuss their advantages and limitations. They then perform a comparative analysis of these methods using data on US equities. They demonstrate how sequence modeling benefits investors in general through incorporating complex historical path dependence and that long short-term memory–based models tend to have the best out-of-sample performance. © 2022 Elsevier B.V., All rights reserved.","Cong, L.W.; Tang, K.; Wang, J.; Zhang, Y.",2021,10.3905/jfds.2020.1.053,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126541141&doi=10.3905%2Fjfds.2020.1.053&partnerID=40&md5=bc886caceb37d23d08acc78479f0ddd8,scopus
20d437cdd0b20220,Deep learning with long short-term memory networks for financial market predictions,"Long short-term memory (LSTM) networks are a state-of-the-art technique for sequence learning. They are less commonly applied to financial time series predictions, yet inherently suitable for this domain. We deploy LSTM networks for predicting out-of-sample directional movements for the constituent stocks of the S&P 500 from 1992 until 2015. With daily returns of 0.46 percent and a Sharpe ratio of 5.8 prior to transaction costs, we find LSTM networks to outperform memory-free classification methods, i.e., a random forest (RAF), a deep neural net (DNN), and a logistic regression classifier (LOG). The outperformance relative to the general market is very clear from 1992 to 2009, but as of 2010, excess returns seem to have been arbitraged away with LSTM profitability fluctuating around zero after transaction costs. We further unveil sources of profitability, thereby shedding light into the black box of artificial neural networks. Specifically, we find one common pattern among the stocks selected for trading – they exhibit high volatility and a short-term reversal return profile. Leveraging these findings, we are able to formalize a rules-based short-term reversal strategy that yields 0.23 percent prior to transaction costs. Further regression analysis unveils low exposure of the LSTM returns to common sources of systematic risk – also compared to the three benchmark models. © 2018 Elsevier B.V., All rights reserved.","Fischer, T.; Krauß, C.",2018,10.1016/j.ejor.2017.11.054,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039970639&doi=10.1016%2Fj.ejor.2017.11.054&partnerID=40&md5=b5354f21b79010e8b9e0f8e44362b4ae,scopus
29abf8e325a84dfb,Deep treasury management for banks,"Retail banks use Asset Liability Management (ALM) to hedge interest rate risk associated with differences in maturity and predictability of their loan and deposit portfolios. The opposing goals of profiting from maturity transformation and hedging interest rate risk while adhering to numerous regulatory constraints make ALM a challenging problem. We formulate ALM as a high-dimensional stochastic control problem in which monthly investment and financing decisions drive the evolution of the bank's balance sheet. To find strategies that maximize long-term utility in the presence of constraints and stochastic interest rates, we train neural networks that parametrize the decision process. Our experiments provide practical insights and demonstrate that the approach of Deep ALM deduces dynamic strategies that outperform static benchmarks. © 2023 Elsevier B.V., All rights reserved.","Englisch, H.; Krabichler, T.; Müller, K.J.; Schwarz, M.",2023,10.3389/frai.2023.1120297,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152561995&doi=10.3389%2Ffrai.2023.1120297&partnerID=40&md5=b02754657e30e9df825a73854a19d290,scopus
827ebc1f4234f963,Deep-learning models for forecasting financial risk premia and their interpretations,"The measurement of financial risk premia, the amount that a risky asset will outperform a risk-free one, is an important problem in asset pricing. The noisiness and non-stationarity of asset returns makes the estimation of risk premia using machine learning (ML) techniques challenging. In this work, we develop ML models that solve the problems associated with risk premia forecasting by separating risk premia prediction into two independent tasks, a time series model and a cross-sectional model, and using neural networks with skip connections to enable their deep neural network training. These models are tested robustly with different metrics, and we observe that our models outperform several existing standard ML models. A known issue with ML models is their ‘black box’ nature, i.e. their opaqueness to interpretability. We interpret these deep neural networks using local approximation-based techniques that provide explanations for our model's predictions. © 2023 Elsevier B.V., All rights reserved.","Lo, A.W.; Singh, M.",2023,10.1080/14697688.2023.2203844,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163601916&doi=10.1080%2F14697688.2023.2203844&partnerID=40&md5=95327ef8a4d77eea1380fa58a81d947c,scopus
bf5e5a0f65403ae9,DeepClue: Visual Interpretation of Text-Based Deep Stock Prediction,"The recent advance of deep learning has enabled trading algorithms to predict stock price movements more accurately. Unfortunately, there is a significant gap in the real-world deployment of this breakthrough. For example, professional traders in their long-term careers have accumulated numerous trading rules, the myth of which they can understand quite well. On the other hand, deep learning models have been hardly interpretable. This paper presents DeepClue, a system built to bridge text-based deep learning models and end users through visually interpreting the key factors learned in the stock price prediction model. We make three contributions in DeepClue. First, by designing the deep neural network architecture for interpretation and applying an algorithm to extract relevant predictive factors, we provide a useful case on what can be interpreted out of the prediction model for end users. Second, by exploring hierarchies over the extracted factors and displaying these factors in an interactive, hierarchical visualization interface, we shed light on how to effectively communicate the interpreted model to end users. Specially, the interpretation separates the predictables from the unpredictables for stock prediction through the use of intercept model parameters and a risk visualization design. Third, we evaluate the integrated visualization system through two case studies in predicting the stock price with financial news and company-related tweets from social media. Quantitative experiments comparing the proposed neural network architecture with state-of-the-art models and the human baseline are conducted and reported. Feedbacks from an informal user study with domain experts are summarized and discussed in details. The study results demonstrate the effectiveness of DeepClue in helping to complete stock market investment and analysis tasks.",L. Shi; Z. Teng; L. Wang; Y. Zhang; A. Binder,2019,10.1109/tkde.2018.2854193,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8408524,ieeexplore
fbf80399751a0d02,"Default, liquidity, and crises: An econometric framework","This article presents a general discrete-time affine framework aimed at jointly modeling yield curves associated with different debtors. The underlying fixed-income securities may differ in terms of credit quality and/or in terms of liquidity. The risk factors follow conditionally Gaussian processes, with drifts and covariance matrices that are subject to regime shifts described by a Markov chain with (historical) non-homogenous transition probabilities. Bond prices are given by quasi-explicit formulas. The tractability of the framework is illustrated by the estimation of a term-structure model of the spreads between U.S. BBB-rated corporate bonds and Treasuries. Alternative applications are proposed, including a sector-contagion model as well as the explicit modeling of credit-rating transitions. © The Author, 2012. © 2013 Elsevier B.V., All rights reserved.","Monfort, A.; Renne, J.-P.",2013,10.1093/jjfinec/nbs020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875255758&doi=10.1093%2Fjjfinec%2Fnbs020&partnerID=40&md5=4142c53787af3e844a2eb0e5d250da50,scopus
0f6fe1c92923c038,"Demand for Information, Uncertainty, and the Response of US Treasury Securities to News","We use clickstream data to show that investors' demand for information about macroeconomic factors affecting the path of future interest rates is a measure of their uncertainty about this path. In particular, an increase in information demand ahead of influential economic announcements affecting investors' beliefs about future interest rates predicts a stronger reaction of U.S. Treasury note yields to these announcements, as it should if information demand positively covaries with uncertainty. This relationship does not vanish after using standard measures of uncertainty as predictors, suggesting that clickstream data contain unique information about investors' uncertainty.","Benamar, Hedi; Foucault, Thierry; Vega, Clara",2021,10.1093/rfs/hhaa072,None,wos
96b3bcf64aff81eb,Density estimation for nonlinear parametric models with conditional heteroscedasticity,"This article studies density and parameter estimation problems for nonlinear parametric models with conditional heteroscedasticity. We propose a simple density estimate that is particularly useful for studying the stationary density of nonlinear time series models. Under a general dependence structure, we establish the root it consistency of the proposed density estimate. For parameter estimation, a Bahadur type representation is obtained for the conditional maximum likelihood estimate. The parameter estimate is shown to be asymptotically efficient in the sense that its limiting variance attains the Cramer-Rao lower bound. The performance of our density estimate is studied by simulations. (C) 2009 Elsevier B.V. All rights reserved.","Zhao, Zhibiao",2010,10.1016/j.jeconom.2009.09.013,None,wos
eb29f049a6d970f8,Departures from Rational Expectations and Asset Pricing Anomalies,"We investigate the potential of the consumption CAPM with pessimism, doubt, and the availability heuristic in the agent's beliefs to resolve the equity premium and risk-free rate puzzles. Using the nonlinear GMM estimation techniques, we find that doubt and the availability heuristic play an important role in explaining the cross-section of asset returns. However, when taken alone, these deviations from rational expectations cannot resolve the equity premium and risk-free rate puzzles. This result is robust to the assumption that the expected value of an uncertain prospect is nonlinear in the subjective outcome probabilities.","Semenov, Andrei",2009,10.1080/15427560903373245,None,wos
c79df7a074626dcb,Detecting Multiple Structural Breaks in Systems of Linear Regression Equations With Integrated and Stationary Regressors,"In this paper, we propose a two‐step procedure based on the group LASSO estimator in combination with a backward elimination algorithm to detect multiple structural breaks in linear regressions with multivariate responses. Applying the two‐step estimator, we jointly detect the number and location of structural breaks and provide consistent estimates of the coefficients. Our framework is flexible enough to allow for a mix of integrated and stationary regressors, as well as deterministic terms. Using simulation experiments, we show that the proposed two‐step estimator performs competitively against the likelihood‐based approach in finite samples. However, the two‐step estimator is computationally much more efficient. An economic application to the identification of structural breaks in the term structure of interest rates illustrates this methodology.","Schweikert, Karsten",2025,10.1111/obes.12666,None,proquest
f1cadf4bf4556874,Determinants of cryptocurrency returns: A LASSO quantile regression approach,"We consider a relatively large set of predictors and investigate the determinants of cryptocurrency returns at different quantiles. Our analysis exclusively focuses on the highly volatile period of COVID-19. The innovation in the paper stems from the fact that we employ the LASSO penalty in a quantile regression framework to select informative variables. We find that US government bond indices and small company stock returns, a new predictor introduce in this study, significantly impact the tail behavior of the cryptocurrency returns. © 2022 Elsevier B.V., All rights reserved.","Ciner, C.; Lucey, B.; Yarovaya, L.",2022,10.1016/j.frl.2022.102990,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133923555&doi=10.1016%2Fj.frl.2022.102990&partnerID=40&md5=01a12ed6ee35436c208a8c486eac384a,scopus
523495f11b524d8c,Developing a Composite Measure to Represent Information Flows in Networks: Evidence from a Stock Market,"There is increasing interest in information systems research to model information flows from different sources (e.g., social media, news) associated with a network of assets (e.g., stocks, products) and to study the economic impact of such information flows. This paper employs a design science approach and proposes a new composite metric, eigen attention centrality (EAC), as a proxy for information flows associated with a node that considers both attention to a node and coattention with other nodes in a network. We apply the EAC metric in the context of financial market where nodes are individual stocks and edges are based on coattention relationships among stocks. Composite information from different channels is used to measure attention and coattention. To evaluate the effectiveness of the EAC metric on predicting outcomes, we conduct an in-depth performance evaluation of the EAC metric by (1) using multiple linear and nonlinear prediction methods and (2) comparing EAC with a benchmark model without EAC and models with a set of alternative network metrics. Our analysis shows that EAC significantly outperforms other measures in predicting the direction and magnitude of abnormal returns of stocks. Besides, our EAC specification has better predictive performance than alternative specifications, and EAC outperforms direct attention in predicting abnormal returns. Using the EAC metric, we derive a stock portfolio and develop a trading strategy that provides significant and positive excess returns. Lastly, we find that composite information has significantly better predictive performance than separate information sources, and such superior performance owes to information from social media instead of traditional media.","Shangguan, Wuyue(Phoebe); Leung, Alvin Chung Man; Agarwal, Ashish; Konana, Prabhudev; Chen, Xi",2022,10.1287/isre.2021.1066,None,proquest
19d08c4e33e25dd9,Development of Adaptive Neuro-Fuzzy Inference System for Assessing Industry Leadership in Accident Situations,"Petroleum activity is characterized as a high-risk activity due to the probability of accidents with material and human losses. The leaders of this segment assume, besides the complex routine tasks, the challenge of making assertive decisions during an accident. This study aims to present an evaluation model of the Industry Leadership Index for Emergencies Situations (ILIE), using the Adaptive Neuro-Fuzzy System (ANFIS). The model was composed of 4 input variables, namely: knowledge, behavior, skill, and attitude; and one output variable, Industry Leadership. The data collection took place in petroleum production units in Brazil, with a sample of 151 respondents through the application of a survey. The observed data were treated in an Excel tabulator and used in the development of the ANFIS model. From this model, it was possible to carry out simulations to predict the impact, which the increase or decrease in the value of each input variable can influence the leader’s profile. The model performed satisfactorily in the Root of the Mean Square Error (RMSE) analysis, being 0.199 in data training and 1.217 in data verification. The results suggest that the ANFIS method can be successfully applied to establish a model to analyze industry leaders prepared for assertive responses in crisis scenarios.",I. C. D. S. Cerqueira; P. P. S. Carvalho; J. L. Moya Rodríguez; S. Á. Filho; F. G. M. Freires,2022,10.1109/access.2022.3206766,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9893569,ieeexplore
6fa5c3f952ccb4dc,"Development of a Machine Learning Model Using Multiple, Heterogeneous Data Sources to Estimate Weekly US Suicide Fatalities","ImportanceSuicide is a leading cause of death in the US. However, official national statistics on suicide rates are delayed by 1 to 2 years, hampering evidence-based public health planning and decision-making.ObjectiveTo estimate weekly suicide fatalities in the US in near real time.Design, Setting, and ParticipantsThis cross-sectional national study used a machine learning pipeline to combine signals from several streams of real-time information to estimate weekly suicide fatalities in the US in near real time. This 2-phase approach first fits optimal machine learning models to each individual data stream and subsequently combines predictions made from each data stream via an artificial neural network. National-level US administrative data on suicide deaths, health services, and economic, meteorological, and online data were variously obtained from 2014 to 2017. Data were analyzed from January 1, 2014, to December 31, 2017.ExposuresLongitudinal data on suicide-related exposures were obtained from multiple, heterogeneous streams: emergency department visits for suicide ideation and attempts collected via the National Syndromic Surveillance Program (2015-2017); calls to the National Suicide Prevention Lifeline (2014-2017); calls to US poison control centers for intentional self-harm (2014-2017); consumer price index and seasonality-adjusted unemployment rate, hourly earnings, home price index, and 3-month and 10-year yield curves from the Federal Reserve Economic Data (2014-2017); weekly daylight hours (2014-2017); Google and YouTube search trends related to suicide (2014-2017); and public posts on suicide on Reddit (2 314 533 posts), Twitter (9 327 472 tweets; 2015-2017), and Tumblr (1 670 378 posts; 2014-2017).Main Outcomes and MeasuresWeekly estimates of suicide fatalities in the US were obtained through a machine learning pipeline that integrated the above data sources. Estimates were compared statistically with actual fatalities recorded by the National Vital Statistics System.ResultsCombining information from multiple data streams, the machine learning method yielded estimates of weekly suicide deaths with high correlation to actual counts and trends (Pearson correlation, 0.811;P < .001), while estimating annual suicide rates with low error (0.55%).Conclusions and RelevanceThe proposed ensemble machine learning framework reduces the error for annual suicide rate estimation to less than one-tenth of that of current forecasting approaches that use only historical information on suicide deaths. These findings establish a novel approach for tracking suicide fatalities in near real time and provide the potential for an effective public health response such as supporting budgetary decisions or deploying interventions.","Choi, Daejin; Sumner, Steven A; Holland, Kristin M; Draper, John; Murphy, Sean; Bowen, Daniel A; Zwald, Marissa; Wang, Jing; Law, Royal; Taylor, Jordan; Konjeti, Chaitanya; De Choudhury, Munmun",2020,10.1001/jamanetworkopen.2020.30932,None,proquest
03db3ea92636934e,Development of hybrid weighted networks of RNN and DBN for facilitating the secure information system in cyber security using meta-heuristic improvement,"As communication and information technologies are integral to everyone’s daily activities, the significance of cybersecurity has become more pronounced due to the growing vulnerability of these technologies to cyber threats. Traditional cyber security systems use various preventive measures to secure the information and trust authentication methods are used to provide the essential security measure against cyber attacks. These methods are efficient and are also equipped to perform in real-world scenarios. However, the conventional cyber security system does not provide essential security against all types of cyber attacks as they are nature-distributed for controlling the systems. Securing these Distributed Control Systems is highly significant for providing a secure and risk-free operation of the connected systems from cyber attacks and other threats. Therefore, a novel method of risk prediction and risk mitigation is developed using the heuristic-based Hybrid Deep Weighted Networks for protecting the data in the information system. The recommended work is based on risk analysis and a cyber security framework built around the information technology security system. This model aimed to design the cyber security system by mitigating all the threats in that particular information system. The main aim is to predict the risk level and mitigate the security threats completely from the system. To achieve this, initially, the data are gathered from different sources and given to the HDWN. The HDWN is developed by combining the Deep Belief Network and a Recurrent Neural Network. These two networks help to predict the risk values of the threat. To attain the enhanced results, the parameters in this model are optimized by using a hybrid algorithm known as African Vultures with Water Wave Optimization, which is developed by combining the Water Wave Optimization algorithm with the African Vulture Optimization Algorithm. Another intention of this model is to mitigate the threat present in the system. Based on the predicted risk value, the system generates warning signals to alert the admin to block the communication. Thus, the threat and risk from the system are predicted and mitigated without interrupting the system’s performance. Finally, the performance validation is performed on the developed model by comparing it with diverse approaches, and the results demonstrate that the proposed model provides impressive outcomes in ensuring data security. © 2025 Elsevier B.V., All rights reserved.","Lakshman Naik, R.L.; Jain, S.; Bairam, M.",2025,10.1007/s11276-025-03955-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003692475&doi=10.1007%2Fs11276-025-03955-x&partnerID=40&md5=d4fbb63b13dd15cc3ea6db266c72f329,scopus
19c5432dca3228fd,Diffusion copulas: Identification and estimation,"We propose a new semiparametric approach for modelling nonlinear univariate diffusions, where the observed process is a nonparametric transformation of an underlying parametric diffusion (UPD). This modelling strategy yields a general class of semiparametric Markov diffusion models with parametric dynamic copulas and nonparametric marginal distributions. We provide primitive conditions for the identification of the UPD parameters together with the unknown transformations from discrete samples. Likelihood-based estimators of both parametric and nonparametric components are developed and we analyse their asymptotic properties. Kernel-based drift and diffusion estimators are also proposed and shown to be normally distributed in large samples. A simulation study investigates the finite sample performance of our estimators in the context of modelling US short-term interest rates. We also present a simple application of the proposed method for modelling the CBOE volatility index data. (C) 2020 Elsevier B.V. All rights reserved.","Bu, Ruijun; Hadri, Kaddour; Kristensen, Dennis",2021,10.1016/j.jeconom.2020.06.004,None,wos
8ab9dc8d5d022eec,Digital transformation: statistical evaluation of success factors of an ICO-campaign,"High rates of growth of the ICO market and its excess returns stipulate a significant interest of investors to projects which use initial token allocation (ICO) for attracting investments. This work takes into account the fact that even a potentially profitable project may fail to collect the required amount of money and to start placing tokens on the stock exchange. We are speaking about success of an ICO-campaign for fund raising. In order to estimate the influence of factors and check the suggested research hypotheses, logistic regression was used. The selection included 672 projects. As a dependent variable, the proportion of the amount collected in the ICO process from the required value is selected. Depending on the tested hypothesis the influencing variables took into account the presence of a pre-sale stage and the bounty program and also the price of the token, the upper limit of fund raising, the duration of the ICO-campaign and the number of team members. The work results allow token emitters to substantiate managing the success of the ICO-campaign of the project and the investors to see whether it deserves their attention. Besides, the obtained materials can be useful for specialists in forming the legal framework of token transactions.","Rasskazova, Albina; Koroleva, Elena; Rasskazov, Sergey",2019,10.1088/1757-899x/497/1/012087,None,proquest
e24f1b7a54c54554,"Digital twin-based cyber-physical manufacturing systems, extended reality metaverse enterprise and production management algorithms, and Internet of Things financial and labor market technologies in generative artificial intelligence economics","Research background: Generative artificial intelligence (AI) and machine learning algorithms support industrial Internet of Things (IoT)-based big data and enterprise asset management in multiphysics simulation environments by industrial big data processing, modeling, and monitoring, enabling business organizational and managerial practices. Machine learning-based decision support and edge generative AI sensing systems can reduce persistent labor shortages and job vacancies and power productivity growth and labor market dynamics, shaping career pathways and facilitating occupational transitions by skill gap identification and laborintensive manufacturing job automation by path planning and spatial cognition algorithms, furthering theoretical implications for management sciences. Generative AI fintech, machine learning algorithms, and behavioral analytics can assist multi-layered payment and transaction processing screening with regard to authorized push payment, account takeover, and synthetic identity frauds, flagging suspicious activities and combating economic crimes by rigorous verification processes. Purpose of the article: We show that edge device management functionalities of cloud industrial IoT and virtual robotic simulation technologies configure plant production and route planning processes across cyber-physical production and industrial automation systems in multi-cloud immersive 3D environments, leading to tangible business outcomes by reinforcement learning and convolutional neural networks. Labor-augmenting automation and generative AI technologies can impact employment participation, increase wage and wealth inequality, and lead to potential job displacement and massive labor market disruptions. The deep learning capabilities of generative AI fintech in terms of adaptive behavioral analytics and credit scoring mechanisms can enhance financial transaction behaviors and algorithmic trading returns, identify fraudulent payment transactions swiftly, and improve financial forecasts, leading to customized investment recommendations and well-informed financial decisions. Methods: Machine learning-based study selection process and text mining systematic review management software and tools leveraged include Abstrackr, CADIMA, Colandr, DistillerSR, EPPI-Reviewer, JBI SUMARI, METAGEAR package for R, SluRp, and SWIFT-Active Screener. Such reference management systems are harnessed for methodologically rigorous evidence synthesis, study selection and characteristic extraction, predictive document classification, machine learning-based citation and record screening, bias assessment, article retrieval automation, and document classification and prioritization.Findings & value added: Industrial IoT and 3D augmented reality technologies can create business value by streamlining virtual product and remote asset management across extended reality-based navigation and robotic autonomous systems in smart factory environments by generative AI and machine learning algorithms, articulating business organizational level and theory of management implications. 3D simulation and operational modeling tools can execute and complete complex cognitive task-oriented and knowledge economy jobs, producing first-rate quality outputs swiftly while leading to unemployment spells, labor market disruptions, job displacement losses, and reduced earnings by machine learning clustering and spatial cognition algorithms.Generative AI decentralized finance, interoperable blockchain networks, cash flow management tools, and asset tokenization can mitigate fraud risks, enable digital fund and crypto investing servicing, and automate treasury operations by integrating real-time payment capabilities, routing and configurable workflows, and lending and payment technologies.","Lazaroiu, George; Gedeon, Tom; Rogalska, Elzbieta; Valaskova, Katarina; Nagy, Marek; Musa, Hussam; Zvarikova, Katarina; Poliak, Milos; Horak, Jakub; Cretoiu, Raluca Ionela; Krulicky, Tomas; Ionescu, Luminita; Popa, Catalin; Hurloiu, Lacramioara Rodica; Nistor, Filip; Avram, Laurentia Georgeta; Braga, Viorica",2024,10.24136/oc.3183,None,wos
43e740c4fd920731,Dimension Reduction via Penalized GLMs for Non-Gaussian Response: Application to Stock Market Volatility,"We fit U.S. stock market volatilities on macroeconomic and financial market indicators and some industry level financial ratios. Stock market volatility is non-Gaussian distributed. It can be approximated by an inverse Gaussian (IG) distribution or it can be transformed by Box–Cox transformation to a Gaussian distribution. Hence, we used a Box–Cox transformed Gaussian LASSO model and an IG GLM LASSO model as dimension reduction techniques and we attempted to identify some common indicators to help us forecast stock market volatility. Via simulation, we validated the use of four models, i.e., a univariate Box–Cox transformation Gaussian LASSO model, a three-phase iterative grid search Box–Cox transformation Gaussian LASSO model, and both canonical link and optimal link IG GLM LASSO models. The latter two models assume an approximately IG distributed response. Using these four models in an empirical study, we identified three macroeconomic indicators that could help us forecast stock market volatility. These are the credit spread between the U.S. Aaa corporate bond yield and the 10-year treasury yield, the total outstanding non-revolving consumer credit, and the total outstanding non-financial corporate bonds.","Li, Tao; Li, Tao; Li, Tao; Desmond, Anthony F; Stengos, Thanasis",2021,10.3390/jrfm14120583,None,proquest
1aaadcf8c464fe28,Disagreement in expectations and the credibility of monetary authorities in the Brazilian inflation targeting regime,"Based on market expectations reported by the Central Bank of Brazil for the SELIC interest rate, the IPCA inflation, the exchange rate (BRL/USD) and the growth rate of industrial production for four different forecasting horizons, this work analyzes the term structures of disagreement in expectations regarding the future values of these variables. It also investigates the driving factors of disagreement, paying special attention to the influence of monetary authorities’ credibility. An extensive regression analysis shows that the levels of the term structures of disagreement are negatively related to the output gap (although this result is not very robust); and that the levels of the term structures of disagreement in expectations about the IPCA inflation rate and the SELIC interest rate have a strong negative relationship with central bankers’ credibility; this relationship is positive in the case of the growth rate of industrial production. © 2019 Elsevier B.V., All rights reserved.","Vereda, L.V.; Curi, A.",2016,10.1016/j.econ.2016.03.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031719048&doi=10.1016%2Fj.econ.2016.03.002&partnerID=40&md5=3986f94f0699536c3421af3af3134519,scopus
01ee1f71747e58fc,Discrete sine transform for multi-scale realized volatility measures,"In this study we present a new realized volatility estimator based on a combination of the multi-scale regression and discrete sine transform (DST) approaches. Multi-scale estimators similar to that recently proposed by Zhang (2006) can, in fact, be constructed within a simple regression-based approach by exploiting the linear relation existing between the market microstructure bias and the realized volatilities computed at different frequencies. We show how such a powerful multi-scale regression approach can also be applied in the context of the Zhou [Nonlinear Modelling of High Frequency Financial Time Series, pp. 109-123, 1998] or DST orthogonalization of the observed tick-by-tick returns. Providing a natural orthonormal basis decomposition of observed returns, the DST permits the optimal disentanglement of the volatility signal of the underlying price process from the market microstructure noise. The robustness of the DST approach with respect to the more general dependent structure of the microstructure noise is also shown analytically. The combination of the multi-scale regression approach with DST gives a multi-scale DST realized volatility estimator similar in efficiency to the optimal Cramer-Rao bounds and robust against a wide class of noise contamination and model misspecification. Monte Carlo simulations based on realistic models for price dynamics and market microstructure effects show the superiority of DST estimators over alternative volatility proxies for a wide range of noise-to-signal ratios and different types of noise contamination. Empirical analysis based on six years of tick-by-tick data for the S&P 500 index future, FIB 30, and 30 year U.S. Treasury Bond future confirms the accuracy and robustness of DST estimators for different types of real data. © 2012 Taylor and Francis Group, LLC. © 2012 Elsevier B.V., All rights reserved.","Curci, G.; Corsi, F.",2012,10.1080/14697688.2010.490561,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857188308&doi=10.1080%2F14697688.2010.490561&partnerID=40&md5=2c4e6b57d7f22d1af8754ae1cd5f005c,scopus
e877d6e0c89d5e6e,Discrete-time affine term structure models with generalized market prices of risk,"This article develops a rich class of discrete-time, nonlinear dynamic term structure models (DTSMs). Under the risk-neutral measure, the distribution of the state vector Xt resides within a family of discrete-time affine processes that nests the exact discrete-time counterparts of the entire class of continuous-time models in Duffie and Kan (1996) and Dai and Singleton (2000). Under the historical distribution, our approach accommodates nonlinear (nonaffine) processes while leading to closed-form expressions for the conditional likelihood functions for zero-coupon bond yields. As motivation for our framework, we show that it encompasses many of the equilibrium models with habit-based preferences or recursive preferences and long-run risks. We illustrate our methods by constructing maximum likelihood estimates of a nonlinear discrete-time DTSM with habit-based preferences in which bond prices are known in closed form. We conclude that habit-based models, as typically parameterized in the literature, do not match key features of the conditional distribution of bond yields. © 2010 The Author. © 2010 Elsevier B.V., All rights reserved.","Le, A.; Singleton, K.J.; Dai, Q.",2010,10.1093/rfs/hhq007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951229447&doi=10.1093%2Frfs%2Fhhq007&partnerID=40&md5=357de60632b52de4ee7c87b041b608ad,scopus
d6ed6a2f0e967ff5,Discrete-time implementation of continuous-time filters with application to regime-switching dynamics estimation,"This paper details the implementation in discrete time of filters for a mean-reverting model formulated under a continuous-time framework, whereby a hidden Markov chain governs the model's parameters. Parameter estimates are determined via adaptive filters designed to extract hidden information from an observable time series. An application involving the dynamic behaviour of spot interest rates is considered. More specifically, we present an empirical study aimed at capturing accurately, on the basis of some benchmarks and statistical validation, the evolution of three country-specific rates in the European zone. Our analysis reveals some similar yield-rate and risk characteristics as well as independent market behaviours of the three EU sovereign states. (C) 2019 Elsevier Ltd. All rights reserved.","Grimm, Stefanie; Erlwein-Sayer, Christina; Mamon, Rogemar",2020,10.1016/j.nahs.2019.08.001,None,wos
bcca295f3d1740ee,Dissecting climate change risk and financial market instability: Implications for ecological risk management,"This research investigates the impact of climate challenges on financial markets by introducing an innovative approach to measure climate risk, specifically the aggregate climate change concern (ACCC) index. The study aims to assess and quantify the potential influence of climate change and risk-related factors on the performance and dynamics of financial markets. In this paper, concern is defined as the attention paid to the risk of climate change and the associated negative consequences. The findings demonstrate that the aggregate index exhibits robust predictability of market risk premiums, both within the sample and out-of-sample. By comparison, the index contains additional information beyond 14 economic predictors and 12 risk/uncertainty indexes in forecasting stock market return. In addition, the index proves valuable for mean-variance investors in asset allocation, leading to significant economic gains. The study identifies the index's ability to capture the reversal of temporary price crashes caused by overreactions to climate change risk. Furthermore, it exhibits stronger return forecasting capability for green stocks, non-state-owned enterprise (non-SOE) stocks, and stocks in regions with low air pollution. Particularly during periods of low air pollution and relaxed regulation, the index displays an enhanced ability to forecast returns. The study's findings provide valuable insights for policymakers and financial institutions as they address 21st-century environmental challenges. Moreover, these findings can inform the design of adaptive measures and interventions aimed at mitigating ecological risks and promoting sustainable economic growth.This research investigates the impact of climate challenges on financial markets by introducing an innovative approach to measure climate risk, specifically the aggregate climate change concern (ACCC) index. The study aims to assess and quantify the potential influence of climate change and risk-related factors on the performance and dynamics of financial markets. In this paper, concern is defined as the attention paid to the risk of climate change and the associated negative consequences. The findings demonstrate that the aggregate index exhibits robust predictability of market risk premiums, both within the sample and out-of-sample. By comparison, the index contains additional information beyond 14 economic predictors and 12 risk/uncertainty indexes in forecasting stock market return. In addition, the index proves valuable for mean-variance investors in asset allocation, leading to significant economic gains. The study identifies the index's ability to capture the reversal of temporary price crashes caused by overreactions to climate change risk. Furthermore, it exhibits stronger return forecasting capability for green stocks, non-state-owned enterprise (non-SOE) stocks, and stocks in regions with low air pollution. Particularly during periods of low air pollution and relaxed regulation, the index displays an enhanced ability to forecast returns. The study's findings provide valuable insights for policymakers and financial institutions as they address 21st-century environmental challenges. Moreover, these findings can inform the design of adaptive measures and interventions aimed at mitigating ecological risks and promoting sustainable economic growth.","Ma, Feng; Cao, Jiawei; Wang, Yizhi; Vigne, Samuel A; Dong, Dayong",2025,10.1111/risa.14265,None,proquest
8d2944af2307c048,Distressed debt prices and recovery rate estimation,"This paper has two purposes. First, it uses distressed debt prices to estimate recovery rates at default. In this regard, estimates are obtained for three recovery rate models: recovery of face value, recovery of Treasury, and recovery of market value. We show that identifying the economic default date, as distinct from the recorded default date, is crucial to obtaining unbiased estimates. The economic default date is defined to be the first date when the market prices the firm's debt as if it has defaulted. An implication is that the standard industry practice of using 30-day post default prices to compute recovery rate yields biased estimates. Second, we construct and estimate a distressed debt pricing model. We use this model to implicitly estimate the parameters of the embedded recovery rate process and to price distressed debt. Our distressed debt pricing model fits market prices well, with an average pricing error of less than one basis point.","Guo, Xin; Jarrow, Robert A.; Lin, Haizhi",2008,10.1007/s11147-009-9029-2,None,wos
d06354eb5a010bbe,Distributional modeling and forecasting of natural gas prices,"We examine the problem of modeling and forecasting European day‐ahead and month‐ahead natural gas prices. For this, we propose two distinct probabilistic models that can be utilized in risk and portfolio management. We use daily pricing data ranging from 2011 to 2020. Extensive descriptive data analysis shows that both time series feature heavy tails and conditional heteroscedasticity and show asymmetric behavior in their differences. We propose state‐space time series models under skewed, heavy‐tailed distributions to capture all stylized facts of the data. They include the impact of autocorrelation, seasonality, risk premia, temperature, storage levels, the price of European Emission Allowances, and related fuel prices of oil, coal, and electricity. We provide rigorous model diagnostics and interpret all model components in detail. Additionally, we conduct a probabilistic forecasting study with significance tests and compare the predictive performance against literature benchmarks. The proposed day‐ahead (month‐ahead) model leads to a 13% (9%) reduction in out‐of‐sample continuous ranked probability score (CRPS) compared with the best performing benchmark model, mainly due to adequate modeling of the volatility and heavy tails.","Berrisch, Jonathan; Ziel, Florian",2022,10.1002/for.2853,None,proquest
4b00fc35dcf2e6b0,Diverging Roads: Theory-Based vs. Machine Learning-Implied Stock Risk Premia,"We compare the performance of theory-based and machine learning (ML) methods for quantifying equity risk premia and assess hybrid strategies that combine the two very different philosophies. The theory-based approach offers advantages at a one-month investment horizon, in particular, if daily frequency risk premium estimates (RPE) are needed. At the one-year horizon, ML has an edge, especially using theory-based RPE as additional feature variables. For a hybrid strategy called Theory with ML Assistance, we employ ML to account for the approximation errors of the theory-based approach. Employing random forests or an ensemble of ML models for theory support yields promising results. © 2025 Elsevier B.V., All rights reserved.","Grammig, J.; Hanenberg, C.; Schlag, C.; Sönksen, J.",2025,10.1093/jjfinec/nbaf005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003374308&doi=10.1093%2Fjjfinec%2Fnbaf005&partnerID=40&md5=a2cce87fcf6aee5edfa0171f297c0c34,scopus
dfa20513b40f2c55,Diving into recession: the collective knowledge of online users as an early warning system for recessionary expectations,"As concerns about economic downturns manifest in online discussions, we investigate whether sentiment extracted from social media can serve as an early warning signal for recessionary pressures. Using a dataset of Twitter (X) posts related to economic prospects, we apply a range of sentiment analysis techniques, including a lexicon and rule-based method (VADER) and deep learning approaches (GPT and BERT). We assess the relationship between online sentiment and key recession indicators, such as the yield curve and GDPNow forecasts, using a combination of econometric and machine learning methods. In addition, we perform a comparative evaluation of sentiment classification techniques, incorporating both traditional models and deep learning architectures. Our results confirm that Twitter discussions precede changes in recessionary indicators and can thus provide forward-looking insights into economic sentiment. Furthermore, the comparative analysis reveals variations in sentiment detection across different methodologies, emphasizing the importance of selecting appropriate approaches in economic forecasting. © 2025 Elsevier B.V., All rights reserved.","Hayawi, K.; Shahriar, S.; Samuel Mathew, S.S.; Polyzos, E.; Ganguli, K.K.",2026,10.1016/j.im.2025.104252,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015563853&doi=10.1016%2Fj.im.2025.104252&partnerID=40&md5=a7e2b0bfc6dee3e9b87a6eddcf573d18,scopus
10aa5400853f1e0c,Do Foreign Yield Curves Predict US Recessions and GDP Growth?,Foreign term spreads constructed from bond yields of non-U.S. G-7 constituents predict future U.S. recessions and foreign term spreads are stronger predictors of U.S. recessions occurring within the next year than U.S. term spreads. U.S. and foreign term spreads are both informative of the U.S. economy but over different horizons and for different components of economic activity. Smaller U.S. term spreads lead to smaller foreign term spreads and U.S. Dollar appreciation. Smaller foreign term spreads do not lead to significant U.S. Dollar depreciation but do lead to persistent declines in U.S. exports and foreign direct investment (FDI) flows into the United States. These findings are consistent with the proposition that foreign term spreads embed growth spillovers from the U.S. and the resulting Dollar strength and slowdown abroad spill back to the United States.,"Ahmed, Rashad; Chinn, Menzie D.",2024,10.1111/jmcb.13164,None,wos
2e0bf09e1ae5d91f,Do Post-Corona European Economic Policies Lift Growth Prospects? Exploring an ML-Methodology,"This article explores the determinants of people’s growth prospects in survey data as well as the impact of the European recovery fund to future growth. The focus is on the aftermath of the Corona pandemic, which is a natural limit to the sample size. We use Eurobarometer survey data and macroeconomic variables, such as GDP, unemployment, public deficit, inflation, bond yields, and fiscal spending data. We estimate a variety of panel regression models and develop a new simulation-regression methodology due to limitation of the sample size. We find the major determinant of people’s growth prospect is domestic GDP per capita, while European fiscal aid does not significantly matter. In addition, we exhibit with the simulation-regression method novel scientific insights, significant outcomes, and a policy conclusion alike.","Herzog, Bodo",2022,10.3390/jrfm15030120,None,proquest
9986949db88cb68d,Do asymmetric and nonlinear adjustments explain the forward premium anomaly?,"This paper explores some of the asymmetries and nonlinearities in an attempt to throw light on the forward premium anomaly, where spot exchange rate returns are typically found to be negatively correlated with the lagged interest rate differential and lead to an apparent rejection of Uncovered Interest Parity (UIP). The approach in this paper is motivated by some recent theoretical literature on the limits to speculation and hysteresis. The paper estimates Logistic Smooth Transition Dynamic Regression (LSTR) models with a variety of transition variables, including the lagged forward premium, monetary and income fundamentals and also variables associated with time varying risk premium, including the conditional variances of some fundamentals. Results are reported for nine different currencies. Many of the estimated LSTR models provide evidence for the existence of an outer regime that is consistent with UIP. Estimation of the standard forward premium regression on observations falling in these regimes across the sample is moderately supportive of UIP holding in the outer regime. A simulation experiment also suggests that an LSTR dgp can produce data consistent with the anomaly. However, parameter estimation issues leads to considerable uncertainty with the estimated transition functions and hence imprecise definitions of regimes. The results are an interesting step in the direction of understanding the nonlinear dimension of the problem without fully resolving the anomaly.","Baillie, R T; Kiliç, R",2006,10.1016/j.jimonfin.2005.10.002,None,proquest
4b6d64e1256f6eb5,Do cross-border investors benchmark commercial real estate markets?: Evidence from relative yields and risk premia for a European investment horizon,"Purpose: The purpose of this study is to introduce a new perspective on determinants of cross-border investments in commercial real estate, namely, the relative attractiveness of a target market. So far, the literature has analyzed only absolute measures of investment attractiveness as determinants of cross-border investment flows. Design/methodology/approach: The empirical study uses a classic ordinary least squares estimation for a European panel data set containing 28 cities in 18 countries, with quarterly observations from Q1/2008 to Q3/2018. After controlling for empirically proven explanatory covariates, the model is extended by the new relative measurement based on relative yields/cap rates and relative risk premia. Additionally, the study applies a generalized additive mixed model (GAMM) to investigate a potentially nonlinear relationship. Findings: The study finds on average a ceteris paribus, statistically significant lagged influence of the proxy for relative attractiveness. Nonetheless, a differentiation is needed; relative risk premia are statistically significant, whereas relative yields are not. Moreover, the GAMM confirms a nonlinear relationship for relative risk premia and cross-border transaction volumes. Practical implications: The results are of interest for both academia and market participants as a means of explaining cross-border capital flows. The existing knowledge on determinants is expanded by relative market attractiveness, as well as an awareness of nonlinear relationships. Both insights help to comprehend the underlying transaction dynamics in commercial real estate markets. Originality/value: Whereas the existing body of literature focuses on absolute attractiveness to explain cross-border transaction activity, this study introduces relative attractiveness as an explanatory variable. © 2021 Elsevier B.V., All rights reserved.","Oertel, C.; Willwersch, J.; Cajias, M.",2020,10.1108/jerer-10-2019-0032,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078991288&doi=10.1108%2FJERER-10-2019-0032&partnerID=40&md5=96b180a1e0163261b87854a8d492aa3e,scopus
adb32e1a86c4dbc0,Do industry returns predict the stock market? A reprise using the random forest,"The prior work reports conflicting evidence on the information content of industry returns for the market index return. We reexamine the out of sample predictive ability of industry returns by considering several relatively advanced methods from the statistical learning literature. We show that when the random forest method, which accounts for both linear and nonlinear dynamics, is used for regression, industry returns indeed contain significant out of sample forecasting power for the market index return. Moreover, our analysis also presents evidence for lead-lag relations among individual industry returns. The reported findings are consistent with the implications of the gradual diffusion of information hypothesis. © 2019 Elsevier B.V., All rights reserved.","Ciner, C.",2019,10.1016/j.qref.2018.11.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057465162&doi=10.1016%2Fj.qref.2018.11.001&partnerID=40&md5=81b05d72c2b849b290de0e292f797a33,scopus
e8d85a38742f329b,Do leading indicators forecast US recessions? A nonlinear re-evaluation using historical data,"This paper analyses to what extent a selection of leading indicators is able to forecast U.S. recessions, by means of both dynamic probit models and Support Vector Machine (SVM) models, using monthly data from January 1871 to June 2016. The results suggest that the probit models predict U.S. recession periods more accurately than SVM models up to six months ahead, while the SVM models are more accurate over longer horizons. Furthermore, SVM models appear to distinguish between recessions and tranquil periods better than probit models do. Finally, the most accurate forecasting models are those that include oil, stock returns and the term spread as leading indicators.","Plakandaras, Vasilios; Cunado, Juncal; Gupta, Rangan; Wohar, Mark E.",2017,10.1111/infi.12111,None,wos
fc35da947a23917f,Do local and global factors impact the emerging markets' sovereign yield curves? Evidence from a data‐rich environment,"This paper investigates the relation between yield curve and macroeconomic factors for 10 emerging sovereign bond markets using the sample from January 2006 to April 2019. To this end, the diffusion indices obtained under four categories (global variables, inflation, domestic financial variables, and economic activity) are incorporated by estimating dynamic panel data regressions together with the yield curve factors. Besides, in order to capture dynamic interaction between yield curve and macroeconomic/financial factors, a panel vector autoregressive (VAR) analysis based on the system generalized method of moments (GMM) approach is utilized. Empirical results suggest that the level factor responds to shocks originated from inflation, domestic financial variables, and global variables. Furthermore, the slope factor is affected by shocks in global variables, and the curvature factor appears to be influenced by domestic financial variables. We also show that macroeconomic/financial factors captures significant predictive information over yield curve factors by running individual country factor‐augmented predictive regressions and variable selection algorithms such ridge regression, least absolute shrinkage operator (LASSO), and Elastic Net. Our findings have important implications for policymakers and fund managers by explaining the underlying forces of movements in the yield curve and forecasting accurately dynamics of yield curve factors.","Cepni, Oguzhan; Ibrahim, Ethem Guney; Kucuksarac, Doruk; Yilmaz, M Hasan",2021,10.1002/for.2763,None,proquest
b0fbff89929bd3a8,Does Rating Consistency Matter? A Micro-Level Study on the Impact of Corporate ESG Rating Divergence on Equity Financing Costs,"The influence of ESG rating divergence on corporate finance is receiving increasing scholarly attention as ESG concerns become more prominent. However, few studies have systematically examined how ESG rating discrepancies affect corporate equity financing costs. This study addresses this gap by analysing data from Chinese A-share listed firms between 2015 and 2022 to explore the impact of ESG rating divergence on equity financing costs and its underlying mechanisms. The results reveal that: (1) ESG rating divergence significantly raises equity financing costs, suggesting that capital markets impose a risk premium on inconsistent ESG information; (2) this effect is more pronounced in firms with greater external analyst forecast dispersion and more severe internal agency problems; (3) firms that are non-state-owned, face significant financial constraints, or have poor information quality are particularly vulnerable to this effect. The study contributes to the understanding of the economic consequences of ESG rating divergence and offers policy implications for regulators, institutions, investors and firms in navigating ESG-related challenges. © 2025 Elsevier B.V., All rights reserved.","Li, J.; Hou, Y.; Tan, C.; Han, L.",2025,10.1111/acfi.70057,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009813119&doi=10.1111%2Facfi.70057&partnerID=40&md5=bad9947ba156708087e4fd04ac55b870,scopus
d98996151ddb63ed,Does Real Estate Determine REIT Bond Risk Premia?,"This study is the first to examine the real estate-specific determinants of REIT bond risk premia. Using a dataset of 33,857 U.S. REIT bond yield spreads and 24 explanatory variables, we predict REIT bond yield spreads with a non-parametric artificial neural network algorithm and interpret the model’s predictions using the explainable machine learning method Accumulated Local Effect Plots (ALE). We report evidence of a direct real estate factor for U.S. REIT bond yield spreads proxied by real estate market total return and REIT property type. In addition, we find a property-type diversification risk premium for REIT bonds, indicating that there is no economic benefit in the form of lower cost of bond debt for most property-type diversification at the REIT-level. We argue that this is due to higher management and valuation complexity of diversified REIT portfolios. This study’s findings have relevant implications for REIT portfolio strategy and REIT capital structure decisions, as we show that specialized REITs generally have lower bond debt costs compared to diversified REITs. Moreover, a better understanding of the drivers influencing REIT bond risk premia helps investors to effectively manage bond portfolio risks. © 2025 Elsevier B.V., All rights reserved.","Kozak, J.; Nagl, C.; Nagl, M.; Beracha, E.; Schaefers, W.",2025,10.1007/s11146-025-10018-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007860488&doi=10.1007%2Fs11146-025-10018-7&partnerID=40&md5=745049e004467b65713fb8985dcc9bcd,scopus
9ed23b41c26184ea,Does a search attention index explain portfolio returns in India?,"Employing asset-pricing models over the period 2012 to 2017, this study examines whether a search attention index (SAI) explains the variation in the weekly excess return of stocks. The study finds that the estimated abnormal return of a portfolio based on search intensity is significantly high for stocks with higher search intensity and low for stocks with lower search intensity. Further, the study observes that, when the SAI is high, the excess returns are high for stocks with a high value, high volatility, and high sensitivity. Interestingly, the study documents that in the Indian market investor attention is irrelevant for stocks with extremely high risk. This study finds that the SAI in India explains the variation in the excess return of stocks as well as the market, size, value, and momentum factors. © 2022 Elsevier B.V., All rights reserved.","Dharani, M.; Hassan, M.K.; Abedin, M.Z.; Ismail, M.A.",2022,10.1016/j.bir.2021.04.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105775150&doi=10.1016%2Fj.bir.2021.04.003&partnerID=40&md5=2e803c6ed55f99bd21aa2e550c14959d,scopus
d3d12a9e1655b3b2,Does conditioning information matter in estimating continuous time interest rate diffusions?,"We examine an important aspect of empirical estimation of term structure models; the role of conditioning information in dynamic term structure models. The use of both real world or simulated data implicitly incorporates conditioning information. We examine the bias created in estimating the drift by a specific form of conditioning, namely truncation. Using the theory of enlargement of filtrations we provide estimates of the extent of this truncation bias for commonly used short rate models. We find that this truncation bias causes the drift of these models to have a nonlinear structure. © 2018 Elsevier B.V., All rights reserved.","Abhyankar, A.; Basu, D.",2001,10.2307/2676286,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035612944&doi=10.2307%2F2676286&partnerID=40&md5=659a2f593a7c8bb3bb31fd10ef82c8f5,scopus
07880a891ad14434,Does extreme climate concern drive equity premiums? Evidence from China,"We construct an extreme climate concern indicator (ECC) on the basis of the coverage of the extreme climate news reports. First, ECC significantly negatively forecasts stock market returns in subsequent months. The predictability of ECC returns outperforms alternative confidence indicators and economic predictors over both in-sample and out-of-sample periods. Second, relative to before the Paris Agreement entered into force, extreme climate concerns prominently enhanced the forecasting capabilities after the signing of the Paris Agreement. Third, the return prediction accuracy of ECC in periods of low climate concern is significantly greater than that in periods of high climate concern, which is also consistent with the limited attention of investors. Finally, ECC substantially brings appreciable economic gains to investors, and the relevant empirical results pass a series of robustness tests.","Xu, Yongan; Liang, Chao",2024,10.1057/s41599-024-03705-y,None,proquest
296118b61e9a3e48,"Does high frequency trading affect technical analysis and market efficiency? And if so, how?","In this paper we investigate how high frequency trading affects technical analysis and market efficiency in the foreign exchange (FX) market by using a special adaptive form of the Strongly Typed Genetic Programming (STGP)-based learning algorithm. We use this approach for real one-minute high frequency data of the most traded currency pairs worldwide: EUR/USD, USD/JPY, GBP/USD, AUD/USD, USD/CHF, and USD/CAD. The STGP performance is compared with that of parametric and non-parametric models and validated by two formal empirical tests. We perform in-sample and out-of-sample comparisons between all models on the basis of forecast performance and investment return. Furthermore, our paper shows the relative strength of these models with respect to the actual trading profit generated by their forecasts. Empirical experiments suggest that the STGP forecasting technique significantly outperforms the traditional econometric models. We find evidence that the excess returns are both statistically and economically significant, even when appropriate transaction costs are taken into account. We also find evidence that HFT has a beneficial role in the price discovery process. © 2013 Elsevier B.V. © 2013 Elsevier B.V., All rights reserved.","Manahov, V.; Hudson, R.; Gebka, B.",2014,10.1016/j.intfin.2013.11.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84888777057&doi=10.1016%2Fj.intfin.2013.11.002&partnerID=40&md5=c39d0f295369ac49ddb0508cf7876015,scopus
bc5db5e2cc4b6eec,Does the mode of financing the budget deficit matter for inflation in Nigeria?,"Purpose: The motivation for this study is to determine whether inflation in Nigeria is driven by the Central Bank’s direct advances and Treasury bills/bonds as modes of financing the budget deficit. Hence, it examines whether the method of deficit financing significantly impacts inflation in Nigeria. Design/methodology/approach: Based on the nature of the study and the availability of data in Nigeria, this study employs the ARDL bound test estimation technique to analyse annual time-series data from 1981 to 2021. Findings: The ARDL bounds test approach to co-integration revealed a long-run co-integrating relationship between Central Bank advances, Treasury bills/bonds, and inflation in Nigeria. Furthermore, the ARDL results provide evidence of a negative and significant relationship between bonds and inflation in both the short and long run. In contrast, Central Bank advances exhibit a statistically significant direct effect on inflation in the short run and an indirect effect in the long run. Research limitations/implications: The study focuses solely on Nigeria, limiting the applicability of the findings to other nations with differing economic structures or fiscal policies. Secondly, while the ARDL bounds testing approach is appropriate for the research context, it may not capture complex nonlinear relationships or structural breaks within the dataset. Lastly, the exclusion of additional potential determinants of inflation, such as external shocks, geopolitical factors, or exchange rate dynamics, could restrict the comprehensiveness of the analysis. Practical implications: This study provides empirical evidence supporting the view that, to achieve lower inflation in Nigeria, policymakers should prioritize using bonds to finance the deficit budget, as they have been shown to have a short-and long-term deflationary effect on the economy. Originality/value: The novelty of this study lies in categorizing deficit budget financing (Central Bank advances and Treasury bills) and identifying which has the greatest impact on inflation in Nigeria. © 2025 Elsevier B.V., All rights reserved.","Abdullahi, S.M.; Kanang, A.A.; Gana, S.S.",2025,10.1108/ajems-04-2024-0265,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002467091&doi=10.1108%2FAJEMS-04-2024-0265&partnerID=40&md5=2af768eadcd1634b02656af15aeca46e,scopus
a3a393575cf364eb,"Dopamine D2 −141C Ins/Del and Taq1A polymorphisms, body mass index, and prediction error brain response","The prediction error model is a widely used paradigm that is conceptually based on neuronal dopamine function. However, whether dopamine receptor gene alleles contribute to human neuroimaging prediction error results is uncertain. Recent research implicated the dopamine D2 receptor in behavior response during a prediction error paradigm and we expected that polymorphisms of that receptor would contribute to prediction error brain response. In this study, healthy female participants in the early follicular phase of the menstrual cycle underwent a taste prediction error paradigm during functional magnetic resonance imaging. Participants were also genotyped for dopamine receptor polymorphisms. Our data suggest that the dopamine D2 receptor −141C Ins/Del and Taq1A polymorphisms together with body mass index selectively explain putamen prediction error response. This was true using a region of interest analysis as well as for a whole-brain analysis (FWE corrected). Polymorphisms for dopamine D1 or D4 receptors, dopamine transporter, or COMT did not significantly contribute to prediction error activation. The prediction error model is a computational reward-learning paradigm that is important in psychiatric research and has been associated with dopamine. The results from this study indicate that dopamine D2 receptor polymorphisms together with body mass index are important determinants to include in research that tests prediction error response of the brain. Psychiatric disorders are frequently associated with elevated or reduced body weight. Adding BMI to genetic information in brain-imaging studies that use reward and the prediction error paradigm may be important to increase validity and reliability of results.","Frank, Guido K W; Shott, Megan E; DeGuzman, Marisa C; Smolen, Andrew",2018,10.1038/s41398-018-0147-1,None,proquest
4bd64fadf8327592,Dynamic Autoregressive Liquidity (DArLiQ),"We introduce a new class of semiparametric dynamic autoregressive models for the Amihud illiquidity measure, which captures both the long-run trend in the illiquidity series with a nonparametric component and the short-run dynamics with an autoregressive component. We develop a generalized method of moments (GMM) estimator based on conditional moment restrictions and an efficient semiparametric maximum likelihood (ML) estimator based on an iid assumption. We derive large sample properties for our estimators. Finally, we demonstrate the model fitting performance and its empirical relevance on an application. We investigate how the different components of the illiquidity process obtained from our model relate to the stock market risk premium using data on the S&P 500 stock market index. © 2024 Elsevier B.V., All rights reserved.","Hafner, C.M.; Linton, O.B.; Wang, L.",2024,10.1080/07350015.2023.2238790,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171686338&doi=10.1080%2F07350015.2023.2238790&partnerID=40&md5=87817b3788132f686907c6a32d52cff2,scopus
1a2c221241c0c808,"Dynamic effect of Bitcoin, fintech and artificial intelligence stocks on eco-friendly assets, Islamic stocks and conventional financial markets: Another look using quantile-based approaches","Against the milieu of rapidly growing investment in technologically induced assets, this study examines the investment role of Bitcoin, fintech, and artificial intelligence (AI) stocks in relation to major environmentally friendly assets (green bonds, sustainable investments, and clean energy), Islamic stocks, and conventional financial markets using quantile-based approaches. To this end, we specifically examine the distributional and directional predictability between the returns of fintech, Bitcoin, and AI and various markets using the nonparametric causality-in-quantiles method and the cross-quantilogram correlation method respectively. We use daily data spanning March 9, 2018 to January 27, 2021. In terms of the distributional predictability of fintech, Bitcoin, and AI in relation to the traditional markets, Islamic stocks, clean energy stocks, and sustainable investments, we find strong evidence of causal asymmetry across quantiles and strong variations across markets. Likewise, findings in terms of directional predictability between the returns of fintech, Bitcoin, and AI and various markets infer that Islamic stocks act as a good hedge against Bitcoin. The S&P Treasury Bond and S&P Green Bond are also perfect hedges for fintech stocks, while S&P Global Clean Energy is a perfect hedge for AI stocks in terms of long-term dynamics. © 2023 Elsevier B.V., All rights reserved.","Abakah, E.J.A.; Tiwari, A.K.; Ghosh, S.; Doğan, B.",2023,10.1016/j.techfore.2023.122566,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152485944&doi=10.1016%2Fj.techfore.2023.122566&partnerID=40&md5=c1f97b045bdb4bd9b8444cb70ca68f6e,scopus
c657958f06d1abb7,Dynamic portfolio insurance strategy: A robust machine learning approach,"In this paper, we propose a robust genetic programming (RGP) model for a dynamic strategy of stock portfolio insurance. With portfolio insurance strategy, we divide the money in a risky asset and a risk-free asset. Our applied strategy is based on a constant proportion portfolio insurance strategy. For determining the amount for investing in the risky asset, a critical parameter is a constant risk multiplier that is calculated in our proposed model using RGP to reflect market dynamics. Our model includes four main steps: (1) Selecting the best stocks for constructing a portfolio using a density-based clustering strategy. (2) Enhancing the robustness of our proposed model with an application of the Adaptive Neuro-Fuzzy Inference Systems (ANFIS) for forecasting the future prices of the selected stocks. The findings show that using ANFIS, instead of a regular multi-layer artificial neural network improves the prediction accuracy and our model’s robustness. (3) Implementing the RGP model for calculating the risk multiplier. Risk variables are used to generate equation trees for calculating the risk multiplier. (4) Determining the optimal portfolio weights of the assets using the well-known Markowitz portfolio optimization model. Experimental results show that our proposed strategy outperforms our previous model. © 2021 Elsevier B.V., All rights reserved.","Dehghanpour, S.; Esfahanipour, A.",2018,10.1080/24751839.2018.1431447,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065718194&doi=10.1080%2F24751839.2018.1431447&partnerID=40&md5=5a81c0b59c02568f89020e86bab8376a,scopus
04924b384fc50756,Dynamic relationship of volatility of returns across different markets: evidence from selected next 11 countries,"Purpose: This paper aims to examine whether the volatility of returns in commodity (gold, oil), bond and forex markets is related over time to the volatility of returns in equity markets of Bangladesh, Indonesia, Pakistan, Philippines, Turkey and Vietnam. In addition, the authors analyze the integration of the commodity, bond, forex and equity markets across these markets. Design/methodology/approach: The dynamic conditional correlation GARCH (DCC-GARCH) model is used to capture the time-varying conditional correlation among markets. The authors use daily data of stock prices, oil prices, gold prices, exchange rates and 10 years' bond yields of the six countries from Datastream and investing.com from January 2001 to April 2021. Findings: Findings reveal that the parameters of dynamic correlation are statistically significant which indicates the importance of time-varying co-movements. Estimation of the DCC-GARCH model suggests that the stock market is significantly correlated with bond, forex, gold and oil markets in all six countries. Practical implications: This study has practical implications for policymakers and investment professionals. A better understanding of dynamic linkages among the markets would help in constructing effective hedging and portfolio diversification strategies. Policy makers can get insight to build proper strategies in order to insulate the economy from factors that cause volatility. Originality/value: Several studies have investigated the linkage between commodity and stock markets and the volatility spillover effect, but very little attention is given to study the interrelationship between groups of market segments of different economies. No study has comparatively examined the dynamic relationship of multiple markets of a group of emerging countries simultaneously. © 2024 Elsevier B.V., All rights reserved.","Shafiq, S.; Qureshi, S.S.; Akbar, M.",2024,10.1108/jeas-09-2022-0216,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197194276&doi=10.1108%2FJEAS-09-2022-0216&partnerID=40&md5=16a64a068d49b634b8f06b98b9336458,scopus
cfa12aa6640fe808,Dynamic semiparametric factor models in risk neutral density estimation,"Dynamic semiparametric factor models (DSFM) simultaneously smooth in space and are parametric in time, approximating complex dynamic structures by time invariant basis functions and low dimensional time series. In contrast to traditional dimension reduction techniques, DSFM allows the access of the dynamics embedded in high dimensional data through the lower dimensional time series. In this paper, we study the time behavior of risk assessments from investors facing random financial payoffs. We use DSFM to estimate risk neutral densities from a dataset of option prices on the German stock index DAX. The dynamics and term structure of risk neutral densities are investigated by Vector Autoregressive (VAR) methods applied on the estimated lower dimensional time series.","Giacomini, Enzo; Haerdle, Wolfgang; Kraetschmer, Volker",2009,10.1007/s10182-009-0115-4,None,wos
ce15cb2f2a6fe0d0,"Dynamic spillovers and linkages between gold, crude oil, S&P 500, and other economic and financial variables. Evidence from the USA","This paper focuses on the price determinants of gold, and on the challenges associated with gold's safe haven property. Specifically, it analyses the interlinkages and the return spillover effect among gold, crude oil, S&P 500, dollar exchange rate, Consumer Price Index (CPI), economic policy uncertainty and Treasury bills, by employing a Vector Autoregression (VAR) and the spillover index of Diebold and Yilmaz (2012), Diebold and Yilmaz (2014). Monthly realized return series, covering the period from 2nd of January 1986 to 31st of December 2019 are used to examine the short-run linkages, and the return spillovers rolling-window estimates in analyzing the transmission mechanism in a time-varying fashion, respectively. Our findings identify gold as a strong dollar hedge, while crude oil and Treasury bills appear to drive inflation; they also indicate strong spillover effects between exchange rate and gold returns. In general, co-movement dynamics display state-dependent characteristics. Both total and directional spillovers increase significantly during market turbulence caused by severe financial crises such as the Global Financial Crisis (GFC) of 2007-2009 and the European Sovereign Debt Crisis of 2010-2012. Net spillovers switch between positive and negative values for all these markets, implying that the recipient/transmitter position changes drastically with market events. Economic policy uncertainty, stock market returns, and crude oil price returns are the main transmitters, while Treasury bills and CPI are the main return shock recipients. Gold and exchange rate act both as receivers and transmitters over the sample period.","Golitsis, Petros; Gkasis, Pavlos; Bellos, Sotirios K.",2022,10.1016/j.najef.2022.101785,None,wos
116d6c5d4db5f1b9,Dynamics of Money Market Interest Rates in Ghana: Time-Frequency Analysis of Volatility Spillovers,"As the second longest practicing inflation targeting economy in Africa, it is of interest to investigate the degree to which policy interest rate influences other money market rates so as to gauge the overall effectiveness of monetary policy transmission in Ghana. This study evaluates the degree of connectedness among money market rates and also determines the most dominant money market rate(s) in Ghana. The basic finding is that the monetary policy rate has a low-to-moderate influence on volatility dynamics of other money market rates in Ghana across historical time-interval and time-frequency domains. This is a reflection of a generally weak capability of policy interest rate to drive other market rates in Ghana. Both monetary policy rate and Treasury bill rate are net transmitters of shocks, while interbank, lending and saving rates are net receivers of shocks in the money market. However, the Treasury bill emerges as the largest shock transmitter in the money market, across all forecast horizons and analytical domains. The lending rate is the largest shock recipient in the money market, largely from the Treasury bill rate which suggests ample evidence of fiscal dominance in Ghana. The study accentuates the exigency for monetary and fiscal policies to expeditiously address the domestic structural bottlenecks, especially in the financial sector and the fragile fiscal profile, in order to strengthen policy transmission in Ghana.","Akosah, Nana Kwame; Alagidede, Imhotep Paul; Schaling, Eric",2021,10.1111/saje.12287,None,wos
d116e668a6034e16,"ECONOMIC INJURY LEVEL, ACTION THRESHOLD, AND A YIELD-LOSS MODEL FOR THE PEA APHID, ACYRTHOSIPHON-PISUM (HOMOPTERA, APHIDIDAE), ON GREEN PEAS, PISUM-SATIVUM","Economic injury level, action threshold, and population development studies with the pea aphid (PA), Acyrthosiphon pisum (Harris), were conducted during 1983-85 [Washington, USA]. Pea aphid densities, simulating those in commercial pea fields, were established using insecticides to manipulate infestation levels. Three experiments, incorporating 12 treatments and six replications, were analyzed. A generalized, nonlinear equation relating pea yield to accumulated aphid feeding days (AFD) is described. The model approximates two phases of a sigmoid infestation-yield curve. An upper maximum plateau and a region of rapidly decreasing yield are approximate. Beyond 1,800 aFD, a lower minimum yield plateau is hypothesized. Economic injury levels calculated for the 3 years'' experiments using the generalized model were 22.2, 18.2, and 12.2 AFD, respectively. Action threshold estimates were determined from linear regression estimates of yield versus aphids per plant at bloom. Action thresholds were 3.6, 0.3, and 0.3 aphids per plant for the years 1983, 1984, 1985, respectively. The pea quality components, tenderometer (TD) and sieve size, were altered by maximum PA densities. High AFD levels increased TD and decreased sieve size significantly when compared with aphid-free controls. Protein content of green peas was not significantly altered by PA feeding.","YENCHO, GC; GETZIN, LW; LONG, GE",1986,10.1093/jee/79.6.1681,None,wos
4e1455a476507192,ESG and corporate credit spreads,"Purpose: The authors investigate the implications of environmental, social and governance (ESG) practices of firms for the pricing of their credit default swaps (CDS). In doing so, the authors compare European and US firms and consider nonlinear and indirect effects. This complements the previous literature focusing on linear and direct effects using bond yields and credit ratings of US firms. Design/methodology/approach: For this purpose, the authors apply fixed effects regressions on a comprehensive panel data set of US and European firms. Further, nonlinear and indirect effects are investigated utilizing quantile regressions and a path analysis. Findings: The evidence indicates that higher ESG ratings mitigate credit risks of US and European firms from 2007 to 2019. The risk mitigation effect is U-shaped across ESG quantiles, which is consistent with opposing effects of growing stakeholder influence capacity and diminishing marginal returns on ESG investments. The authors further reveal a mediating indirect volatility channel that substantially amplifies the direct effect of ESG on credit risk. A one-standard-deviation improvement in ESG ratings is estimated to reduce CDS spreads of low, medium and high ESG firms by approximately 4%, 8% and 3%, respectively. Originality/value: This is the first study to examine whether credit markets reflect regional differences between Europe and the US with regard to the ESG-CDS-relationship. In addition, this paper contributes to the existing literature by investigating differences in the response of CDS spreads across ESG quantiles and to study potential indirect channels connecting ESG and CDS spreads using structural credit risk variables. © 2022 Elsevier B.V., All rights reserved.","Barth, F.; Hübel, B.; Scholz, H.",2022,10.1108/jrf-03-2021-0045,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124343222&doi=10.1108%2FJRF-03-2021-0045&partnerID=40&md5=17a558b0787d2116f8797fc6df2d9467,scopus
03cc69643da21feb,ESG in the headlines: Media-driven reputational risk and stock performance,"This study examines the impact of environmental, social, and governance (ESG) reputational risks on stock performance. We use a unique dataset of media-driven ESG reputational risk indicators, covering 4963 Chinese firms from 2009 to 2023. On average, a one-standard-deviation increase in ESG reputational risks is associated with a 4.5 % decrease in simple stock returns, a 14.5 % reduction in excess stock returns relative to the market index, and a 12.2% decline in excess stock returns compared to peer firms of similar size. These negative effects contradict the traditional risk-return relationship predicted by risk premium theory. Further analysis identifies reduced investor confidence and tighter financing constraints as key mechanisms through which ESG reputational risks negatively affect stock returns. Heterogeneity analyses indicate that the negative impact is more pronounced for firms in non-pollution-intensive industries, those facing financing difficulties, and those exposed to environment-related reputational risks.","Zhou, Bole; Ge, Wanjun",2025,10.1016/j.gfj.2025.101127,None,wos
ae8ad37dda607103,ESTIMATING AN UPPER BOUND ON THE PRATT RISK-AVERSION COEFFICIENT WHEN THE UTILITY FUNCTION IS UNKNOWN,None,"MCCARL, BA; BESSLER, DA",1989,10.1111/j.1467-8489.1989.tb00481.x,None,wos
5d75205f29fc9e07,ESTIMATING WEIGHTED BANK BETA INDEX UNDER MACRO EFFECTS IN VIETNAM IN INDUSTRY 4.0 AND ROLES OF DIGITAL TRANSFORMATION FOR BETTER RISK MANAGEMENT INFORMATION SYSTEM,"The applications of mathematics in finance have been developed widely in recent years. In our study, authors aim to propose weighted beta index formula in banking industry and then, factors that affect bank sustainable development, as well as risk management policies and strategies for commercial banks in Vietnam financial market. This study mainly use combination of quantitative methods (statistics, calculation formulas) and qualitative methods including synthesis, inductive and explanatory methods. Our study results show that first, because mean value of weighted beta in period 2011-2020 higher than beta in 2011-2016 time, we need to pay attention to risk management solution in bank system. Second, as CPI has negative impact while G, IM and R has positive impact on weighted beta: and Risk free rate have higher effects on market risks of banks, Ministry of Finance, State bank of Vietnam and relevant agencies need to control GDP growth as well as rates of Treasury bonds and lending rate (not increase so much) toward benefits for managing risk. And do not need to reduce CPI too much. Then we also mention the roles of digital data and transformation to help us to build better risk model and management information system at banks. © 2025 Elsevier B.V., All rights reserved.","Xuan Que, H.; Tran Ngoc Huy, D.; Duc Thang, T.; Van Thanh, T.; Hoang, H.",2022,10.31407/ijees12.338,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172739866&doi=10.31407%2Fijees12.338&partnerID=40&md5=9077207f47188466c73640dbdb313952,scopus
3573c812918e3c81,Early Warning of Systemic Financial Risk of Local Government Implicit Debt Based on BP Neural Network Model,"In recent years, local governments have boosted their local economies by raising large amounts of debt. Even though the state further strictly controls local government debt, the hidden debt formed by the local government borrowing in disguised form can infect systemic financial risks, creating an urgent need to carry out risk warning based on local government hidden debt. The paper uses the macro indicators of local government implicit debt risk at the prefecture-level city level, and introduces the micro indicators of PPP projects, financing platform bank debt, and urban investment debt to establish a BP neural network model. We not only study the contagion effect of local government hidden debt on systemic financial risks, but also predict the systemic financial risks in 2019 and construct an early warning risk system based on the prefecture-level city data from 2015 to 2018. In addition, the early warning effect of local government implicit debt on systemic financial risk under different stress scenarios is investigated. The study found that the implicit debt risk of local governments, the scale of financing platform bank debt, the scale of PPP, and the scale of urban investment bonds have a significant impact on systemic financial risks. The neural network model constructed by introducing these four variables at the same time can better predict the level of systemic financial risk. The model can also accurately predict the changes in systemic financial risks under the stress test of the increase in hidden debt of different local governments, and has a good early warning effect.","Zhao, Yinglan; Li, Yi; Chen, Feng; Gong, Chi; Gong, Chi; Tan, Hongru",2022,10.3390/systems10060207,None,proquest
53fb42b70ec1f6c0,Early warning strategies for corporate operational risk: A study by an improved random forest algorithm using FCM clustering,"To enhance the accuracy and response speed of the risk early warning system, this study develops a novel early warning system that combines the Fuzzy C-Means (FCM) clustering algorithm and the Random Forest (RF) model. Firstly, based on operational risk theory, market risk, research and development risk, financial risk, and human resource risk are selected as the primary indicators for enterprise risk assessment. Secondly, the Criteria Importance Through Intercriteria Correlation (CRITIC) weight method is employed to determine the importance of these risk indicators, thereby enhancing the model's prediction ability and stability. Following this, the FCM clustering algorithm is utilized for pre-processing sample data to improve the efficiency and accuracy of data classification. Finally, an improved RF model is constructed by optimizing the parameters of the RF algorithm. The data selected is mainly from RESSET/DB, covering the issuance, trading, and rating data of fixed-income products such as bonds, government bonds, and corporate bonds, and provides basic information, net value, position, and performance data of funds. The experimental results show that the model achieves an F1 score of 87.26%, an accuracy of 87.95%, an Area under the Curve (AUC) of 91.20%, a precision of 89.29%, and a recall of 87.48%. They are respectively 6.45%, 4.45%, 5.09%, 4.81%, and 3.83% higher than the traditional RF model. In this study, an improved RF model based on FCM clustering is successfully constructed, and the accuracy of risk early warning models and their ability to handle complex data are significantly improved.To enhance the accuracy and response speed of the risk early warning system, this study develops a novel early warning system that combines the Fuzzy C-Means (FCM) clustering algorithm and the Random Forest (RF) model. Firstly, based on operational risk theory, market risk, research and development risk, financial risk, and human resource risk are selected as the primary indicators for enterprise risk assessment. Secondly, the Criteria Importance Through Intercriteria Correlation (CRITIC) weight method is employed to determine the importance of these risk indicators, thereby enhancing the model's prediction ability and stability. Following this, the FCM clustering algorithm is utilized for pre-processing sample data to improve the efficiency and accuracy of data classification. Finally, an improved RF model is constructed by optimizing the parameters of the RF algorithm. The data selected is mainly from RESSET/DB, covering the issuance, trading, and rating data of fixed-income products such as bonds, government bonds, and corporate bonds, and provides basic information, net value, position, and performance data of funds. The experimental results show that the model achieves an F1 score of 87.26%, an accuracy of 87.95%, an Area under the Curve (AUC) of 91.20%, a precision of 89.29%, and a recall of 87.48%. They are respectively 6.45%, 4.45%, 5.09%, 4.81%, and 3.83% higher than the traditional RF model. In this study, an improved RF model based on FCM clustering is successfully constructed, and the accuracy of risk early warning models and their ability to handle complex data are significantly improved.","Fang, Xini",2025,10.1371/journal.pone.0318491,None,proquest
c3b936939fcbc181,Earthquake Insurance via CAT Bonds Utilizing Autoregressive Neural Networks and Active Faults,"Catastrophe (CAT) bonds necessitate a robust construction with regard to the estimated probability measure of their triggering parameter. This article concentrates on earthquakes as the primary natural catastrophe of concern. By leveraging the geometry of active faults for estimating default probability, we utilize seismic event information spanning up to 15,000 years in the past—thereby surpassing the restricted time range of available historical catalogs commonly used in other analyses, which typically cover only a few hundred years. This article introduces the design and pricing methodology of CAT bonds employing autoregressive neural networks, extending the standard VAR Nelson-Siegel model for yield curves. It presents a case study focused on the region of Greece, estimating that an additional spread of approximately 500 basis points over LIBOR constitutes the minimum premium required to attract an investor to undertake the associated risk. This premium could be absorbed by insured parties as an alternative to the conventional insurance process. © 2024 Elsevier B.V., All rights reserved.","Louloudis, E.; Zimbidis, A.; Tsekrekos, A.; Yannacopoulos, A.",2024,10.3905/jfi.2024.1.186,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206015299&doi=10.3905%2Fjfi.2024.1.186&partnerID=40&md5=16f2c58895e0134693f922a1467a33d0,scopus
7b6e0566cefac712,Econometric Model Using Arbitrage Pricing Theory and Quantile Regression to Estimate the Risk Factors Driving Crude Oil Returns,"This work presents a novel approach to determining the risk and return of crude oil stocks by employing Arbitrage Pricing Theory and Quantile Regression. Arbitrage Pricing Theory identifies the risk factors likely to impact crude oil returns. Subsequently, Quantile Regression estimates the relationship between the selected factors and the returns across different distribution quantiles. The West Texas Intermediate (WTI) crude oil price is used in this study as a benchmark for crude oil prices. WTI’s price fluctuations can significantly impact the performance of global crude oil stocks and, subsequently, the global economy. Various statistical measures are used in this study to determine the proposed model's stability. The results show that changes in WTI returns can have varying effects depending on market conditions and levels of volatility. This study emphasizes the influence of structural discontinuities on returns. These are likely generated by changes in the global economy and the unpredictable demand for crude oil during the pandemic. The inclusion of pandemic, geopolitical, and inflation-related explanatory variables adds uniqueness to the study as it considers current global events that can affect crude oil returns. Findings show that the key factors that pose significant risks to returns are industrial production, inflation, the global price of energy, the shape of the yield curve, and global economic policy uncertainty. This implies that while making investment decisions in WTI futures, investors should pay particular attention to these elements. © 2024 Elsevier B.V., All rights reserved.","Maitra, S.; Mishra, V.; Kundu, S.; Chopra, M.",2024,10.62527/joiv.8.1.2268,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189629613&doi=10.62527%2Fjoiv.8.1.2268&partnerID=40&md5=91a6c326b4237fac4db0eac49a9b571c,scopus
f94fec6a124c4ff8,Economic Evaluation and Risk Premium Estimation of Rainfed Soybean under Various Planting Practices in a Semi-Humid Drought-Prone Region of Northwest China,"Economic benefits and risk premiums significantly affect the production system decision making of farmers and government departments. This study evaluated the economic feasibility and estimated the risk premium of 12 rainfed soybean production systems with various planting densities, fertilization rates and planting patterns by considering the impact of soybean price fluctuation. There were two planting densities (D1: 160,000 plants ha−1 and D2: 320,000 plants ha−1), two fertilization rates (F1: 20 kg ha−1 N, 30 kg ha−1 P, 30 kg ha−1 K; F2: 40 kg ha−1 N, 60 kg ha−1 P, 60 kg ha−1 K) and three planting patterns (F+W0: flat cultivation with no irrigation; R+W0: plastic-mulched ridge-furrow cultivation (PMRF) with no irrigation; R+W1: PMRF with supplemental irrigation of 30 mm at the pod-filling stage). Based on the two-year (2019–2020) field data in a semi-humid drought-prone region of northwest China and soybean price fluctuation from January 2014 to June 2021, the net income (NI) was calculated by considering the impact of soybean price fluctuation and assuming constant soybean production costs. The net present value (NPV) method and the stochastic efficiency with respect to a function (SERF) method were used to evaluate the profitability of protective alternatives and the risk of these alternatives. The results showed that the 12 proposed soybean production systems were economically feasible. Reducing the fertilization rate reduced the input costs, but it did not necessarily result in a decrease in soybean yield and NI. The payback period of all production systems was within two years for farmers investing through loans. High-fertilizer and high-density production systems made personal investment obtain the highest economic benefit in this study, which was not the best investment strategy from the perspective of production-to-investment ratio and environmental protection departments. The preferences of farmers with various risk aversion and environmental protection departments in terms of risk premium were also proposed. The economic and risk assessment framework of this study can enhance the understanding of the adjustment of production systems from different perspectives, and provide strategies for promoting the protection of economic, environmental and socially sustainable agricultural systems.","Liao, Zhenqi; Shengzhao Pei; Bai, Zhentao; Lai, Zhenlin; Wen, Lei; Zhang, Fucang; Li, Zhijun; Fan, Junliang",2023,10.3390/agronomy13112840,None,proquest
194f421df0135388,"Economic Freedom, Budget Deficits, and Perceived Risk from Larger National Debt-to-GDP Ratios: An Exploratory Analysis of Their Real Interest Rate Effects","Since the early 1980s, there have been a number of principally empirical studies of the impact of government budget deficits on interest rates that have typically tested the hypothesis that larger deficits raise interest rates. However, in more recent years, this topic has received far less attention. Accordingly, this study seeks to “update” the findings of such studies and to do so for the dominant North American economies of Canada and the U.S. Furthermore, in the pursuit of further insights into interest rates, the present study also investigates an effectively heretofore overlooked variable that arguably also might influence interest rates, namely, economic freedom. Finally, given the increased upward trend of government debt (relative to GDP) in recent years in Canada and the U.S., this study investigates the interest rate impact of rising national debt-to-GDP ratios. For the 1995–2024 period (and also in one estimate for the 1985–2001 period), this exploratory study finds compelling evidence (1) that the real interest rate yield on 10-year Treasuries in Canada and the real interest rate yield on 10-year U.S. Treasury notes are increasing functions of the central government budget deficits in both Canada and the U.S., respectively, and (2) the real interest rate yields on 10-year Treasuries in Canada and 10-year U.S. Treasury notes are both decreasing functions of economic freedom in Canada and the U.S., respectively. On the other hand, regarding the impact of a higher national debt-to-GDP ratio on the real ten-year Treasury yield, there is only very mixed support for an impact, with support for its impact coming from the Canadian estimates but no support whatsoever coming from the U.S. estimates.","Cebula, Richard J",2024,10.3390/jrfm17100469,None,proquest
ab86b8847a95a2fb,"Economic costs of Fusarium Head Blight, scab and deoxynivalenol","Fusarium Head Blight (FHB) has led to major economic costs for wheat and barley producers. Grain products and feed grain contaminated with deoxynivalenol (DON) (commonly known as vomitoxin) are subject to Food and Drug Administration advisory limits and as a result end-users place restrictions on their use. This has led to steep price discounts, as well as higher risks for producers and grain merchandisers. Varietal research has led to development of varieties that are resistant or moderately resistant to FHB. Studies indicate combinations of genetic resistance, fungicides and some management practices (combine settings, tillage practices, etc.) can be used to decrease economic costs due to FHB. The purpose of this study was to estimate the economic costs of scab. To do so we developed several economic models, analysed extensive data and conducted surveys of wheat flour millers, barley maltsters, and grain handlers. A detailed assessment of costs indicates the most important costs accrued by the wheat and barley industries were the risk premium paid to induce adoption of DON reducing technologies and the value of yield forgone. These were followed by the direct costs of fungicide, added shipping costs, testing and segregation and discounts.","Wilson, W; Dahl, B; Nganje, W",2018,10.3920/wmj2017.2204,None,proquest
10e22f6f446668c0,Economic forces and seasonality in secirity returns,"This article finds strong seasonal behavior in the innovations for three Canadian macroeconomic variables (industrial production, unexpected inflation and GDP). An APT model is estimated as a restricted nonlinear multivariate regression system using seven macroeconomic variables, various residual market factor (RMF) proxies, and the returns on fifty size related portfolios of equities that traded on the Toronto Stock Exchange (TSE). As in Chen, Roll and Ross (1986), five macrofactors (lagged industrial production, lagged GDP, term structure, unexpected inflation, and risk premium) have significantly priced risk premia. The risk premia are insignificant for RMF based on two value weighted indices, and marginally significant (0.10 level) for the RMF based on an equally weighted index, which is somewhat consistent with McElroy and Burmeister (1988) and Brown and Otsuki (1989). The significance of the RMF risk premium appears not to be robust to whether portfolios or individual securities are used in the estimations. The significance of the estimated risk premia for the macrofactors also appear not to be robust to the number of portfolios (equations) used in the estimations. Unlike the risk premia estimates for the RMF, those for the other macrofactors are generally unaffected by the inclusion of a January dummy. This implies that the January seasonal remains a market phenomenon that requires further study. © 1992 Kluwer Academic Publishers. © 2007 Elsevier B.V., All rights reserved.","Kryzanowski, L.; Zhang, H.",1992,10.1007/bf00586436,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0039122166&doi=10.1007%2FBF00586436&partnerID=40&md5=7c54072676b2de26142e5bce6c6f16dc,scopus
6af02ce8367645c4,Effectiveness of family policy in Russia: Evidence-based approach,"Family policy in Russia, is based on a “narrow” demographic interpretation that neglects policy effectiveness and impact of state support on fertility indicators. This gap can be addressed using the evidence-based approach, which embraces both the influence of public policies on fertility, and human capital. The paper discusses the theoretical underpinnings of policy based on the Becker-Barreau and Baldrin-Jones concepts. We show the importance of incorporating “Big Data” into family policy analysis to address the problem of data completeness and analytical information for family policy needs. We rely on A. Sagradov’s ideas about quantitative determination of population reproduction patterns with non-demographic processes, including institutional changes and transformation of economic mechanisms of family policy. We estimated the demographic result per unit of budget expenditures in Russia (based on empirical data from EMISS and the Federal Treasury for 86 regions from 2011 to 2021, with a breakdown by months). The “random forest” method is used to identify the key factors influencing the results of the machine learning model, and to demonstrate the significance of parameters for assessing the socio-economic effectiveness of family policy in Russia. The research findings indirectly confirm the pro-natalist nature of family policy in Russia, the effectiveness of which is ensured by economic mechanisms of direct cash payments to the population. The paper concludes with a discussion of the prospects for using an evidence-based approach to family policy in Russia. © 2021 Elsevier B.V., All rights reserved.","Kapoguzov, E.A.; Chupin, R.I.",2021,10.18522/2073-6606-2021-19-3-20-36,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119446410&doi=10.18522%2F2073-6606-2021-19-3-20-36&partnerID=40&md5=2ee5f6c1dca99c380322ca57d563bd35,scopus
0657bf71f73e0954,Efficient MCMC estimation of some elliptical copula regression models through scale mixtures of normals,"This paper proposes an efficient estimation method for some elliptical copula regression models by expressing both copula density and marginal density functions as scale mixtures of normals (SMN). Implementing these models using the SMN is novel and allows efficient estimation via Bayesian methods. An innovative algorithm for the case of complex semicontinuous margins is also presented. We utilize the facts that copulas are invariant to the location and scale of the margins; all elliptical distributions have the same correlation structure; and some densities can be represented by the SMN. Two simulation studies, one on continuous margins and the other on semicontinuous margins, highlight the favorable performance of the proposed methods. Two empirical studies, one on the US excess returns and one on the Thai wage earnings, further illustrate the applicability of the proposals. © 2019 Elsevier B.V., All rights reserved.","Wichitaksorn, N.; Gerlach, R.; Choy, S.T.B.",2019,10.1002/asmb.2410,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053731638&doi=10.1002%2Fasmb.2410&partnerID=40&md5=f78b5cba81fbb9780f1904c40f0be3e3,scopus
b9ed21f0c6e8f1fe,Efficient importance sampling maximum likelihood estimation of stochastic differential equations,"Maximum likelihood estimation (MLE) of stochastic differential equations (SDEs) is difficult because in general the transition density function of these processes is not known in closed form, and has to be approximated somehow. An approximation based on efficient importance sampling (EIS) is detailed. Monte Carlo experiments, based on widely used diffusion processes, evaluate its performance against an alternative importance sampling (IS) strategy, showing that EIS is at least equivalent, if not superior, while allowing a greater flexibility needed when examining more complicated models. (C) 2010 Elsevier B.V. All rights reserved.","Pastorello, S.; Rossi, E.",2010,10.1016/j.csda.2010.02.001,None,wos
a06cc3cac03f41d9,"Elliptical Capital Asset Pricing Models: Formulation, Diagnostics, Case Study with Chilean Data, and Economic Rationale","The capital asset pricing model (CAPM) is often based on the Gaussianity or normality assumption. However, such an assumption is frequently violated in practical situations. In this paper, we introduce the symmetric CAPM considering distributions with lighter or heavier tails than the normal distribution. These distributions are symmetric and belong to the family of elliptical distributions. We pay special attention to the family members related to the normal, power-exponential, and Student-t cases, with the power-exponential distribution being particularly considered, as it has not been explored widely. Based on these cases, the expectation-maximization algorithm can be used to facilitate the estimation of model parameters utilizing the maximum likelihood method. In addition, we derive the leverage and local influence methods to carry out diagnostics in the symmetric CAPM. We conduct a detailed case study to apply the obtained results estimating the systematic risk of the financial assets of a Chilean company with real data. We employ the Akaike information criterion to conclude that the studied models provide better results than the CAPM under Gaussianity.","Leal, Danilo; Jiménez, Rodrigo; Riquelme, Marco; Leiva, Víctor; Leiva, Víctor",2023,10.3390/math11061394,None,proquest
fd197540678bf733,"Emerging markets’ resource booms and busts, borrowing risk and regime change","Resource booms create real sector and credit expansion in resource-rich countries; however it can also give rise to over-borrowing. If a resource bust hits, the affected economies contract through declining export revenues, and possibly face increased default risk. Thus, both booms and busts can create macroeconomic instability. Using a dynamic growth model, we model regime changes which reveal nonlinear effects of debt on the economy, depending on the level of leveraging. We find a change from stable to unstable dynamics if the external debt to capital ratio rises above a certain threshold. Risk premia are introduced highlighting the state-dependent borrowing costs for the dynamic paths. We study excess debt and over-leveraging as deviations from sustainable ratios. We find country-specific risk premia that are likely associated with booms and busts for the given debt assessment. Our empirical estimates suggest that certain oil-exporting countries are at a heightened risk for debt crises. © 2017 Elsevier B.V., All rights reserved.","Nyambuu, U.; Semmler, W.",2017,10.1016/j.strueco.2017.02.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014406799&doi=10.1016%2Fj.strueco.2017.02.001&partnerID=40&md5=93c2c5125aae33db8872245de3e2f76d,scopus
d4797281fa14540f,Empirical Asset Pricing via Machine Learning,"We perform a comparative analysis of machine learning methods for the canonical problem of empirical asset pricing: measuring asset risk premiums. We demonstrate large economic gains to investors using machine learning forecasts, in some cases doubling the performance of leading regression-based strategies from the literature. We identify the best-performing methods (trees and neural networks) and trace their predictive gains to allowing nonlinear predictor interactions missed by other methods. All methods agree on the same set of dominant predictive signals, a set that includes variations on momentum, liquidity, and volatility.Authors have furnished an Internet Appendix, which is available on the Oxford University Press Web site next to the link to the final published paper online.","Gu, Shihao; Kelly, Bryan; Xiu, Dacheng",2020,10.1093/rfs/hhaa009,None,proquest
e504e29bd4408ea9,Empirical asset pricing with nonlinear risk premia,"We introduce a new model for the joint dynamics of the S&P 100 index and the VXO implied volatility index. The nonlinear specification of the variance process is designed to simultaneously accommodate extreme persistence and strong mean reversion. This grants superior forecasting power over the standard (linear) specifications for implied variance forecasting.We obtain statistically significant predictions in an out-of-sample exercise spanning several market crashes starting 1986 and including the recent subprime crisis. The model specification is possible through a simple continuous-time no-arbitrage asset pricing framework that combines semi-analytic pricing with a nonlinear specification for the market price of risk. © The Author, 2013. Published by Oxford University Press. All rights reserved. © 2014 Elsevier B.V., All rights reserved.","Mijatović, A.; Schneider, P.",2014,10.1093/jjfinec/nbt018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902659724&doi=10.1093%2Fjjfinec%2Fnbt018&partnerID=40&md5=1106d2afa715a821243ef162a47eabd7,scopus
f010f2916ddce7c3,Empirical causal analysis of flood risk factors on U.S. flood insurance payouts:Implications for solvency and risk reduction,"This paper presents a regression model that quantifies the causal relationship between flood risk factors and the flood insurance payout in the U.S. The flood risk factors that have been considered in this research are flood exposure, infrastructure vulnerability, social vulnerability, and the number of mobile homes. Historical data for the annual flood insurance payout, flood risk factors, and other control variables were collected for six years between 2016 and 2021 and used in a Mixed Effects Regression model to derive the empirical relationships. The regression model expressed the natural logarithm of the annual flood insurance payout in a county based on the flood risk factors and control variables. The paper presents the regression coefficients that quantify the causal influence. It has been found that all four flood risk factors have statistically significant positive influence on the flood insurance payout in a county. However, the extent of the influence is different for different flood risk factors. Among them, flood exposure has the highest influence on the flood insurance payout, which is followed by the number of mobile homes, infrastructure vulnerability, and social vulnerability. Since the federal flood insurance program in the U.S. has a large debt to the U.S. treasury, the government should plan for effective risk reduction that can reduce the flood insurance payout in future to keep the program solvent. The outcomes of this research are expected to facilitate that decision-making process by providing the empirical relationship between flood risk factors and flood insurance payout. © 2024 Elsevier B.V., All rights reserved.","Bhattacharyya, A.; Hastak, M.",2024,10.1016/j.jenvman.2024.120075,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182725293&doi=10.1016%2Fj.jenvman.2024.120075&partnerID=40&md5=b9178af6b532ea7a3bb7c2201e439a3b,scopus
03ea7ad65ff3f52e,Empirical evaluation of the market price of risk using the CIR model,"We describe a simple but effective method for the estimation of the market price of risk. The basic idea is to compare the results obtained by following two different approaches in the application of the Cox-Ingersoll-Ross (CIR) model. In the first case, we apply the non-linear least squares method to cross sectional data (i.e., all rates of a single day). In the second case, we consider the short rate obtained by means of the first procedure as a proxy or the real market short rate. Starting from this new proxy, we evaluate the parameters of the CIR model by means of martingale estimation techniques. The estimate of the market price of risk is provided by comparing results obtained with these two techniques, since this approach makes possible to isolate the market price of risk and evaluate, under the Local Expectations Hypothesis, the risk premium given by the market for different maturities. As a test case, we apply the method to data of the European Fixed Income Market. (c) 2006 Elsevier B.V. All rights reserved.","Bernaschi, M.; Torosantucci, L.; Uboldi, A.",2007,10.1016/j.physa.2006.10.072,None,wos
de032d8bca7f4579,Empirical evidence on the Euler equation for consumption in the US,"Recently developed econometric methods, that are robust to weak instruments and exploit information in possible structural changes, are applied to study the Euler equation for consumption using aggregate US post-war data. Several extensions to the baseline Euler equation model are investigated. The results are insensitive to using linear versus nonlinear specifications, different instruments or different consumption data, but they are very sensitive to asset returns. With risk-free returns, the elasticity of intertemporal substitution is tightly estimated around zero, while with stock market returns, it is significantly positive but very imprecisely estimated. There is no evidence of parameter instability. © 2021 Elsevier B.V., All rights reserved.","Ascari, G.; Magnusson, L.M.; Mavroeidis, S.",2021,10.1016/j.jmoneco.2019.12.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076864764&doi=10.1016%2Fj.jmoneco.2019.12.004&partnerID=40&md5=977ffefb7cfe3b8791af31afbd50e27f,scopus
d434a775f2150cee,Empirical reverse engineering of the pricing kernel,"This paper proposes an econometric procedure that allows the estimation of the pricing kernel without either any assumptions about the investors preferences or the use of the consumption data. We propose a model of equity price dynamics that allows for (i) simultaneous consideration of multiple stock prices, (ii) analytical formulas for derivatives such as futures, options and bonds, and (iii) a realistic description of all of these assets. The analytical specification of the model allows us to infer the dynamics of the pricing kernel. The model, calibrated to a comprehensive dataset including the S&P 500 index, individual equities, T-bills and gold futures, yields the conditional filter of the unobservable pricing kernel. As a result we obtain the estimate of the kernel that is positive almost surely (i.e. precludes arbitrage), consistent with the equity risk premium, the risk-free discounting, and with the observed asset prices by construction. The pricing kernel estimate involves a highly nonlinear function of the contemporaneous and lagged returns on the S&P 500 index. This contradicts typical implementations of CAPM that use a linear function of the market proxy return as the pricing kernel. Hence, the S&P 500 index does not have to coincide with the market portfolio if it is used in conjunction with nonlinear asset pricing models. We also find that our best estimate of the pricing kernel is not consistent with the standard time-separable utilities, but potentially could be cast into the stochastic habit formation framework of Campbell and Cochrane (J. Political Economy 107 (1999) 205). © 2003 Elsevier B.V. All rights reserved. © 2008 Elsevier B.V., All rights reserved.","Chernov, M.",2003,10.1016/s0304-4076(03)00111-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0346937478&doi=10.1016%2FS0304-4076%2803%2900111-8&partnerID=40&md5=887c4b2dc8caa87597889e2ab5275885,scopus
9d3cef205fa28fe7,End-to-end transport network digital twins with cloud-native SDN controllers and generative AI [Invited],"This paper explores the potential of network digital twins (NDTs) in networking (both IP Ethernet networks and optical transport networks), highlighting their integration with cloud-native software-defined networking (SDN) controllers and intent-based networking enabled by generative artificial intelligence (GenAI). The proposed framework represents an approach that combines advanced virtualization, real-time analytics, and GenAI. The use of NDTs enables a comprehensive and dynamic digital representation of the physical network, capturing critical aspects, such as topology, traffic patterns, and performance metrics, which permits data-driven decision-making to lead to more efficient networking operations. The incorporation of cloud-native SDN controllers along with an NDT ensures that the system remains scalable, flexible, and responsive to dynamic network conditions. Intent-based networking, powered by GenAI, allows the network to interpret high-level objectives from operators and autonomously translate them into actionable configurations that are enforced by orchestrators and SDN controllers. This eliminates manual intervention, minimizes errors, accelerates the deployment of network services, and provides a means for easier network management. The presented framework significantly enhances automation, enabling predictive maintenance by identifying potential issues before they impact network performance. It optimizes network design by simulating various configurations and testing their feasibility in a risk-free environment. These capabilities collectively improve operational efficiency, reduce downtime, and ensure optimal resource utilization.",A. Abishek; D. Adanza; P. Alemany; L. Gifre; R. Casellas; R. Martinez; R. Munoz; R. Vilalta,2025,10.1364/jocn.550864,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10974926,ieeexplore
c7ed342d298e889b,Endogenous inattention and risk-specific price underreaction in corporate bonds,"Corporate bond prices are slow to respond to default risk and interest rate shocks, as proxied by firm-level stock returns and Treasury returns, respectively. Furthermore, the underreaction is risk-specific: bonds with better credit quality underreact more to default risk, while those with worse quality underreact more to interest rates. The underreactions imply substantial out-of-sample return predictability, and investors appear to be leaving too much money on the table. The results are consistent with behavioral inattention models in which investors endogenously allocate more attention to payoff-relevant (or salient) risks, and they are not explained by traditional trading friction mechanisms. © 2022 Elsevier B.V., All rights reserved.","Li, J.",2022,10.1016/j.jfineco.2021.09.025,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117362116&doi=10.1016%2Fj.jfineco.2021.09.025&partnerID=40&md5=c050948826a3bbc8282b4b542ccd0387,scopus
36465bfe50fa4423,Engineering viable foot-and-mouth disease viruses with increased thermostability as a step in the development of improved vaccines,"We have rationally engineered foot-and-mouth disease virus to increase its stability against thermal dissociation into subunits without disrupting the many biological functions needed for its infectivity. Amino acid side chains located near the capsid intersubunit interfaces and either predicted or found to be dispensable for infectivity were replaced by others that could establish new disulfide bonds or electrostatic interactions between subunits. Two engineered viruses were normally infectious, genetically stable, and antigenically indistinguishable from the natural virus but showed substantially increased stability against irreversible dissociation. Electrostatic interactions mediated this stabilizing effect. For foot-and-mouth disease virus and other viruses, some evidence had suggested that an increase in virion stability could be linked to an impairment of infectivity. The results of the present study show, in fact, that virion thermostability against dissociation into subunits may not be selectively constrained by functional requirements for infectivity. The thermostable viruses obtained, and others similarly engineered, could be used for the production, using current procedures, of foot-and-mouth disease vaccines that are less dependent on a faultless cold chain. In addition, introduction of those stabilizing mutations in empty (nucleic acid-free) capsids could facilitate the production of infection-risk-free vaccines against the disease, one of the economically most important animal diseases worldwide. Copyright © 2008, American Society for Microbiology. All Rights Reserved. © 2009 Elsevier B.V., All rights reserved.; MEDLINE® is the source for the MeSH terms of this document.","Mateo, R.; Luna, E.; Rincón, V.; Mateu, M.G.",2008,10.1128/jvi.01553-08,https://www.scopus.com/inward/record.uri?eid=2-s2.0-57349125715&doi=10.1128%2FJVI.01553-08&partnerID=40&md5=312eebb857432143e3d20a48dc5ffa60,scopus
8132ab240b3a2bd6,Enhancing Customer Service Efficiency: Automating Responses to Customer Queries using Natural Language Processing and Radial Basis Function Neural Network (RBFNN),"The insurance sector is progressively embracing Artificial Intelligence (AI) and Natural Language Processing (NLP) to enhance customer service and streamline operations. This research offers a comprehensive framework that seamlessly integrates a chatbot system, empowered by advanced natural language processing techniques, with a Radial Basis Function Neural Network (RBFNN). In this approach, a chatbot serves as the primary user interface, facilitating easy and efficient communication regarding insurance policies and claims. Natural language processing algorithms are employed to interpret user queries, extract vital information, and generate structured responses. However, the key innovation lies in the application of the RBFNN, which is adapted to model and predict various aspects of insurance documents, including policy terms, premium calculations, and claim procedures. The RBFNN's ability to capture intricate data patterns significantly enhances the accuracy and efficiency of document generation. The combined approach accelerates document creation, reduces errors, and enhances the overall customer experience in the insurance domain. The performance of the proposed technique is evaluated in the Python platform and compared with existing approaches. Empirical results and comparisons with traditional methods illustrate the advantages in terms of accuracy and efficiency. The RBFNN achieved an average accuracyof99% across the five folds. This means that the RBFNN was able to correctly generate insurance documents for 99% of the customers in the test set, on average. © 2024 Elsevier B.V., All rights reserved.","Kolambe, S.A.; Kaur, P.",2024,10.62441/nano-ntp.v20is6.64,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203091771&doi=10.62441%2Fnano-ntp.v20iS6.64&partnerID=40&md5=7bed1d5ec424827f558477f89ed58e15,scopus
d1f11092e4cf4435,Enhancing stock timing predictions based on multimodal architecture: Leveraging large language models (LLMs) for text quality improvement,"This study aims to enhance stock timing predictions by leveraging large language models (LLMs), specifically GPT-4, to filter and analyze online investor comment data. Recognizing challenges such as variable comment quality, redundancy, and authenticity issues, we propose a multimodal architecture that integrates filtered comment data with stock price dynamics and technical indicators. Using data from nine Chinese banks, we compare four filtering models and demonstrate that employing GPT-4 significantly improves financial metrics like profit-loss ratio, win rate, and excess return rate. The multimodal architecture outperforms baseline models by effectively preprocessing comment data and combining it with quantitative financial data. While focused on Chinese banks, the approach can be adapted to broader markets by modifying the prompts of large language models. Our findings highlight the potential of LLMs in financial forecasting and provide more reliable decision support for investors. © 2025 Elsevier B.V., All rights reserved.","Chen, M.; Tang, Y.; Qi, Q.; Dai, H.; Lin, Y.; Ling, C.; Li, T.",2025,10.1371/journal.pone.0326034,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008471640&doi=10.1371%2Fjournal.pone.0326034&partnerID=40&md5=98a5d95e4c7ae2a55e9367ab9130232b,scopus
02d7fb5a3d6611e6,Equilibrium forward curves for commodities,"We develop an equilibrium model of the term structure of forward prices for storable commodities. As a consequence of a nonnegativity constraint on inventory, the spot commodity has an embedded timing option that is absent in forward contracts. This option's value changes over time due to both endogenous inventory and exogenous transitory shocks to supply and demand. Our model makes predictions about Volatilities of forward prices at different horizons and shows how conditional violations of the Samuelson effect occur. We extend the model to incorporate a permanent second factor and calibrate the model to crude oil futures data.","Routledge, BR; Seppi, DJ; Spatt, CS",2000,10.1111/0022-1082.00248,None,wos
e533d86ac723242f,Equilibrium modeling of asset prices: Rationality versus rules of thumb,"General equilibrium models with representative agents have proved to be inadequate descriptions of U.S. financial data. I present a model with heterogeneous agents, optimizers, and nonoptimizers that exhibits high stock-price volatility and mimics empirical regularities found in U.S. consumption, stock return, and three-month treasury-bill return data. The simulation and estimation of the model are performed using a new technique called “backsolving,” which is of independent interest to researchers attempting to solve nonlinear, stochastic models. © 1990 American Statistical Association. © 2016 Elsevier B.V., All rights reserved.","Ingram, B.F.",1990,10.1080/07350015.1990.10509781,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910958135&doi=10.1080%2F07350015.1990.10509781&partnerID=40&md5=c2de1a714026f6f119f9fc2871c0c81a,scopus
440aa6efc3a8c2bf,Equity Return Dispersion and Stock Market Volatility: Evidence from Multivariate Linear and Nonlinear Causality Tests,"We employ bivariate and multivariate nonlinear causality tests to document causality from equity return dispersion to stock market volatility and excess returns, even after controlling for the state of the economy. Expansionary (contractionary) market states are associated with a low (high) level of equity return dispersion, indicating asymmetries in the relationship between return dispersion and economic conditions. Our findings indicate that both return dispersion and business conditions are valid joint forecasters of stock market volatility and excess returns and that return dispersion possesses incremental information regarding future stock return dynamics beyond that which can be explained by the state of the economy.","Demirer, Riza; Gupta, Rangan; Lv, Zhihui; Wing-Keung Wong",2019,10.3390/su11020351,None,proquest
f3a9a0a79144a932,"Equity market valuation, systematic risk and monetary policy","This study examines the relationship between equity market valuation and risk indicators that portend economic downswings. The indicators are implied options volatility, Treasury-Eurodollar (TED) spread and exchange rate. While implied volatility captures market risk in that it reflects the fear factor embedded in the price of an option, TED spread reflects the default risk premium that is priced into a key short-term credit instrument. Equity markets often show a tendency to reflect the incidence of these risk factors. And because they provide valuable information about the health of the economy, many have argued that equity market valuation be taken into account in the formulation of monetary policy. Results of this study not only show a statistically significant inverse relationship between the stock market and these risk factors, but also evidence of a cointegration. In a variance decomposition of the series, we find that equity valuation is a major contributor to the forecast error variances of each of the risk indicators, a finding that lends tacit support to the argument that risk indicators associated with the equity market be considered in monetary policy decisions.","Obi, Pat; Dubihlela, Job; Choi, Jeong-Gil",2012,10.1080/00036846.2011.579065,None,wos
b0057b5ec8318381,Equity returns of financial institutions and the pricing of interest rate risk,"This study investigates the issue of whether financial intermediaries' common stock returns incorporate a risk premium for their inherent exposure to unexpected changes in interest rates. A wide range of financial institutions is employed to test the hypothesis that the interest rate risk is priced by capital markets. In addition, the above sample is extended by incorporating firms from the non-financial sector. A two-factor model with the market portfolio and the changes in market yields, as exogenously specified risk variables, is employed. The model is estimated via a seemingly unrelated regression estimation (SURE) framework with both cross-equation restrictions and within equation nonlinear constraints on the parameters. The findings indicate that financial institutions' equity returns incorporate a risk premium for their exposure to market yields' surprises. The return generating function of the insurance business could be further explained by an additional factor such as currency movements. It is also empirically supported that the market premium drops out from the estimation process. When commercial and industrial firms are included in the estimation process, the findings unveil a reduction in the magnitude of the interest rate risk premium. © 2005 Taylor & Francis Group Ltd. © 2008 Elsevier B.V., All rights reserved.","Staikouras, S.K.",2005,10.1080/09603100500039557,https://www.scopus.com/inward/record.uri?eid=2-s2.0-17744384695&doi=10.1080%2F09603100500039557&partnerID=40&md5=081d75e8784219025c52e20bc5c362a1,scopus
b186ed887412ad85,"Equity risk premiums (ERP): Determinants, estimation and implications - A post-crisis update","The risk premium is a fundamental and critical component in portfolio management, corporate finance and valuation. Given its importance, it is surprising that more attention has not been paid in practical terms to estimation issues. In this paper, we began by looking at the determinants of equity risk premiums including macro economic volatility, investor risk aversion and behavioral components. We then looked at the three basic approaches used to estimate equity risk premiums - the survey approach, where investors or managers are asked to provide estimates of the equity risk premium for the future, the historical return approach, where the premium is based upon how well equities have done in the past and the implied approach, where we use future cash flows or observed bond default spreads to estimate the current equity risk premium. The premiums we estimate can vary widely across approaches, and we considered two questions towards the end of the paper. The first is why the numbers vary across approaches and the second is how to choose the right number to use in analysis. For the latter question, we argued that the choice of a premium will depend upon the forecast period, whether your believe markets are efficient and whether you are required to be market neutral in your analysis. © 2009 New York University Salomon Center and Wiley Periodicals, Inc. © 2012 Elsevier B.V., All rights reserved.","Damodaran, A.",2009,10.1111/j.1468-0416.2009.00151.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-72149127876&doi=10.1111%2Fj.1468-0416.2009.00151.x&partnerID=40&md5=c449d6a2cfde5f6af31db937ef4a7b0b,scopus
f74524ca4a843b41,Equity/bond yield correlation and the FED model: evidence of switching behaviour from the G7 markets,"This paper considers how the strength and nature of the relation between the equity and bond yield varies with the level of the real bond yield. We demonstrate that at low levels of the real bond yield, the correlation between the equity and bond yields turns negative. This arises as the lower bond yield implies heightened macroeconomic risk (e.g. deflation and economic stagnation) and causes equity and bond prices to move in opposite directions. The FED model relies on a positive relation for its success in predicting future returns. Thus, we argue that the mixed empirical evidence regarding the FED model arises due to this switch in correlation behaviour. We present supportive evidence for the switching relation and its link to the level of the bond yield using linear and nonlinear smooth transition panel regression techniques for the G7 markets. The results presented here should be of interest to market practitioners who may wish to use the FED model to aid market timing decisions and for academics interested in understanding the interrelations between markets. © 2018 Elsevier B.V., All rights reserved.","Humpe, A.; McMillan, D.G.",2018,10.1057/s41260-018-0091-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052958299&doi=10.1057%2Fs41260-018-0091-x&partnerID=40&md5=da878cf9fc2d0e5c1d3d00c3aa2fbdb2,scopus
c621221de8365a99,Estimating Interest Rate Curves by Support Vector Regression,"A model that seeks to estimate an interest rate curve should have two desirable capabilities in addition to the usual characteristics required from any function-estimation model: it should incorporate the bid-ask spreads of the securities from which the curve is extracted and restrict the curve shape. The goal of this article is to estimate interest rate curves by using Support Vector Regression (SVR), a method derived from the Statistical Learning Theory developed by Vapnik (1995). The motivation is that SVR features these extra capabilities at a low estimation cost. The SVR is specified by a loss function, a kernel function and a smoothing parameter. SVR models the daily U.S. dollar interest rate swap curves, from 1997 to 2001. As expected from a priori and sensibility analyses, the SVR equipped with the kernel generating a spline with an infinite number of nodes was the best performing SVR. Comparing this SVR with other models, it achieved the best cross-validation interpolation performance in controlling the bias-variance trade-off and generating the lowest error considering the desired accuracy fixed by the bid-ask spreads.","Monteiro, Andre d'Almeida",2010,10.1080/07474938.2010.481998,None,wos
2792a90443961f45,Estimating Latent Factors Based on Statistical Data Analysis,"In recent years, statistical methods have been widely used to estimate latent risk factors that affect the prices of financial assets. This paper develops new estimators for asset pricing factors by introducing dependence measure--distance covariance, that can identify nonlinear dependence. We combined distance covariance with Principal Component Analysis (PCA) and Risk-Premium PCA (RPPCA) and made contrast analysis based on Chinese market data. RPPCA, as a new method, shows strong applicability and detects factors with high Sharpe-ratio efficiently. Moreover, distance covariance produces better performance than covariance in PCA as a factor estimator, which illustrates the superiority of the distance covariance. Finally, the most striking results revealed by the study is that RPPCA including distance covariance of residuals outperforms others with a smaller pricing error and a significantly large Sharpe-ratio.","Xu, Guoqing; Yang, Guoxiao",2021,10.1088/1742-6596/1995/1/012065,None,proquest
85e46487d751331e,Estimating and testing non-affine option pricing models with a large unbalanced panel of options,"In this paper, we considerjoint estimation of objective and risk-neutral parameters for stochastic volatility option pricing models using both stock and option prices. A common strategy simplifies the task by limiting the analysis to just one option per date. We first discuss its drawbacks on the basis of model interpretation, estimation results and pricing exercises. We then turn the attention to a more flexible approach, that successfully exploits the wealth of information contained in large heterogeneous panels of options, and we apply it to actual S&P 500 index and index call options data. Our approach breaks the stochastic singularity between contemporaneous option prices by assuming that every observation is affected by measurement error, essentially recasting the problem as a non-linear filtering one. The resulting likelihood function is evaluated using a Monte Carlo Importance Sampling (MC-IS) strategy, combined with a Particle Filter algorithm. The results provide useful intuitions on the directions that should be followed to extend the model, in particular by allowing jumps or regime switching in the volatility process.","Ferriani, Fabrizio; Pastorello, Sergio",2012,10.1111/j.1368-423x.2012.00372.x,None,wos
8407ab83849bf0fa,Estimating dynamic equilibrium models using mixed frequency macro and financial data,"We provide a framework for inference in dynamic equilibrium models including financial market data at daily frequency, along with macro series at standard lower frequency. Our formulation of the macro finance model in continuous time conveniently accounts for the difference in observation frequency. We suggest the use of martingale estimating functions (MEF) to infer the structural parameters of the model directly through a nonlinear scheme. This method is compared to regression-based methods and the generalized method of moments (GMM). We illustrate our approaches by estimating various versions of the AK-Vasicek model with mean-reverting interest rates. We provide asymptotic theory and Monte Carlo evidence on the small sample behavior of the estimators and report empirical estimates using 30 years of US macro and financial data. (C) 2016 Elsevier B.V. All rights reserved.","Christensen, Bent Jesper; Posch, Olaf; van der Wel, Michel",2016,10.1016/j.jeconom.2016.04.005,None,wos
904282cbb11b87c7,Estimating global bank network connectedness,"We use LASSO methods to shrink, select, and estimate the high‐dimensional network linking the publicly traded subset of the world's top 150 banks, 2003–2014. We characterize static network connectedness using full‐sample estimation and dynamic network connectedness using rolling‐window estimation. Statically, we find that global bank equity connectedness has a strong geographic component, whereas country sovereign bond connectedness does not. Dynamically, we find that equity connectedness increases during crises, with clear peaks during the Great Financial Crisis and each wave of the subsequent European Debt Crisis, and with movements coming mostly from changes in cross‐country as opposed to within‐country bank linkages.","Demirer, Mert; Diebold, Francis X; Liu, Laura; Yilmaz, Kamil",2018,10.1002/jae.2585,None,proquest
a1c75d18c64e29d7,Estimating latent asset-pricing factors,"We develop an estimator for latent factors in a large-dimensional panel of financial data that can explain expected excess returns. Statistical factor analysis based on Principal Component Analysis (PCA) has problems identifying factors with a small variance that are important for asset pricing. We generalize PCA with a penalty term accounting for the pricing error in expected returns. Our estimator searches for factors that can explain both the expected return and covariance structure. We derive the statistical properties of the new estimator and show that our estimator can find asset-pricing factors, which cannot be detected with PCA, even if a large amount of data is available. Applying the approach to portfolio data we find factors with Sharpe-ratios more than twice as large as those based on conventional PCA and with smaller pricing errors.","Lettau, Martin; Pelger, Markus",2020,10.1016/j.jeconom.2019.08.012,None,proquest
cade2431f60ef1f8,Estimating market liquidity from daily data: Marrying microstructure models and machine learning,"We apply machine learning to estimate daily measures of market liquidity by combining microstructure models with low-frequency daily data only, in stock markets in the United States and China. Boosting trees and neural networks significantly improve the performance across different liquidity measures. Our machine learning models are interpretable and improvements are due to (a) more information from raw data that microstructure models do not capture; and (b) better use of information from learned nonlinear and non-monotonic relationships. We further demonstrate two applications of our trained machine learning models in estimating the illiquidity risk premium and systematic liquidity risk. © 2025 Elsevier B.V., All rights reserved.","Dai, Y.; Shi, C.; Zhang, R.",2025,10.1016/j.finmar.2025.101019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017326098&doi=10.1016%2Fj.finmar.2025.101019&partnerID=40&md5=3e7a6b83920c50e3f9a006efbbac3e9e,scopus
cecb8e178cdb3ad6,Estimating stochastic discount factor models with hidden regimes: Applications to commodity pricing,"We develop new likelihood-based methods to estimate factor-based Stochastic Discount Factors (SDF) that may accommodate Hidden Markov dynamics in the factor loadings. We use these methods to investigate whether it is possible to find a SDF that jointly prices the cross-section of eight U.S. portfolios of stocks, Treasuries, corporate bonds, and commodities. In particular, we test a range of possible different specification of the SDF, including single-state and Hidden Markov models and compare their statistical and pricing performances. In addition, we assess whether and to which extent a selection of these models replicates the observed moments of the return series, and especially correlations. We report that regime-switching models clearly outperform single-state ones both in term of statistical and pricing accuracy. However, while a four-state model is selected by the information criteria, a two-state three-factor full Vector Autoregression model outperforms the others as far as the pricing accuracy is concerned. © 2017 Elsevier B.V., All rights reserved.","Giampietro, M.; Guidolin, M.; Pedio, M.",2018,10.1016/j.ejor.2017.07.045,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029533759&doi=10.1016%2Fj.ejor.2017.07.045&partnerID=40&md5=290458cda6fa18cfc85c520063b195a2,scopus
49367fe67a852c41,Estimating the Equity Premium,"Existing empirical research investigating the size of the equity premium has largely consisted of a series of innovations around a common theme: producing a better estimate of the equity premium by using better data or a better estimation technique. The equity premium estimate that emerges from most of this work matches one moment of the data alone: the mean difference between an estimate of the return to holding equity and a risk-free rate. We instead match multiple moments of U.S. market data, exploiting the joint distribution of the dividend yield, return volatility, and realized excess returns, and find that the equity premium lies within 50 basis points of 3.5%, a range much narrower than was achieved in previous studies. Additionally, statistical tests based on the joint distribution of these moments reveal that only those models of the conditional equity premium that embed time variation, breaks, and/or trends are supported by the data. In order to develop the joint distribution of the dividend yield, return volatility, and excess returns, we need a model of price and return fundamentals. We document that even recently developed analytically tractable models that permit autocorrelated dividend growth rates and discount rates impose restrictions that are rejected by the data. We therefore turn to a wider range of models, requiring numerical solution methods and parameter estimation by the simulated method of moments.","Donaldson, R. Glen; Kamstra, Mark J.; Kramer, Lisa A.",2010,10.1017/s0022109010000347,None,wos
00660d636f49d59e,Estimating the Term Structure with Linear Regressions: Getting to the Roots of the Problem,"Linear estimators of the affine term structure model are inconsistent since they cannot reproduce the factors used in estimation. This is a serious handicap empirically, giving a worse fit than the conventional ML estimator that ensures consistency. We show that a simple self-consistent estimator can be constructed using the eigenvalue decomposition of a regression estimator. The remaining parameters of the model follow analytically. Estimates from this model are virtually indistinguishable from that of the ML estimator. We apply the method to estimate various models of U.S. Treasury yields. These exercises greatly extend the range of models that can be estimated. © 2021 Elsevier B.V., All rights reserved.","Goliǹski, A.; Spencer, P.",2021,10.1093/jjfinec/nbz031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099520801&doi=10.1093%2Fjjfinec%2Fnbz031&partnerID=40&md5=fefd9e28937e02b26df6e38c509d65ee,scopus
67ffed0d0ca4ce92,Estimating the risk-return profile of new venture investments using a risk-neutral framework and 'thick' models,"This study proposes cascade neural networks to estimate the model parameters of the Cox-Ross-Rubinstein risk-neutral approach, which, in turn, explain the risk-return profile of firms at venture capital and initial public offering (IPO)financing rounds. Combining the two methods provides better estimation accuracy than risk-adjusted valuation approaches, conventional neural networks, and linear benchmark models. The findings are persistent across in-sample and out-of-sample tests using 3926 venture capital and 1360 US IPO financing rounds between January 1989 and December 2008. More accurate estimates of the risk-return profile are due to less heterogeneous risk-free rates of return from the risk-neutral framework. Cascade neural networks nest both the linear and nonlinear functional estimation form in addition to taking account of variable interaction effects. Better estimation accuracy of the risk-return profile is desirable for investors so they can make a more informed judgement before committing capital at different stages of development and various financing rounds. Reprinted by permission of Routledge, Taylor and Francis Ltd.","Reber, Beat",2014,10.1080/1351847x.2012.708471,None,proquest
817d1aea113ecade,Estimating the spot rate curve using the Nelson-Siegel model. A ridge regression approach,"The Nelson-Siegel model is widely used in practice for fitting the term structure of interest rates. Due to the ease in linearizing the model, a grid search or an OLS approach using a fixed shape parameter are popular estimation procedures. The estimated grid search parameters, however, have been reported (1) to behave erratically over time, and (2) to have relatively large variances. On the other hand, parameter estimates based on a fixed shape parameter, while avoiding multicollinearity, turn out to be too smooth. We show that the Nelson-Siegel model can become heavily collinear depending on the estimated/fixed shape parameter. A simple procedure based on ridge regression can remedy the reported problems significantly. © 2013 Elsevier Inc. © 2013 Elsevier B.V., All rights reserved.","Annaert, J.; Claes, A.G.P.; Ceuster, M.J.K.; Zhang, H.",2013,10.1016/j.iref.2013.01.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876326729&doi=10.1016%2Fj.iref.2013.01.005&partnerID=40&md5=4bbf46f64bd8757be4fa5c077b100dfb,scopus
786cba4cf35e5a45,Estimating time-varying risk premia in UK long-term government bonds,"Simple models of time-varying risk premia are used to measure the risk premia in long-term UK government bonds. The parameters of the models can be estimated using nonlinear seemingly unrelated regression (NL-SUR), which permits efficient use of information across the entire yield curve and facilitates the testing of various cross-sectional restrictions. The estimated time-varying premia are found to be substantially different to those estimated using models that assume constant risk premia. © 2004 Taylor and Francis Ltd. © 2008 Elsevier B.V., All rights reserved.","Steeley, J.M.",2004,10.1080/0960310042000211632,https://www.scopus.com/inward/record.uri?eid=2-s2.0-1542639767&doi=10.1080%2F0960310042000211632&partnerID=40&md5=19ff6b7366f9cad45ca9caab1717eb0d,scopus
fa6fbbea2ecc0680,Estimating volatility from ATM options with lognormal stochastic variance and long memory,"In this article we propose a nonlinear state space representation to model At-The-Money (ATM) implied volatilities and to estimate the unobserved Stochastic Volatility (SVOL) for the underlying asset. We derive a polynomial measurement model relating fractionally cointegrated implied and spot volatilities. We then use our state space representation to obtain Maximum Likelihood (ML) estimates of the short-memory model parameters, and for filtering the fractional spot volatility. We are also able to estimate the average volatility risk premia. We applied our methodology to implied volatilities on eurodollar options, from which we filter the unobserved spot local variance. These data arise from Over The Counter (OTC) transactions that account for high liquidity. For these data, we estimated a positive average volatility risk premia, which is consistent with the Intertemporal Capital Asset Pricing Model (ICAPM) setup of Merton (1973). We also had evidence of highly nonlinear relation between eurodollar spot and implied volatilities. From a methodological and computational point of view, the likelihood function, and all the iterative procedures associated with it, converged uniformly in the parameter space at very little computational expense. We illustrated the effectiveness of our approach by evaluating the approximated Information matrix, the Hotelling's T2 test along with other diagnostic procedures. Reprinted by permission of Routledge, Taylor and Francis Ltd.","Cardinali, Alessandro",2012,10.1080/09603107.2011.624082,None,proquest
65a824924d8fbb16,Estimating yield curves of the U.S. Treasury securities: An interpolation approach,"Following the approach of interpolation, this paper proposes the multiple exponential decay model to fit yield curves for both the U.S. TIPS market and the conventional Treasury security market. Several estimation methods, including the unconstrained/constrained nonlinear minimization, quadratic programming, and the iterative linear least squares, are applied to estimate the unknown parameters according to different curve-fitting purposes. Comparisons between the proposed model and the alternatives show that the multiple exponential decay successfully (1) adapts to a variety of shapes associated with yield curves, (2) (partially) keeps in line with the economic interpretations of Nelson–Siegel summarized by Diebold and Li (), and (3) dominates the competing models in curve-fitting performance measured by mean fitted-price errors over the sample period. In addition, the exact specification of a nonparametric interpolation model is pinned down by applying three statistical tools, which enable us to jointly take into account validity, optimality, and parsimoniousness of the proposed model. © 2020 Elsevier B.V., All rights reserved.","Guo, F.",2019,10.1002/rfe.1039,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055113189&doi=10.1002%2Frfe.1039&partnerID=40&md5=04461965ab8433b380f1e433878baeda,scopus
cb24c90ea906f755,Estimation and Forecasting of Sovereign Credit Rating Migration Based on Regime Switching Markov Chain,"Our research aims to develop the regime switching Markov chain (RSMC), a discrete time Markov chain whose underlying regime is depending on a hidden Markov model, which express the dynamics of sovereign credit rating migration. Estimated based on a version of the Expectation-Maximization algorithm, the regime in RSMC indicates either economic expansion or contraction. Then, we apply RSMC to the monthly time series of the sovereign credit rating of 41 nations from January 1994 to December 2018. At first, we confirm that the estimation of RSMC is superior to a homogeneous Markov chain. It implies that the credit rating dynamics are subject to the underlying economic condition. Secondly, we observe that the second tier and non-investment credit ratings in economic contractions are likely to be downgraded. We also detect the continental clustering of economic contractions for the Asian currency and European sovereign debt crises. Lastly, we discover that the forecasting performance of RSMC is superior to that of the benchmark, especially for the second tier and non-investment credit ratings. In conclusion, we claim that RSMC can improve the management of sovereign credit risk exposures.","Oh, Sung Youl; Song, Jae Wook; Chang, Woojin; Lee, Minhyuk",2019,10.1109/access.2019.2934516,None,wos
d06548d8a3fc3d66,Estimation and empirical evaluation of the time-dependent Extended-CIR term structure model,"Empirical study of 25 years US Treasury bills data shows that even when the spot interest rate remains fixed, its volatility varies significantly over time. Constant-coefficient models cannot capture these changes as they give rise to time-homogeneous distributions. Maximum likelihood fitting of a one-factor time-dependent Extended-CIR model of the term structure, whose closed-form solution was previously obtained by the author, shows that it can capture these changes, as well as achieve significantly higher likelihood value. It is shown that exploitation of the closed-form solutions substantially improves the accuracy and efficiency of Monte Carlo simulations over high-order discretization algorithms. It is also shown that the feasibility of exact one-to-one calibration of the model to any continuous yield curve allows valuation of bond options significantly more accurately and efficiently.",Y. MAGHSOODI,2000,10.1093/imaman/11.3.161,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8132325,ieeexplore
e3fc14003bf395e3,Estimation of Parameters in Mean-Reverting Stochastic Systems,"Stochastic differential equation (SDE) is a very important mathematical tool to describe complex systems in which noise plays an important role. SDE models have been widely used to study the dynamic properties of various nonlinear systems in biology, engineering, finance, and economics, as well as physical sciences. Since a SDE can generate unlimited numbers of trajectories, it is difficult to estimatemodel parameters based on experimental observationswhichmay represent only one trajectory of the stochastic model. Although substantial research efforts have been made to develop effective methods, it is still a challenge to infer unknown parameters in SDE models from observations that may have large variations. Using an interest rate model as a test problem, in this work we use the Bayesian inference and Markov Chain Monte Carlo method to estimate unknown parameters in SDE models.","Tian, Tianhai; Zhou, Yanli; Wu, Yonghong; Ge, Xiangyu",2014,10.1155/2014/317059,None,wos
204aa7a29bdc5b45,"Estimation of the concurrent radiological dosage to humans due to the transfer of 226Ra, 228Ra, and 40K from soil-to-Malaysian traditional medicinal plants","Medicinal plants have been incorporated into various traditional medicine systems worldwide to reduce disease risk, treat illnesses, and provide medicinal remedies. Today, the pharmaceutical industry uses the most active plant compounds in drug synthesis. Possible high levels of naturally occurring radionuclides in medicinal plants have raised public concern about the consequent radiological impact on the consumption of medicinal plants and herbs. This paper reports the first study of soil-to-plant mobilities of natural radionuclides in native medicinal plants in Malaysia. Representative samples of soils and organically grown traditional medicinal plants from western Malaysia were collected and studied using HPGe gamma-ray spectrometry. Average activity concentrations for 226Ra, 228Ra, and 40K in the soils are respectively 57, 84, and 520 Bq/kg, and the respective values in the medicinal plants are 10, 4, and 498 Bq/kg. The respective transfer factors (TFs) for the medicinal leaves are 0.18, 0.05, and 1.18. The TFs of 40K were higher than others due to higher uptake and its essentiality in plant growth. These findings indicate that plant growth habits greatly influenced the radionuclides' uptake. The radioactivities in soils and their corresponding mobilities are in accordance with literature data. To discard any radiological hazards to human health, the estimated threshold consumption rate is found to be approximately 46 kg/y. Annual effective doses and excess lifetime cancer risk for adult members of the public due to the consumption of medicinal plants are found to be negligible. It is suggested that the use of traditional medicinal plants may provide a risk-free and safe means of maintaining public health. © 2025 Elsevier B.V., All rights reserved.","Shuaibu, H.K.; Mohamed, F.; Khandaker, M.U.; Ismail, A.F.; Osman, H.",2024,10.1016/j.radphyschem.2024.111982,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197039271&doi=10.1016%2Fj.radphyschem.2024.111982&partnerID=40&md5=9e5010be32b9a982b5a0f2752b665351,scopus
aa64a2822074ac0d,Ethical and regulatory challenges in machine learning-based healthcare systems: A review of implementation barriers and future directions,"Machine learning significantly enhances clinical decision-making quality, directly impacting patient care with early diagnosis, personalized treatment, and predictive analytics. Nonetheless, the increasing proliferation of such ML applications in practice raises potential ethical and regulatory obstacles that may prevent their widespread adoption in healthcare. Key issues concern patient data privacy, algorithmic bias, absence of transparency, and ambiguous legal liability. Fortunately, regulations like the General Data Protection Regulation (GDPR), the Health Insurance Portability and Accountability Act (HIPAA), and the FDA AI/ML guidance have raised important ways of addressing things like fairness, explainability, legal compliance, etc.; however, the landscape is far from risk-free. AI liability is another one of the gray areas approaching black, worrying about who is liable for an AI medical error — the developers, the physicians, or the institutions. The study reviews ethical risks and potential opportunities, as well as regulatory frameworks and emerging challenges in AI-driven healthcare. It proposes solutions to reduce bias, improve transparency, and enhance legal accountability. This research addresses these challenges to support the safe, fair, and effective deployment of ML-based systems in clinical practice, guaranteeing that patients can trust, regulators can approve, and healthcare can use them. © 2025 Elsevier B.V., All rights reserved.","Mohammed, S.; Malhotra, N.",2025,10.1016/j.tbench.2025.100215,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007763586&doi=10.1016%2Fj.tbench.2025.100215&partnerID=40&md5=e0577e0306751fa9b17e4ec0fb7e7501,scopus
b07e605b9567222c,European Union Allowance price forecasting with Multidimensional Uncertainties: A TCN-iTransformer Approach for Interval Estimation,"In response to the research demand for forecasting European Union Allowance (EUA) prices, this paper proposes a probabilistic forecasting framework based on a spatiotemporal convolutional neural network. This framework innovatively integrates multidimensional external uncertainty indicators, captures the long-term dependencies of carbon prices through a spatiotemporal convolutional structure, and combines quantile regression with conformal prediction to effectively estimate prediction intervals. Empirical studies demonstrate that the proposed TCN-iTransformer model outperforms existing methods in both point prediction and interval prediction, exhibiting excellent prediction interval coverage probability and normalized average width at different confidence intervals. The Diebold–Mariano (DM) test and ordinary least squares (OLS) regression analysis further validate the predictive advantages of the proposed model. Furthermore, SHAP analysis reveals that the U.S. Treasury yield spread has the most significant impact on EUA price forecasting, while geopolitical risks predominantly exert negative effects. The research findings provide important references for constructing risk mitigation strategies in the European Union carbon emissions market under complex market environments. © 2025 Elsevier B.V., All rights reserved.","Wu, R.; Abedin, M.; Zeng, H.; Lucey, B.",2025,10.1002/for.70024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105016613972&doi=10.1002%2Ffor.70024&partnerID=40&md5=9305158e398c871b8bd5e60c86d2c3c3,scopus
fd910f31509a0f0d,European options in a nonlinear incomplete market model with default,"We study the superhedging prices and the associated superhedging strategies for European options in a nonlinear incomplete market model with default. The underlying market model consists of one risk-free asset and one risky asset, whose price may admit a jump at the default time. The portfolio processes follow nonlinear dynamics with a nonlinear driver f. By using a dynamic programming approach, we first provide a dual formulation of the seller's (superhedging) price for the European option as the supremum, over a suitable set of equivalent probability measures Q ∈ Q, of the fevaluation/expectation under Q of the payoff. We also establish a characterization of the seller's (superhedging) price as the initial value of the minimal supersolution of a constrained backward stochastic differential equation with default. Moreover, we provide some properties of the terminal profit made by the seller, and some results related to replication and no-arbitrage issues. Our results rely on first establishing a nonlinear optional and a nonlinear predictable decomposition for processes which are Ef-strong supermartingales under Q for all Q ∈ Q. © 2020 Elsevier B.V., All rights reserved.","Grigorova, M.; Quenez, M.-C.; Sulem, A.",2020,10.1137/20m1318018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091823497&doi=10.1137%2F20M1318018&partnerID=40&md5=2cdc28d979b26bd118cd3f70ddad0322,scopus
12936628b2b341f7,European spreads at the interest rate lower bound,"This paper analyzes the effect of the interest rate lower bound on long-term sovereign bond spreads in the euro area. We specify a joint shadow rate term structure model for the risk-free, the German, and the Italian sovereign yield curves. In our model, the behavior of long-term spreads becomes strongly nonlinear in the underlying factors when interest rates are close to the lower bound, which occurs in the data since the beginning of 2012. We fit the model via Quasi-Maximum Likelihood and show three consequences of the nonlinear behavior of sovereign spreads: (i) they are asymmetrically distributed, (ii) they are affected by (possibly exogenous) changes in the lower bound, and (iii) they become less informative about sovereign risk than when interest rates are far from the lower bound. Shadow spreads, however, still provide reliable information. (C) 2020 The Author(s). Published by Elsevier B.V.","Coroneo, Laura; Pastorello, Sergio",2020,10.1016/j.jedc.2020.103979,None,wos
2d1d209d11b460c3,Evaluating credit rating prediction by using the KMV model and random forest,"PurposeAn increasing number of investors have begun using financial data to develop optimal investment portfolios; therefore, the public financial data shared in the capital market plays a critical role in credit ratings. These data enable investors to understand the credit levels of debtors from a bank perspective; this facilitates predicting the debtor default rate to efficiently evaluate investment risks. The paper aims to discuss these issues.Design/methodology/approachA credit rating model can be developed to reduce the risk of adverse selection and moral hazard caused by information asymmetry in the loan market. In this study, a random forest (RF) was used to evaluate financial variables and construct credit rating prediction models. Data-mining techniques, including an RF, decision tree, neural networks, and support vector machine, were used to search for suitable credit rating forecasting methods. The distance to default from the KMV model was then incorporated into the credit rating model as a research variable to increase predictive power of various data-mining techniques. In addition, four-level and nine-level classification were set to investigate the accuracy rates of various models.FindingsThe experimental results indicated that applying the RF in the variable feature selection process and developing a forecasting model was the most effective method of predicting credit ratings; the four-level and nine-level feature-selection settings achieved 95.5 and 87.8 percent accuracy rates, respectively, indicating that RF demonstrated outstanding feature selection and forecasting capacity.Research limitations/implicationsThe experimental cases were based on financial data from public companies in North America.Practical implicationsPractical implication of this study indicates the most effective financial variables were dividends common/ordinary, cash dividends, volatility assumption, and risk-free rate assumption.Originality/valueThe RF model can be used to perform feature selection and efficiently filter numerous financial variables to obtain crediting rating information instantly.","Hsu-Che, Wu; Yu-Ting, Wu",2016,10.1108/k-12-2014-0285,None,proquest
7612e5acd7dc712d,Evaluating the 'Fed Model' of Stock Price Valuation: An out-of-sample forecasting perspective,"The ""Fed Model"" postulates a cointegrating relationship between the equity yield on the S&P 500 and the bond yield. We evaluate the Fed Model as a vector error correction forecasting model for stock prices and for bond yields. We compare out-of-sample forecasts of each of these two variables from a univariate model and various versions of the Fed Model including both linear and nonlinear vector error correction models. We find that for stock prices the Fed Model improves on the univariate model for longer-horizon forecasts, and the nonlinear vector error correction model performs even better than its linear version. © 2006 Elsevier Ltd. All rights reserved. © 2008 Elsevier B.V., All rights reserved.","Jansen, D.W.; Wang, Z.",2006,10.1016/s0731-9053(05)20026-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33645856784&doi=10.1016%2FS0731-9053%2805%2920026-9&partnerID=40&md5=6ec05711fd88e6ea0dcf87377d48d09f,scopus
a8cf076865ff9282,Evaluating the combined forecasts of the dynamic factor model and the artificial neural network model using linear and nonlinear combining methods,"The paper evaluates the advantages of combined forecasts from the dynamic factor model (DFM) and the artificial neural networks (ANN). The analysis was based on three financial variables namely the Johannesburg Stock Exchange Return Index, Government Bond Return Index and the Rand/Dollar Exchange Rate in South Africa. The forecasts were based on the out-of-sample period from January 2006 to December 2011. Compared to benchmark autoregressive (AR) models, both the DFM and ANN offer more accurate forecasts with reduced root-mean-square error (RMSE) of around 2–12 % for all variables and over all forecasting horizons. The ANN as a nonlinear combining method outperforms all linear combining methods for all variables and over all forecasting horizons. The results suggest that the ANN combining method can be used as an alternative to linear combining methods to achieve greater forecasting accuracy. The ANN combining method produces out-of-sample forecasts that are substantially more accurate with a sizeable reduction in RMSE of both the AR benchmark model and the best individual forecasting model. We attribute the superiority of the ANN combining method to its ability to capture any existing nonlinear relationship between the individual forecasts and the actual forecasting values. © 2017 Elsevier B.V., All rights reserved.","Babikir, A.; Mwambi, H.",2016,10.1007/s00181-015-1049-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954512445&doi=10.1007%2Fs00181-015-1049-1&partnerID=40&md5=11ab9cf5dd4d813d51fc5ba1afb4d024,scopus
cedfa0a421c3207f,Evaluation of the influence of surface structure on tribological properties of the solid–liquid interface: Analytical and experimental assessment,"Nowadays, multiple strategies have been suggested to improve product efficiency on the basis of risk free techniques. Owing to the vast applications of the structured surface in many industrial sectors, considerable attention has been paid by many scholars to improve the surface performance aspects by studying their solid–liquid interface characterizations. In the current study, a new technique is introduced to manufacture a functional surface with water repellency feature through grinding process. Based on the solid–liquid interface evaluations of the modified surface, by structuring the surface, the contact angle increases from 35° (untreated surface) to 127° for structured surface. Therefore, the reinforced surface showed hydrophobicity with a 263% improvement for a scratch area fraction more than 75%. Formation of air pads trapped in the vacant space of the scratches was the main cause to enhance contact angle for structured surface. Since air molecules have very low inclination to chemical bonding with water molecules, the water droplet did not penetrate the scratches space and contact angle enhanced. A new analytical model for predicting the solid–liquid surface property was simultaneously developed by interaction of the kinematics of the grinding technique with single diamond and the basic wettability theory of the Cassie-Baxter. Therefore, the effect of all input parameters on the output results was studied in terms of achieving the best solid–liquid interaction performance through expanded model. The optimal values were calculated and the proposed structured surface was manufactured during the grinding process. According to the value of the static contact angle measured during experimental tests (127°) and its analytical value (123°), less than 4% error was observed between the results, which showed the high accuracy of the equation expanded on the present work. © 2023 Elsevier B.V., All rights reserved.","Musavi, S.H.; Razfar, M.; Domiri Ganji, D.D.",2023,10.1016/j.molliq.2023.122967,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170069308&doi=10.1016%2Fj.molliq.2023.122967&partnerID=40&md5=f2510f436420d6846dc300fecee68675,scopus
c949481fe9582fec,Event-based approach for probabilistic agricultural drought risk assessment under rainfed conditions,"An event-based approach for the probabilistic risk assessment of agricultural drought under rainfed conditions to estimate the economic impact is proposed. The risk parameters are evaluated in an event-based probabilistic framework for a set of hazard events; these results are probabilistically integrated including, in a formal way, all uncertainties related to every part of the process. The hazard is defined as a stochastic or historic set of events, collectively exhaustive and mutually exclusive, that describes the spatial distribution, the annual frequency, and the randomness of the hazard intensity. The risk is expressed in different economic terms: the average annual loss (or pure risk premium) and the loss exceedance curve; these metrics are of particular importance for risk retention (financing) schemes or risk transfer instruments. As an illustrative example, this approach is applied to probabilistic drought risk assessment of maize under rainfed conditions in Mexico. These results are the base of further studies in defining strategies for financial protection against agricultural losses and disasters.","Quijano, Juan A; Jaimes, Miguel A; Torres, Marco A; Reinoso, Eduardo; Castellanos, Luisarturo; Escamilla, Jesus; Ordaz, Mario",2015,10.1007/s11069-014-1550-4,None,proquest
aef88f4d9148de8f,Evolutionary-based return forecasting with nonlinear STAR models: evidence from the Eurozone peripheral stock markets,"Traditional linear regression and time-series models often fail to produce accurate forecasts due to inherent nonlinearities and structural instabilities, which characterize financial markets and challenge the Efficient Market Hypothesis. Machine learning techniques are becoming widespread tools for return forecasting as they are capable of dealing efficiently with nonlinear modeling. An evolutionary programming approach based on genetic algorithms is introduced in order to estimate and fine-tune the parameters of the STAR-class models, as opposed to conventional techniques. Using a hybrid method we employ trading rules that generate excess returns for the Eurozone southern periphery stock markets, over a long out-of-sample period after the introduction of the Euro common currency. Our results may have important implications for market efficiency and predictability. Investment or trading strategies based on the proposed approach may allow market agents to earn higher returns.","Avdoulas Christos; Bekiros Stelios; Sabri, Boubaker",2018,10.1007/s10479-015-2078-z,None,proquest
ac8f1b6ca53d639a,Evolving Fuzzy-GARCH Approach for Financial Volatility Modeling and Forecasting,"Volatility modeling and forecasting play a key role in asset allocation, risk management, derivatives pricing and policy making. The purpose of this paper is to develop an evolving fuzzy-GARCH modeling approach for stock market asset returns forecasting. The method addresses GARCH volatility modeling within the framwork of evolving fuzzy systems. This hybrid methodology aims to account for time-varying volatility, from GARCH approach, as well as volatility clustering and nonlinear time series identification, from evolving fuzzy systems, which use time-varying data streams to continuously and simultaneously adapt the structure and functionality of fuzzy models. The motivation is to improve model performance as new data is input through gradual model construction, inducing model adaptation and refinement without catastrophic forgetting while keeping current model useful. An empirical application includes the forecasting of S&P 500 and Ibovespa indexes by the evolving fuzzy-GARCH against traditional GARCH-family models and a fuzzy GJR-GARCH methodology. The results indicate the high potential of the evolving fuzzy-GARCH model to forecast stock returns volatility, which outperforms GARCH-type models and showed comparable forecasts with fuzzy GJR-GARCH methodology.","Maciel, Leandro; Gomide, Fernando; Ballini, Rosangela",2016,10.1007/s10614-015-9535-2,None,wos
c11bf27ee96c2868,Evolving fuzzy modelling for yield curve forecasting,"Forecasting the term structure of interest rates plays a crucial role in portfolio management, household finance decisions, business investment planning, and policy formulation. This paper aims to address yield curve forecasting and evolving fuzzy systems modelling using data from US and Brazilian fixed income markets. Evolving fuzzy models provide a high level of system adaptation and learn the system dynamic continuously, which is essential for uncertain environments as interest rate markets. Computational experiments show that the evolving fuzzy modelling approaches describe the interest rate behaviour accurately, outperforming traditional econometric techniques in terms of error measures and statistical tests. Moreover, evolving models provide promising results for short and long-term maturities and for both fixed income markets evaluated, highlighting its potential to forecast complex nonlinear dynamics in uncertain environments. © 2020 Elsevier B.V., All rights reserved.","Maciel, L.; Ballini, R.; Gomide, F.",2018,10.1504/ijebr.2018.091047,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045552146&doi=10.1504%2FIJEBR.2018.091047&partnerID=40&md5=7727d894acc5a836f5878e176fffd734,scopus
b7b9b2e3bc16ed4a,Examination and Modification of Multi-Factor Model in Explaining Stock Excess Return with Hybrid Approach in Empirical Study of Chinese Stock Market,"To search significant variables which can illustrate the abnormal return of stock price, this research is generally based on the Fama-French five-factor model to develop a multi-factor model. We evaluated the existing factors in the empirical study of Chinese stock market and examined for new factors to extend the model by OLS and ridge regression model. With data from 2007 to 2018, the regression analysis was conducted on 1097 stocks separately in the market with computer simulation based on Python. Moreover, we conducted research on factor cyclical pattern via chi-square test and developed a corresponding trading strategy with trend analysis. For the results, we found that except market risk premium, each industry corresponds differently to the rest of six risk factors. The factor cyclical pattern can be used to predict the direction of seven risk factors and a simple moving average approach based on the relationships between risk factors and each industry was conducted in back-test which suggested that SMB (size premium), CMA (investment growth premium), CRMHL (momentum premium), and AMLH (asset turnover premium) can gain positive return.","Liu, Huazhang",2019,10.3390/jrfm12020091,None,proquest
bee113618fd74452,Examining the myths of connected and autonomous vehicles: Analysing the pathway to a driverless mobility paradigm,"Connected and autonomous vehicles (CAVs) could become the most powerful mobility intervention in the history of human race; possibly greater than the conception of the wheel itself or the shift from horse-carriages to automobiles. Despite CAVs' likely traffic safety, economic, environmental, social inclusion and network performance benefits their full-scale implementation may not be as predictable, uncomplicated, acceptable and risk-free as it is often communicated by a large share of automotive industries, policy-makers and transport experts. Framing an 'unproven', 'disruptive' and 'life-changing' intervention, primarily based on its competitive advantages over today's conventional automobile technologies, may create misconceptions, overreaching expectations and room for errors that societies need to be cautious about. This article 'tests' eleven myths referring to an overly optimistic CAVs' development and adoption timeline. This approach highlights unresolved issues that need to be addressed before an inescapable CAV-based mobility paradigm transition takes place and provides relevant policy recommendations on how to achieve that. © 2020 Elsevier B.V., All rights reserved.","Nikitas, A.; Tchouamou Njoya, E.T.; Dani, S.",2019,10.1504/ijatm.2019.098513,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063507634&doi=10.1504%2FIJATM.2019.098513&partnerID=40&md5=7076e763a81cf64f2fa696878081f9af,scopus
73113e90a23f638b,Exchange rate parities and Taylor rule deviations,"This paper investigates the PPP and UIP conditions by taking into account possible nonlinearities as well as the role of Taylor rule deviations under alternative monetary policy frameworks. The analysis is conducted using monthly data from January 1993 to December 2020 for five inflation-targeting countries (the UK, Canada, Australia, New Zealand and Sweden) and three non-targeting ones (the USA, the Euro Area and Switzerland). Both a benchmark linear VECM and a nonlinear Threshold VECM are estimated; the latter includes Taylor rule deviations as the threshold variable. The results can be summarized as follows. First, the nonlinear specification provides much stronger evidence for the PPP and UIP conditions, the estimated adjustment speed towards equilibrium being twice as fast. Second, Taylor rule deviations play an important role: the adjustment speed is twice as fast when deviations are small and the credibility of the central bank is higher. Third, inflation targeting tends to generate a higher degree of credibility for the monetary authorities, thereby reducing deviations of the exchange rate from the PPP- and UIP-implied equilibrium.","Anderl, Christina; Caporale, Guglielmo Maria",2022,10.1007/s00181-021-02192-3,None,proquest
8aebf3ff75b87c23,Exchange rate predictability in emerging markets,"This paper uses financial and macroeconomic variables to predict currency returns, by using a two-step procedure. The first step consists of a cointegration equation that explains the exchange rate level as a function of global and domestic financial factors. The second step estimates an error-correction equation, for modeling the expected returns. This approach is a factor model analysis, where a Lasso derived technique is used for variable selection. This paper will focus on the five most frequently traded Latin American currencies, Brazilian Real (BRL), Chilean Peso (CLP), Colombian Peso (COL), Mexican Peso (MXN) and Peruvian Sol (PEN), during the time horizon from December 2001 until February 2016. The first finding is that the Global Exchange Rate Factor offers information about the exchange rate movements. In addition, this paper shows that commodity, equity prices and domestic risk premium are important variables for explaining exchange rates. Moreover, it confirms the existing results for the carry and slope variables. © 2019 Elsevier B.V., All rights reserved.","Baku, E.",2019,10.1016/j.inteco.2018.06.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049573296&doi=10.1016%2Fj.inteco.2018.06.003&partnerID=40&md5=fc8de85fd1f55752a97088fd14aeb2fd,scopus
5405d96dfae218a6,Experience rating of risk premium for Esscher premium principle,"In this article, a new method is introduced under the Bayesian framework to derive the credibility estimator of risk premiums based on the Esscher premium principle. This new estimator offers desirable statistical properties, making it more useful and practical compared to existing estimators. Additionally, Bayesian models for policy portfolios are established, and empirical Bayes methods are employed to estimate the structural parameters. The empirical Bayesian estimation of risk premiums is also discussed in detail. The convergence rate and goodness of the proposed estimators are verified through simulations. The results demonstrate the effectiveness and accuracy of the new estimator and its superior performance compared to other existing methods. Finally, an empirical analysis is conducted using real insurance data, which further confirms the applicability and reliability of the proposed credibility estimator and its superiority in practical insurance applications. © 2024 Elsevier B.V., All rights reserved.","Zhang, Y.; Wen, L.",2024,10.1080/03610926.2023.2286192,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178100660&doi=10.1080%2F03610926.2023.2286192&partnerID=40&md5=41e426440e05e0182b9e7d5f4d9127c3,scopus
8c75e56f2f9a5385,Experimental Evidence on Socioeconomic Differences in Risk‐Taking and Risk Premiums,"Using a route choice experiment with embedded travel time variability, this study empirically estimates car commuters’ risk attitudes and taste preferences within a nonlinear mixed logit model. In addition to the identified overall risk‐taking behaviour, we find that risk attitudes covary with some sociodemographic characteristics, that is, older commuters are more risk‐taking than young ones and higher‐income commuters are less risk‐taking than low‐income ones. The implications of accounting for systematic risk attitude heterogeneity for valuing travellers’ willingness to pay for travel time improvement are also discussed.","Li, Zheng",2020,10.1111/1475-4932.12544,None,proquest
e2d7c330b34a3f2e,Experiments on the application of IOHMMs to model financial returns series,"Input-output hidden Markov models (IOHMMs) are conditional hidden Markov models in which the emission (and possibly the transition) probabilities can be conditioned on an input sequence. For example, these conditional distributions can be linear, logistic, or nonlinear (using for example multilayer neural networks), We compare the generalization performance of several models which are special cases of input-output hidden Markov models on financial time-series prediction tasks: an unconditional Gaussian, a conditional linear Gaussian, a mixture of Gaussians, a mixture of conditional linear Gaussians, a hidden Markov model, and various IOHMMs. The experiments compare these models on predicting the conditional density of returns of market and sector indices. Note that the unconditional Gaussian estimates the first moment with the historical average. The results show that, although for the first moment the historical average gives the best results, for the higher moments, the IOHMMs yielded significantly better performance, as estimated by the out-of-sample likelihood.","Bengio, Y; Lauzon, VP; Ducharme, R",2001,10.1109/72.896800,None,wos
c053694d929092d7,Exploiting Visual Features in Financial Time Series Prediction,"The possibility to enhance prediction accuracy for foreign exchange rates was investigated in two ways: first applying an outside the box approach to modeling price graphs by exploiting their visual properties, and secondly employing the most efficient methods to detect patterns to classify the direction of movement. The approach that exploits the visual properties of price graphs which make use of density regions along with high and low values describing the shape; hence, the authors propose the name 'Finance Vision.' The data used in the predictive model consists of 1-hour past price values of 4 different currency pairs, between 2003 and 2016. Prediction performances of state-of-the-art methods; Extreme Gradient Boosting, Artificial Neural Network and Support Vector Machines are compared over the same data with the same sets of features. Results show that density based visual features contribute considerably to prediction performance.","Karacor, Adil Gursel; Erkan, Turan Erman",2020,10.4018/ijcini.2020040104,None,wos
a3feea8e4d7e241d,Exploration of Stock Portfolio Investment Construction Using Deep Learning Neural Network,"To study the intelligent and efficient stock portfolio in China’s financial market, based on the relevant theories such as deep learning (DL) neural network (NN) and stock portfolio, this study selects 111 stable stocks from the constituent stocks of the China Security Index (CSI) 300 from January 1, 2018, to December 31, 2021, as the research samples. Then, it analyzes these research samples and imports the relevant data of 111 stocks into the DL NN model. The corresponding prediction results of stock prices are obtained. Finally, the stock portfolio model based on DL NN is compared with the data results of the Shanghai Stock Exchange (SSE) 50 Index and CSI 500 Index. The results show that the closing prices of the selected 111 stocks are relatively stable and fluctuate up and down around the horizontal axis, and the positive and negative returns are relatively balanced, roughly between −5% and 5%. There is a phenomenon of fluctuation aggregation to a certain extent. Comparing the prediction results of different models reveals that the prediction results of model c are closest to the actual stock price trend. Comparing the relevant returns of the proposed stock portfolio with other stocks uncovers that the annualized return of the stock portfolio based on the DL NN model is 47.44%. The sharp ratio is 1.52, the maximum pullback is 18.15%, the monthly excess return is 3.11%, and the information ratio is 0.82. Compared with other indexes, the proposed stock portfolio shows the best results. Therefore, the proposal of the stock portfolio based on DL NN provides a theoretical basis for the development of the financial field in the future.","Xie, Zizheng; Wang, Yi",2022,10.1155/2022/7957097,None,proquest
13331c75c58f2aa1,Exploring External Influences on Cryptocurrency Prices: Using A Multi-Analytical Approach,"Cryptocurrencies have experienced exponential growth within the last decade, with market capitalization hovering above the one-trillion-dollar mark since 2022. One area of concern for current and potential crypto users and investors is their unprecedented price volatility. As cryptos become interlinked with the regulated financial system, questions emerge regarding the possibility of linkages of their prices to the external environments. Financial and macroeconomic factors of inflation, economic growth, interest rates, currency exchange rates, equity market returns, corporate bond yields, gold and oil prices are examined against the cryptocurrency returns. This study encompasses a multi-analytical approach, firstly with the empirical tests of Spearman’s correlational analysis to discover the most pertinent relationships, followed by the PCA analysis to reduce redundancy. The predictive regression model of the Granger Causality test, a vector autoregression (VAR) time series forecasting method, is applied to examine whether the highly effective factors Granger cause the crypto price movements. The Machine Learning Random Forest Regression is also applied where a nuanced understanding of the external factors affecting cryptos prices is gained. The findings of this study pertain to more recent times when the pandemic crisis has subsided and stable economies are in place. The results examined four major cryptos of Bitcoin, Binance Coin, Ripple and Tether, where most behaviours suggest that users and investors are willing to take on riskier assets during periods of economic growth, a strong equity market complements crypto demands and gold and oil are good substitutes for cryptos. Tether, a stablecoin, was the least impacted by external factors and behaved similarly to a fiat currency. This investigation into external factors will empower cryptocurrency users and investors with valuable insights into the crypto price mechanisms, enabling them to refine their investing and portfolio diversification strategies.","Daruwala, Zaheda",2025,10.32479/ijefi.19455,None,proquest
728df2bee0b1fd08,Exploring Low-Risk Anomalies: A Dynamic CAPM Utilizing a Machine Learning Approach,"Low-risk pricing anomalies, characterized by lower returns in higher-risk stocks, are prevalent in equity markets and challenge traditional asset pricing theory. Previous studies primarily relied on linear regression methods, which analyze a limited number of factors and overlook the advantages of machine learning in handling high-dimensional data. This study aims to address these anomalies in the Chinese market by employing machine learning techniques to measure systematic risk. A large dataset consisting of 770 variables, encompassing macroeconomic, micro-firm, and cross-effect factors, was constructed to develop a machine learning-based dynamic capital asset pricing model. Additionally, we investigated the differences in factors influencing time-varying beta between state-owned enterprises (SOEs) and non-SOEs, providing economic explanations for the black-box issues. Our findings demonstrated the effectiveness of random forest and neural networks, with the four-layer neural network performing best and leading to a substantial rise in the excess return of the long–short portfolio, up to 0.36%. Notably, liquidity indicators emerged as the primary drivers influencing beta, followed by momentum. Moreover, our analysis revealed a shift in variable importance during the transition from SOEs to non-SOEs, as liquidity and momentum gradually replaced fundamentals and valuation as key determinants. This research contributes to both theoretical and practical domains by bridging the research gap in incorporating machine learning methods into asset pricing research. © 2023 Elsevier B.V., All rights reserved.","Wang, J.; Chen, Z.",2023,10.3390/math11143220,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166206513&doi=10.3390%2Fmath11143220&partnerID=40&md5=d85880f568724fa7255d579695735817,scopus
11ebfbf1a9e886e4,Exploring the role of artificial intelligence in orthopedic medical education: A narrative review,"Artificial intelligence (AI) is transforming orthopedic medical education by enhancing diagnostic accuracy, surgical training, and personalized learning. This narrative review explores AI's applications, including machine learning (ML) and computer vision for interpreting imaging studies, virtual reality (VR) and augmented reality (AR) for immersive surgical simulations, and natural language processing (NLP) for streamlining clinical workflows. AI-powered tools offer objective feedback, adaptive learning modules, and risk-free environments for skill acquisition, bridging gaps in traditional training methods. However, challenges such as data privacy, algorithmic bias, and the need for robust validation remain. Ethical considerations, including patient trust and trainee over-reliance on AI, must also be addressed. Despite these barriers, AI democratizes access to high-quality education, particularly in resource-limited settings, through cloud-based platforms and mobile applications. The future of AI in orthopedics is promising, with advancements in predictive analytics, robotic-assisted surgery, and haptic feedback technologies poised to further revolutionize training. Collaborative efforts among educators, clinicians, and developers are essential to ensure responsible integration. This review highlights AI's potential to reshape orthopedic education while emphasizing the importance of preserving the mentor-trainee relationship and fostering evidence-based adoption.Artificial intelligence (AI) is transforming orthopedic medical education by enhancing diagnostic accuracy, surgical training, and personalized learning. This narrative review explores AI's applications, including machine learning (ML) and computer vision for interpreting imaging studies, virtual reality (VR) and augmented reality (AR) for immersive surgical simulations, and natural language processing (NLP) for streamlining clinical workflows. AI-powered tools offer objective feedback, adaptive learning modules, and risk-free environments for skill acquisition, bridging gaps in traditional training methods. However, challenges such as data privacy, algorithmic bias, and the need for robust validation remain. Ethical considerations, including patient trust and trainee over-reliance on AI, must also be addressed. Despite these barriers, AI democratizes access to high-quality education, particularly in resource-limited settings, through cloud-based platforms and mobile applications. The future of AI in orthopedics is promising, with advancements in predictive analytics, robotic-assisted surgery, and haptic feedback technologies poised to further revolutionize training. Collaborative efforts among educators, clinicians, and developers are essential to ensure responsible integration. This review highlights AI's potential to reshape orthopedic education while emphasizing the importance of preserving the mentor-trainee relationship and fostering evidence-based adoption.","Das, Lakshmana S; Das, Deepanjan; Chandrakar, Denish; Bhavani, Prashant; Dubepuria, Amol; Barik, Sitanshu",2025,10.1016/j.jcot.2025.103100,None,proquest
6e8a4c15b74abc41,"External shocks, cross-border flows and macroeconomic risks in emerging market economies","We study the relationship between cross-border flows and risks to macroeconomic stability for a sample of ten major emerging market economies (EMEs) from 2000 to 2017 in the presence of external shocks. We examine this relationship with a focus on two key channels of cross-border flows, namely external debt securities (EDS) and cross-border loans (CBLs). Our analysis focuses on the transition in cross-border flows post-global financial crisis 2008 (GFC) termed as the second phase of global liquidity (Shin in Keynote address at Federal Reserve Bank of San Francisco Asia economic policy conference, 2013). Panel vector autoregression estimations show that volatility in global risk perception affects cross-border flows to EMEs more as compared to the effect of the US monetary policy stance. Post-GFC, EDS flows rise with shocks in global risk perception, while CBL flows register a decline. CBL flows are also associated with larger risks post-GFC compared to the pre-GFC period, which is in contrast to the result for EDS flows. Second, a panel threshold estimation confirms a nonlinear association between EDS/CBL flows and macroeconomic risks largely dependent upon global uncertainty. US GDP growth also affects the nonlinearity, but US federal funds rate have insignificant threshold effects. Our results conclude that global uncertainty is a significant driver of cross-border flows to EMEs post-GFC and that it is a strong signal in determining riskiness of EDS flows and CBL flows for EMEs.","Goyal, Ashima; Verma, Akhilesh K.; Sengupta, Rajeswari",2022,10.1007/s00181-021-02099-z,None,wos
aa74a4500fdd27b8,Extrapolating Long-Run Yield Curves: An Innovative and Consistent Approach,"This article proposes a method to build term structures that are consistent with market data and that provide interest rates for which the volatility, on average, decreases as maturities increase. The method is designed for continuous repetitive use and is consistent with work by Diebold and Li, providing reasonable extrapolated rates, with an appropriate level of volatility over time. The Svensson model is adopted, and its parameters are estimated by the combination of a genetic algorithm and a quasi-Newton nonlinear optimization method. We innovate with a new objective function that focuses on both parts of the estimated curves (interpolated and extrapolated). For this purpose, a stability component is added. The new objective function aims to solve the problem of estimating long-term rates not observable in the market, for which the estimates are usually artificially stable or excessively volatile. The results show that the estimation method is able to bring the volatility of extrapolated rates to levels consistent with those observed for the longest liquid rate. Estimation errors are small enough and there is no statistical evidence that they are biased. The method is useful for the insurance market, since it provides interest rates that do not lead to artificially stable or excessively volatile technical provisions. © 2023 Elsevier B.V., All rights reserved.","Signorelli, T.P.; Campani, C.H.; Neves, C.D.R.",2023,10.1080/10920277.2022.2102040,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138326527&doi=10.1080%2F10920277.2022.2102040&partnerID=40&md5=a98fb2ad043814ee043fadaf75c64129,scopus
f62c257dbca918f1,FINITE-SAMPLE PROPERTIES OF THE GENERALIZED-METHOD OF MOMENTS IN TESTS OF CONDITIONAL ASSET PRICING-MODELS,"We develop evidence on the finite sample properties of the Generalized Method of Moments (GMM) in an asset pricing context. The models imply nonlinear, cross-equation restrictions on predictive regressions for security returns. We find that a two-stage GMM approach produces goodness-of-fit statistics that reject the restrictions too often. An iterated GMM approach has superior finite sample properties. The coefficient estimates are approximately unbiased in simpler models, but their asymptotic standard errors are understated. Simple adjustments for the standard errors are partially successful in correcting the bias. In more complex models the coefficients and their standard errors can be highly unreliable. The power of the tests to reject a single-premium model is higher against a two-premium, fixed-beta alternative than against a conditional Capital Asset Pricing Model with time-varying betas.","FERSON, WE; FOERSTER, SR",1994,10.1016/0304-405x(94)90029-9,None,wos
8edd8d9e068332ee,FORECASTING DEMAND FOR MONEY UNDER CHANGING TERM STRUCTURE OF INTEREST-RATES - APPLICATION OF RIDGE REGRESSION,None,"WATSON, DE; WHITE, KJ",1976,10.2307/1057334,None,wos
99d45debc2b13a50,FORECASTING SERIES CONTAINING OFFSETTING BREAKS: OLD SCHOOL AND NEW SCHOOL METHODS OF FORECASTING TRANSNATIONAL TERRORISM,"Transnational terrorism data are difficult to forecast because they contain an unknown number of structural breaks of unknown functional form. The rise of religious fundamentalism, the demise of the Soviet Union, and the rise of al Qaeda have changed the nature of transnational terrorism. 'Old School' forecasting methods simply smooth or difference the data. 'New School' methods use estimated break dates to control for regime shifts when forecasting. We compare the various forecasting methods using a Monte Carlo study with data containing different types of breaks. The study's results are used to forecast various types of transnational terrorist incidents.","Enders, Walter; Liu, Yu; Prodan, Ruxandra",2009,10.1080/10242690802425772,None,wos
05792d551d45f496,Factor Investing Based on Musharakah Principle,"Shariah stock investing has become a widely discussed topic in financial industry as part of today's investment strategy. The strategy primarily applies market capitalization allocations. However, some researchers have argued that market capitalization weighting is inherently flawed and have advocated replacing market capitalization allocations with factor allocations. In this paper, we discuss the rationale for factor investing based on Musharakah principle. The essential elements or factors of Musharakah principle such as business sector, management capability, profitability growth and capital efficiency are embedded in the Shariah-compliant stock. We then transform these factors into indexation for better analysis and performance measurement. Investment universe for this research covers Malaysian stocks for the period of January 2009 to December 2013. We found out that these factor indexes have historically earned excess returns over market capitalization weighted indexes and experienced higher Sharpe Ratios.","Simon, Shahril; Omar, Mohd; Lazam, Norazliani Md; Amin, Mohd Nazrul Mohd",2015,10.1063/1.4932468,None,wos
718e4320f8bbc4bd,Factor Investment or Feature Selection Analysis?,"This study has made significant findings in A-share market data processing and portfolio management. Firstly, by adopting the Lasso method and CPCA framework, we effectively addressed the problem of multicollinearity among feature indicators, with the Lasso method demonstrating superior performance in handling this issue, thus providing a new method for financial data processing. Secondly, Deep Feedforward Neural Networks (DFN) exhibited exceptional performance in portfolio management, significantly outperforming other evaluated machine learning methods, and achieving high levels of out-of-sample performance and Sharpe ratios. Additionally, we consistently identified price changes, earnings per share, net assets per share, and excess returns as key factors influencing predictive signals. Finally, this study combined the Lasso method with DFN, providing a new perspective and methodological support for asset pricing measurement in the financial field.","Jifang Mai; Zhang, Shaohua; Zhang, Shaohua; Zhao, Haiqing; Pan, Lijun",2025,10.3390/math13010009,None,proquest
1783e8e530cbe052,"Factor Models, Machine Learning, and Asset Pricing","We survey recent methodological contributions in asset pricing using factor models and machine learning. We organize these results based on their primary objectives: estimating expected returns, factors, risk exposures, risk premia, and the stochastic discount factor as well as model comparison and alpha testing. We also discuss a variety of asymptotic schemes for inference. Our survey is a guide for financial economists interested in harnessing modern tools with rigor, robustness, and power to make new asset pricing discoveries, and it highlights directions for future research and methodological advances.","Giglio, Stefano; Kelly, Bryan; Xiu, Dacheng",2022,10.1146/annurev-financial-101521-104735,None,wos
3fbafc43043d6b52,Failure Propagation in SAP MultiBank Payment Batches Due to Unsynchronized Secure Channel Negotiations,"In SAP MultiBank systems, the payment batch processing failures are usually due to out-of-sync secure channel negotiations between the corporate SAP treasury systems and the banking interfaces that are integrated and connected. This research looks into the failure timing impacts of secure channel handshake intervals such as the time-to-first-byte, SSL certificate validation delays, and out-of-sync cryptographic negotiations occurring asynchronously. Using transaction logs, synthetic datasets, and real-world data, we construct a failure propagation framework that models transaction execution disruptions across various API types and geographical endpoints. The research confirms that there is a strong dependency between the level of channel desynchronization and the average payment failure rate with retry latencies and the volume of batches serving as extreme multipliers. Through recovery strategy analysis based on manual realignments, scheduled syncs, and AI anomaly driven adaptive predictions, we quantify the changes in batch stability and the integrity of transmitted data. The findings illustrate that diverse systems require synchronous coordinated negotiation protocols for secure cryptographic negotiation per transaction, stressing the treasury teams provide seamless payment failure continuity, enhanced compliance standards, and robust compliance standards for interbank integration. © 2025 Elsevier B.V., All rights reserved.","Jamithireddy, N.S.",2025,10.58346/jisis.2025.i2.036,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012485585&doi=10.58346%2FJISIS.2025.I2.036&partnerID=40&md5=4f31951178fd939d4f4e5b7ce6ed7171,scopus
a940e3bbceaea481,False Safe Haven Assets: Evidence From the Target Volatility Strategy Based on Recurrent Neural Network,"This paper examines which safe haven assets should be used when improving out-of-sample portfolio performance. We define a market state with recurrent neural network (RNN) volatility predictions and construct an investment strategy that dynamically combines equity, cash, and safe havens. The equity is allocated by targeting the volatility, and investing in safe havens depends on the predicted market state. We consider the S&P500 index with 13 safe haven assets, such as long-term government bonds, commodities, gold, and other precious metals. Other indices, NIKKEI225, NIFTY50, and STOXX50, are examined for robustness. With analysis conducted over a 20-year sample period, we find that RNN delivers sound predictions to construct the volatility targeting strategy. Among considered assets, only long-term Treasury bonds act as a safe haven and improve the strategy performance. Other considered assets have no such potential. Our findings are relevant to portfolio managers and investors actively managing portfolio risk. © 2021 Elsevier B.V., All rights reserved.","Kaczmarek, T.; Be̜dowska-Sójka, B.; Grobelny, P.; Perez, K.",2022,10.1016/j.ribaf.2021.101610,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122282703&doi=10.1016%2Fj.ribaf.2021.101610&partnerID=40&md5=19f8d4a3c02c1effd32fe5951dcc2048,scopus
4b1a93d999b867fb,Filtering of a Discrete-Time HMM-Driven Multivariate Ornstein-Uhlenbeck Model With Application to Forecasting Market Liquidity Regimes,"This paper investigates the modeling of risk due to market and funding liquidity by capturing the joint dynamics of three time series: the treasury-Eurodollar spread, the VIX, and a metric derived from the S&P 500 spread. We propose a two-regime mean-reverting model for explaining the behaviour of three time series, which mirror liquidity levels for financial markets. An expectation-maximisation algorithm in conjunction with multivariate filters is employed to construct optimal parameter estimates of the proposed model. The selection of the modeling set-up is justified by balancing the best-fit criterion and model complexity. The model performance is demonstrated on historical market data, and a descriptive analysis of the different liquidity measures shows the presence of clear high and low states.",A. Tenyakov; R. Mamon; M. Davison,2016,10.1109/jstsp.2016.2549499,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7445144,ieeexplore
7cef1491c4ad8156,Financial Stock Investment Management Using Deep Learning Algorithm in the Internet of Things,"This paper aims to explore a new model to study financial stock investment management (SIM) and obtain excess returns. Consequently, it proposes a financial SIM model using deep Q network (DQN) as reinforcement earning (RL) algorithm and Long Short-Term Memory (LSTM) as deep neural network (DNN). Then, after training and optimization, the proposed model is back-tested. The research findings are as follows: the LSTM neural network (NN)-based model will import the observation of the market at each time and the change of transaction information over time. The LSTM network can find and learn the potential relationship between time series data. There are two hidden layers and one output layer in the model. The hidden layer is an LSTM structure and the output layer is the fully connected NN. DQN algorithm first stores the experience sample data of the agent-environment interaction into the experience pool. It then randomly selects a small batch of data from the experience pool to train the network. Doing so removes the correlation and dependence between samples so that the DNN model can better learn the value function in the RL task. The model can predict the future state according to historical information and decide which actions to take in the next step. Meanwhile, five stocks of Chinese A-shares are selected to form an asset pool. The initial 500,000 amount of the account is divided into five equal shares, which are invested and traded. Overall, the model account’s rate of return (RoR) during the back-test is 32.12%. The Shanghai Stock Exchange (SSI) has risen by 19.157% in the same period. Thus, the model’s performance has exceeded the SSI’s in the same period. E stock has the maximum RoR of 78.984%. The RoR of A, B, and C stocks is 54.129%, 11.594%, and 9.815%, respectively. B stock presents a minimum RoR of 6.084%. All these stocks have got positive returns. Therefore, the proposed financial SIM based on the DL algorithm is scientific and feasible. The research content has certain significant reference for the DL-based financial SIM.","Fan, Jianjuan; Shen, Peng",2022,10.1155/2022/4514300,None,proquest
a7bce1b51fda5973,"Financial asset returns, direction-of-change forecasting, and volatility dynamics","We consider three sets of phenomena that feature prominently in the financial economics literature: (1) conditional mean dependence (or lack thereof) in asset returns, (2) dependence (and hence forecastability) in asset return signs, and (3) dependence (and hence forecastability) in asset return volatilities. We show that they are very much interrelated and explore the relationships in detail. Among other things, we show that (1) volatility dependence produces sign dependence, so long as expected returns are nonzero, so that one should expect sign dependence, given the overwhelming evidence of volatility dependence; (2) it is statistically possible to have sign dependence without conditional mean dependence; (3) sign dependence is not likely to be found via analysis of sign autocorrelations, runs tests, or traditional market timing tests because of the special nonlinear nature of sign dependence, so that traditional market timing tests are best viewed as tests for sign dependence arising from variation in expected returns rather than from variation in volatility or higher moments; (4) sign dependence is not likely to be found in very high-frequency (e.g., daily) or very low-frequency (e.g., annual) returns; instead, it is more likely to be found at intermediate return horizons; and (5) the link between volatility dependence and sign dependence remains intact in conditionally non-Gaussian environments, for example, with time-varying conditional skewness and/or kurtosis.","Christoffersen, Peter F.; Diebold, Francis X.",2006,10.1287/mnsc.1060.0520,None,wos
50461e7a8d89df57,Financial attention and the demand for information,"This study tracks the daily traffic on the leading financial websites in the US, and uses the attention paid to these websites as a proxy for retailers’ aggregate demand for information. We determine that attention to financial websites is positively correlated with uncertainty and negatively associated with investor sentiment. Furthermore, market shocks drive attention to financial websites, and heightened attention predicts an increase in the following trading day's volatility. Consistent with the information arrival hypothesis, the search for information is higher on Mondays and Tuesdays and lower on weekends. As some retail investors are noise traders, attention to financial websites has a positive effect on volatility and increases trading volume. Finally, using 5-min intraday data, we construct a daily-implied risk aversion proxy and provide evidence supporting the theoretical contention that risk-averse agents gather information as a hedge against uncertainty. However, our findings do not support the avoidance of information theories. © 2019 Elsevier B.V., All rights reserved.","Qadan, M.; Zoua'bi, M.",2019,10.1016/j.socec.2019.101450,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069670415&doi=10.1016%2Fj.socec.2019.101450&partnerID=40&md5=a6e61eecd3f0a101c774cad8ea7d88e8,scopus
76f6fcb6934e9db1,Financial conditions and nonlinearities in the European Central Bank (ECB) reaction function: In-sample and out-of-sample assessment,"Our purpose is to investigate how the European Central Bank (ECB) sets interest rates in the context of both linear and nonlinear policy reaction functions. This work contributes to the current debate on central banks having additional objectives over and above control of inflation and output. Three findings emerge. First, the ECB takes financial conditions into account when setting interest rates. Second, amongst Taylor rule models, linear and nonlinear models are empirically indistinguishable within sample, and model specifications with real-time data provide the best description of in-sample ECB interest rate setting behaviour. Third, the 2007-2009 financial crisis witnessed a shift from inflation targeting to output stabilization, and a shift from an asymmetric policy response to financial conditions at high inflation rates to a more symmetric response regardless of the state of inflation. Finally, guidance is provided as regards models for forecasting interest rates in the Eurozone area. Without imposing an a priori choice of the parametric functional form, semiparametric models and autoregressive processes forecast the out-of-sample ECB interest rate setting behaviour better than linear and nonlinear Taylor rule models. (C) 2011 Elsevier B.V. All rights reserved.","Milas, Costas; Naraidoo, Ruthira",2012,10.1016/j.csda.2011.06.032,None,wos
ce476a18889360d0,"Financial conditions, macroeconomic factors and disaggregated bond excess returns","Bond excess returns can be predicted by macro factors, however, large parts remain still unexplained. We apply a novel term structure model to decompose bond excess returns into expected excess returns (risk premia) and the innovation part. In order to explore these risk premia and innovations, we complement macro variables by financial condition variables as possible determinants of bond excess returns. We find that the expected part of bond excess returns is driven by macro factors, whereas innovations seem to be mainly influenced by financial conditions, before and after the financial crisis. Thus, financial conditions, such as financial stress, deserve attention when analyzing bond excess returns. © 2015 Elsevier B.V., All rights reserved.","Fricke, C.; Menkhoff, L.",2015,10.1016/j.jbankfin.2015.03.015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930672701&doi=10.1016%2Fj.jbankfin.2015.03.015&partnerID=40&md5=cca2912022d65911e1c5b4829a830f9e,scopus
0726da9e365f79a8,"Financing anomaly, mispricing and cross-sectional return predictability","This study investigates the persistence of financing anomaly in the Chinese stock market. The results show that the long-short portfolio earns an average monthly excess return of 0.88% for the following 12 months based on this anomaly. We provide a behavioral mispricing-based explanation for this anomaly that financing anomaly is stronger in stocks or period with high investor overconfidence. Moreover, we find that financing anomaly is stronger in stocks with more investor attention, indicating that excessive investor attention increases mispricing and reduces market efficiency. However, idiosyncratic volatility cannot capture the arbitrage costs faced by financing anomaly, and investors' lottery-like preference cannot explain financing anomaly. Our findings are robust after controlling for other firm characteristic variables, considering shell value contamination and different sample periods. © 2022 Elsevier B.V., All rights reserved.","Yang, B.; Ye, T.; Ma, Y.",2022,10.1016/j.iref.2022.02.062,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125476546&doi=10.1016%2Fj.iref.2022.02.062&partnerID=40&md5=ce0991486424799573e1de259da53f4a,scopus
5842551f94fabb30,Firm-level productivity and stock return: New evidence from China,"This study provides novel insights into the stock return predictability related to the firm-level total factor productivity (TFP) in the China's stock market, covering the period from 1999 to 2020. Contrary to studies on other countries, our research identifies a positive correlation between the productivity of Chinese firms and their future stock returns. We suggest that this correlation is driven by mispricing rather than risk premium. Specifically, we argue that investors' difficulties in accurately assessing firm-level productivity and limited attention result in the inadequate incorporation of this information into stock prices. Furthermore, our analysis explores additional factors contributing to the observed productivity-related market anomaly, including investor overconfidence, positive feedback trading, lottery preference, information uncertainty, and limits to arbitrage, indicating investors' irrationality and behavioral biases. Importantly, our study also demonstrates that firm-level productivity serves as a reliable predictor of a firm's future profitability. © 2024 Elsevier B.V., All rights reserved.","Tang, N.; Gao, M.; Zhou, Y.; Zhou, F.; Zhu, J.",2024,10.1016/j.iref.2024.103557,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203455085&doi=10.1016%2Fj.iref.2024.103557&partnerID=40&md5=766099b5385b7c429057e195b3e80ea1,scopus
a2159b3d0ab0216f,Fiscal multipliers in South Africa after the global financial crisis,"Background: South Africa’s fiscal position has deteriorated considerably over the last 10 years, with debt levels reaching historical highs in the post-apartheid period. National Treasury’s intentions for fiscal consolidation have again drawn attention to the fiscal multiplier literature.Aim: The aim in the study is to calculate the size of fiscal expenditure multipliers over the period 2009 to 2019, taking into account the specific economic conditions and the funding choices of government.Setting: In the study fiscal policy is considered at a time when the debt to gross domestic product (GDP) ratio was rising rapidly.Methods: We use an econometric model to calculate the fiscal multipliers over the past decade. Our estimates take account of the specific fiscal conditions for each year, in particular the changing relationship between debt and the sovereign risk premia as well as the impact of tax increases.Results: The model suggests that the fiscal multiplier declined from 1.5 in 2010 to around zero in 2019 as the debt levels became progressively more unsustainable and large tax increases muted the aggregate demand effects from higher government expenditure.Conclusion: The low fiscal multipliers suggest that fiscal consolidation will be less costly in terms of growth forgone than generally perceived.JEL classification: C50, E62, H62, H63","van Rensburg, Theo Janse; de Jager, Shaun; Makrelov, Konstantin Hristov",2022,10.4102/sajems.v25i1.4191,None,proquest
30116f36dc2b4789,Fiscal policy and asset markets: A semiparametric analysis,"Using a flexible semiparametric varying coefficient model specification, this paper examines the role of fiscal policy on the US asset markets (stocks, Corporate and treasury bonds). We consider two possible roles of fiscal deficits (or surpluses): as a separate direct information variable and as a (indirect) conditioning information variable indicating binding constraints oil monetary policy actions. The results show that the impact of monetary policy on the stock market varies, depending oil fiscal expansion or contraction. The impact of fiscal policy on corporate and treasury bond yields follow similar patterns as in the equity market. The results are consistent with the notion of strong interdependence between monetary and fiscal policies. (C) 2008 Elsevier B.V. All rights reserved.","Jansen, Dennis W.; Li, Qi; Wang, Zijun; Yang, Jian",2008,10.1016/j.jeconom.2008.09.007,None,wos
f0af41484ecdd8f7,Flexible inflation targeting and stock market volatility: Evidence from emerging market economies,"Since the recent financial crisis, inflation targeting has been considered as one of the causes of the authorities’ unresponsiveness to the buildup of financial instability. Related research has either emphasized the effects of the central bank instrument and/or outcome or exclusively the impact of a unique central bank institutional characteristic, but never all of them as a core part of a unified framework. We fulfill this gap by providing evidence on whether the stock market volatility from Flexible Inflation Targeting (FIT) countries is less than volatility from non-FIT countries. Using data on a large set of emerging and employing causal inference methods, we examine the impact of FIT on stock market volatility. The results demonstrate that FIT is effective in containing volatility. By anchoring market operators’ expectations, FIT shapes the risk premium, which compensates for inflation uncertainty by lowering its main component, i.e. uncertainty, hence eventually bringing down the stock market volatility. © 2023 Elsevier B.V., All rights reserved.","Dridi, I.; Boughrara, A.",2023,10.1016/j.econmod.2023.106420,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165012437&doi=10.1016%2Fj.econmod.2023.106420&partnerID=40&md5=aefbb3defb36a70add814f54d2335234,scopus
76084a9656211a02,Fluctuations and Forecasting of Carbon Price Based on A Hybrid Ensemble Learning GARCH-LSTM-Based Approach: A Case of Five Carbon Trading Markets in China,"Carbon trading risk management and policy making require accurate forecasting of carbon trading prices. Based on the sample of China’s carbon emission trading pilot market, this paper firstly uses the Augmented Dickey–Fuller test and Autoregressive conditional heteroscedasticity model to test the stationarity and autocorrelation of carbon trading price returns, uses the Generalized Autoregressive Conditional Heteroscedasticity family model to analyze the persistence, risk and asymmetry of carbon trading price return fluctuations, and then proposes a hybrid prediction model neural network (generalized autoregressive conditional heteroscedasticity–long short-term memory network) due to the shortcomings of GARCH models in carbon price fluctuation analysis and prediction. The model is used to predict the carbon trading price. The results show that the carbon trading pilots have different degrees of volatility aggregation characteristics and the volatility persistence is long, among which only the Shanghai and Beijing carbon trading markets have risk premiums. The other pilot returns have no correlation with risks, and the fluctuations of carbon trading prices and returns are asymmetrical. The prediction results of different models show that the root mean square error (RMSE) of Hubei, Shenzhen and Shanghai carbon trading pilots based on the GARCH-LSTM model is significantly lower than that of the single GARCH model, and the RMSE values are reduced by 0.0006, 0.2993 and 0.0151, respectively. The RMSE in the three pilot markets improved by 0.0007, 0.3011 and 0.0157, respectively, compared to the standalone LSTM model. At the same time, compared with the single model, the GARCH-LSTM model significantly increased the R^2 value in Hubei (0.2000), Shenzhen (0.7607), Shanghai (0.0542) and Beijing (0.0595). Therefore, compared with other models, the GARCH-LSTM model can significantly improve the prediction accuracy of carbon price and provide a new idea for scientifically predicting the fluctuation of financial time series such as carbon price.","Liu, Sha; Liu, Sha; Zhang, Yiting; Wang, Junping; Feng, Danlei",2024,10.3390/su16041588,None,proquest
c0681b26b82dfcaf,Fluctuations in economic and activity and stabilization policies in the CIS,"In this study, a highly flexible form of nonlinear time series models called artificial neural networks (ANNs) are employed to predict fluctuations in economic activity in selected members (Armenia, Azerbaijan, Georgia, Kazakhstan, and Kyrgyzstan) of the Commonwealth of Independent States (CIS) using macroeconomic time series [treasury bill rate (T-bill), long term bond rate (BondLT), money supply (MS), industrial production (IP), spread (10-year treasury bond rate less 3-month treasury bill rate), BRTB (bank rate less 3-month treasury bill rate), and GDP growth rate]. Forecasting recessions being very important though challenging, recessions in the selected countries are modeled recursively 1-10 quarters ahead out-of-sample using ANNs in conjunction with macroeconomic time series for all the countries. The out-of-sample forecast results show that in general no single macroeconomic variable employed appears to be useful for predicting recessions in any of the series. However, for Armenia, the treasury bill rate, industrial production, money supply, and the spread (the yield curve) are candidate variables for predicting recessions 1-10 quarters ahead. For Georgia, Kazakhstan, and Kyrgyzstan, the treasury bill rate and money supply series are candidate variables for predicting recessions 1-10 quarters ahead. Reprinted by permission of Springer","Kiani, Khurshid M",2011,10.1007/s10614-010-9233-z,None,proquest
1fe2cd17cb91c3ec,Fluoride-treated water and the problem of merit goods,"This paper inquires into the fluoride treatment of community water in the United States to determine why and how conflicts in the production, consumption, and distribution of merit goods arise and are resolved. Primary and secondary data were employed to analyze statewide and municipality-level fluoridation initiatives in one key “battleground” state. We find that obstacles to successful fluoridation include a unidimensional policy space, high risk premia assigned by the affected population to health and environmental hazards, concerns over government interference with personal health choices, perceived adequacy of fluoride sources, “customer bundling,” and lack of a critical middle ground for consensus-building. The accessibility and social desirability of merit goods, like fluoridated water, cannot therefore be considered as value-free choices. How consumer demand is expressed, how fluoridation costs and benefits are estimated, how conflicts over its provision and production are resolved, and how the merits of science-based policies can be equally recast in terms of their presumed demerits require serious attention on the part of decision-makers in formulating and implementing health promotion policies.",Roger Lee Mendoza,2011,10.2166/wp.2010.127,None,proquest
f97af69cf5e63254,Forecasting CDS Term Structure Based on Nelson–Siegel Model and Machine Learning,"In this study, we analyze the term structure of credit default swaps (CDSs) and predict future term structures using the Nelson–Siegel model, recurrent neural network (RNN), support vector regression (SVR), long short-term memory (LSTM), and group method of data handling (GMDH) using CDS term structure data from 2008 to 2019. Furthermore, we evaluate the change in the forecasting performance of the models through a subperiod analysis. According to the empirical results, we confirm that the Nelson–Siegel model can be used to predict not only the interest rate term structure but also the CDS term structure. Additionally, we demonstrate that machine-learning models, namely, SVR, RNN, LSTM, and GMDH, outperform the model-driven methods (in this case, the Nelson–Siegel model). Among the machine learning approaches, GMDH demonstrates the best performance in forecasting the CDS term structure. According to the subperiod analysis, the performance of all models was inconsistent with the data period. All the models were less predictable in highly volatile data periods than in less volatile periods. This study will enable traders and policymakers to invest efficiently and make policy decisions based on the current and future risk factors of a company or country.","Kim, Won Joong; Jung, Gunho; Sun-Yong, Choi",2020,10.1155/2020/2518283,None,proquest
a3e32d7e88b2a9d3,Forecasting Chinese Stock Market Volatility With Volatilities in Bond Markets,"In this paper, we investigate whether the bond markets contain important information that can improve the accuracy of stock market volatility forecasts in China. We use realized volatility (RV) implemented by different maturity treasury bond futures contracts to predict the Chinese stock market volatility. Our work is based on the heterogeneous autoregressive (HAR) framework. Empirical results show that the volatility of treasury bond contracts with longer maturities (especially 10 years) has the best effect on predicting the Chinese stock market volatility, both in sample and out of sample. Two machine learning methods, the scaled principal component analysis (SPCA) and the least absolute shrinkage and selection operator (lasso), are also more effective than the HAR benchmark model's prediction. Finally, mean–variance investors can achieve substantial economic gains by allocating their investment portfolios based on volatility forecasts after introducing treasury bond futures volatility.","Likun Lei; He, Mengxi; Zhang, Yi; Zhang, Yaojie",2025,10.1002/for.3215,None,proquest
87ee8ce6a35b9443,Forecasting ETF Performance: A Comparative Study of Deep Learning Models and the Fama-French Three-Factor Model,"The global financial landscape has witnessed a significant shift towards Exchange-Traded Funds (ETFs), with their market capitalization surpassing USD 10 trillion in 2023, due to advantages such as low management fees, high liquidity, and broad market exposure. As ETFs become increasingly central to investment strategies, accurately forecasting their performance has become crucial. This study addresses this need by comparing the efficacy of deep learning models against the traditional Fama-French three-factor model in predicting daily ETF returns. The methodology employs eight artificial neural network architectures, including ANN, LSTM, GRU, CNN, and their variants, implemented in Python and applied to data ranging from 2010 to 2020, while also exploring the impact of additional factors on forecast accuracy. Empirical results reveal that LSTM and the Fama-French three-factor model exhibit a superior performance in ETF return prediction. This study contributes to the literature on financial forecasting and offers practical insights into investment decision making. By leveraging advanced artificial intelligence techniques, this study aims to enhance the toolkit available for ETF performance analysis, potentially improving investment strategies in this dynamic market segment.","Shih, Kuang-Hsun; Yi-Hsien, Wang; Yi-Hsien, Wang; I-Chen, Kao; Fu-Ming, Lai",2024,10.3390/math12193158,None,proquest
f1a1288e75912242,Forecasting Government Bond Yields with Neural Networks Considering Cointegration,"This paper discusses techniques that might be helpful in predicting interest rates and tries to evaluate a new hybrid forecasting approach. Results of examining government bond yields in Germany and France reported in this study indicate that a hybrid forecasting approach which combines techniques of cointegration analysis with neural network (NN) forecasting models can produce superior results to the use of NN forecasting models alone. The findings documented in this paper could be a consequence of the fact that examining differenced data under certain conditions will lead to a loss of information and that the inclusion of the error correction term from the cointegration model can help to cope with this problem. The paper also discusses some possibly interesting directions for further research. Copyright © 2015 John Wiley & Sons, Ltd.","Wegener, Christoph; Christian von Spreckelsen; Basse, Tobias; Hans‐Jörg von Mettenheim",2016,10.1002/for.2385,None,proquest
e58c9d418af5a8e9,Forecasting Key Macroeconomic Variables of the South African Economy using Bayesian Variable Selection,"This study analyzed the forecasting performances of various multivariate models in predicting 1-8-quarters-ahead of the growth rate of GDP, the consumer price index inflation rate and the three months Treasury bill rate for South Africa over an out-of-sample period of 2000:Q1-2011:Q2, using an in-sample period of 1960:Ql-1999:Q4. The study compared the forecasting performances of the classical and the Minnesota-type Bayesian vector autoregressive (VAR) models with those of linear (fixed-parameter) and nonlinear (time-varying parameter) VARs involving a stochastic search algorithm for variable selection, estimated using Markov Chain Monte Carlo methods. In general, the study finds that variable selection, whether imposed on a time-varying VAR or a fixed parameter VAR, and non-linearity in VARs, play an important part in improving predictions when compared to the linear fixed coefficients classical VAR. However, the results does not indicate marked gains in forecasting power across the different Bayesian models, as well as, over the classical VAR model, possibly because the problem of over parameterization in the classical VAR is not that acute in our three-variable system. Hence, future research would aim to look at VAR models that include over 10 variables.","Chama-Chiliba, M C; Gupta, R; Nkambule, N; Tlotlego, N",2012,10.3923/jas.2012.645.652,None,proquest
56a900a32f4d205c,Forecasting NFT coin prices using machine learning: Insights into feature significance and portfolio strategies,"With the rise in popularity of Non-Fungible Tokens (NFTs), the demand for NFT coins has also surged. NFT coins are cryptocurrencies that facilitate NFT ecosystems by supporting NFT trading and platform governance. Accurate price predictions of NFT coins are crucial for risk managing volatility and constructing optimal portfolios. This study employs machine learning techniques to predict the daily price direction of four key NFT coins, namely ENJ, MANA, THETA, and XTZ. The machine learning methods employed include three decision tree-based methods (random forests, extremely randomized trees, XGBoost), support vector machine, Lasso and Naïve Bayes. The findings show that random forests, extremely randomized trees, XGBoost, and support vector machine models have accuracy ranging between 80% and 90% for predictions in the 14 to 21 day range. This adds to the literature showing that machine learning methods have high prediction accuracy for cryptocurrency prices. Conversely, Lasso or Naïve Bayes models yield considerably lower prediction accuracy. Feature importance is assessed using Shapley values. The Shapley value feature importance calculated from random forests highlights that, for 14 and 21-day forecasts, four variables - five-year expected inflation, ten-year bond yields, the interest rate spread, and on balance volume - are consistently highly ranked across all NFT coins. Additionally, the MA50, MA200, and WAD also emerge as important features. These results highlight the importance of including macroeconomic variables which capture business cycle conditions and technical analysis indicators that capture investor psychology as features. NFT coin portfolios constructed using trading signals generated from Extra Trees outperforms a buy and hold portfolio. Extra Trees are easy and fast to implement and investors not making use of this information are likely making sub-optimal investment decisions. © 2023 Elsevier B.V., All rights reserved.","Henriques, I.; Sadorsky, P.",2023,10.1016/j.gfj.2023.100904,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174468022&doi=10.1016%2Fj.gfj.2023.100904&partnerID=40&md5=4aa2aaf1db2dce93e2690576c3902f88,scopus
5afe5ce80e830918,Forecasting Stock Market Crashes via Machine Learning,"This paper uses a comprehensive set of predictor variables from the five largest Eurozone countries to compare the performance of simple univariate and machine learning-based multivariate models in forecasting stock market crashes. In terms of statistical predictive performance, a support vector machine-based crash prediction model outperforms a random classifier and is superior to the average univariate benchmark as well as a multivariate logistic regression model. Incorporating nonlinear and interactive effects is both imperative and foundation for the outperformance of support vector machines. Their ability to forecast stock market crashes outof-sample translates into substantial value-added to active investors. From a policy perspective, the use of machine learning-based crash prediction models can help activate macroprudential tools in time.","Dichtl, Hubert; Drobetz, Wolfgang; Otto, Tizian",2023,10.1016/j.jfs.2022.101099,None,wos
dd40387ccca4c795,Forecasting WTI crude oil futures returns: Does the term structure help?,"Nelson-Siegel (NS) factors extracted from the term structure of WTI oil futures are shown to predict subsequent WTI holding period returns in-sample. This in-sample predictability is not diminished by augmenting with macroeconomic indicators or oil market specific predictors. Allowing the decay factor in the Nelson-Siegel model to vary over time improves in-sample predictions at medium horizon return forecasts. We conduct out-of-sample forecasting exercises on models that use NS factors, such as a simple two factor model that uses a composite leading indicator along with the NS decay factor, and a LASSO model that combines NS factors with macroeconomic indicators and oil market specific predictors. These models significantly reduce forecast errors relative to a no change benchmark across a range of return horizons and futures contract maturities. We also find consistent evidence that models that use the NS factors result in trading strategies with higher Sharpe ratios and better skewness properties than buy and hold strategies and historical mean strategies.","Bredin, Don; O'Sullivan, Conall; Spencer, Simon",2021,10.1016/j.eneco.2021.105350,None,proquest
8fb8a050541580b5,Forecasting Yield Curves with Survey Information,"In recent years, affine term structure models have provided alternatives to the expectations hypothesis and have become very popular in the finance literature. In particular, the widely accepted dynamic Nelson-Siegel model employs ingenious measures of the level, slope, and curvature of the yield curve that captured the attention of Francis and Hua. They supplement the dynamic Nelson-Siegel model with the Federal Reserve's Survey of Professional Forecasters data. Because these data utilize information from dozens of professional forecasters who study numerous macroeconomic variables, the author's wanted to see if this information-rich supplementary data could be used to improve the interest rate forecasting models for out-of-sample forecasts for Treasury bond maturities ranging from three months to 10 years that extend from three months to one year into the future.","Francis, Jack Clark; Hua, Jian",2012,10.3905/jpm.2012.38.3.149,None,wos
fd8a58d650cc3e18,Forecasting and trading credit default swap indices using a deep learning model integrating Merton and LSTMs,"Using macroeconomic and financial conditions to forecast credit default swap (CDS) spreads is a challenging task. In this paper, we propose the Merton-LSTM model, a modified LSTM model formed by integrating with the Merton determinants model, to forecast the CDS indices. We provide the rigorous math behind the Merton-LSTM model, which demonstrates that by leveraging the nonlinear learning ability of LSTM with increased model capacity, the Merton-LSTM model is expected to learn the inherent association between the Merton determinants and CDS spreads. Further, the Merton-LSTM model is compared with the machine learning models LSTM, gated recurrent unit (GRU), multilayer perceptron network (MLP), support vector machine (SVM) and a typical sto-chastic series model in forecasting the two most liquid five-year CDS indices, North America High Yield index (CDX.NA.HY) and North America Investment Grade index (CDX.NA.IG) through the root mean squared error (RMSE) and the Diebold-Mariano test. The comparison results show that the RMSEs of the Merton-LSTM model are the lowest (6.2570-27.2000 for CDX.NA.HY and 1.3168-6.4772 for CDX.NA.IG) compared to other competitive models. The superiority of the Merton-LSTM model in forecasting performance is highlighted in long-term prediction even with a forecasting horizon extended to 28 days. Simulated trading with different thresholds and horizons is conducted in this study. We find that the Merton-LSTM trading strategy yields the highest annualized Sharpe ratios and lowest maximum losses at most thresholds and horizons, highlighting the economic significance of the proposed model.","Mao, Weifang; Zhu, Huiming; Wu, Hao; Lu, Yijie; Wang, Haidong",2023,10.1016/j.eswa.2022.119012,None,wos
d630613e595b8156,Forecasting benchmarks of long-term stock returns via machine learning,"Recent advances in pension product development seem to favour alternatives to the risk free asset often used in the financial theory as a performance standard for measuring the value generated by an investment or a reference point for determining the value of a financial instrument. To this end, in this paper, we apply the simplest machine learning technique, namely, a fully nonparametric smoother with the covariates and the smoothing parameter chosen by cross-validation to forecast stock returns in excess of different benchmarks, including the short-term interest rate, long-term interest rate, earnings-by-price ratio, and the inflation. We find that, net-of-inflation, the combined earnings-by-price and long-short rate spread form our best-performing two-dimensional set of predictors for future annual stock returns. This is a crucial conclusion for actuarial applications that aim to provide real-income forecasts for pensioners.","Kyriakou, Ioannis; Mousavi, Parastoo; Nielsen, Jens Perch; Scholz, Michael",2019,10.1007/s10479-019-03338-4,None,proquest
9169d6d7b0d2309e,Forecasting carbon emissions future prices using the machine learning methods,"Due to the uncertainty surrounding the coupling and decoupling of natural gas, oil, and energy commodity futures prices, the current study seeks to investigate the interactions between energy commodity futures, oil price futures, and carbon emission futures from a forecasting perspective with implications for environmental sustainability. We employed daily data on natural gas futures prices, crude oil futures prices, carbon futures prices, and Dow Jones energy commodity futures prices from January 2018 to October 2021. For empirical analysis, we applied machine learning tools including traditional multiple linear regression (MLR), artificial neural network (ANN), support vector regression (SVR), and long short-term memory (LSTM). The machine learning analysis provides two key findings. First, the nonlinear frameworks outperform linear models in developing the relationships between future oil prices (crude oil and heating oil) and carbon emission futures prices. Second, the machine learning findings establish that when oil prices and natural gas prices display extreme movement, carbon emission futures prices react nonlinearly. Understanding the nonlinear dynamics of extreme movements can help policymakers design climate and environmental policies, as well as adjust natural gas and oil futures prices. We discuss important implications to sustainable development goals mainly SDG 7 and SDG 12.","Shahzad, Umer; Sengupta, Tuhin; Rao, Amar; Cui, Lianbiao",2024,10.1007/s10479-023-05188-7,None,wos
6a8220afadf7341f,Forecasting cryptocurrencies returns: Do macroeconomic and financial variables improve tail expectation predictions?,"This study aims to jointly predict conditional quantiles and tail expectations for the returns of the most popular cryptocurrencies (Bitcoin, Ethereum, Ripple, Dogecoin and Litecoin) using financial and macroeconomic indicators as explanatory variables. We adopt a Monotone Composite Quantile Regression Neural Network (MCQRNN) model to make one- and five-steps-ahead predictions of Value-at-Risk (VaR) and Expected Shortfall (ES) based on a rolling window and compare the performance of our model against the Historical simulation and the standard ARMA(1,1)-GARCH(1,1) model used as benchmarks. The superior set of models is then chosen by backtesting VaR and ES using a Model Confidence Set procedure. Our results show that the MCQRNN performs better than both benchmark models for jointly predicting VaR and ES when considering daily data. Models with the implied volatility index, treasury yield spread and inflation expectations sharpen the extreme return predictions. The results are consistent for the two risk measures at the 1% and 5% level both, in the case of a long and short position and for all cryptocurrencies.","Lawuobahsumo, Kokulo K.; Algieri, Bernardina; Leccadito, Arturo",2024,10.1007/s11135-023-01761-1,None,proquest
43890536593eb51e,Forecasting day-ahead expected shortfall on the EUR/USD exchange rate: The (I)relevance of implied volatility,"The existing literature provides mixed results on the usefulness of implied volatility for managing risky assets, while evidence for expected shortfall predictions is almost nonexistent. Given its forward-looking nature, implied volatility might be more valuable than backward-looking measures of realized price fluctuations. Conversely, the volatility risk premium embedded in implied volatility leads to overestimating the observed price variation. This paper explores the benefits of augmenting econometric models used in forecasting the expected shortfall, a risk measured endorsed in the Basel III Accord, with information on implied volatility obtained from EUR/USD option contracts. The day-ahead forecasts are obtained from several classes of econometric models: historical simulation, EGARCH, quantile regression-based HAR, joint VaR and ES model, and combination forecasts. We verify whether the resulting expected shortfall forecasts are well-specified and test the models' accuracy. Our results provide evidence that the information provided by forward-looking implied volatility is more valuable than that in backward-looking realized measures. These results hold across multiple model specifications, are stable over time, hold under alternative loss functions, and are more pronounced during periods of higher market uncertainty when risk modeling matters most. (c) 2023 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.","Lyocsa, Stefan; Plihal, Tomas; Vyrost, Tomas",2024,10.1016/j.ijforecast.2023.11.003,None,wos
bd6374063056c122,Forecasting equity risk premium: The role of investor concern on oil price volatility,"We explore the impact of investor concern to oil price volatility on Chinese equity risk premium by constructing an investor oil price volatility concern index (IOPVC) using Baidu Index. Our analysis demonstrates that IOPVC is a strong predictor of equity risk premium, with a negative correlation to future returns. Robustness checks, including the use of different data sources, various prediction windows, and differing levels of risk aversion, confirm that the relationship between IOPVC and equity risk premium is reliable. Furthermore, our analysis reveals that IOPVC is a leading indicator of forthcoming economic scenarios and exerts a significant influence on investor risk aversion.","Li, Dakai",2025,10.1016/j.ribaf.2025.102990,None,wos
b6b619d5ca55a0f5,Forecasting exchange rate: A bibliometric and content analysis,"The study aims to present a systematic overview of the research in the field of exchange rate projection models through bibliometric techniques and content analysis. First, 775 articles published in journals within the scope of the international Web of Science database from 1966 to May 2021 were analyzed through bibliometric techniques. Second, a selected sample of 69 articles was analyzed through a detail content analysis to identify hot topics and new avenues of interest in the field. The research findings suggest that the scientific production on the subject is in wide development. New approaches have been incorporated, such as neural networks, requiring a broad perspective by the researcher in the evaluation of the empirical results.","Vasconcelos, Camila de Souza; Hadad Jr, Eli",2023,10.1016/j.iref.2022.09.006,None,wos
a8145ad99ef09055,Forecasting foreign exchange rates with an intrinsically nonlinear dynamic speed of adjustment model,"Forecasting foreign exchange rates is an important but difficult process; therefore, it is important to use a superior forecasting model. The paper takes up this criterion and proposes to describe and forecast foreign exchange rates by developing an intrinsically nonlinear model with variable and dynamic speeds of adjustment. It is found that the speed of adjusting the random (or expected) to the equilibrium rate is very slow, implying that fiscal policy (statistically insignificat) and monetary policy (statistically significant) may be ineffective to induce changes in the adjustment speed. We also find that the nonlinear dynamic model improves forecasting performance, implying that nonlinearities in the sense of functional forms are exploitable for improved point forecasting of foreign exchange rates.","Lin, WT; Chen, YH",1998,10.1080/000368498325822,None,wos
5c20933515d8c65b,Forecasting gold price using machine learning methodologies,"This study investigates the potential of advanced Machine Learning (ML) methodologies to predict fluctuations in the price of gold. The study employs data from leading global stock indices, the S&P500 VIX volatility index, major commodity futures, and 10-year bond yields from the US, Germany, France, and Japan. Lagged values of these features up to 10 previous days are also used. Four machine learning models are used: Random Forest, Gradient Boosted Regression Trees (GBRT), and Extreme Gradient Boosting (XGBoost), to forecast future gold prices. The study finds that the most influential stocks indices for prediction are one-day lagged data of ASX, S&P500, TA35, IBEX, and AEX, as well as U.S. and Japan bonds yields and delayed data of gas and silver. Furthermore, the study's models identify that one-day lagged VIX score and our VIX dummy variable have a significant impact on gold price, indicating that economic uncertainty affects gold prices. The results suggest that incorporating various financial indicators and moving averages can be a powerful tool for predicting future gold prices. GBRT and XGBoost can be valuable models for making informed decisions about gold investments. © 2023 Elsevier B.V., All rights reserved.","Cohen, G.; Aiche, A.",2023,10.1016/j.chaos.2023.114079,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171768860&doi=10.1016%2Fj.chaos.2023.114079&partnerID=40&md5=242166c0eb01ccf4ae2e69b83f662f2b,scopus
7e4c9c9b08bf9ff8,Forecasting government bond spreads with heuristic models: evidence from the Eurozone periphery,"This study investigates the predictability of European long-term government bond spreads through the application of heuristic and metaheuristic support vector regression (SVR) hybrid structures. Genetic, krill herd and sine–cosine algorithms are applied to the parameterization process of the SVR and locally weighted SVR (LSVR) methods. The inputs of the SVR models are selected from a large pool of linear and non-linear individual predictors. The statistical performance of the main models is evaluated against a random walk, an Autoregressive Moving Average, the best individual prediction model and the traditional SVR and LSVR structures. All models are applied to forecast daily and weekly government bond spreads of Greece, Ireland, Italy, Portugal and Spain over the sample period 2000–2017. The results show that the sine–cosine LSVR is outperforming its counterparts in terms of statistical accuracy, while metaheuristic approaches seem to benefit the parameterization process more than the heuristic ones.","Filipa Da Silva Fernandes; Stasinakis, Charalampos; Zekaite, Zivile",2019,10.1007/s10479-018-2808-0,None,proquest
c0df2178fdcd2fdd,Forecasting interest rate swap spreads using domestic and international risk factors: evidence from linear and non-linear models,"This paper explores the ability of factor models to predict the dynamics of US and UK interest rate swap spreads within a linear and a non-linear framework. We reject linearity for the US and UK swap spreads in favour of a regime-switching smooth transition vector autoregressive (STVAR) model, where the switching between regimes is controlled by the slope of the US term structure of interest rates. We compare the ability of the STVAR model to predict swap spreads with that of a non-linear nearest-neighbours model as well as that of linear AR and VAR models. We find some evidence that the non-linear models predict better than the linear ones. At short horizons, the nearest-neighbours (NN) model predicts better than the STVAR model US swap spreads in periods of increasing risk conditions and UK swap spreads in periods of decreasing risk conditions. At long horizons, the STVAR model increases its forecasting ability over the linear models, whereas the NN model does not outperform the rest of the models. Copyright John Wiley & Sons. Reproduced with permission. An electronic version of this article is available online at http://www.interscience.wiley.com","Lekkos, Ilias; Milas, Costas; Panagiotidis, Theodore",2007,10.1002/for.1048,None,proquest
4f0fd761748ec99f,Forecasting interest rates: a comparative assessment of some second-generation nonlinear models,"Modeling and forecasting of interest rates has traditionally proceeded in the framework of linear stationary methods such as ARMA and VAR, but only with moderate success. We examine here three methods, which account for several specific features of the real world asset prices such as nonstationarity and nonlinearity. Our three candidate methods are based, respectively, on a combined wavelet artificial neural network (WANN) analysis, a mixed spectrum (MS) analysis and nonlinear ARMA models with Fourier coefficients (FNLARMA). These models are applied to weekly data on interest rates in India and their forecasting performance is evaluated vis--vis three GARCH models [GARCH (1,1), GARCH-M (1,1) and EGARCH (1,1)] as well as the random walk model. Both the WANN and MS methods show marked improvement over other benchmark models, and may thus hold out several potentials for real world modeling and forecasting of financial data.","Nachane, Dilip; Clavel, Jose G.",2008,10.1080/02664760701835243,None,wos
4ac39d877a1b7094,Forecasting macroeconomy based on the term structure of credit spreads: Evidence from China,"This article establishes an original methodology to forecast macroeconomy based on the term structure of credit spreads. It combines the traditional Svensson model with genetic algorithms to obtain the interest rate term structures of government bonds and corporate bonds and calculates credit spreads as their differences. And this article defines three factors of the term structure of credit spreads: level, slope and curvature. Based on these three factors and several macroeconomic variables, VAR models are developed and tested to forecast macroeconomic variables. The empirical results confirm that VAR models can predict the changes of China's macroeconomy well, which indicates that the term structure of credit spreads contains information of future changes of macroeconomic variables. We believe this result has significant implications for macroeconomy policy-makers. © 2013 Copyright Taylor and Francis Group, LLC. © 2013 Elsevier B.V., All rights reserved.","Zhou, R.; Wang, X.; Tong, G.",2013,10.1080/13504851.2013.806778,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883325066&doi=10.1080%2F13504851.2013.806778&partnerID=40&md5=eafa30b532af4735b80691807774aefd,scopus
5cddc2ece6191d79,Forecasting market trends with neural networks,"Neural networks are just one of the many technologies that are giving businesses a competitive edge.  Neural networks (NN) are a branch of artificial intelligence which has generated considerable interest across many disciplines during the past few years.  An NN is a nonlinear type of model which receives its inspiration from the neural architecture of the human brain.  Three sample neural networks are presented:  1.  real estate assessment, 2.  credit application evaluation, and 3.  Treasury Bill rate forecasting.","Aiken, Milam; Bsat, Mohammad",1999,none,None,proquest
8459fc80a83ccbd0,Forecasting nonlinear green bond yields in China: Deep learning for improved accuracy and policy awareness,"This study develops a convolutional neural network bidirectional long short-term memory model with an attention mechanism to forecast yields in China's green bond market. The model incorporates macroeconomic indicators, financial variables, policy factors, and issuer heterogeneity to enhance predictive accuracy. Empirical results show the model outperforms traditional approaches in point forecasting. It also offers superior robustness under identical confidence levels, increasing its utility for risk management and policy assessment in green finance. It is a practical tool for regulators, investors, and issuers. © 2025 Elsevier B.V., All rights reserved.","Wang, L.; Wang, Y.; Wang, J.; Yu, L.",2025,10.1016/j.frl.2025.107889,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009696841&doi=10.1016%2Fj.frl.2025.107889&partnerID=40&md5=3f3d8b8a179e9671678fa81f21beab95,scopus
cb1a4b16413ff22b,"Forecasting oil prices with penalized regressions, variance risk premia and Google data","This paper investigates whether augmenting models with the variance risk premium (VRP) and Google search data improves the quality of the forecasts for real oil prices. We considered a time sample of monthly data from 2007 to 2019 that includes several episodes of high volatility in the oil market. Our evidence shows that penalized regressions provided the best forecasting performances across most of the forecasting horizons. Moreover, we found that models using the VRP as an additional predictor performed best for forecasts up to 6–12 months ahead forecasts, while models using Google data as an additional predictor performed better for longer-term forecasts up to 12–24 months ahead. However, we found that the differences in forecasting performances were not statistically different for most models, and only the Principal Component Regression (PCR) and the Partial least squares (PLS) regression were consistently excluded from the set of best forecasting models. These results also held after a set of robustness checks that considered model specifications using a wider set of influential variables, a Hierarchical Vector Auto-Regression model estimated with the LASSO, and a set of forecasting models using a simplified specification for Google Trends data. © 2024 Elsevier B.V., All rights reserved.","Lycheva, M.; Mironenkov, A.; Kurbatskii, A.; Fantazzini, D.",2022,10.22394/1993-7601-2022-68-28-49,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148285877&doi=10.22394%2F1993-7601-2022-68-28-49&partnerID=40&md5=96233f97d9b1ad6c3495359610f59ea2,scopus
6af741a2238a82fe,"Forecasting realized volatility: HAR against Principal Components Combining, neural networks and GARCH","This paper examines whether nonlinear models, like Principal Components Combining, neural networks and GARCH are more accurate on realized volatility forecasting than the Heterogeneous Autoregressive (HAR) model. The answer is no. The realized volatility property of persistence is too important to leave out of a realized volatility forecasting model. However, the Principal Components Combining model is ranked very close to HAR. Analysis is implemented in seven US financial markets: spot equity, spot foreign exchange rates, exchange traded funds, equity index futures, US Treasury bonds futures, energy futures, and commodities options. © 2016 Elsevier B.V., All rights reserved.","Vortelinos, D.I.",2017,10.1016/j.ribaf.2015.01.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925263796&doi=10.1016%2Fj.ribaf.2015.01.004&partnerID=40&md5=221cb713631134e38331665696f3cf0c,scopus
43dc1beb6d439217,Forecasting sovereign risk in the Euro area via machine learning,"We test the usefulness of machine learning (ML) for the valuation and pricing of sovereign risk in the Euro area along two important dimensions: i) its predictive accuracy compared with traditional econometric methods, and ii) its assessment of the main economic factors underlying market perceptions of sovereign risk.We find that ML techniques can capture the dynamics inherent in the market valuation of country risk far more efficiently than traditional econometric models, both in the cross‐section and in the time series. Moreover, we show that public sentiment about financial news, redenomination fears and the degree of hawkishness/dovishness expressed in the ECB president's speeches are major contributors to sovereign bond spreads. We also confirm that macroeconomic and global financial factors affect sovereign risk assessment and the corresponding formation of sovereign spreads.","Belly, Guillaume; Boeckelmann, Lukas; Carlos Mateo Caicedo Graciano; Alberto Di Iorio; Istrefi, Klodiana; Siakoulis, Vasileios; Arthur Stalla‐Bourdillon",2023,10.1002/for.2938,None,proquest
e40de4704078dfd2,Forecasting stock market returns with a lottery index: Evidence from China,"This study constructs a Chinese lottery index (LI) based on six popular lottery preference variables by using the partial least squares method and examines the relationship between the LI and future stock market returns during the period from January 2000 to December 2021. We find that the LI can negatively predict stock market excess returns in‐sample and out‐of‐sample. In addition, the LI can generate a large economic gain for a mean–variance investor. Finally, the predictive sources of the LI stem from a cash flow channel and can be explained by the positive volume–volatility relationship and investor attention.","Zhang, Yaojie; Han, Qingxiang; He, Mengxi",2024,10.1002/for.3100,None,proquest
dd4d8625e825c87e,Forecasting stock prices changes using long-short term memory neural network with symbolic genetic programming,"This study introduces an augmented Long-Short Term Memory (LSTM) neural network architecture, integrating Symbolic Genetic Programming (SGP), with the objective of forecasting cross-sectional price returns across a comprehensive dataset comprising 4500 listed stocks in the Chinese market over the period from 2014 to 2022. Using the S&P Alpha Pool Dataset for China as basic input, this architecture incorporates data augmentation and feature extraction techniques. The result of this study demonstrates significant improvements in Rank Information coefficient (Rank IC) and IC information ratio (ICIR) by 1128% and 5360% respectively when it is applied to fundamental indicators. For technical indicators, the hybrid model achieves a 206% increase in Rank IC and an impressive surge of 2752% in ICIR. Furthermore, the proposed hybrid SGP-LSTM model outperforms major Chinese stock indexes, generating average annualized excess returns of 31.00%, 24.48%, and 16.38% compared to the CSI 300 index, CSI 500 index, and the average portfolio, respectively. These findings highlight the effectiveness of SGP-LSTM model in improving the accuracy of cross-sectional stock return predictions and provide valuable insights for fund managers, traders, and financial analysts.","Li, Qi; Kamaruddin, Norshaliza; Yuhaniz, Siti Sophiayati; Al-Jaifi, Hamdan Amer Ali",2024,10.1038/s41598-023-50783-0,None,proquest
547e3e2a7c69aaf4,Forecasting the European Monetary Union equity risk premium with regression trees,"This paper investigates whether classification and regression trees ensemble algorithms such as bagging, random forests and boosting improve on traditional parametric models for forecasting the equity risk premium. In particular, we work with European Monetary Union (EMU) data for the period from its foundation in 2000 to 2020. The paper first compares the monthly out-of-sample forecasting ability of multiple economic and technical variables using univariate linear regression models and regression tree techniques. The results obtained suggest that regression trees do not show better forecasting ability than a first-order autoregressive benchmark model and univariate linear regressions. The paper then analyses asset allocation strategies with regression trees and checks whether these can select the best economic pre-dictors to form dynamic portfolios composed of two assets: a risk-free asset and an equity index. The results indicate that trading strategies built with two or three economic predictors selected with boosting and random forest algorithms can generate economic value for a risk-averse investor with a quadratic utility function. © 2022 Elsevier B.V., All rights reserved.","Cortés-Sánchez, D.; Soriano-Felipe, P.",2022,10.21314/jor.2022.035,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138497197&doi=10.21314%2FJOR.2022.035&partnerID=40&md5=1675b21b61b962828b2cd173adb7b029,scopus
aed67019ca485822,Forecasting the Volatility of US Oil and Gas Firms With Machine Learning,"Forecasting the realized volatility of oil and gas firms is of interest to investors and practitioners trading on the energy spot and derivative markets. In this paper, we assess whether several machine learning (ML) techniques can offer superior forecasts compared to HAR models for predicting realized volatility at the firm level. Moreover, we investigate whether economically motivated variables and technical indicators contain valuable information for forecasting firm volatility beyond those contained in various volatility factors previously identified in the literature. Our results demonstrate that certain ML techniques provide superior forecasting accuracy compared to the benchmark model. Additionally, we identify variables such as the 1‐month treasury bill and the aggregate VIX index as significant drivers of realized firm volatility in the oil and gas industry.","Díaz, Juan D.; Hansen, Erwin; Cabrera, Gabriel",2025,10.1002/for.3245,None,proquest
84691e655de528a2,Forecasting the equity risk premium: The role of technical indicators,"Academic research relies extensively on macroeconomic variables to forecast the U.S. equity risk premium, with relatively little attention paid to the technical indicators widely employed by practitioners. Our paper fills this gap by comparing the predictive ability of technical indicators with that of macroeconomic variables. Technical indicators display statistically and economically significant in-sample and out-of-sample predictive power, matching or exceeding that of macroeconomic variables. Furthermore, technical indicators and macroeconomic variables provide complementary information over the business cycle: technical indicators better detect the typical decline in the equity risk premium near business-cycle peaks, whereas macroeconomic variables more readily pick up the typical rise in the equity risk premium near cyclical troughs. Consistent with this behavior, we show that combining information from both technical indicators and macroeconomic variables significantly improves equity risk premium forecasts versus using either type of information alone. Overall, the substantial countercyclical fluctuations in the equity risk premium appear well captured by the combined information in technical indicators and macroeconomic variables. © 2014 Elsevier B.V., All rights reserved.","Neely, C.J.; Rapach, D.E.; Tu, J.; Zhou, G.",2014,10.1287/mnsc.2013.1838,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897701069&doi=10.1287%2Fmnsc.2013.1838&partnerID=40&md5=e863e6e4d1820309d93770b620ce4674,scopus
cb57365d4beae37e,Forecasting the stock risk premium: A new statistical constraint,"We develop a new statistical constraint to improve the stock return forecasting performance of predictive models. This constraint uses a new objective function that combines the Huber loss function with the Ridge penalty. Out‐of‐sample results indicate that our constraint improves the predictive ability of the univariate models. The constrained univariate models significantly outperform the historical average benchmark model assuming no predictability. The forecast improvement based on the new constraint is also evident for multivariate information methods including forecast combination and diffusion index. The model is capable of capturing time‐varying risk which serves as the potential economic explanation of the improved return predictability. Our results are robust to different evaluation subsamples, validation sample lengths, and different risk aversion coefficients.","Hao, Xianfeng; Wang, Yudong",2023,10.1002/for.2984,None,proquest
019c24267ee95568,Forecasting the term structure of crude oil futures prices with neural networks,"The paper contributes to the limited literature modelling the term structure of crude oil markets. We explain the term structure of crude oil prices using the dynamic Nelson-Siegel model and propose to forecast oil prices using a generalized regression framework based on neural networks. The newly proposed framework is empirically tested on 24. years of crude oil futures prices covering several important recessions and crisis periods. We find 1-month-, 3-month-, 6-month- and 12-month-ahead forecasts obtained from a focused time-delay neural network to be significantly more accurate than forecasts from other benchmark models. The proposed forecasting strategy produces the lowest errors across all times to maturity. © 2017 Elsevier B.V., All rights reserved.","Baruník, J.; Malinská, B.",2016,10.1016/j.apenergy.2015.11.051,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951017088&doi=10.1016%2Fj.apenergy.2015.11.051&partnerID=40&md5=48247872417761781a5c770a7d5dcee8,scopus
04e2f27a592dcab7,Forecasting the term structure of government bond yields,"Despite powerful advances in yield curve modeling in the last 20 years, comparatively little attention has been paid to the key practical problem of forecasting the yield curve. In this paper we do so. We use neither the no-arbitrage approach nor the equilibrium approach. Instead, we use variations on the Nelson-Siegel exponential components framework to model the entire yield curve, period-by-period, as a three-dimensional parameter evolving dynamically. We show that the three time-varying parameters may be interpreted as factors corresponding to level, slope and curvature, and that they may be estimated with high efficiency. We propose and estimate autoregressive models for the factors, and we show that our models are consistent with a variety of stylized facts regarding the yield curve. We use our models to produce term-structure forecasts at both short and long horizons, with encouraging results. In particular, our forecasts appear much more accurate at long horizons than various standard benchmark forecasts. © 2008 Elsevier B.V., All rights reserved.","Diebold, F.X.; Li, C.",2006,10.1016/j.jeconom.2005.03.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-31344448314&doi=10.1016%2Fj.jeconom.2005.03.005&partnerID=40&md5=c1160704fad68807ebd914e62fa33324,scopus
d9e813cb1f5afe0d,Forecasting the term structure of interest rates using integrated nested laplace approximations,"This article discusses the use of Bayesian methods for inference and forecasting in dynamic term structure models through integrated nested Laplace approximations (INLA). This method of analytical approximation allows accurate inferences for latent factors, parameters and forecasts in dynamic models with reduced computational cost. In the estimation of dynamic term structure models it also avoids some simplifications in the inference procedures, such as the inefficient two-step ordinary least squares (OLS) estimation. The results obtained in the estimation of the dynamic Nelson-Siegel model indicate that this method performs more accurate out-of-sample forecasts compared to the methods of two-stage estimation by OLS and also Bayesian estimation methods using Markov chain Monte Carlo (MCMC). These analytical approaches also allow efficient calculation of measures of model selection such as generalized cross-validation and marginal likelihood, which may be computationally prohibitive in MCMC estimations. Copyright © 2014 John Wiley & Sons, Ltd. Copyright © 2014 John Wiley & Sons, Ltd. © 2022 Elsevier B.V., All rights reserved.","Laurini, M.P.; Hotta, L.K.",2014,10.1002/for.2288,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897012994&doi=10.1002%2Ffor.2288&partnerID=40&md5=a252763e08afa540fa05096fdebc11ac,scopus
3341cd39f6436146,Forecasting time series subject to multiple structural breaks,"This paper provides a new approach to forecasting time series that are subject to discrete structural breaks. We propose a Bayesian estimation and prediction procedure that allows for the possibility of new breaks occurring over the forecast horizon, taking account of the size and duration of past breaks (if any) by means of a hierarchical hidden Markov chain model. Predictions are formed by integrating over the parameters from the meta-distribution that characterizes the stochastic break-point process. In an application to U.S. Treasury bill rates, we find that the method leads to better out-of-sample forecasts than a range of alternative methods. © 2006 The Review of Economic Studies Limited. © 2008 Elsevier B.V., All rights reserved.","Pesaran, M.; Pettenuzzo, D.; Timmermann, A.",2006,10.1111/j.1467-937x.2006.00408.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749045516&doi=10.1111%2Fj.1467-937X.2006.00408.x&partnerID=40&md5=5ea9b46ce031cdf0af74247798ef4184,scopus
c0db7e92ec868ec7,Foreign Residency Rights and Corporate Bond Yield Spreads,"We investigate the effect of ultimate controllers' foreign residency rights on corporate bond yield spreads. Using data on Chinese listed firms from 2010 to 2021, this study reveals a positive association between foreign residency rights and corporate bond yield spreads. The positive relationship is robust across different measures of foreign residency rights, estimation methods and after considering potential endogeneity issues. We propose two potential channels for the positive effect of foreign residency rights on corporate bond yield spreads: increasing firms' earnings management and taking more risk. Further, stronger external governance and internal governance alleviate the positive effects of foreign residency rights on corporate bond yield spreads. Additional analyses indicate that ultimate controllers with overseas residency rights are associated with more bond covenants, higher bank loan spreads and shorter loan maturity. Overall, our results indicate that corporate bondholders are fully aware of the expropriation risk created by controllers' foreign residency rights. Thus, investors and regulators in emerging markets should pay attention to controllers' foreign residency rights. © 2025 Elsevier B.V., All rights reserved.","Su, Z.-Q.; Zhu, Y.; Jin, H.; Wu, M.",2025,10.1002/ijfe.70029,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012620539&doi=10.1002%2Fijfe.70029&partnerID=40&md5=e5ab7afd2b6ee1f120a929042e541067,scopus
34890fd3f79a548b,Foreign exchange risk and risk exposure in the Japanese stock market,"Purpose - Whether stock returns are linked to exchange rate changes and whether foreign exchange risk is priced in a domestic context are less conclusive and thus still subject to a great debate. The purpose of this paper is to provide new empirical evidence on these two inter-related issues, which are critical to investors and corporate risk management. Design/methodology/approach - This paper applies two different econometric approaches: Nonlinear Seemingly Unrelated Regression (NLSUR) via Hansen's Generalized Method of Moment (GMM) and multivariate GARCH in mean (MGARCH-M) to examine the exchange rate exposure and its pricing. Findings - Using industry data for Japan, similar to previous studies, foreign exchange risk is not priced based on the test of an unconditional two-factor asset pricing model. However, strong evidence of time-varying foreign exchange risk premium and significant exchange rate betas are obtained based on the tests of conditional asset pricing models using MGARCH-M approach where both conditional first and second moments of industry returns and risk factors are estimated simultaneously. Research limitations/implications - The strong empirical evidence found in this study implies that corporate currency hedging not only results in more stable cash flows for a firm, but also reduces its cost of capital, and hence is justifiable. Originality/value - This paper conducts an in-depth investigation regarding the exchange rate exposure and its pricing by utilizing two different econometric approaches: NLSUR via Hansen's GMM and MGARCH-M. In doing so, a more reliable conclusion about the exchange rate exposure and its pricing can be drawn.","Tai, Chu-Sheng",2010,10.1108/03074351011042991,None,proquest
400f23285a075f7c,Forward contracts for the operation of an electricity industry under spot pricing,A study is reported of the use of forward contracts as risk instruments for electricity industries operating under spot pricing. Forward contracts involve financial transactions or commitments which relate to a physical trade at a later time instance. Price setting and appropriate participant responses are discussed. Simulation studies are used to demonstrate that forward contracts offer participants an opportunity to reduce their risk exposure without removing the incentive to respond to higher spot prices.<>,R. J. Kaye; H. R. Outhred; C. H. Bannister,1990,10.1109/59.49085,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=49085,ieeexplore
aa513308423e330e,"Fractional Black-Scholes option pricing, volatility calibration and implied Hurst exponents in South African context","Background: Contingent claims on underlying assets are typically priced under a framework that assumes, inter alia, that the log returns of the underlying asset are normally distributed. However, many researchers have shown that this assumption is violated in practice. Such violations include the statistical properties of heavy tails, volatility clustering, leptokurtosis and long memory. This paper considers the pricing of contingent claims when the underlying is assumed to display long memory, an issue that has heretofore not received much attention.Aim: We address several theoretical and practical issues in option pricing and implied volatility calibration in a fractional Black-Scholes market. We introduce a novel eight-parameter fractional Black-Scholes-inspired (FBSI) model for the implied volatility surface, and consider in depth the issue of calibration. One of the main benefits of such a model is that it allows one to decompose implied volatility into an independent long-memory component - captured by an implied Hurst exponent - and a conditional implied volatility component. Such a decomposition has useful applications in the areas of derivatives trading, risk management, delta hedging and dynamic asset allocation.Setting: The proposed FBSI volatility model is calibrated to South African equity index options data as well as South African Rand/American Dollar currency options data. However, given the focus on the theoretical development of the model, the results in this paper are applicable across all financial markets.Methods: The FBSI model essentially combines a deterministic function form of the 1-year implied volatility skew with a separate deterministic function for the implied Hurst exponent, thus allowing one to model both observed implied volatility surfaces as well as decompose them into independent volatility and long-memory components respectively. Calibration of the model makes use of a quasi-explicit weighted least-squares optimisation routine.Results: It is shown that a fractional Black-Scholes model always admits a non-constant implied volatility term structure when the Hurst exponent is not 0.5, and that 1-year implied volatility is independent of the Hurst exponent and equivalent to fractional volatility. Furthermore, we show that the FBSI model fits the equity index implied volatility data very well but that a more flexible Hurst exponent parameterisation is required to fit accurately the currency implied volatility data.Conclusion: The FBSI model is an arbitrage-free deterministic volatility model that can accurately model equity index implied volatility. It also provides one with an estimate of the implied Hurst exponent, which could be very useful in derivatives trading and delta hedging.","Flint, Emlyn; Maré, Eben",2017,10.4102/sajems.v20i1.1532,None,proquest
8413a03397041cf2,From Man vs. Machine to Man plus Machine: The art and AI of stock analyses,"An AI analyst trained to digest corporate disclosures, industry trends, and macroeconomic indicators surpasses most analysts in stock return predictions. Nevertheless, humans win Man vs. Machinewhen institutional knowledge is crucial, e.g., involving intangible assets and financial distress. AI wins when information is transparent but voluminous. Humans provide significant incremental value in Man + Machine, which also substantially reduces extreme errors. Analysts catch up with machines after alternative databecome available if their employers build AI capabilities. Documented synergies between humans and machines inform how humans can leverage their advantage for better adaptation to the growing AI prowess.","Cao, Sean; Jiang, Wei; Wang, Junbo; Yang, Baozhong",2024,10.1016/j.jfineco.2024.103910,None,wos
5c50a6dc234cc7e9,Front-Page News: The Effect of News Positioning on Financial Markets,"This paper estimates the effect of news positioning on the speed of price discovery, using exogenous variation in prominent (front-page) positioning of news articles on the Bloomberg terminal. Front-page articles see 240% higher trading volume and 176% larger absolute excess returns during the first 10 minutes after publication than equally important non-front-page articles. Overall, the information in front-page articles is fully incorporated into prices within an hour of publication. The response to non-front-page information of similar importance eventually converges but takes more than two days to be fully reflected in prices.","Fedyk, Anastassia",2024,10.1111/jofi.13287,None,wos
129b8cefa68fea23,Functional Autoregression for Sparsely Sampled Data,"We develop a hierarchical Gaussian process model for forecasting and inference of functional time series data. Unlike existing methods, our approach is especially suited for sparsely or irregularly sampled curves and for curves sampled with nonnegligible measurement error. The latent process is dynamically modeled as a functional autoregression (FAR) with Gaussian process innovations. We propose a fully nonparametric dynamic functional factor model for the dynamic innovation process, with broader applicability and improved computational efficiency over standard Gaussian process models. We prove finite-sample forecasting and interpolation optimality properties of the proposed model, which remain valid with the Gaussian assumption relaxed. An efficient Gibbs sampling algorithm is developed for estimation, inference, and forecasting, with extensions for FAR(p) models with model averaging over the lag p. Extensive simulations demonstrate substantial improvements in forecasting performance and recovery of the autoregressive surface over competing methods, especially under sparse designs. We apply the proposed methods to forecast nominal and real yield curves using daily U.S. data. Real yields are observed more sparsely than nominal yields, yet the proposed methods are highly competitive in both settings. Supplementary materials, including R code and the yield curve data, are available online. © 2019 Elsevier B.V., All rights reserved.","Kowal, D.R.; Matteson, D.S.; Ruppert, D.",2019,10.1080/07350015.2017.1279058,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019636100&doi=10.1080%2F07350015.2017.1279058&partnerID=40&md5=8ef118146d36427daf34c568a470d5cd,scopus
908b5e72a4fe08fa,Functional shocks to inflation expectations and real interest rates and their macroeconomic effects,"This paper applies a recently developed method (Inoue and Rossi, 2021) to estimate functional inflation expectations and ex-ante real interest rate shocks, and then examines their macroeconomic effects in the context of a Functional Vector Autoregressive model with exogenous variables (Functional VARX). Monthly data from January 1998 to May 2023 for the US, the UK and the euro area are used for the analysis. The estimated impulse responses show significant effects of the functional shocks on both inflation and output. In addition, threshold functional local projections indicate that the effects are nonlinear and depend on central bank credibility. Further, inflation expectations shocks have similar effects to supply (demand) ones when they are driven by long-term (short-term) changes. In the presence of an inverted (steepening) real interest rate term structure, the effects are inflationary (deflationary) and expansionary (recessionary). Finally, the responses of inflation, output and the policy rate are driven primarily by the slope and curvature factors of the term structure shocks, which contain important information not captured by traditional scalar shocks.",None,2024,10.1007/s10290-024-00538-4,None,proquest
b6874ce0d132be04,"Funding shortages, expectations, and forward rate risk premium",This paper estimates term risk premium and expected future spot rates embedded in Treasury forward rates to study the impact of short-term funding shortages on these quantities. Our approach is consistent with dynamic equilibrium models and avoids the arbitrage-free dynamic inconsistency problems exhibited by traditional methods. We find that short-term funding shortages in money markets affect both expectations of spot rates and forward rate risk premium for all maturity forward rates. The leverage ratio of intermediaries (primary dealers) significantly affects term risk premium but not expectations of future spot rates. Yield curve inversion has no impact on the forward rate curve's evolution.,"Jarrow, Robert; Lamichhane, Sujan",2022,10.1080/14697688.2022.2057352,None,wos
853f428121b4ba0c,Futures Open Interest and Speculative Pressure Dynamics via Bayesian Models of Long-Memory Count Processes,"In this work, we develop time series regression models for long-memory count processes based on the generalized linear Gegenbauer autoregressive moving average (GLGARMA) framework. We present a comprehensive Bayesian formulation that addresses both in-sample and out-of-sample forecasting within a broad class of generalized count time series regression models. The GLGARMA framework supports various count distributions, including Poisson, negative binomial, generalized Poisson, and double Poisson distributions, offering the flexibility to capture key empirical characteristics such as underdispersion, equidispersion, and overdispersion in the data. We connect the counting process to a time series regression framework through a link function, which is associated with a stochastic linear predictor incorporating the family of long-memory GARMA models. This linear predictor is central to the model's formulation, requiring careful specification of both the GLGARMA Bayesian likelihood and the resulting posterior distribution. To model the stochastic error terms driving the linear predictor, we explore two approaches: parameter-driven and observation-driven frameworks. For model estimation, we adopt a Bayesian approach under both frameworks, leveraging advanced sampling techniques, specifically the Riemann manifold Markov chain Monte Carlo (MCMC) methods implemented via R-Stan. To demonstrate the practical utility of our models, we conduct an empirical study of open interest dynamics in US Treasury Bond Futures. Our Bayesian models are used to forecast speculative pressure, a crucial concept for understanding market behavior and agent actions. The analysis includes 136 distinct time series from the US Commodity Futures Trading Commission (CFTC), encompassing futures-only and futures-and-options data across four US government-issued fixed-income securities. Our findings indicate that the proposed Bayesian GLGARMA models outperform existing state-of-the-art models in forecasting open interest and speculative pressure. These improvements in forecast accuracy directly enhance portfolio performance, underscoring the practical value of our approach for bond futures portfolio construction. This work advances both the methodology for modeling long-memory count processes and its application in financial econometrics, particularly in improving the forecasting of speculative pressure and its impact on investment strategies. © 2025 Elsevier B.V., All rights reserved.","Yan, H.; Peters, G.; Bagnarosa, G.; Chan, J.",2025,10.1002/for.70001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009700778&doi=10.1002%2Ffor.70001&partnerID=40&md5=72ceb973c96f77374b0a2198f1f0c781,scopus
31f65a4ef29b519a,Futures price modeling under exchange rate volatility and its multi-period semi-variance portfolio selection,"Considering the stochastic exchange rate, a four-factor futures model with the underling asset, convenience yield, instantaneous risk-free interest rate and exchange rate, is established. These processes follow jump-diffusion processes (Weiner process and Poisson process). The corresponding partial differential equation (PDE) with terminal boundary condition of the model is drawn. The general solution with parameters of the above PDE is derived. The parameters are estimated by using the weight least squares approach with historical data for special cases. For the objective of risk assessment, downside risk has impacted on the practitioner's view of risk apparently. Variance is substituted by semi-variance. Moreover, one period portfolio selection is extended to multi-period. A class of multi-period semi-variance model is formulated. A hybrid genetic algorithm, which makes use of the position displacement strategy of the particle swarm optimiser as a mutation operation, is applied to solve the multi-period semi-variance model. Finally, in order to demonstrate the effectiveness of the theoretical models and numerical methods, fuel futures in the Shanghai exchange market is selected to be an example. © 2010 Elsevier B.V., All rights reserved.","Yan, W.; Li, S.",2009,10.1080/00207720902985385,https://www.scopus.com/inward/record.uri?eid=2-s2.0-75649121144&doi=10.1080%2F00207720902985385&partnerID=40&md5=76b4efe53044da4e6519f0e46370cf28,scopus
b391e6771a6ea657,G-PINNs: A Bayesian-Optimized GRU-Enhanced Physics-Informed Neural Network for Advancing Short Rate Model Predictions,"Interest rate modeling plays a crucial role in financial risk management, derivative pricing, and economic forecasting. To address the challenges of capturing complex stochastic dynamics, this study proposes a novel Bayesian-Optimized GRU-Enhanced Physics-Informed Neural Network (G-PINNs) architecture, integrated with the Hull–White (HW) short-rate model, to improve the prediction accuracy of yield forecasting, zero-coupon bond (ZCB) pricing, and option pricing. The proposed framework effectively models time dependent variations and stochastic behavior in interest rate dynamics by leveraging Gated Recurrent Units (GRU) for sequential pattern recognition and Physics Informed Neural Networks (PINNs) to enforce financial constraints through partial differential equations (PDEs) of the HW model. For empirical validation, US treasury yield data from April 2020 to March 2025 is utilized. To achieve the best optimal hyperparameters to enhance both predictive accuracy and training efficiency, Bayesian Optimization (BO) is employed for hyperparameter tuning. The proposed model outperforms Vanilla PINNs as evidenced by higher R2 values and reduced error metrics (MAE, MSE, RMSE, Max & Min error, MSLE, Huber loss, MedAE) in yield prediction, ZCB pricing, and option pricing, as indicated by the numerical results. Furthermore, the results are statistically validated through the paired t-test, which confirms that the G-PINNs model's performance improvement is significant and not a consequence of random variation. Also, 5-fold cross-validation is performed to ensure robust and unbiased model evaluation across different data splits. © 2025 Elsevier B.V., All rights reserved.","Rani, I.; Kumar Verma, C.K.",2025,10.1016/j.enganabound.2025.106396,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011519011&doi=10.1016%2Fj.enganabound.2025.106396&partnerID=40&md5=f568c88dee94315797af2ea970c71c42,scopus
9c9a62d1d4915359,"GDP Forecasting: Machine Learning, Linear or Autoregression?","This paper compares the predictive power of different models to forecast the real U.S. GDP. Using quarterly data from 1976 to 2020, we find that the machine learning K-Nearest Neighbour (KNN) model captures the self-predictive ability of the U.S. GDP and performs better than traditional time series analysis. We explore the inclusion of predictors such as the yield curve, its latent factors, and a set of macroeconomic variables in order to increase the level of forecasting accuracy. The predictions result to be improved only when considering long forecast horizons. The use of machine learning algorithm provides additional guidance for data-driven decision making.","Maccarrone, Giovanni; Morelli, Giacomo; Spadaccini, Sara",2021,10.3389/frai.2021.757864,None,wos
e7deb740efeb41c6,Gaussian Weighting Reversion Strategy for Accurate Online Portfolio Selection,"In this paper, we design and implement a new on-line portfolio selection strategy based on reversion mechanism and weighted on-line learning. Our strategy, called “Gaussian Weighting Reversion” (GWR), improves the reversion estimator to form optimal portfolios and effectively overcomes the shortcomings of existing on-line portfolio selection strategies. Firstly, GWR uses Gaussian function to weight data in a sliding window to exploit the “time validity” of historical market data. It means that the more recent data are more valuable for market prediction than the earlier. Secondly, the self-learning for various sliding windows is created to make our strategy adaptive to different markets. In addition, double estimations are first proposed to be made at each time point, and the average of double estimations is obtained to alleviate the influence of noise and outliers. Extensive evaluation on six public datasets shows the advantages of our strategy compared with other nine competing strategies, including the state-of-the-art ones. Finally, the complexity analysis of GWR shows its availability in large-scale real-life online trading.",X. Cai; Z. Ye,2019,10.1109/tsp.2019.2941067,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8834832,ieeexplore
3495aca6d5866e34,Gaussian scale mixture model for estimating volatility as a function of economic factor,"In this paper the scale mixture of Gaussian distribution is used to model the stock return data in financial market. There are many volatility models and forecasting methods. Some of the models are Historical volatility models, Implied volatility models, Autoregressive Conditional Heteroskedasticity models, models based on Artificial Neural Network. All these models are direct models. In these models the influence of economic factors like price level uncertainty, riskless rate of interest, the equity risk premium and the ratio of expected profit to expected revenue for the economy are not taken into account. Here the volatility parameter 'σ' is treated as a function of an economic factor. The main economic factor considered is the ratio of expected profit to expected revenue. Economic ratio is assumed to follow the exponential distribution. The resultant distribution is fitted to Dow Jones Industrial Average (DJIA) data by estimating the parameters. It is observed that this mixture distribution is a better fit than the GARCH fit. © 2016 Elsevier B.V., All rights reserved.","Seethalakshmi, R.; Saavithri, V.; Vijayabanu, C.",2014,10.5829/idosi.wasj.2014.32.06.783,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975509067&doi=10.5829%2Fidosi.wasj.2014.32.06.783&partnerID=40&md5=0af32d633e8e0428f18b827b74333b0b,scopus
de78bdadecbb5d17,Generalist CEOs and Credit Ratings*,"A recent trend is that firms prefer to hire generalist CEOs with transferable skills (across firms or industries) over hiring specialist CEOs, but the consequences of this trend are unclear. In this study, we examine whether credit rating agencies consider a CEO's general skills as a credit risk factor when assessing an entity's overall creditworthiness. We predict and find that generalist CEOs are associated with lower credit ratings, suggesting that the presence of generalist CEOs is a significant credit rating factor. We also find that generalist CEOs are likely to take on more risks, which leads to more volatile performance ex post, and our path analyses confirm default risk is a significant mediator between credit ratings and CEOs' general skills. Our results hold in the presence of additional controls (e.g., CEO characteristics and corporate governance), when applying different fixed‐effect models and different matching methods, and for a subsample with forced CEO turnover. We also find that the negative relationship is attenuated for R&D‐intensive firms and firms in competitive industries. Last, we provide evidence that firms with generalist CEOs face higher borrowing costs, such as bond yields and syndicated loan spreads. Overall, our results contribute to a growing literature on the costs and benefits of hiring generalist CEOs, by providing a full picture of why hiring a generalist CEO may benefit shareholders but also cause misalignments with bondholders' interests.","Ma, Zhiming; Ruan, Lufei; Wang, Danye; Zhang, Haiyan",2021,10.1111/1911-3846.12662,None,proquest
abed275e49b577b6,Generalized Forecast Error Variance Decomposition for Linear and Nonlinear Multivariate Models,"We propose a new generalized forecast error variance decomposition with the attractive property that the proportions of the impact accounted for by innovations in each variable sum to unity. Our decomposition is based on the generalized impulse response function, and it can easily be obtained by simulation. The new decomposition is illustrated in an empirical application to US output growth and interest rate spread data.","Lanne, Markku; Nyberg, Henri",2016,10.1111/obes.12125,None,wos
7ff2a7cb36ec3f22,Generating currency trading rules from the term structure of forward foreign exchange premia,"The quality of an exchange rate forecasting model has typically been judged relative to a random-walk in terms of out-of-sample forecast errors. The difficulty of outperforming this benchmark is well documented, although Clarida and Taylor have demonstrated how the random walk can be beaten in this metric by exploiting information embedded within the term structure of forward exchange rate premia. But this achievement does not guarantee success within an investment context. We therefore assess whether the Clarida-Taylor framework can be used to generate significant trading profits in combination with an acceptable degree of risk in a realistic investment portfolio context. (C) 2013 Published by Elsevier Ltd.","Sager, Michael; Taylor, Mark P.",2014,10.1016/j.jimonfin.2013.03.005,None,wos
246c475ec932cfd5,Global market factors that impact Baltic Dry Index,"The Baltic Dry Index is used as a strategic tool by shipping companies to monitor the daily movement of freight rates for the transportation of bulk cargoes on predetermined routes for the different types of bulk carriers. Therefore, the management of shipping companies pays great attention to the factors that can contribute to the prediction of the price movement of the Baltic Dry Index. Main goal of this paper is to explore if stock market indices of United States of America (S&P 500 stock index) and China (Shanghai stock exchange Composite index), 10 Year bond yield, CRB index, WTI Crude oil and Gold as global market factors, but also as leading macroeconomic global indicators, have impact on movement of BDI. We explored period from January 1, 2003 to December 31, 2021, with monthly data for which the multiple linear regression method was used to analyse mentioned global market factors impact on BDI. The research found that the movement of S&P 500 and SSECI stock indices and CRB index had a positive impact on the movement of BDI, while the movement of Gold and WTI crude oil had negative impact on BDI for the observed period. The scientific contribution of this paper is manifested through observation and exploring relationship of mentioned global market factors with BDI, previous papers observed shorter time period and included macroeconomic indicators which are lagging, together with some global market factors. © 2023 Elsevier B.V., All rights reserved.","Pepur, P.; Peronja, I.; Laća, S.",2022,10.31217/p.36.2.8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144355072&doi=10.31217%2Fp.36.2.8&partnerID=40&md5=477b721368b0945e8012ecc7dd331876,scopus
111d1c4701af692a,Gold Price Prediction Using Two-layer Decomposition and XGboost Optimized by the Whale Optimization Algorithm,"Gold price prediction is of great importance in big data computing and economic sphere. This paper aims to contribute to the study of hybrid models that can be used to forecast the price of gold. In this study, The Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) is employed to decompose a residual term containing complex information following the variational modal decomposition (VMD) and an extreme gradient boosting tree (XGBoost) optimized by the Whale Optimization Algorithm (WOA) is combined to construct the VMD-RES.-CEEMDAN-WOA-XGBoost model. The closing price data of COMEX gold futures from 1 October 2018 to 20 November 2023 were selected as examples of gold futures price. A variety of factors that can affect the price of gold are considered in the research. This study indicates that the combined forecasting model proposed in this paper has superior performance when compared to the other comparison forecasting models evaluated. Furthermore, it has been found through SHAP analysis that the Nasdaq index, silver price, and the yield of US 10-year Treasury bonds are most closely related to the prediction of gold price.","Guo, Yibin; Li, Chen; Wang, Xiang; Duan, Yonghui",2025,10.1007/s10614-024-10736-9,None,proquest
703481e0f3994ee0,"Good volatility, bad volatility, and the cross section of cryptocurrency returns","This paper examines the predictability of realized volatility measures (RVM), especially the realized signed jumps (RSJ), on future volatility and returns. We confirm the existence of volatility persistence and future volatility is more strongly related to the volatility of past positive returns than to that of negative returns in the cryptocurrency market. RSJ-sorted cryptocurrency portfolios yield statistically and economically significant differences in the subsequent portfolio returns. After controlling for cryptocurrency market characteristics and existing risk factors, the differences remain significant. The investor attention explains the predictability of realized jump risk in future cryptocurrency returns.","Zhang, Zehua; Zhao, Ran",2023,10.1016/j.irfa.2023.102712,None,wos
f274dfa7538c8887,Government Bonds of the CIS Countries: Integration Dynamics of Debt Markets in the Context of External Instability,"The paper examines development specifics of government bond markets in the CIS countries. The sample includes Russia, Kazakhstan, Uzbekistan and Azerbaijan, since only these countries, among the CIS members, possess enough government bonds included in the global debt market. The relevance of the study is due to the increasing financial uncertainty, which attracts attention to relatively reliable means of public debt; the need to understand the functioning of debt markets against the background of anti -Russian sanctions and the increasing influence of the State. The aim of the work is to empirically verify the connectivity, integration and predictability of the government bond markets of Russia, Kazakhstan, Uzbekistan and Azerbaijan. Empirical data include daily refinancing rates of national central banks, indices of total government bond yields, G -spreads of international bonds of the countries in relation to the conditionally risk -free US bond yield curve for 2019-2023. The effects of market development features are divided into local, regional and global, such as the reaction to COVID-19 and anti -Russian sanctions after 2022. We use the following methods: dynamics analysis, correlation, factor and regression analysis. The novelty of the research lies in introducing new empirical data into scientific discourse, testing a methodology that allows us to assess the interaction of monetary policies and the functioning of government bond markets, common features and differences in the behavior of these markets before and after the imposition of sanctions against the Russian financial system. We conclude that the integration of the considered markets within the CIS is violated, which poses risks to the effective economic development of the region. We consider the relatively developed and integrated, but poorly predictable markets of Russia and Kazakhstan. Unlike Russia, Kazakhstan has more connectivity regarding its monetary policy, government bond yields and risks. The yield of Azerbaijan's government bonds is influenced by a more developed market of Kazakhstan, especially in terms of risk assessment, but the market itself is developed poorly. Uzbekistan's market is even less integrated and developed.","Romashkina, G. f.; Andrianov, K. v.; Yukhtanova, Yu. A.",2024,10.15838/esc.2024.2.92.8,None,wos
d88500794b020572,Governmental Investment Impacts on the Construction Sector Considering the Liquidity Trap,"Considering the liquidity trap is critical as a primary step for a complete understanding of public investment's impacts on the financial supply and demand within the construction industry during deflationary periods. However, minimal research has been conducted to formulate efficient models that can quantify optimal governmental investments. To bridge the gap, an integrated model of the investment savings-liquidity preference money supply (IS-LM) curve and the dynamic stochastic general equilibrium (DSGE) analysis was developed to investigate the balance of supply and demand during deflation status in addition to the associated spending adjustment mechanisms. The most recent data were analyzed, and the deep parameters were obtained using Bayesian estimation via the Markov chain Monte Carlo (MCMC) technique. The analysis result showed that public investment within economies in a deflationary state, which is in a liquidity trap, are expected to crowd out private investment. Also, due to the issuance of government bonds during deflation, the effect of public investment in this situation is more significant than that during inflation. Therefore, decision makers can use the proposed model to manage and quantify the highway construction and maintenance sector's governmental annual optimal investment. © 2021 Elsevier B.V., All rights reserved.","Alshboul, O.; Shehadeh, A.; Hamedat, O.",2022,10.1061/(asce)me.1943-5479.0001003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122233790&doi=10.1061%2F%28ASCE%29ME.1943-5479.0001003&partnerID=40&md5=f82449215e4cf8df3ce0d0b1678d527e,scopus
0871d13199519d67,Graph-based stock correlation and prediction for high-frequency trading systems,"In this paper, we have implemented a high-frequency quantitative system that can obtain stable returns for the Chinese A-share market, which has been running for more than 3 months (from March 27, 2020 to June 30, 2020) with the expected results. A number of rules and barriers exist in the Chinese A-share market such as trading restrictions and high fees, as well as scarce and expensive hedging tools. It is difficult to achieve stable absolute returns in such a market. Stock correlation analysis and price prediction play an important role to achieve any profitable trading. The portfolio management and subsequent trading decisions highly depend on the results of stock correlation analysis and price prediction. However, it is nontrivial to analyze and predict any stocks, being time-varying and affected by unlimited factors in a given market. Traditional methods only take some certain factors into consideration but ignore others that may be changed dynamically. In this paper, we propose a novel machine learning model named Graph Attention Long Short-Term Memory (GALSTM) to learn the correlations between stocks and predict their future prices automatically. First, a multi-Hawkes Process is used to initial a correlation graph between stocks. This procedure provides a good training start as the multi-Hawkes Processes will be studied on the most saint feature fluctuations with any correlations being statistically significant. Then an attention-based LSTM is built to learn the weighting matrix underlying the dynamic graph. In addition, we also build matching data process plus portfolio management modules to form a complete system. The proposed GALSTM enables us to expand the scope of stock selection under the premise of controlling risks with limited hedging tools in the A-share market, thereby effectively increasing high-frequency excess returns. We then construct a long and short positions combination, select long positions in the A shares of the entire market, and use stock index futures to short. With GALSTM model, the products managed by our fully automatic quantitative trading system achieved an absolute annual return rate of 44.71% and the standard deviation of daily returns is only 0.42% in three months of operation. Only 1 week loss in 13 weeks of running time. © 2021 Elsevier B.V., All rights reserved.","Yin, T.; Liu, C.; Ding, F.; Feng, Z.; Yuan, B.; Zhang, N.",2022,10.1016/j.patcog.2021.108209,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113573353&doi=10.1016%2Fj.patcog.2021.108209&partnerID=40&md5=971f0fc98ae32339efd70adf33e67ef9,scopus
dbf26bba8abe658f,"Green bonds forecasting: evidence from pre-crisis, Covid-19 and Russian–Ukrainian crisis frameworks","PurposeWithout precedent, green bonds confront, for the first time since their emergence, a twofold crisis context, namely the Covid-19-Russian–Ukrainian crisis period. In this context, this paper aims to investigate the connectedness between the two pioneering bond market classes that are conventional and treasury, with the green bonds market.Design/methodology/approachIn their forecasting target, authors use a Support Vector Regression model on daily S&P 500 Green, Conventional and Treasury Bond Indexes for a year from 2012 to 2022.FindingsAuthors argue that conventional bonds could better explain and predict green bonds than treasury bonds for the three studied sub-periods (pre-crisis period, Covid-19 crisis and Covid-19-Russian–Ukrainian crisis period). Furthermore, conventional and treasury bonds lose their forecasting power in crisis framework due to enhancements in market connectedness relationships. This effect makes spillovers in bond markets more sensitive to crisis and less predictable. Furthermore, this research paper indicates that even if the indicators of the COVID-19 crisis have stagnated and the markets have adapted to this rather harsh economic framework, the forecast errors persist higher than in the pre-crisis phase due to the Russian–Ukrainian crisis effect not yet addressed by the literature.Originality/valueThis study has several implications for the field of green bond forecasting. It not only illuminates the market participants to the best market forecasters, but it also contributes to the literature by proposing an unadvanced investigation of green bonds forecasting in Crisis periods that could help market participants and market policymakers to anticipate market evolutions and adapt their strategies to period specificities.","Souhir Amri Amamou; Mouna Ben Daoud; Bargaoui, Saoussen Aguir",2025,10.1108/jes-01-2024-0061,None,proquest
82eadd829f8e6a8b,Habit formation and macroeconomic models of the term structure of interest rates,"This paper introduces a new class of nonaffine models of the term structure of interest rates that is supported by an economy with habit formation. Distinguishing features of the model are that the interest rate dynamics are nonlinear, interest rates depend on lagged monetary and consumption shocks, and the price of risk is not a constant multiple of interest rate volatility. We find that habit persistence can help reproduce the nonlinearity of the spot rate process, the documented deviations from the expectations hypothesis, the persistence of the conditional volatility of interest rates, and the lead-lag relationship between interest rates and monetary aggregates.","Buraschi, Andrea; Jiltsov, Alexei",2007,10.1111/j.1540-6261.2007.01299.x,None,wos
1ffdcdc331372c74,Have trend-following signals in commodity futures markets become less reliable in recent years?,"Various trend-following trading rules have been shown to be valuable for predicting market directions and thus the formulation of investment strategies. However, recent equity market research has provided striking evidence that the predictive power of such rules appears to diminish over time due to increased investor attention and lowered arbitrage barriers. Given that trend-following rules are also very successful and have been widely used in futures markets, we analyze whether a similar effect can be observed for commodity futures contracts. Using a trend regression approach based on time-varying success ratios, we detect significantly higher predictive accuracy for cross-sectional than for time-series strategies. In addition, with the exception of a few commodities, we find no significant trending behavior in trading rule reliability. These results, which are robust in a variety of settings, indicate strong momentum stability in futures markets and justify the application of this class of trading rules in commodity futures investing.","Auer, Benjamin R.",2021,10.1007/s11408-021-00385-5,None,wos
0cdd1e39bd843201,Hawkes-diffusion process and the conditional probability of defaults in the Eurozone,"This study examines market information embedded in the European sovereign CDS (credit default swap) market by analyzing the sovereign CDSs of 13 Eurozone countries from January 1, 2008, to February 29, 2012, which includes the recent Eurozone debt crisis period. We design the conditional probability of defaults for the CDS prices based on the Hawkes-diffusion process and obtain the theoretical prices of CDS indexes. To estimate the model parameters, we calibrate the model prices to empirical prices obtained from individual sovereign CDS term structure data. The estimated parameters clearly explain both cross-sectional and time-series data. Our empirical results show that the probability of a huge loss event sharply increased during the Eurozone debt crisis, indicating a contagion effect. Even countries with strong and stable economies, such as Germany and France, suffered from the contagion effect. We also find that the probability of small events is sensitive to the state of the economy, spiking several times due to the global financial crisis and the Greek government debt crisis. (C) 2015 Elsevier B.V. All rights reserved.","Kim, Jungmu; Park, Yuen Jung; Ryu, Doojin",2016,10.1016/j.physa.2015.12.087,None,wos
27f14e8e035e6ffd,Health and Quality Risk Assessment of Bottled Water,"The risk and quality assessment paper is dedicated to estimation of impact (for human health) of bottled drinking-water package (especially PET one). The investigation is concentrated on using one integral method for different risk types (factors connected with potential carcinogenicity: concentrations of antimony, formaldehyde, diethylhexylphthalate; and organoleptic factors: turbidity, colour, and pH). We imply the nature of organoleptic (quality assessment) factors close to risk ones because their indirect influence on polluting power of chemicals can be amplifying. The acceptable risk levels for these types are fixed as 10-1 and 10-5 respectively. The research is based on Russian and International (principally, American) scientific researches and standards. The calculation of risk metric is proposed to be estimated in dimensionless number (hazard quotient – HQ). HQ can be transformed in probabilistic numbers in conversion to events per million (Risk Index – RI and risk of olfactory-reflectory impact factors, Integral Index of Water Risk). In the article we used the idea of “chronic daily intake” (CDI) as an acceptable risk-free measure of factors of potential carcinogenicity, which is an adequate evaluation of permissible concentration. 5 brands of Russian bottled water were analyzed, it turned out that one of them had an exceeded acceptable level of risk.","Birzul, A N; Pitilyak, D A; Videnin, I I",2019,10.1088/1755-1315/272/2/022142,None,proquest
0249536574416828,Heartbeat classification based on single lead-II ECG using deep learning,"The analysis and processing of electrocardiogram (ECG) signals is a vital step in the diagnosis of cardiovascular disease. ECG offers a non-invasive and risk-free method for monitoring the electrical activity of the heart that can assist in predicting and diagnosing heart diseases. The manual interpretation of the ECG signals, however, can be challenging and time-consuming even for experts. Machine learning techniques are increasingly being utilized to support the research and development of automatic ECG classification, which has emerged as a prominent area of study. In this paper, we propose a deep neural network model with residual blocks (DNN-RB) to classify cardiac cycles into six ECG beat classes. The MIT-BIH dataset was used to validate the model resulting in a test accuracy of 99.51%, average sensitivity of 99.7%, and average specificity of 98.2%. The DNN-RB method has achieved higher accuracy than other state-of-the-art algorithms tested on the same dataset. The proposed method is effective in the automatic classification of ECG signals and can be used for both clinical and out-of-hospital monitoring and classification combined with a single-lead mobile ECG device. The method has also been integrated into a web application designed to accept digital ECG beats as input for analyses and to display diagnostic results.The analysis and processing of electrocardiogram (ECG) signals is a vital step in the diagnosis of cardiovascular disease. ECG offers a non-invasive and risk-free method for monitoring the electrical activity of the heart that can assist in predicting and diagnosing heart diseases. The manual interpretation of the ECG signals, however, can be challenging and time-consuming even for experts. Machine learning techniques are increasingly being utilized to support the research and development of automatic ECG classification, which has emerged as a prominent area of study. In this paper, we propose a deep neural network model with residual blocks (DNN-RB) to classify cardiac cycles into six ECG beat classes. The MIT-BIH dataset was used to validate the model resulting in a test accuracy of 99.51%, average sensitivity of 99.7%, and average specificity of 98.2%. The DNN-RB method has achieved higher accuracy than other state-of-the-art algorithms tested on the same dataset. The proposed method is effective in the automatic classification of ECG signals and can be used for both clinical and out-of-hospital monitoring and classification combined with a single-lead mobile ECG device. The method has also been integrated into a web application designed to accept digital ECG beats as input for analyses and to display diagnostic results.","Issa, Mohamed F; Yousry, Ahmed; Tuboly, Gergely; Juhasz, Zoltan; AbuEl-Atta, Ahmed H; Selim, Mazen M",2023,10.1016/j.heliyon.2023.e17974,None,proquest
48a52c4662bbacda,"Heterogeneity, dividends and complex dynamics in asset pricing; 投资者异质性、分红与资产价格的复杂动态","A lot of empirical researches have shown that the dividend policy can affect investor trading behaviors and price volatility. Different types of Investors may response differently to the dividend policy. For instance, individual investors are insensitive to the dividend policy, while the institutional investors usually prefer to the stocks with stable dividend. Some studies have provided evidences that the unstable dividend may lead to great fluctuations of stock price. In this paper, we attempt to develop a theoretical model based on investor behaviors, and investigate the impacts of dividend policy on price dynamics. In real financial markets, investors are heterogeneous and have asymmetric information. They make trading decisions based on the information they observe and take different trading strategies. Some investors may buy the stock and care about the dividend. Some others may trade based on the fundamentals of the stock. They estimate the fundamental value and buy the stock when the price is below the fundamental value. In this paper, investors are assumed to be boundedly rational, and their behaviors are modeled with the heterogenous agent model. In the model, we consider two types of trading strategies, i. e., the fundamental strategy and the technical strategy. These strategies reflect the heterogeneous expectations of investors. Investors choose between the two strategies according to their performance. The better performance one strategy has, the higher probability the strategy is chosen. The strategy switching mechanism is expressed by the logit response function. It can also depict the dynamics of investor fractions in the market. The price is generated through the trading behaviors of investors. We model the price adjustment process based on the aggregate excess demand. When the aggregate excess demand is positive, the price increases, and vice versa. In Section 1, we establish the model and derive a nonlinear dynamical system, which can characterize the evolutionary dynamics of stock price and investor structure. As it shows, the dynamical system involves a variety of parameters such as investor risk appetites, the level of bounded rationality, market liquidity, trading costs, dividend, fundamental value, and risk-free rate. Using the analysis of dynamical system, we study the impacts of these factors on asset pricing and volatility. In Section 2, we investigate the equilibrium of the dynamical system with mathematical analysis. In the case with rational and homogeneous investors, the equilibrium price equals to the intrinsic value which is determined by dividends. Furthermore, we solve the equilibrium in the case with bounded rational and heterogeneous investors. The equilibrium price is a weighted average of the estimated fundamental value and the intrinsic value. When the estimated fundamental value is equal to the intrinsic value, the equilibrium price is the same as the rational equilibrium price. We study the difference between the estimated fundamental value and the intrinsic value, and analyze its impacts on asset pricing and investor structure. The fraction of fundamentalists in the market is positively correlated with the absolute difference between the estimated fundamental value and the intrinsic value. Moreover, by using the Schur-Cohn criterion, we solve the stability conditions for the equilibrium. The stability conditions are determined by the parameters such as market liquidity, risk appetites and the deviation of the fundamental value from the intrinsic value. To guarantee the stability conditions, the difference between the estimated fundamental value and the intrinsic value should be neither too great nor too small. In Section 3, the simulation analysis is implemented. Under different parameter settings, we investigate the stability region, the bifurcation diagram and the phase portrait. When the stability conditions are not satisfied, the periodic and chaotic dynamics can be observed. The results of this study can explain the empirical findings of previous literatures. If the dividend policy is unstable, the volatility of dividend is great. Then, according to our study, investors would have less demand for stocks, and fundamentalists would take a small proportion in the market. This reflects institutional investors’ preference for dividend policy. In addition, if the dividend policy is unstable, the estimated fundamental value might deviate greatly from the intrinsic value, and the stability conditions cannot be satisfied. As a result, the price might fluctuate greatly. Then, the market might collapse. The findings provide some significant implications for understanding the complex phenomena in financial markets, making dividends policy and implementing market regulations. When companies formulate dividend policies, they should consider investors′ fundamental valuations of stocks, and should not make dividends too low or too high. In addition, market regulators can take measures to promote the disclosure of information, guide investors to have a reasonable valuation of stocks, so as to reduce market instability. © 2024 Elsevier B.V., All rights reserved.","Qingbin, G.; Diao, D.",2024,10.13587/j.cnki.jieem.2024.03.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193751502&doi=10.13587%2Fj.cnki.jieem.2024.03.004&partnerID=40&md5=3e73a674019bd1a2b77639a59c3d526c,scopus
f2f52763d61493da,Heterogeneous Demand and Supply for an Insurance‐linked Credit Product in Kenya: A Stated Choice Experiment Approach,"We employ a discrete choice experiment to elicit demand and supply side preferences for insurance‐linked credit, a promising market‐based tool for managing agricultural weather risks and providing access to credit for farmers. We estimate preference heterogeneity using primary data from smallholder farmers and managers of lenders/insurers combined with household socio‐economic survey data in Kenya. We analyse the choice data using maximum simulated likelihood and Hierarchical Bayes estimation of a mixed logit model. Although there are some similarities, we find that there is conflicting demand and supply side preferences for credit terms, collateral requirements, and loan use flexibility. We also analyse willingness to buy and willingness to offer for farmers and suppliers, respectively, for the risk premium for different attributes and their levels. Identifying the preferred attributes and levels for both farmers and financial institutions can guide optimal packaging of insurance and credit providing market participation and adoption motivation for insurance‐bundled credit product.","Shee, Apurba; Turvey, Calum G; Marr, Ana",2021,10.1111/1477-9552.12401,None,proquest
24c473804012a63d,Heterogeneous beliefs with information processing capacity constraints and asset pricing in a monetary economy,"This paper proposes a monetary model to explore the influences of heterogeneous beliefs and information processing capacity constraints on the dynamics of asset prices. The capacity constraints not only influence the estimations of the capacity constrained investor, but also generate persistent disagreements among the investors. The model implies that reducing the levels of capacity constraints can alleviate the influences of heterogeneous beliefs and helps to stabilize financial markets. The model also reveals that introducing heterogeneous beliefs about both real and nominal sectors not only leads the stock with low monetary policy exposure to have significantly higher average return than the stock with high monetary policy exposure, but also can explain the mixed results about the relationship between the volatility and the risk premium of the aggregate stock market.","Wang, Hailong; Hu, Duni",2024,10.1016/j.najef.2024.102143,None,wos
7711efe41665e70e,Hidden persistent disasters and asset prices,"This study analyzes the effects of agents' learning about hidden persistent economic disasters on asset prices. In this study, it is assumed that aggregate consumption follows a hidden Markov regime-switching process and a representative agent infers the current regime, normal regime, or disaster regime, sequentially from the realized path of the past consumption process. In this setting, the fluctuation in the agent's posterior probabilities of the disaster regime augments the volatility of equity returns. By utilizing the stochastic differential utility, this study demonstrates that the current model can help resolve many asset pricing puzzles including the equity premium puzzle, equity volatility puzzle, and risk-free rate puzzle simultaneously. Further, the current model predicts the counter-cyclical pattern in the equity premium and equity-return volatility on the normal regime, although asset returns are negative and highly volatile during disasters. The study also demonstrates that, if the agent's preferences are restricted to time-additive power utility, the consideration of hidden persistent disasters deepens the asset pricing puzzles. © 2013 Springer-Verlag Berlin Heidelberg. © 2014 Elsevier B.V., All rights reserved.","Suzuki, M.",2014,10.1007/s10436-013-0226-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905013524&doi=10.1007%2Fs10436-013-0226-5&partnerID=40&md5=bbf69d9f4aeb9390f5e08124536c8c25,scopus
33f5d072b20c21b6,Hierarchical Bayesian Models for Regularization in Sequential Learning,"We show that a hierarchical Bayesian modeling approach allows us to perform regularization in sequential learning. We identify three inference levels within this hierarchy: model selection, parameter estimation, and noise estimation. In environments where data arrive sequentially, techniques such as cross validation to achieve regularization or model selection are not possible. The Bayesian approach, with extended Kalman filtering at the parameter estimation level, allows for regularization within a minimum variance framework. A multilayer perceptron is used to generate the extended Kalman filter nonlinear measurements mapping. We describe several algorithms at the noise estimation level that allow us to implement on-line regularization. We also show the theoretical links between adaptive noise estimation in extended Kalman filtering, multiple adaptive learning rates, and multiple smoothing regularization coefficients.",J. F. G. d. Freitas; M. Niranjan; A. H. Gee,2000,10.1162/089976600300015655,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6789428,ieeexplore
b521620833f1dd7a,Hierarchical Bayesian collective risk model: an application to health insurance,"This paper deals with the main statistical steps involved in building an insurance plan, with special emphasis on an application to health insurance. The pure premium is predicted based on the available past information concerning the number and the amount of losses, and also the population exposed to risk. Both the size and the number of losses are treated in a stochastic manner. The claims are assumed to follow a Poisson process and the claim sizes are independent and identically distributed non-negative random variables. The model proposed is a generalization of the collective risk model, usually applied in practice. The evolution of the population at risk is also stochastically described via a nonlinear hierarchical growth model. Furthermore, a theoretical decision framework is adopted for evaluating the premium. Model selection and premium calculation are obtained from the predictive distribution, incorporating all the uncertainties involved.","Migon, H S; Moura, FAS",2005,10.1016/j.insmatheco.2004.11.006,None,proquest
2c4a4637c32b86cb,High frequency online inflation and term structure of interest rates: Evidence from China,"In the digital era, the information value of online prices, characterized by weak price stickiness and high sensitivity to economic shocks, deserves more attention. This paper integrates the high-frequency online inflation rate into the dynamic Nelson-Siegel (DNS) model to explore its relationship with the term structure of interest rates. The empirical results show that the weekly online inflation significantly predicts the yield curve, especially the slope factor, whereas the monthly official inflation cannot predict the yield curve and is instead predicted by the yield curve factors. The mechanism analysis reveals that, due to low price stickiness, online inflation is more sensitive to short-term economic fluctuations and better reflects money market liquidity, thereby having significant predictive power for short-term interest rates and the slope factor. Specifically, online inflation for non-durable goods and on weekdays shows stronger predictive power for the slope factor. The heterogeneity in price stickiness across these categories explains the varying impacts on the yield curve. © 2025 Elsevier B.V., All rights reserved.","Zhang, T.; Tang, K.; Liu, T.; Jiang, T.",2025,10.1016/j.jempfin.2025.101626,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006742365&doi=10.1016%2Fj.jempfin.2025.101626&partnerID=40&md5=3f0e5cbafd7d26ef438cc757b09558ad,scopus
87e3f1fd4dcceed0,Hoarding the herd: the convenience of productive stocks,"This paper investigates the convenience yield that emerges in markets with productive stocks. We isolate the economic fundamentals giving rise to the yield, and show how these map to the empirical convenience yield measure. A model for price dynamics is derived from an economic model for optimal stock levels. We show how the price process reduces to a simple non-linear first-order Markov process. The model is estimated for the Norwegian market for farmed salmon by Generalized Methods of Moments, where stock growth is approximated by sea-water temperature. Our estimation result supports the theorized role of stock growth as a convenience yield component. Our results are relevant for the functioning of futures markets for commodities such as fish and other animal production where systematic stock growth affects the term structure. © 2014 Wiley Periodicals, Inc. Jrl Fut Mark 35:679-694, 2015 Copyright John Wiley & Sons. Reproduced with permission. An electronic version of this article is available online at http://www.interscience.wiley.com","Oglend, Atle; Zhang, Dengjun; Asche, Frank",2015,10.1002/fut.21679,None,proquest
7263c110b7556c6d,"How Are Interbank and Sovereign Debt Markets Linked? Evidence from 14 OECD Countries, the Euro Area and Russia","The paper explores causal linkages between interbank and sovereign bond markets in 14 OECD countries, the Euro area and Russia during the 2008-2009 crisis and post-crisis period. The analysis has been carried out for individual countries and in a multivariate framework. It enables to identify systemically important countries in both markets. The USA, Switzerland, Australia, South Korea and Russia are of particular significance in the interbank lending market. Switzerland, the UK, Poland, Australia and Canada play a pivotal role in the public debt market. The analysis under the multivariate framework reveals substantial heterogeneity in the network structure of both markets. Only 12% of causal relationships coincide, which may fuel financial contagion. Volatility spillovers underlie the causal linkages. They are estimated by means of dynamic volatility indices based on rolling correlation matrices and help identify the transformation of the international banking turmoil into the sovereign debt crisis.","Stolbov, Mikhail",2014,10.2298/pan1403331s,None,wos
13680c9aa7a8de08,How Do Macroeconomic Fundamentals Affect Sovereign Bond Yields? New Evidence from European Forecasts,"Macroeconomic fundamentals impact the long-term insolvency problem of a country. This article empirically assesses the role played by both macroeconomic and fiscal fundamentals, proxied by a set of European Commission's forecasts, in affecting sovereign bond yields. We look at a large panel of 25 European countries between 1992 and 2015. By means panel and time-series approaches, we find that lower short-term interest rates and better fiscal institutions tend to lower bond yields. The better the economic and fiscal outlooks going forward, the lower the yields demanded in international markets. Timing also matters: investors seem to pay more attention to forecasts the shorter the forecast horizon, and they started carrying more weight since the Global Financial Crisis. Finally, the impact of yields' determinants is different across countries, being more prominent in those characterized by economic hardship conditions (Greece, Ireland, Spain, and Portugal). (JEL codes: C23, E44, H68) © 2019 Elsevier B.V., All rights reserved.","Tovar Jalles, J.T.",2019,10.1093/cesifo/ify025,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064515400&doi=10.1093%2Fcesifo%2Fify025&partnerID=40&md5=7535ceeeb760f8019d70ad6693a12d0a,scopus
983957a87777ab21,How Much Can Machines Learn Finance from Chinese Text Data?,"How much can we learn finance directly from text data? This paper presents a new framework for learning textual data based on the factor augmentation model and sparsity regularization, called the factor-augmented regularized model for prediction (FarmPredict), to let machines learn financial returns directly from news. FarmPredict allows the model itself to extract information directly from articles without predefined information, such as dictionaries or pretrained models as in most studies. Using unsupervised learned factors to augment the predictors would benefit our method with a ""doublerobust""feature: that the machine would learn to balance between individual words or text factors/topics. It also avoids the information loss of factor regression in dimensionality reduction. We apply our model to the Chinese stock market with a large proportion of retail investors by using Chinese news data to predict financial returns. We show that positive sentiments scored by our FarmPredict approach from news generate on average 83 basic points (bps) stock daily excess returns, and negative news has an adverse impact of 26 bps on the days of news announcements, where both effects can last for a few days. This asymmetric effect aligns well with the short-sale constraints in the Chinese equity market. The result shows that the machine-learned prediction does provide sizeable predictive power with an annualized return of 54% at most with a simple investment strategy. Compared with other statistical and machine learning methods, FarmPredict significantly outperforms them on model prediction and portfolio performance. Our study demonstrates the far-reaching potential of using machines to learn text data. © 2024 Elsevier B.V., All rights reserved.","Zhou, Y.; Fan, J.; Xue, L.",2024,10.1287/mnsc.2022.01468,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201264430&doi=10.1287%2Fmnsc.2022.01468&partnerID=40&md5=86523d9245d5c88bd1b6868500e9f558,scopus
585f44403016e47b,How do zero-coupon inflation swaps predict inflation rates in the euro area? Evidence of efficiency and accuracy on 1-year contracts,"This paper examines the risk-neutral efficient market hypothesis for inflation swap markets in the euro area from 2005.10 to 2014.07. Overall, we conclude that 1-year zero-coupon inflation swap rates are unbiased predictors of inflation rates. Further, there is no empirical evidence of an inflation risk premium and the assumption of rationality seems to hold. Definitely, these inferences encourage the reading of inflation expectations embedded in short-term inflation swaps. Additionally, we compare the predictive ability of inflation swaps with other measures of inflation expectations. The in-sample results show that, in contrast with surveys, market-based measures are able to accurately forecast inflation rates. In turn, based on an out-of-sample analysis, a straightforward econometric model dominates other sources. Therefore, a combined analysis that uses different sources contributes to a more robust view of future inflation rates.","Ribeiro, Pedro Pires; Curto, Jose Dias",2018,10.1007/s00181-017-1268-8,None,wos
a033461cc1b0a21a,How good are analyst forecasts of oil prices?,"Even though there is a wide consensus that having good oil price forecasts is very valuable for many agents in the economy, results have not been fully satisfactory and there is an ongoing effort to improve their accuracy. Research has explored many different modeling approaches including time series, regressions, and artificial intelligence, among others. Also, many different sources of input data have been used like spot and futures prices, product spreads, and micro and macro variables. This paper explores how useful analyst expected price data are for forecasting when appropriate measures are taken to account for their sparse nature and high volatility. It proposes a multifactor stochastic pricing model, with time-varying risk premiums calibrated with filtered futures and analyst forecasts using a Kalman Filter. The forecasting model is applied to ten years of oil prices and analyst forecasts, from NYMEX and Bloomberg, respectively. Results are very encouraging showing that the model forecasts are much better than the no-change forecasts, commonly used as a benchmark, and better than those from the widely used Bloomberg's Consensus Expected Price Model. We conclude that analyst forecasts are a valuable source of input data that should be considered in future forecasting models.","Cortazar, Gonzalo; Ortega, Hector; Valencia, Consuelo",2021,10.1016/j.eneco.2021.105500,None,proquest
4ad7c5f96fa212c7,How informative are variance risk premium and implied volatility for Value-at-Risk prediction? International evidence,"The aim of this paper is to examine the information embedded in the implied volatility index and the variance risk premium in terms of quantifying market risk for developed and emerging stock markets. The backtesting results indicate that incorporating the relative variance risk premium into the GARCH model, greatly enhances the forecasts of one-day-ahead Value-at-Risk (VaR) for a long trading position in developed markets, while the standard GARCH is the most relevant specification in capturing risk in emerging markets. Results are found to be robust against distressed financial markets and alternative measures of the variance risk premium. Moreover, the empirical evidence shows that the superior performance of these models cannot completely reduce the scope of implied volatility as a risk management tool. Including implied volatility into the GARCH model incurs substantial savings in terms of efficient regulatory capital provisions. (C) 2019 Board of Trustees of the University of Illinois. Published by Elsevier Inc. All rights reserved.","Slim, Skander; Dahmene, Meriam; Boughrara, Adel",2020,10.1016/j.qref.2019.08.006,None,wos
5927b0f01ca92e54,How to Rate the Financial Performance of Private Companies? A Tailored Integrated Rating Methodology Applied to North-Eastern Italian Districts,"This paper contributes to solving the puzzle of assessing the financial performance of private/unlisted companies. The inner characteristics of these companies make the adoption of traditional best practices in estimating risk premia difficult or impossible. Moreover, the lack of market data and comparable information biases the perception of corporate performance and generates the misallocation of credit fundings (both quantities and pricing). Hence, in this paper, we develop an Integrated Rating Methodology (IRM) to estimate a more efficient corporate “return-to-risk” measure. Our IRM is rooted in the seminal “certainty equivalent” model as developed by Lintner in 1965, but we modify it using a shortfall approach, and then compute a “confident equivalent” that is compliant with Fischer Black’s zero-beta model as well as the Basel agreements. An empirical application of the approach is conducted with a sample of 13,583 non-financial SMEs in the north-east regions of Italy, where there is evidence of inefficient bank financing. We back-test our IRM by rating these companies using corporate financial data during the period 2007–2014, which encompasses both the Great Financial Crisis and the European sovereign debt crisis. Our empirical results depict a clear crowding-out effect of credit allocations when we compare our IRM scoring measure with the actual raising ability and the cost of capital relating to these firms. We find that 36% of companies are underfunded, even if they have a superior IRM score, while 27% of them are funded without merit. Interestingly, this last figure is in line with the average non-performing loan ratio provided by official Italian statistics from 2015 to 2020. Therefore, we conclude that our IRM methodology is promising and may be better at estimating risk financing in small private companies (including start-ups) than internal banking models. These initial results will drive our forthcoming research towards creating an IRM 2.0.","Mantovani, Guido Max; Mantovani, Guido Max; Gadzinski, Gregory",2022,10.3390/jrfm15110493,None,proquest
72c1d3b4cb2ecc1d,How to fly to safety without overpaying for the ticket,"For most active investors treasury bonds (govs) provide diversification and thus reduce the risk of a portfolio. These features of govs become particularly desirable in times of elevated risk which materialize in the form of the flight-To-safety (FTS) phenomenon. The FTS for govs provides a shelter during market turbulence and is exceptionally beneficial for portfolio drawdown risk reduction. However, what if the unsatisfactory expected return from treasuries discourages higher bonds allocations? This research proposes a solution to this problem with Deep Target Volatility Equity-Bond Allocation (DTVEBA) that dynamically allocate portfolios between equity and treasuries. The strategy is driven by a state-of-The-Art recurrent neural network (RNN) that predicts next-day market volatility. An analysis conducted over a twelve year out-of-sample period found that with DTVEBA an investor may reduce treasury allocation by two (three) times to get the same Sharpe (Calmar) ratio and overper-forms the S&P500 index by 43% (115%). © 2023 Elsevier B.V., All rights reserved.","Kaczmarek, T.; Grobelny, P.",2023,10.18559/ebr.2023.2.738,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168003715&doi=10.18559%2Febr.2023.2.738&partnerID=40&md5=234075bf4afac4ab4e8170ed913b55f1,scopus
2b243bd486565209,"Human health risk assessment for exposure to BTEXN in an urban aquifer using deterministic and probabilistic methods: A case study of Chennai city, India","The aquifer in Tondiarpet, Chennai, had been severely contaminated with petroleum fuels due to an underground pipeline leakage. Groundwater samples were analyzed quarterly for priority pollutants such as benzene, toluene, ethylbenzene, xylenes, and naphthalene (BTEXN) using purge and trap gas chromatography and mass spectrometer from 2016 to 2018. The maximum concentrations of BTEXN in groundwater at the site were found to be greater than the permissible limits significantly. Among the five sampling locations (MW1, MW2, MW3, MW4, and MW5), mean BTEXN levels were found to be higher near MW2, confirming the source location of petroleum leakage. Human health risk assessment was carried out using deterministic and probabilistic methods for exposure to BTEXN by oral and dermal exposure pathways. Risk analysis indicated that mean cancer and non-cancer risks were many times higher than the allowable limits of 1E-06 and 1 respectively in all age groups (children, teens, and adults), implying the adverse health effects. Oral exposure is predominately contributing (60-80%) to the total health risk in comparison to the dermal exposure route. Variability and uncertainty were addressed using the Monte Carlo simulations and the resultant minimum, maximum, 5th, 95th, and mean percentile risks were predicted. Under the random exposure conditions to BTEXN, it was estimated that the risk would become unacceptable for >98.7% of the exposed population. Based on the sensitivity analysis, exposure duration, and ingestion rate are the crucial variables contributing significantly to the health risk. As part of the risk management, preliminary remediation goals for the study site were estimated, which require >99% removal of the BTEXN contamination for risk-free exposures. It is suggested that the residents of Tondiarpet shouldn't utilize the contaminated groundwater mainly for oral ingestion to lower the cancer incidence related to exposure to BTEXN.The aquifer in Tondiarpet, Chennai, had been severely contaminated with petroleum fuels due to an underground pipeline leakage. Groundwater samples were analyzed quarterly for priority pollutants such as benzene, toluene, ethylbenzene, xylenes, and naphthalene (BTEXN) using purge and trap gas chromatography and mass spectrometer from 2016 to 2018. The maximum concentrations of BTEXN in groundwater at the site were found to be greater than the permissible limits significantly. Among the five sampling locations (MW1, MW2, MW3, MW4, and MW5), mean BTEXN levels were found to be higher near MW2, confirming the source location of petroleum leakage. Human health risk assessment was carried out using deterministic and probabilistic methods for exposure to BTEXN by oral and dermal exposure pathways. Risk analysis indicated that mean cancer and non-cancer risks were many times higher than the allowable limits of 1E-06 and 1 respectively in all age groups (children, teens, and adults), implying the adverse health effects. Oral exposure is predominately contributing (60-80%) to the total health risk in comparison to the dermal exposure route. Variability and uncertainty were addressed using the Monte Carlo simulations and the resultant minimum, maximum, 5th, 95th, and mean percentile risks were predicted. Under the random exposure conditions to BTEXN, it was estimated that the risk would become unacceptable for >98.7% of the exposed population. Based on the sensitivity analysis, exposure duration, and ingestion rate are the crucial variables contributing significantly to the health risk. As part of the risk management, preliminary remediation goals for the study site were estimated, which require >99% removal of the BTEXN contamination for risk-free exposures. It is suggested that the residents of Tondiarpet shouldn't utilize the contaminated groundwater mainly for oral ingestion to lower the cancer incidence related to exposure to BTEXN.","Rajasekhar, Bokam; Nambi, Indumathi M; Govindarajan, Suresh Kumar",2020,10.1016/j.envpol.2020.114814,None,proquest
6dccf983332b4384,Hybrid LSTM–Transformer Architecture with Multi-Scale Feature Fusion for High-Accuracy Gold Futures Price Forecasting,"Amidst global economic fluctuations and escalating geopolitical risks, gold futures, as a pivotal safe-haven asset, demonstrate price dynamics that directly impact investor decision-making and risk mitigation effectiveness. Traditional forecasting models face significant limitations in capturing long-term trends, addressing abrupt volatility, and mitigating multi-source noise within complex market environments characterized by nonlinear interactions and extreme events. Current research predominantly focuses on single-model approaches (e.g., ARIMA or standalone neural networks), inadequately addressing the synergistic effects of multimodal market signals (e.g., cross-market index linkages, exchange rate fluctuations, and policy shifts) and lacking the systematic validation of model robustness under extreme events. Furthermore, feature selection often relies on empirical assumptions, failing to uncover non-explicit correlations between market factors and gold futures prices. A review of the global literature reveals three critical gaps: (1) the insufficient integration of temporal dependency and global attention mechanisms, leading to imbalanced predictions of long-term trends and short-term volatility; (2) the neglect of dynamic coupling effects among cross-market risk factors, such as energy ETF-metal market spillovers; and (3) the absence of hybrid architectures tailored for high-frequency noise environments, limiting predictive utility for decision support. This study proposes a three-stage LSTM–Transformer–XGBoost fusion framework. Firstly, XGBoost-based feature importance ranking identifies six key drivers from thirty-six candidate indicators: the NASDAQ Index, S&P 500 closing price, silver futures, USD/CNY exchange rate, China’s 1-year Treasury yield, and Guotai Zhongzheng Coal ETF. Second, a dual-channel deep learning architecture integrates LSTM for long-term temporal memory and Transformer with multi-head self-attention to decode implicit relationships in unstructured signals (e.g., market sentiment and climate policies). Third, rolling-window forecasting is conducted using daily gold futures prices from the Shanghai Futures Exchange (2015–2025). Key innovations include the following: (1) a bidirectional LSTM–Transformer interaction architecture employing cross-attention mechanisms to dynamically couple global market context with local temporal features, surpassing traditional linear combinations; (2) a Dynamic Hierarchical Partition Framework (DHPF) that stratifies data into four dimensions (price trends, volatility, external correlations, and event shocks) to address multi-driver complexity; (3) a dual-loop adaptive mechanism enabling endogenous parameter updates and exogenous environmental perception to minimize prediction error volatility. This research proposes innovative cross-modal fusion frameworks for gold futures forecasting, providing financial institutions with robust quantitative tools to enhance asset allocation optimization and strengthen risk hedging strategies. It also provides an interpretable hybrid framework for derivative pricing intelligence. Future applications could leverage high-frequency data sharing and cross-market risk contagion models to enhance China’s influence in global gold pricing governance.","Zhao, Yali; Guo Yingying; Wang, Xuecheng",2025,10.3390/math13101551,None,proquest
f85dca55e6510587,"Identifying and Exploiting Alpha in Linear Asset Pricing Models with Strong, Semi-Strong, and Latent Factors","The risk premia of traded factors are the sum of factor means and a parameter vector, we denote by ϕ, which is identified from the cross-sectional regression of α<inf>i</inf> on the vector of factor loadings, β<inf>i</inf>. If ϕ is non-zero, then α<inf>i</inf> are non-zero and one can construct “phi-portfolios” which exploit the systematic components of non-zero alpha. We show that for known values of β<inf>i</inf> and when ϕ is non-zero, there exist phi-portfolios that dominate mean–variance (MV) portfolios. This article then proposes a two-step bias corrected estimator of ϕ and derives its asymptotic distribution allowing for idiosyncratic pricing errors, weak missing factors, and weak error cross-sectional dependence. Small sample results from extensive Monte Carlo experiments show that the proposed estimator has the correct size with good power properties. This article also provides an empirical application to a large number of U.S. securities with risk factors selected from a large number of potential risk factors according to their strength and constructs phi-portfolios and compares their Sharpe ratios to MV and S&P portfolios. © 2025 Elsevier B.V., All rights reserved.","Pesaran, M.H.; Smith, R.P.",2025,10.1093/jjfinec/nbae029,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003408796&doi=10.1093%2Fjjfinec%2Fnbae029&partnerID=40&md5=f1f288926de6bb2574a79c557b5caa70,scopus
b6709facf4548a31,Identifying and measuring the contagion channels at work in the European financial crises,"We investigate the phenomenon of contagion with a special focus on the recent financial crisis, distinguishing four alternative channels, namely the flight-to-quality, flight-to-liquidity, risk premium, and correlated information channels. Specifically, we employ the differences among estimates and impulse response functions across linear and nonlinear models to identify and measure cross-asset contagion. An application to weekly Eurozone data for a 2007–2014 sample reveals that a two-state Markov switching model shows economically weak, though accurately estimated, contagion effects in a crisis regime. These findings are mainly explained by a flight-to-quality channel. Furthermore, we extend our analysis to explore whether European markets may or may not have been subject to contagion when exposed to external shocks, such as those originated from the US subprime crisis. © 2017 Elsevier B.V., All rights reserved.","Guidolin, M.; Pedio, M.",2017,10.1016/j.intfin.2017.01.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009812010&doi=10.1016%2Fj.intfin.2017.01.001&partnerID=40&md5=28b192b2ae5c94f358f7816372c12690,scopus
b4ddb6ca2cc67764,Impact of China’s Provincial Government Debt on Economic Growth and Sustainable Development,"Macroeconomic stability is the core concept of sustainable development. However, the coronavirus disease (COVID-19) pandemic has caused government debt problems worldwide. In this context, it is of practical significance to study the impact of government debt on economic growth and fluctuations. Based on panel data of 30 provinces in China from 2012 to 2019, we used the Mann–Kendall method and Kernel Density estimation to analyze the temporal and spatial evolution of China’s provincial government debt ratio and adopted a panel model and HP filtering method to study the impact of provincial government debt on economic growth and fluctuation. Our findings indicate that, during the sample period, China’s provincial government debt promoted economic growth and the regression coefficient (0.024) was significant. From different regional perspectives, the promotion effect of the central region (0.027) is higher than that of the eastern (0.020) and western regions (0.023). There is a nonlinear relationship between China’s provincial government debt and economic growth, showing an inverted “U-shaped” curve. Fluctuations in government debt aggravate economic volatility, with a coefficient of 0.009; tax burden fluctuation and population growth rate aggravate economic changes. In contrast, the optimization of the province’s industrial structure and the improvement of the opening level of provinces slow down economic fluctuations.","Yang, Wanping; Zhang, Zhenya; Zhang, Zhenya; Wang, Yajuan; Wang, Yajuan; Deng, Peidong; Guo, Luyao",2022,10.3390/su14031474,None,proquest
b1f77f14c23e3395,Impact of Wind Electricity Forecasts on Bidding Strategies,"The change in the generation mix from conventional electricity sources to renewables has important implications for bidding behaviour and may have an impact on prices. The main goal of this work is to discover the role played by expected wind production, together with other relevant factors, in explaining the day-ahead market price through a data panel model. The Spanish market, given the huge increase in wind generation observed in the last decade, has been chosen for this study as a paradigmatic example. The results obtained suggest that wind power forecasts are a new key determinant for supply market participants when bidding in the day-ahead market. We also provide a conservative quantification of the effect of such trading strategies on marginal prices at an hourly level for a specific year in the sample. The consequence has been an increase in marginal price to levels higher than what could be expected in a context with notable wind penetration. Therefore, the findings of this work are of interest to practitioners and regulators and support the existence of a wind risk premium embedded in electricity prices to compensate for the uncertainty of wind production.","Ballester, Cristina; Furio, Dolores",2017,10.3390/su9081318,None,wos
40a4f9a58fc4e15c,Implementation Tests of Financial Market Analysis by Text Mining,"In this study, we propose a new text-mining method for long-term market analysis. Using our method, we performe out-of-sample tests using monthly price data of financial markets; Japanese government bond market, Japanese stock market, and the yen-dollar market. First we extract feature vectors from monthly reports of Bank of Japan. Then, trends of each market are estimated by regression analysis using the feature vectors. As a result of comparison with support vector regression, the proposal method could forecast in higher accuracy about both the level and direction of long-term market trends. Moreover, our method showed high returns with annual rate averages as a result of the implementation test.","Izumi, Kiyoshi; Goto, Takashi; Matsui, Tohgoroh",2011,10.1527/tjsai.26.313,None,proquest
2bf3df700a0b5572,Implied Filtering Densities on the Hidden State of Stochastic Volatility,"Abstract: We formulate and analyse an inverse problem using derivative prices to obtain an implied filtering density on volatility’s hidden state. Stochastic volatility is the unobserved state in a hidden Markov model (HMM) and can be tracked using Bayesian filtering. However, derivative data can be considered as conditional expectations that are already observed in the market, and which can be used as input to an inverse problem whose solution is an implied conditional density on volatility. Our analysis relies on a specification of the martingale change of measure, which we refer to as separability. This specification has a multiplicative component that behaves like a risk premium on volatility uncertainty in the market. When applied to SPX options data, the estimated model and implied densities produce variance-swap rates that are consistent with the VIX volatility index. The implied densities are relatively stable over time and pick up some of the monthly effects that occur due to the options’ expiration, indicating that the volatility-uncertainty premium could experience cyclic effects due to the maturity date of the options. © 2015 Elsevier B.V., All rights reserved.","Fuertes, C.; Papanicolaou, A.",2014,10.1080/1350486x.2014.891357,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926101307&doi=10.1080%2F1350486X.2014.891357&partnerID=40&md5=3c8204565e0f0de1bea8624f18a14859,scopus
1ff0c33a84a29bac,Implied volatility sentiment: a tale of two tails,"We propose a sentiment measure jointly derived from out-of-the-money index puts and single stock calls: implied volatility (IV-) sentiment. In contrast to implied correlations, our measure uses information from the tails of the risk-neutral densities from these two markets rather than across their entire moneyness structures. We find that IV-sentiment measure adds value over and above traditional factors in predicting the equity risk premium out-of-sample. Forecasting results are superior when constrained ensemble models are used vis-à-vis unregularized machine learning techniques. In a mean-reversion strategy, our IV-sentiment measure delivers economically significant results, with limited exposure to a set of cross-sectional equity factors, including Fama and French's five factors, the momentum factor and the low-volatility factor, and seems valuable in preventing momentum crashes. Our novel measure reflects overweight of tail events, which we interpret as a behavioral bias. However, we cannot rule out a risk-compensation rationale. © 2020 Elsevier B.V., All rights reserved.","Félix, L.; Kräussl, R.; Stork, P.",2020,10.1080/14697688.2019.1696018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078861813&doi=10.1080%2F14697688.2019.1696018&partnerID=40&md5=411cec64c69eb2f534d55dd481c69d0b,scopus
53eaa29638130e5b,Implied volatility surface predictability: The case of commodity markets,"Recent literature seek to forecast implied volatility derived from equity, index, foreign exchange, and interest rate options using latent factor and parametric frameworks. Motivated by increased public attention borne out of the financialization of futures markets in the early 2000s, we investigate if these extant models can uncover predictable patterns in the implied volatility surfaces of the most actively traded commodity options between 2006 and 2016. Adopting a rolling out-of-sample forecasting framework that addresses the common multiple comparisons problem, we establish that, for energy and precious metals options, explicitly modeling the term structure of implied volatility using the Nelson-Siegel factors produces the most accurate forecasts. © 2019 Elsevier B.V., All rights reserved.","Kearney, F.; Shang, H.L.; Sheenan, L.",2019,10.1016/j.jbankfin.2019.105657,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072749898&doi=10.1016%2Fj.jbankfin.2019.105657&partnerID=40&md5=725a9ef86c2c5b30331c554ee665baeb,scopus
5f39172024a62f24,Improving CAT bond pricing models via machine learning,"Enhanced machine learning methods provide an encouraging alternative to forecast asset prices by extending or generalizing the possible model specifications compared to conventional linear regression methods. Even if enhanced methods of machine learning in the literature often lead to better forecasting quality, this is not clear for small asset classes, because in small asset classes enhanced machine learning methods may potentially over-fit the in-sample data. Against this background, we compare the forecasting performance of linear regression models and enhanced machine learning methods in the market for catastrophe (CAT) bonds. We use linear regression with variable selection, penalization methods, random forests and neural networks to forecast CAT bond premia. Among the considered models, random forests exhibit the highest forecasting performance, followed by linear regression models and neural networks. © 2020 Elsevier B.V., All rights reserved.","Götze, T.; Gürtler, M.; Witowski, E.",2020,10.1057/s41260-020-00167-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089556740&doi=10.1057%2Fs41260-020-00167-0&partnerID=40&md5=43b235afab54d4b10b4bcae23c45d2d9,scopus
8a92241a88c5f917,Improving Quality of Long-Term Bond Price Prediction Using Artificial Neural Networks,"Purpose: The aim of this paper is to propose nonlinear autoregressive neural network which can improve quality of bond price forecasting.Methodology/Approach: Due to the complex nature of market information that influence bonds, artificial intelligence could be accurate, robust and fast choice of bond price prediction method.Findings: Our results have reached a coefficient of determination higher than 95% in the training, validation and testing sets. Moreover, we proposed the nonlinear autoregressive network with external inputs using 50 year interest-rate swaps denominated in EUR and volatility index VIX as two external variables.Research Limitation/Implication: Our sample of daily prices between 4th January 2016 and 13th January 2021 (totally 1,270 trading days) suggest that both Levenberg-Marquardt and Scaled conjugate gradient learning algorithms achieved excellent results.Originality/Value of paper: Despite the fact that both learning algorithms achieved satisfying outcomes, implementation of an independent variable into the autoregressive neural network environment had no significant impact on prediction ability of the model.Category: Research paper","Verner, Robert; Tkac, Michal, Sr.; Tkac, Michal, Jr.",2021,10.12776/qip.v25i1.1532,None,wos
a28fca24b7615f52,Improving credit risk assessment in P2P lending with explainable machine learning survival analysis,"Recent research using explainable machine learning survival analysis demonstrated its ability to identify new risk factors in the medical field. In this study, we adapted this methodology to credit risk assessment. We used a comprehensive dataset from the Estonian P2P lending platform Bondora, consisting of over 350,000 loans and 112 features with a loan volume of 915 million euros. First, we applied classical (linear) and machine learning (extreme gradient-boosted) Cox models to estimate the risk of these loans and then risk-rated them using risk stratification. For each rating category we calculated default rates, rates of return, and plotted Kaplan–Meier curves. These performance criteria revealed that the boosted Cox model outperformed both the classical Cox model and the platform’s rating. For instance, the boosted model’s highest rating category had an annual excess return of 18% and a lower default rate compared to the platform’s best rating. Second, we explained the machine learning model’s output using Shapley Additive Explanations. This analysis revealed novel nonlinear relationships (e.g., higher risk for borrowers over age 55) and interaction effects (e.g., between age and housing situation) that provide promising avenues for future research. The machine-learning model also found feature contributions aligning with existing research, such as lower default risk associated with older borrowers, females, individuals with mortgages, or those with higher education. Overall, our results reveal that explainable machine learning survival analysis excels at risk rating, profit scoring, and risk factor analysis, facilitating more precise and transparent credit risk assessments. © 2024 Elsevier B.V., All rights reserved.","Bone-Winkel, G.F.; Reichenbach, F.",2024,10.1007/s42521-024-00114-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208063837&doi=10.1007%2Fs42521-024-00114-3&partnerID=40&md5=818beb0a3f30b92b63502ce3db0e3345,scopus
2fbd206d2b574353,Improving the Accuracy of Forecasting the TSA Daily Budgetary Fund Balance Based on Wavelet Packet Transforms,"Improving the accuracy of cash flow forecasting in the TSA is the key to fulfilling government payment obligations, minimizing the cost of maintaining the cash reserve, providing the absence of outstanding debt accumulation, and ensuring investment in various financial instruments to obtain additional income. The article describes a method for improving the accuracy of forecasting a time series composed of daily budgetary fund balances in the TSA, based on its preliminary decomposition using a discrete wavelet packet transform of the Daubechies family. This makes it possible to increase the accuracy of traditional forecasting methods from 80% to more than 96%. The decomposition level varied from one to eight to minimize the mean absolute error and improve the forecasting accuracy. Calculations of statistical tests for adequacy confirm the effectiveness of the proposed method for improving forecasting accuracy. The scientific novelty of the proposed method for improving the forecasting accuracy of time series from daily budgetary fund balances in the TSA lies in proving the need for preliminary timeseries decomposition and subsequent construction of forecasts for the obtained parts, resulting in high forecasting accuracy. The result differs significantly from traditional econometric methods (ARIMA/SARIMA), characterized by a much lower accuracy (50–80%) and a decrease in forecasting accuracy with an increase in the forecast horizon. This article is novel, as it forms a new approach to solving the problem of increasing the efficiency of using budgetary funds, associated with improving the accuracy of forecasting daily budgetary fund balance in the TSA.","Karaev, Alan K; Gorlova, Oksana S; Sedova, Marina L; Ponkratov, Vadim V; Shmigol, Nataliya S; Demidova, Svetlana E",2022,10.3390/joitmc8030107,None,proquest
17c70911a878167b,Incorporating Markov decision process on genetic algorithms to formulate trading strategies for stock markets,"With the arrival of low interest rates, investors entered the stock market to seek higher returns. However, the stock market proved volatile, and only rarely could investors gain excess returns when trading in real time. Most investors use technical indicators to time the market. However the use of technical indicators is associated with problems, such as indicator selection, use of conflicting versus similar indicators. Investors thus have difficulty relying on technical indicators to make stock market investment decisions. This research combines Markov decision process and genetic algorithms to propose a new analytical framework and develop a decision support system for devising stock trading strategies. This investigation uses the prediction characteristics and real-time analysis capabilities of the Markov decision process to make timing decisions. The stock selection and capital allocation employ string encoding to express different investment strategies for genetic algorithms. The parallel search capabilities of genetic algorithms are applied to identify the best investment strategy. Additionally, when investors lack sufficient money and stock, the architecture of this study can complete the transaction via credit transactions. The experiments confirm that the model presented in this research can yield higher rewards than other benchmarks. © 2017 Elsevier B.V., All rights reserved.","Chang, Y.-H.; Lee, M.-S.",2017,10.1016/j.asoc.2016.09.016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994403308&doi=10.1016%2Fj.asoc.2016.09.016&partnerID=40&md5=7f450fb3552c013c98635d476b9fe7e5,scopus
78d04132c4e91fcb,Incorporating Research Reports and Market Sentiment for Stock Excess Return Prediction: A Case of Mainland China,"The prediction of stock excess returns is an important research topic for quantitative trading, and stock price prediction based on machine learning is receiving more and more attention. This article takes the data of Chinese A-shares from July 2014 to September 2017 as the research object, and proposes a method of stock excess return forecasting that combines research reports and investor sentiment. The proposed method measures individual stocks released by analysts, separates the two indicators of research report attention and rating sentiment, calculates investor sentiment based on external market factors, and uses the LSTM model to represent the time series characteristics of stocks. The results show that (1) the accuracy and F1 evaluation indicators are used, and the proposed algorithm is better than the benchmark algorithm. (2) The performance of deep learning LSTM algorithm is better than traditional machine learning algorithm SVM. (3) Investor sentiment as the initial hidden state of the model can improve the accuracy of the algorithm. (4) The attention of the split research report takes the two indicators of investor sentiment and price as the input of the model, which can effectively improve the performance of the model.","Song, Huilin; Peng, Diyun; Huang, Xin",2020,10.1155/2020/8894757,None,proquest
345281eb8dc19585,Incorporating economic indicators and market sentiment effect into US Treasury bond yield prediction with machine learning,"Accurate prediction of US Treasury bond yields is crucial for investment strategies and economic policymaking. This paper explores the application of advanced machine learning techniques, specifically Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM) models, in forecasting these yields. By integrating key economic indicators and policy changes, our approach seeks to enhance the precision of yield predictions. Our study demonstrates the superiority of LSTM models over traditional RNNs in capturing the temporal dependencies and complexities inherent in financial data. The inclusion of macroeconomic and policy variables significantly improves the models’ predictive accuracy. This research underscores a pioneering movement for the legacy banking industry to adopt artificial intelligence (AI) in financial market prediction. In addition to considering the conventional economic indicator that drives the fluctuation of the bond market, this paper also optimizes the LSTM to handle situations when rate hike expectations have already been priced-in by market sentiment. © 2024 Elsevier B.V., All rights reserved.","Li, Z.; Wang, B.; Chen, Y.",2024,10.24294/jipd.v8i9.7671,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204238837&doi=10.24294%2Fjipd.v8i9.7671&partnerID=40&md5=7603a9906c2d14dd96d306253e3a6399,scopus
049416f83ae200ea,"Indian equity options: Smile, risk premiums, and efficiency","We study the pricing of equity options in India which is one of the world's largest options markets. Our findings are supportive of market efficiency: A parsimonious smile-adjusted Black model fits option prices well, and the implied volatility (IV) has incremental predictive power for future volatility. However, the risk premium embedded in IV for Single Stock Options appears to be higher than in other markets. The study suggests that even a very liquid market with substantial participation of global institutional investors can have structural features that lead to systematic departures from the behavior of a fully rational market while being microefficient.","Jain, Sonali; Varma, Jayanth R.; Agarwalla, Sobhesh Kumar",2019,10.1002/fut.21971,None,wos
03b10f7fa6784a1a,Indicator variables for inflation expectations in the Euro area,"In this paper, we model the Euro area market-based inflation expectations extracted from the inflation-linked swaps, and study the macroeconomic information embedded in expected inflation. First, we estimate the Gaussian affine term structure model to decompose the forward ILS-implied inflation rate into inflation expectations and inflation risk premium at one-, two- and three-year horizons. Secondly, from a large panel of macroeconomic series we identify the most significant indicator variables for inflation expectations using the elastic net modification of the LASSO regression. Finally, we measure partial contributions of individual indicator variables to the changes in inflation expectations. Our findings reveal that across horizons considered inflation expectations are correlated to the measures of current inflation of the overall price level and price level of services, the unemployment rate, and the Euro exchange rate. The identified indicators provide a useful information about the evolution of inflation expectations with different intensities at different horizons.","Masten, Igor; Maver, Vida",2021,10.1504/ijse.2021.114615,None,proquest
cf9e82b6c1d97962,Industry bubbles and unexpected consumption shocks: A cross-sectional explanation of stock returns under recursive preferences,"Assuming an environment with rational and informed agents, where investors exhibit recursive preferences and make their economic decisions embedding industry bubbles into their information sets, we study to what extent unexpected consumption shocks can proxy for revisions in expected consumption growth and, consequently, explain the cross-sectional behavior of stock returns. Our results show that unexpected consumption shocks help forecast future consumption growth, allowing the Epstein-Zin model to satisfactorily explain the equity risk premium of different anomaly portfolios on the Tokyo Stock Exchange. Furthermore, our model provides a better understanding on the dynamics of consumption and its relationship to stock returns. © 2023 Elsevier B.V., All rights reserved.","Rojo-Suárez, J.; Alonso-Conde, A.B.; Lago-Balsalobre, R.",2024,10.1016/j.iref.2023.07.086,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169004311&doi=10.1016%2Fj.iref.2023.07.086&partnerID=40&md5=d9b4ad7092203f77787e79d262f307c7,scopus
716bd56fb97759d4,Inference in Bayesian additive vector autoregressive tree models,"Vector autoregressive (VAR) models assume linearity between the endogenous variables and their lags. This assumption might be overly restrictive and could have a deleterious impact on forecasting accuracy. As a solution we propose combining VAR with Bayesian additive regression tree (BART) models. The resulting Bayesian additive vector autoregressive tree (BAVART) model is capable of capturing arbitrary nonlinear relations between the endogenous variables and the covariates without much input from the researcher. Since controlling for heteroscedasticity is key for producing precise density forecasts, our model allows for stochastic volatility in the errors. We apply our model to two datasets. The first application shows that the BAVART model yields highly competitive forecasts of the U.S. term structure of interest rates. In a second application we estimate our model using a moderately sized Eurozone dataset to investigate the dynamic effects of uncertainty on the economy. © 2023 Elsevier B.V., All rights reserved.","Huber, F.; Rossini, L.",2022,10.1214/21-aoas1488,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127778413&doi=10.1214%2F21-AOAS1488&partnerID=40&md5=742157785b372051b99fe7333df16fb0,scopus
2d6d353747309f2d,Inference in asset pricing models with a low-variance factor,"This paper concerns with the effects of including a low-variance factor in an asset pricing model. When a low-variance factor is present, the commonly applied Fama-MacBeth two-pass regression procedure is very likely to yield misleading results. Local asymptotic analysis and simulation evidence indicate that the risk premiums corresponding to all factors are very likely to be unreliably estimated. Moreover, t- and F-statistics are less likely to detect whether the risk premiums are significantly different from zero. We recommend Kleibergen's (2009)FAR statistic when there is a low-variance factor included in an asset pricing model. All rights reserved, Elsevier","Shang, H",2013,10.1016/j.jbankfin.2012.11.007,None,proquest
f02729ef603cf0e9,Inference on co-integration parameters in heteroskedastic vector autoregressions,"We consider estimation and hypothesis testing on the coefficients of the co-integrating relations and the adjustment coefficients in vector autoregressions driven by shocks which display both conditional and unconditional heteroskedasticity of a quite general and unknown form. We show that the conventional results in Johansen (1996) for the maximum likelihood estimators and associated likelihood ratio tests derived under homoskedasticity do not in general hold under heteroskedasticity. As a result, standard confidence intervals and hypothesis tests on these coefficients are potentially unreliable. Solutions based on Wald tests (using a sandwich estimator of the variance matrix) and on the use of the wild bootstrap are discussed. These do not require the practitioner to specify a parametric model for volatility. We establish the conditions under which these methods are asymptotically valid. A Monte Carlo simulation study demonstrates that significant improvements in finite sample size can be obtained by the bootstrap over the corresponding asymptotic tests in both heteroskedastic and homoskedastic environments. An application to the term structure of interest rates in the US illustrates the difference between standard and bootstrap inferences regarding hypotheses on the co-integrating vectors and adjustment coefficients. (C) 2015 Elsevier B.V. All rights reserved.","Boswijk, H. Peter; Cavaliere, Giuseppe; Rahbek, Anders; Taylor, A. M. Robert",2016,10.1016/j.jeconom.2015.07.005,None,wos
65827861f45c0f78,Inflation Prediction Method Based on Deep Learning,"Forward-looking forecasting of the inflation rate could help the central bank and other government departments to better use monetary policy to stabilize prices and prevent the impact of inflation on market entities, especially for low- and middle-income groups. It can also help financial institutions and investors better make investment decisions. In this sense, the forecast of inflation rate is of great significance. The existing literature mainly uses linear models such as autoregressive (AR) and vector autoregressive (VAR) models to predict the inflation rate. The nonlinear relationship between variables and the mining of historical data information are relatively lacking. Therefore, the prediction strategies and accuracy of the existing literature need to be improved. The predictive model designed in deep learning can fully mine the nonlinear relationship between variables and process complex long-term time series dynamic information, thereby making up for the deficiencies of existing research. Therefore, this paper employs the recurrent neural networks with gated recurrent unit (GRU-RNN) model to train and analyze the Consumer Price Index (CPI) indicators to obtain inflation-related prediction results. The experimental results on historical data show that the GRU-RNN model has good performance in predicting China's inflation rate. In comparison, the performance of the proposed method is significantly better than some traditional models, showing its superior effectiveness.","Yang, Cheng; Guo, Shuhua",2021,10.1155/2021/1071145,None,wos
701ad234b9ed241c,Inflation bets or deflation hedges? the changing risks of nominal bonds,"The covariance between US Treasury bond returns and stock returns has moved considerably over time. While it was slightly positive on average in the period 1953 to 2014, it was unusually high in the early 1980s and negative in the early 21st Century, particularly in the downturns of 2001 and 2007 to 2009. This paper specifies and estimates a model in which the nominal term structure of interest rates is driven by four state variables: the real interest rate, temporary and permanent components of expected inflation, and the nominalreal covariance of inflation and the real interest rate with the real economy. The last of these state variables enables the model to fit the changing covariance of bond and stock returns. In the model, a high nominal-real covariance implies a high term premium and a concave yield curve. The decline in this covariance since the early 1980s has driven down our model-implied term premium on 10-year zero-coupon nominal Treasury bonds by about two percentage points. © 2018 Elsevier B.V., All rights reserved.","Campbell, J.Y.; Sunderam, A.; Viceira, L.M.",2017,10.1561/104.00000043,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019756733&doi=10.1561%2F104.00000043&partnerID=40&md5=d1ab4f1d0502d33a087d900282246a09,scopus
475fb32ab8e4049d,Informed Trading and Return Predictability in China: Research Based on Ensemble Neural Network,"We construct a new informed trading index based on the high-frequency trading data of the Chinese A-share market using the ensemble neural network algorithm. We find that the informed trading index is a strong negative predictor of future aggregate stock market returns, with monthly in-sample and out-of-sample (Formula presented.) of 5.45% and 3.53%, respectively, which is far greater than the predictive power of other previously studied informed trading indicators and macroeconomic variables. The asset allocation strategy based on our index can generate large economic gains for the mean-variance investors, with annualized CER (certain equivalent return) gains ranging from 10.91% to 7.80% as the investor’s risk appetite varies. The driving force of the predictive power appears to stem from the liquidity provider role that informed traders play, which decreases the market’s illiquidity risk and lowers the risk premium of equity. Our analysis complements the returns predictability study by adding a new predictor on the one hand and informs market timing strategies on the other. © 2024 Elsevier B.V., All rights reserved.","Li, P.; Yang, L.",2025,10.1080/1540496x.2024.2379471,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200154249&doi=10.1080%2F1540496X.2024.2379471&partnerID=40&md5=45cabd8cde831077ff35ce5455b1167b,scopus
07ccec1141e89737,Institutional investor attention and stock market volatility and liquidity: international evidence,"In this paper, we examine the influence of the daily institutional investor attention to particular stocks on stock volatility and liquidity. The institutional investor attention is measured from the number of times that users of Bloomberg terminal, who are mostly institutional investors, search for or read articles on a specific stock. Relying on a large international dataset of approximately a million daily observations over the period 2011-2020 from nine countries (Canada, France, Germany, Japan, Russia, South Korea, Switzerland, the UK, and the US), we find that this recent measure of institutional investor attention has a strong positive effect on stock volatility and liquidity. Confirmed by a battery of robustness tests, our findings suggest that this continuous barometer of attention by institutional investors can be used by financial practitioners to predict future stock volatility and liquidity.","El Ouadghiri, Imane; Erragragui, Elias; Jaballah, Jamil; Peillex, Jonathan",2022,10.1080/00036846.2022.2036689,None,wos
7cad7bb9373c17b7,Integrated methodology for estimating zero-coupon yield curves: Evidence from Turkish government nominal bonds,"This study estimates the zero-coupon yield curves for Turkish government nominal bonds from February 2005 to June 2022 using the Nelson–Siegel–Svensson parametric model. We implement a weighting scheme in the objective function, where squared pricing errors are weighted by the inverse of the square root of the bond duration. This weighting scheme strikes a better balance between the short- and long-maturity bonds during the optimization process. Moreover, by employing four nonlinear optimization algorithms and three parameter initialization approaches, we aim to prevent premature convergence to local optima and improve the quality of fit. Our integrated methodology yields reasonably low in-sample root mean squared error values for price errors and offers clear guidance and a framework for researchers in constructing zero-coupon yield curves. © 2025 Elsevier B.V., All rights reserved.","Paçcı, M.Ü.; Okay, N.",2025,10.1016/j.bir.2025.05.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006716439&doi=10.1016%2Fj.bir.2025.05.003&partnerID=40&md5=89e8caa6f97eab08251fe089078164ce,scopus
c98db5fb581ab79d,Integrated prediction of green bond return under the dual risks of climate change and energy crisis,"Prediction of bond return is a classic problem in financial area, providing an important basis for portfolio construction and risk management. The sustainable investment attribute of green bonds has been favored by investors, so that green bonds have become an important component for major asset allocation. However, due to the specific investment focus of green bonds, investors' return expectations are influenced not only by traditional corporate bond factors, but also by related factors such as climate change and energy transition. Against the backdrop of increasingly severe climate risks and the global energy crisis, this paper analyses the volatility characteristics of China's green bonds at multiple time scales, and introduces exogenous variables such as returns of the alternative financial assets, climate risks and returns of energy markets for prediction. Based on the LSTM model, the volatility of green bond yield at different time scales is separately predicted using optimal exogenous variable before integration. It is found that the new integrated prediction model can significantly improve the forecasting performance compared to traditional single LSTM models and simple decomposition-integrated models. Further, both climate risks and energy markets variables have a significant improvement effect on predicting green bond in low-frequency item, while energy markets variables also have a better predictive effect on trend items. Building on the use of only LSTM model, it could be further enhanced by integrating more algorithms to select the best single model for each component, further improve the prediction accuracy and provide a more effective quantitative tool for investment decision-making and risk management in related fields.","Nie, Qimiao; Chen, Siying; Chen, Yiming; Hu, Yiguo",2023,10.3389/fenvs.2023.1336867,None,wos
6b96cc3b210ad231,Intelligent Optimization Based Multi-Factor Deep Learning Stock Selection Model and Quantitative Trading Strategy,"With the rapid development of financial research theory and artificial intelligence technology, quantitative investment has gradually entered people's attention. Compared with traditional investment, the advantage of quantitative investment lies in quantification and refinement. In quantitative investment technology, quantitative stock selection is the foundation. Without good stock selection ability, the effect of quantitative investment will be greatly reduced. Therefore, this paper builds an effective multi-factor stock selection model based on intelligent optimization algorithms and deep learning and proposes corresponding trading strategies based on this. First of all, this paper selects 26 effective factors of financial indicators, technical indicators and public opinion to construct the factor database. Secondly, a Gated Recurrent Unit (GRU) neural network based on the Cuckoo Search (CS) optimization algorithm is used to build a stock selection model. Finally, a quantitative investment strategy is designed, and the proposed multi-factor deep learning stock selection model based on intelligent optimization is applied to practice to test its effectiveness. The results show that the quantitative trading strategy based on this model achieved a Sharpe ratio of 127.08%, an annualized rate of return of 40.66%, an excess return of 13.13% and a maximum drawdown rate of -17.38% during the back test period. Compared with other benchmark models, the proposed stock selection model achieved better back test performance.","Wang, Jujie; Zhuang, Zhenzhen; Feng, Liu",2022,10.3390/math10040566,None,wos
04ea9823b9217dee,Intelligent forecasting in bitcoin markets,"This paper examines the effectiveness of Artificial Intelligence (AI) in predicting Bitcoin's price movements. To achieve this, we developed two distinct trading strategies and compared their performance against each other and the traditional Buy and Hold (B&H) strategy. Over the period from January 2018 to September 2023, we found that the strategy optimized by ChatGPT 01-Preview, which integrates multiple technical indicators and sentiment analysis into a weighted composite index, delivered an exceptional total return of 944.85 %. The second strategy, that is using Extreme Gradient Boosting (XGBoost) technique achieved a total return of 189.05 %. The AI strategy's excess return of 755.8 % over the XGBoost strategy highlights the significant advantage of AI particularly in utilizing diverse data sources, such as social media, to predict Bitcoin's price trends more effectively than relying solely on economic data. Both trading strategies significantly outperformed the traditional B&H strategy, which returned 73.08 % over the same period. Furthermore, we found that AI has an advantage during periods of high Bitcoin price volatility. © 2024 Elsevier B.V., All rights reserved.","Cohen, G.; Aiche, A.",2025,10.1016/j.frl.2024.106487,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209232540&doi=10.1016%2Fj.frl.2024.106487&partnerID=40&md5=73aba1a778a03fbc9a4a154ac9f78596,scopus
46aa043b290272aa,Inter-Factor Determinants of Return Reversal Effect with Dynamic Bayesian Network Analysis: Empirical Evidence from Pakistan,"Bayesian Networks are multivariate probabilistic factor graphs that are used to assess underlying factor relationships. From January 2005 to December 2018, the study examines how Dynamic Bayesian Networks can be utilized to estimate portfolio risk and return as well as determine inter-factor relationships among reversal profit-generating components in Pakistan's emerging market (PSX). The goal of this article is to uncover the factors that cause reversal profits in the Pakistani stock market. In visual form, Bayesian networks can generate causal and inferential probabilistic relationships. Investors might update their stock return values in the network simultaneously with fresh market information, resulting in a dynamic shift in portfolio risk distribution across the networks. The findings show that investments in low net profit margin, low investment, and high volatility-based designed portfolios yield the biggest dynamical reversal profits. The main triggering aspects related to generation reversal profits in the Pakistan market, in the long run, are net profit margin, market risk premium, investment, size, and volatility factor. Investors should invest in and build portfolios with small companies that have a low price-to-earnings ratio, small earnings per share, and minimal volatility, according to the most likely explanation.","Haque, Abdul; Rao, Marriam; Qamar, Muhammad Ali Jibran",2022,10.13106/jafeb.2022.vol9.no3.0203,None,wos
f383135eb5699171,Interest Rate Based on The Lie Group SO(3) in the Evidence of Chaos,"This paper aims to test the structure of interest rates during the period from 1 September 1981 to 28 December 2020 by using Lie algebras and groups. The selected period experienced substantial events impacting interest rates, such as the economic crisis, the military intervention of the USA in Iraq, and the COVID-19 pandemic, in which economies were in lockdown. These conditions caused the interest rate to have a nonlinear structure, chaotic behavior, and outliers. Under these conditions, an alternative method is proposed to test the random and nonlinear structure of interest rates to be evolved by a stochastic differential equation captured on a curved state space based on Lie algebras and group. Then, parameter estimates of this equation were obtained by OLS, NLS, and GMM estimators (hereafter, LieNLS, LieOLS, and LieGMM, respectively). Therefore, the interest rates that possess nonlinear structures and/or chaotic behaviors or outliers were tested with LieNLS, LieOLS, and LieGMM. We compared our LieNLS, LieOLS, and LieGMM results with the traditional OLS, NLS, and GMM methods, and the results favor the improvement achieved by the proposed LieNLS, LieOLS, and LieGMM in terms of the RMSE and MAE in the out-of-sample forecasts. Lastly, the Lie algebras with NLS estimators exhibited the lowest RMSE and MAE followed by the Lie algebras with GMM, and the Lie algebras with OLS, respectively.","Bildirici, Melike; Ucan, Yasemen; Lousada, Sérgio; Lousada, Sérgio",2022,10.3390/math10213998,None,proquest
9e2b52f34baf3156,Interest Rate Model With Investor Attitude and Text Mining,"This paper develops and estimates an interest rate model with investor attitude factors, which are extracted by a text mining method. First, we consider two contrastive attitudes (optimistic versus conservative) towards uncertainties about Brownian motions driving economy, develop an interest rate model, and obtain an empirical framework of the economy consisting of permanent and transitory factors. Second, we apply the framework to a bond market under extremely low interest rate environment in recent years, and show that our three-factor model with level, steepening and flattening factors based on different investor attitudes is capable of explaining the yield curve in the Japanese government bond (JGB) markets. Third, text mining of a large text base of daily financial news reports enables us to distinguish between steepening and flattening factors, and from these textual data we can identify events and economic conditions that are associated with the steepening and flattening factors. We then estimate the yield curve and three factors with frequencies of relevant word groups chosen from textual data in addition to observed interest rates. Finally, we show that the estimated three factors, extracted only from the bond market data, are able to explain the movement in stock markets, in particular Nikkei 225 index.",S. Nakatani; K. G. Nishimura; T. Saito; A. Takahashi,2020,10.1109/access.2020.2992477,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9086462,ieeexplore
b5ff09ccbbe072af,Interest rate fluctuations and the UK financial services industry,"The article explores the relationship between short-term interest rates and the equity returns of the UK financial services industry. Based on the arbitrage pricing theory, the present study seeks to answer the sensitivity and pricing questions. The former is tested with a linear two-index model attempting to identify any interest rate risk exposure of these stock returns. The latter, however, is examined using a nonlinear multivariate analysis based on the Seemingly Unrelated Regression Equations (SURE) model by imposing cross- and within-equation constraints on the estimated parameters. The econometric analysis unveils a significant negative interest rate effect and the existence of a risk premium incorporated in the expected returns of portfolios consisting of these stocks. © 2007 Elsevier B.V., All rights reserved.","Artikis, P.; Kalotychou, E.; Staikouras, S.K.",2007,10.1080/17446540601118319,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548570513&doi=10.1080%2F17446540601118319&partnerID=40&md5=519a8765fc7ddc63aca544b961ed56b8,scopus
471849c4c2e8e8d5,Interest rate models on Lie groups,"This paper examines an alternative approach to interest rate modeling, in which the nonlinear and random behavior of interest rates is captured by a stochastic differential equation evolving on a curved state space. We consider as candidate state spaces the matrix Lie groups; these offer not only a rich geometric structure, butunlike general Riemannian manifoldsalso allow for diffusion processes to be constructed easily without invoking the machinery of stochastic calculus on manifolds. After formulating bilinear stochastic differential equations on general matrix Lie groups, we then consider interest rate models in which the short rate is defined as linear or quadratic functions of the state. Stochastic volatility is also augmented to these models in a way that respects the Riemannian manifold structure of symmetric positive-definite matrices. Methods for numerical integration, parameter identification, pricing, and other practical issues are addressed through examples.","Park, F. C.; Chun, C. M.; Han, C. W.; Webber, N.",2011,10.1080/14697680903468963,None,wos
7a23cbb917fcc583,"Interest rate next-day variation prediction based on hybrid feedforward neural network, particle swarm optimization, and multiresolution techniques","Multiresolution analysis techniques including continuous wavelet transform, empirical mode decomposition, and variational mode decomposition are tested in the context of interest rate next-day variation prediction. In particular, multiresolution analysis techniques are used to decompose interest rate actual variation and feedforward neural network for training and prediction. Particle swarm optimization technique is adopted to optimize its initial weights. For comparison purpose, autoregressive moving average model, random walk process and the naive model are used as main reference models. In order to show the feasibility of the presented hybrid models that combine multiresolution analysis techniques and feedforward neural network optimized by particle swarm optimization, we used a set of six illustrative interest rates; including Moody's seasoned Aaa corporate bond yield, Moody's seasoned Baa corporate bond yield, 3-Month, 6-Month and 1-Year treasury bills, and effective federal fund rate. The forecasting results show that all multiresolution-based prediction systems outperform the conventional reference models on the criteria of mean absolute error, mean absolute deviation, and root mean-squared error. Therefore, it is advantageous to adopt hybrid multiresolution techniques and soft computing models to forecast interest rate daily variations as they provide good forecasting performance. © 2021 Elsevier B.V., All rights reserved.","Lahmiri, S.",2016,10.1016/j.physa.2015.09.061,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945945078&doi=10.1016%2Fj.physa.2015.09.061&partnerID=40&md5=68bb4b64f208c7540f7135a221279046,scopus
ae189095c8b70524,Interest rate prediction: a neuro-hybrid approach with data preprocessing,"The following research implements a differential evolution-based fuzzy-type clustering method with a fuzzy inference neural network after input preprocessing with regression analysis in order to predict future interest rates, particularly 3-month T-bill rates. The empirical results of the proposed model is compared against nonparametric models, such as locally weighted regression and least squares support vector machines, along with two linear benchmark models, the autoregressive model and the random walk model. The root mean square error is reported for comparison.","Mehdiyev, Nijat; Enke, David",2014,10.1080/03081079.2014.883386,None,wos
2f9cd73a4b3f546d,Interest rate spreads as predictors of German inflation and business cycles,"We have studied the comparative performance of a number of interest rate spreads as predictors of the German inflation and business cycle in the post-Bretton Woods era. The two-regime Markov-switch model that we used as a nonlinear filter allows the dynamic behavior of the economy to vary between expansions and recessions in terms of duration and volatility. We found that the bank term structure, the public term structure, and the spread based on the call rate predicted all recessions with a comfortable lead, although they lagged some of the recoveries by a few months. The bank-public spread generates a series of false signals, and missed completely the upturn in the mid-1970s, but detected the last two recoveries with an average lead of nearly 12 months. The source of the predictive power of interest rate spreads lies in the information they contain not only about monetary policy, but also about an assortment of general macroeconomic shocks. The filter probabilities from three of the interest rate differentials also foreshadowed the long swings in the German inflation rate remarkably well, with a lead time of 2-4 years without any false signals. © International Institute of Forecasters. © 2017 Elsevier B.V., All rights reserved.","Ivanova, D.; Lahiri, K.; Seitz, F.",2000,10.1016/s0169-2070(99)00029-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0010061067&doi=10.1016%2FS0169-2070%2899%2900029-1&partnerID=40&md5=7b914d1774858e720fa00fff034fe499,scopus
770dcddf8d700ba0,Interest rate term structure modeling using free-knot splines,"In this article a new methodology for estimating the term structure of interest rates is developed. Using polynomial splines, a reliable approximation to term structure may depend crucially upon intelligent selection of numbers and position of spline knots, which can be a combinatorially very complex task. A different approach based on heuristic optimization techniques called genetic algorithms is presented. The optimal spline function takes into account the goodness of fit of the spline function. The new methodology was applied to estimating the term structure using data on zero-coupon Euro market bonds. © 2006 by The University of Chicago. All rights reserved. © 2011 Elsevier B.V., All rights reserved.","Fernández-Rodríguez, F.",2006,10.1086/508009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847039555&doi=10.1086%2F508009&partnerID=40&md5=8d8b9389b44d5169d8cc6a2819340341,scopus
e1ac05598dcf5552,Interest rates mapping,"The present study deals with the analysis and mapping of Swiss franc interest rates. Interest rates depend on time and maturity, defining term structure of the interest rate curves (IRC). In the present study IRC are considered in a two-dimensional feature space-time and maturity. Exploratory data analysis includes a variety of tools widely used in econophysics and geostatistics. Geostatistical models and machine learning algorithms (multilayer perceptron and Support Vector Machines) were applied to produce interest rate maps. IR maps can be used for the visualisation and pattern perception purposes, to develop and to explore economical hypotheses, to produce dynamic asset-liability simulations and for financial risk assessments. The feasibility of an application of interest rates mapping approach for the IRC forecasting is considered as well. © 2008 Elsevier Ltd. All rights reserved. © 2008 Elsevier B.V., All rights reserved.","Kanevski, M.; Maignan, M.; Pozdnoukhov, A.; Timonin, V.",2008,10.1016/j.physa.2008.02.069,https://www.scopus.com/inward/record.uri?eid=2-s2.0-42649101653&doi=10.1016%2Fj.physa.2008.02.069&partnerID=40&md5=3d37fefbc596802a878a5487263c92be,scopus
e259919b32e771b4,International evidence on the predictability of return to securitized real estate assets: Econometric models versus neural networks,"The performance of various statistical models and commonly used financial indicators for forecasting securitised real estate returns are examined for five European countries: the UK, Belgium, the Netherlands, France and Italy. Within a VAR framework, it is demonstrated that the gilt-equity yield ratio is in most cases a better predictor of securitized returns than the term structure or the dividend yield. In particular, investors should consider in their real estate return models the predictability of the gilt-equity yield ratio in Belgium, the Netherlands and France, and the term structure of interest rates in France. Predictions obtained from the VAR and univariate time-series models are compared with the predictions of an artificial neural network model. It is found that, whilst no single model is universally superior across all series, accuracy measures and horizons considered, the neural network model is generally able to offer the most accurate predictions for 1-month horizons. For quarterly and half-yearly forecasts, the random walk with a drift is the most successful for the UK, Belgian and Dutch returns and the neural network for French and Italian returns. Although this study underscores market context and forecast horizon as parameters relevant to the choice of the forecast model, it strongly indicates that analysts should exploit the potential of neural networks and assess more fully their forecast performance against more traditional models. © 2004 Elsevier Science B.V., Amsterdam. All rights reserved.","Brooks, C.; Tsolacos, S.",2003,10.1080/0959991032000109517,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0141671708&doi=10.1080%2F0959991032000109517&partnerID=40&md5=551008a304241f4cd4b10fcc00d8a1bf,scopus
84ac3579499de299,Interval forecasting. An analysis based upon ARCH-quantile estimators,"In this paper we explore techniques for obtaining interval forecasts based on estimated time-series models for processes which may exhibit autoregressive conditional heteroskedasticity (ARCH). To deal with the available variety of possible interval forecasts, we propose a method for combining these forecasts based on quantile regression techniques. Our approach is practical rather than theoretical, with attention focused directly on obtaining interval forecasts for two U.S. time series: a measure of unemployment and a Treasury bill rate. We evaluate the performance of our procedures using a variety of diagnostics. We find interval estimates which perform reasonably well, judged by both in-sample and out-of-sample criteria. Our experience suggests that a certain amount of care is required in order to obtain useful forecasts. © 1989. © 2014 Elsevier B.V., All rights reserved.","Granger, C.W.J.; White, H.; Kamstra, M.",1989,10.1016/0304-4076(89)90031-6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-38249026075&doi=10.1016%2F0304-4076%2889%2990031-6&partnerID=40&md5=38e979d6b16ecea739e87e183cf50b40,scopus
835037460463ea4b,Intraday technical trading in the foreign exchange market,"This paper examines the out-of-sample performance of intraday technical trading strategies selected using two methodologies, a genetic program and an optimized linear forecasting model. When realistic transaction costs and trading hours are taken into account, we find no evidence of excess returns to the trading rules derived with either methodology. Thus, our results are consistent with market efficiency. We do find, however, that the trading rules discover some remarkably stable patterns in the data. © 2003 Elsevier Science Ltd. All rights reserved. © 2019 Elsevier B.V., All rights reserved.","Neely, C.J.; Weller, P.A.",2003,10.1016/s0261-5606(02)00101-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037375935&doi=10.1016%2FS0261-5606%2802%2900101-8&partnerID=40&md5=23d064c24d32aa4af4ee08497bfe753f,scopus
ad94029bc09772d2,Introduction to m-m processes,"In this paper, we introduce a new type of nonlinear model, called the min-max model, and analyze its properties for a pair of series. The stability conditions of this system are given for a nonlinearly integrated bivariate series. Under these stability conditions, the difference between the two series exhibits threshold-type nonlinearity. It is possible to construct a threshold error correction model from the min-max processes. Neglected nonlinearity tests are applied, both to the univariate series and to the bivariate system, in order to detect nonlinearity, and it turns out that the tests using the bivariate series have better power. We apply the min-max model to U.S. Treasury bills and commercial paper interest rates. The spread of these interest rates shows threshold-type nonlinearity, and this model outperforms a linear model in terms of its predictability for out-of-sample data. © 2005 Elsevier B.V. All rights reserved. © 2008 Elsevier B.V., All rights reserved.","Granger, C.W.J.; Hyung, N.",2006,10.1016/j.jeconom.2004.09.013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-28244490968&doi=10.1016%2Fj.jeconom.2004.09.013&partnerID=40&md5=9e94f88585e6c3c302b12e0c1abef8a6,scopus
f8e4b18d78c3c3ad,Investigation of the Financial Stability of S&P 500 Using Realized Volatility and Stock Returns Distribution,"In this work, the financial data of 377 stocks of Standard & Poor’s 500 Index (S&P 500) from the years 1998–2012 with a 250-day time window were investigated by measuring realized stock returns and realized volatility. We examined the normal distribution and frequency distribution for both daily stock returns and volatility. We also determined the beta-coefficient and correlation among the stocks for 15 years and found that, during the crisis period, the beta-coefficient between the market index and stock’s prices and correlation among stock’s prices increased remarkably and decreased during the non-crisis period. We compared the stock volatility and stock returns for specific time periods i.e., non-crisis, before crisis and during crisis year in detail and found that the distribution behaviors of stock return prices has a better long-term effect that allows predictions of near-future market behavior than realized volatility of stock returns. Our detailed statistical analysis provides a valuable guideline for both researchers and market participants because it provides a significantly clearer comparison of the strengths and weaknesses of the two methods.","Akter, Nahida; Nobi, Ashadun",2018,10.3390/jrfm11020022,None,proquest
5f6fd09a9aa772ab,Investment Portfolio Allocation and Insurance Solvency: New Evidence from Insurance Groups in the Era of Solvency II,"This study examines the effect of the investment portfolio structure on insurers’ solvency, as measured by the Solvency Capital Requirement ratio. An empirical sample of 88 EU-based insurance groups was analyzed to provide robust evidence of the portfolio’s impact on the Solvency Capital Requirement ratio from 2016 to 2022. Linear regression and supervised machine learning models, particularly extra trees regression, were used to predict the solvency ratios, with the latter outperforming the former. The investigation was supplemented with panel data analysis. Firm-specific factors, including, unit-linked and index-linked liabilities, firm size, investments in property, collective undertakings, bonds and equities, and the ratio of government bonds to corporate bonds and country-specific factors, such as life and non-life market concentration, domestic bond market development, private debt development, household spending, banking concentration, non-performing loans, and CO<inf>2</inf> emissions, were found to have an important effect on insurers’ solvency ratios. The novelty of this research lies in the investigation of the connection of solvency ratios with variables that prior studies have not yet explored, such as portfolio asset allocation, the life and non-life insurance market concentration, and unit-linked and index-linked products, via the employment of a battery of traditional and machine enhanced methods. Furthermore, it identifies the relation of solvency ratios with bond market development and investments in collective undertakings. Finally, it addresses the substantial solvency risks posed by the high banking sector concentration to insurers under Solvency II. © 2024 Elsevier B.V., All rights reserved.","Poufinas, T.; Siopi, E.",2024,10.3390/risks12120191,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213010620&doi=10.3390%2Frisks12120191&partnerID=40&md5=89d1209f8fc21c4be96e743edb1fe259,scopus
6106d7247b95d1cc,Investor Attention and Stock Returns,"We propose an investor attention index based on proxies in the literature and find that it predicts the stock market risk premium significantly, both in sample and out of sample, whereas every proxy individually has little predictive power. The index is extracted using partial least squares, but the results are similar by the scaled principal component analysis. Moreover, the index can deliver sizable economic gains for mean-variance investors in asset allocation. The predictive power of the investor attention index stems primarily from the reversal of temporary price pressure and from the stronger forecasting ability for high-variance stocks.","Chen, Jian; Tang, Guohao; Yao, Jiaquan; Zhou, Guofu",2022,10.1017/s0022109021000090,None,proquest
85c477dfff28cf7e,Investor Sentiment and Bond Risk Premia: Evidence from China,"This article shows the statistical signi?cance of a set of variables related to market sentiment and uses them to predict the risk premium embedded in China's sovereign bonds. We construct a composite index of market-wide investor sentiment as a linear combination of proxies for a degree of market participation and risk appetite of investors. Further, we show that these sentiment-related factors can be summarized in a single-return forecasting factor, similar in a spirit of Cochrane and Piazzesi (2005). Our empirical results show that this sentiment factor has predictive power beyond that contained in the yield curve and macroeconomic variables, and this predictability is robust for out-of-sample testing. In addition, the predictive power of the sentiment factor shows relevance during the 2008 global financial crisis, indicating that the forecasting ability of investor sentiment is mainly derived by a sentiment-induced flight-to-quality.","Lee, Kiryoung; Kim, Minki",2019,10.1080/1540496x.2018.1466276,None,wos
57b422147c25c2e6,Investor attention and FX market volatility,"We study the relationship between investors' active attention, measured by a Google search volume index (SVI), and the dynamics of currency prices. Investor attention is correlated with the trading activities of large FX market participants. Investor attention comoves with contemporaneous FX market volatility and predicts subsequent FX market volatility, after controlling for macroeconomic fundamentals. In addition, investor attention is related to the currency risk premium. Our results suggest that investor attention is a priced source of risk in FX markets. © 2015 Elsevier B.V., All rights reserved.","Goddard, J.; Kita, A.; Wang, Q.",2015,10.1016/j.intfin.2015.05.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931270574&doi=10.1016%2Fj.intfin.2015.05.001&partnerID=40&md5=74e9e7e91322306d1e91a40836ecb27b,scopus
26003fee30aeb702,Investor attention and Google Search Volume Index: Evidence from an emerging market using quantile regression analysis,"This study investigates whether the investor attention measured by the Google Search Volume Index (GSVI) is effective in forecasting stock returns. The evolving literature on investor attention suggests that higher GSVI can predict higher returns for the first one or two weeks, but with a subsequent price reversal. We use a more recent dataset that covers S&P BSE 500 companies listed on the Indian stock exchange for 2012-2017 and employ the quantile regression approach because it alleviates the statistical problems arising from biased distribution data. The results suggest that a higher GSVI predicts positive and significant returns in the subsequent first and second weeks. Higher quantiles of GSVI experience higher excess returns. The panel cointegration test results support the findings regarding the cointegration of the GSVI and stock returns. Our empirical evidence shows that our model is robust when using a trading strategy based on the Fama-French four-factor model. Thus, the model with GSVI acts as a better predictor of both the direction and magnitude of the excess returns than the model without GSVI.","Swamy, Vighneswara; Dharani, M.; Takeda, Fumiko",2019,10.1016/j.ribaf.2019.04.010,None,wos
e73d458497820c5b,Investor attention and cryptocurrency: Evidence from the Bitcoin market,"[...]investor attention had been applied in traditional financial markets, i.e., stock market and FX market, and proved to be an influential factor in certain markets.The empirical results may shed lights on investors in Bitcoin market to focus more on the variations in behavioral variable; Second, existing studies mainly focused on the linear connections between Bitcoin market and investor attention, failing to comprehensively explore the non-linear connections between the two.[...]current research may be incomplete in explaining the relationships between investor attention and Bitcoin market.The results for out-of-sample predictions further illustrate the importance of investor attention in Bitcoin market and will surely guide the investors to forecast the Bitcoin return with the investor attention.[...]the empirical results add evidence on the in-sample and out-of-sample analysis; Fourth, based on the empirical results of out-of-sample predictions for Bitcoin return, we construct several simple portfolios including Bitcoin asset and risk-free asset to further explore the usefulness of investor attention in Bitcoin portfolio management based on the framework of asset allocation.[...]Neves [42] suggested that investment attractiveness had a prominent role in Bitcoin price formation, while other researchers [3, 34, 43, 44] argued the stock market, exchange rate, gold, oil, Economic Policy Uncertainty (EPU), and the Geopolitical Risk Index, etc.","Zhu, Panpan; Zhang, Xing; Wu, You; Zheng, Hao; Zhang, Yinpeng",2021,10.1371/journal.pone.0246331,None,proquest
d7eb87f6f4ac7e58,Investor attention and stock market volatility,"We investigate, in a theoretical framework, the joint role played by investors' attention to news and learning uncertainty in determining asset prices. The model provides two main predictions. First, stock return variance and risk premia increase with both attention and uncertainty. Second, this increasing relationship is quadratic. We empirically test these two predictions, and we show that the data lend support to the increasing relationship. The evidence for a quadratic relationship is mixed. Overall, our study shows theoretically and empirically that both attention and uncertainty are key determinants of asset prices. © 2019 Elsevier B.V., All rights reserved.","Andrei, D.; Hasler, M.",2015,10.1093/rfs/hhu059,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939258280&doi=10.1093%2Frfs%2Fhhu059&partnerID=40&md5=6ea0f026b737f00de5f512be2b375874,scopus
0f6bc4846ceae885,Investor attention using the Google search volume index – impact on stock returns,"PurposeThe purpose of this paper is to investigate whether the investor attention using the Google search volume index (GSVI) can be used to forecast stock returns. The authors also find the answer to whether the “price pressure hypothesis” would hold true for the Indian stock market.Design/methodology/approachThe authors employ a more recent fully balanced panel data for the period from July 2012 to Jun 2017 (260 weeks) of observations for companies of NIFTY 50 of the National Stock Exchange in the Indian stock market. The authors are motivated by Tetlock (2007) and Bijl et al. (2016) to employ regression approach of econometric estimation.FindingsThe authors find that high Google search volumes lead to positive returns. More precisely, the high Google search volumes predict positive and significant returns in the subsequent fourth and fifth weeks. The GSVI performs as an useful predictor of the direction as well as the magnitude of the excess returns. The higher quantiles of the GSVI have corresponding higher excess returns. The authors notice that the domestic investor searches are correlated with higher excess returns than the worldwide investor searches. The findings imply that the signals from the search volume data could be of help in the construction of profitable trading strategies.Originality/valueTo the best of the authors knowledge, no paper has examined the relationship between Google search intensity and stock-trading behavior in the Indian stock market. The authors use a more recent data for the period from 2012 to 2017 to investigate whether search query data on company names can be used to predict weekly stock returns for individual firms. This study complements the prior studies by investigating the relationship between search intensity and stock-trading behavior in the Indian stock market.","Swamy, Vighneswara; Munusamy Dharani",2019,10.1108/rbf-04-2018-0033,None,proquest
5c62e0f1a86ccf3e,Investor attention: Can google search volumes predict stock returns?,"This paper investigates the role of investor attention in predicting future stock market returns for Brazilian stocks using Google Search Volume (GSV). We tested whether lagged variations in GSV are followed by changes in excess returns by testing 57 stocks from the Ibovespa using weekly search data from Google Brazil from 2014 to 2018. Similar to previous research on the U.S. market, we found that increases in GSV are followed by lower excess returns. Additionally, we show that the more traded a stock is, the higher the effect. This is consistent with the hypothesis that higher individual investor attention leads to lower subsequent returns, suggesting that increasing popularity causes stock prices to deviate from their fundamental value. © 2021 Elsevier B.V., All rights reserved.","Yoshinaga, C.; Rocco, F.",2020,10.15728/bbr.2020.17.5.3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100415030&doi=10.15728%2Fbbr.2020.17.5.3&partnerID=40&md5=d2051069c272e875c103600f36b929cb,scopus
60a0da6f58c3e011,Investor flows and the 2008 boom/bust in oil prices,"This paper explores the impact of investor flows and financial market conditions on returns in crude oil futures markets. I argue that informational frictions and the associated speculative activity may induce prices to drift away from ""fundamental"" values, and may result in price booms and busts. Particular attention is given to the interplay between imperfect information about real economic activity, including supply, demand, and inventory accumulation, and speculative activity in oil markets. Furthermore, I present new evidence that there were economically and statistically significant effects of investor flows on futures prices, after controlling for returns in the United States and emerging-economy stock markets, a measure of the balance sheet flexibility of large financial institutions, open interest, the futures/spot basis, and lagged returns on oil futures. The largest impacts on futures prices were from intermediate-term growth rates of index positions and managed-money spread positions. Moreover, my findings suggest that these effects were through risk or informational channels distinct from changes in convenience yield. Finally, the evidence suggests that hedge fund trading in spread positions in futures impacted the shape of term structure of oil futures prices. © 2014 INFORMS. © 2014 Elsevier B.V., All rights reserved.","Singleton, K.J.",2014,10.1287/mnsc.2013.1756,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894362096&doi=10.1287%2Fmnsc.2013.1756&partnerID=40&md5=7afb35ff36a50061f0a050888e34e1ed,scopus
3e4b27043ebffa04,Investors' and Central Bank's Uncertainty Embedded in Index Options,"Shocks to equity options' implied volatility are followed by persistently lower short-term rates. Shocks to puts' over calls' out-of-the-money implied volatilities (P/C) are followed by persistently higher rates. Stock and Treasury bond implied volatilities, which measure market and policy uncertainty, are countercyclical, while P/C, which measures downside risk, is procyclical. An equilibrium model in which investors and the central bank learn about composite regimes of economic and policy variables explains these dynamics, linking them to a learning-based, forward-looking Taylor rule. Survey data support our model's predictions on the effect of uncertainty on the level and fluctuations of implied volatilities.","David, Alexander; Veronesi, Pietro",2014,10.1093/rfs/hhu024,None,wos
1b472252ddcaa3e6,Is BRCA Mutation Testing Cost Effective for Early Stage Breast Cancer Patients Compared to Routine Clinical Surveillance? The Case of an Upper Middle-Income Country in Asia,"Objective Previous studies showed that offering BRCA mutation testing to population subgroups at high risk of harbouring the mutation may be cost effective, yet no evidence is available for low- or middle-income countries (LMIC) and in Asia. We estimated the cost effectiveness of BRCA mutation testing in early-stage breast cancer patients with high pre-test probability of harbouring the mutation in Malaysia, an LMIC in Asia. Methods We developed a decision analytic model to estimate the lifetime costs and quality-adjusted life-years (QALYs) accrued through BRCA mutation testing or routine clinical surveillance (RCS) for a hypothetical cohort of 1000 early-stage breast cancer patients aged 40 years. In the model, patients would decide whether to accept testing and to undertake risk-reducing mastectomy, oophorectomy, tamoxifen, combinations or neither. We calculated the incremental cost-effectiveness ratio (ICER) from the health system perspective. A series of sensitivity analyses were performed. Results In the base case, testing generated 11.2 QALYs over the lifetime and cost US$4815 per patient whereas RCS generated 11.1 QALYs and cost US$4574 per patient. The ICER of US$2725/QALY was below the cost-effective thresholds. The ICER was sensitive to the discounting of cost, cost of BRCA mutation testing and utility of being risk-free, but the ICERs remained below the thresholds. Probabilistic sensitivity analysis showed that at a threshold of US$9500/QALY, 99.9% of simulations favoured BRCA mutation testing over RCS. Conclusions Offering BRCA mutation testing to early-stage breast cancer patients identified using a locally-validated risk-assessment tool may be cost effective compared to RCS in Malaysia.","Lim, Ka Keat; Yoon, Sook Yee; Taib, Nur Aishah Mohd; Shabaruddin, Fatiha Hana; Dahlui, Maznah; Woo, Yin Ling; Thong, Meow Keong; Teo, Soo Hwang; Chaiyakunapruk, Nathorn",2018,10.1007/s40258-018-0384-8,None,proquest
1a7da81a013d9178,Is There an On-the-Run Premium in TIPS?,"In the U.S. Treasury market, the most recently issued, or so-called on-the-run, security typically trades at a price above those of more seasoned but otherwise comparable securities. This difference is known as the on-the-run premium. In this paper, yield spreads between pairs of Treasury Inflation-Protected Securities (TIPS) with both matching and nearly-matching maturities but of separate vintages are analyzed. Adjusting for differences in conventional liquidity premiums, values of embedded deflation options, and coupon rates, the results show a small, insignificant premium on recently issued TIPS, which leads us to conclude that there is no on-the-run premium in the TIPS market.","Christensen, Jens H. E.; Lopez, Jose A.; Shultz, Patrick J.",2020,10.1142/s201013922050007x,None,wos
06a3c0d9a8182e9f,Is nonlinear drift implied by the short end of the term structure?,"Nonlinear drift models of the short rate are estimated using data on the short end of the term structure, where the cross-sectional relation is obtained by an analytical approximation. The findings reveal that (i) nonlinear physical drift is not implied unless it is strongly affected by cross-sectional dimensions of the data; (ii) nonlinear risk-neutral drift that allows for fast mean reversion for high rates is desirable to explain and predict observed patterns of yield spreads; and (iii) for higher frequency data from which transitory shocks are removed, (ii) still remains valid although the nonlinearity is somewhat reduced. Reprinted by permission of Oxford University Press","Takamizawa, Hideyuki",2008,10.1093/rfs/hhm072,None,proquest
465719be2fd4d237,Is the short rate drift actually nonlinear?,"Ait-Sahalia (1996) and Stanton (1997) use nonparametric estimators applied to short-term interest rate data to conclude that the drift function contains important nonlinearities. We study the finite-sample properties of their estimators by applying them to simulated sample paths of a square-root diffusion. Although the drift function is linear, both estimators suggest nonlinearities of the type and magnitude reported in Ait-Sahalia (1996) and Stanton (1997). Combined with the results of a weighted least squares estimator, this evidence implies that nonlinearity of the short rate drift is not a robust stylized fact.","Chapman, DA; Pearson, ND",2000,10.1111/0022-1082.00208,None,wos
ea00aca5b04457b7,Is the term structure nonlinear? A semiparametric investigation,A semiparametric error correction model (ECM) is estimated using US term structure data. We use 5 and 10 year interest rates to predict short-term (1 month to 12 month) interest rates. It is found that the semiparametric ECM model predicts better than the popular linear ECM. These results provide further evidence of nonlinearity in the term structure.,"Bachmeier, L; Li, Q",2002,10.1080/13504850110053275,None,wos
d398e1bb9cf578bc,Iterative and Recursive Estimation in Structural Nonadaptive Models,"An inference method, called latent backfitting, is proposed. This method appears well suited for econometric models where the structural relationships of interest define the observed endogenous variables as a known function of unobserved state variables and unknown parameters. This nonlinear state-space specification paves the way for iterative or recursive EM-like strategies. In the E steps, the state variables are forecasted given the observations and a value of the parameters. In the M steps, these forecasts are used to deduce estimators of the unknown parameters from the statistical model of latent variables. The proposed iterative/recursive estimation is particularly useful for latent regression models and for dynamic equilibrium models involving latent state variables. Practical implementation issues are discussed through the example of term structure models of interest rates. © 2020 Elsevier B.V., All rights reserved.","Pastorello, S.; Patilea, V.; Renault, E.",2003,10.1198/073500103288619124,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0242318897&doi=10.1198%2F073500103288619124&partnerID=40&md5=89bd95f11924d290104a4169ffefdf21,scopus
1931a2bd3a13f6eb,Joint Estimation of Factor Sensitivities and Risk Premia for the Arbitrage Pricing Theory,"The APT is represented as a multivariate regression model with across‐equations restrictions. Both observed and unobserved (latent) macroeconomic factors are included, thus generalizing and unifying two previous strands of literature. Large portfolios representing unobserved factors are treated as endogenous, and nonlinear 3SLS estimates are shown to differ sharply from estimates that ignore this endogeneity. Using monthly stock returns and six factors, we cannot reject January effects. The following results are invariant with respect to the inclusion of January effects: we reject the CAPM in favor of the APT; however, we cannot reject the APT restrictions on the linear factor model. 1988 The American Finance Association © 2016 Elsevier B.V., All rights reserved.","Burmeister, E.; McElroy, M.B.",1988,10.1111/j.1540-6261.1988.tb04603.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977711619&doi=10.1111%2Fj.1540-6261.1988.tb04603.x&partnerID=40&md5=e622a3c5536f6ad1f7416c41a68d2843,scopus
c35e1a92cfdc2c3d,Jump and variance risk premia in the S&P 500,"We analyze the risk premia embedded in the S&P 500 spot index and option markets. We use a long time series of spot prices and a large panel of option prices to jointly estimate the diffusive stock risk premium, the price jump risk premium, the diffusive variance risk premium and the variance jump risk premium. The risk premia are statistically and economically significant and move over time. Investigating the economic drivers of the risk premia, we are able to explain up to 63% of these variations. (C) 2016 Elsevier B.V. All rights reserved.","Neumann, Maximilian; Prokopczuk, Marcel; Simen, Chardin Wese",2016,10.1016/j.jbankfin.2016.03.013,None,wos
f4e21d42f7de9c14,Jumps and time-varying correlations in daily foreign exchange rates,"This paper extends the multivariate latent factor ARCH model approach of Diebold and Nerlove (Journal of Applied Econometrics 4 (1989) 1) as a parsimonious alternative that pays particular attention to time series properties of daily foreign exchange rates such as jumps and to changing volatilities in both the common and country-specific factors. Using seven major daily dollar exchange rates from January 1 1992 to December 31 1996, this paper finds evidence of significant time-varying correlations and the country-specific variances. Consistent with the finding of Alexius and Sellin (1997) (A latent factor model of European exchange rate risk premia. Manuscript, The Economic Research Institute, Stockholm School of Economics), the two factor model appears to be a reasonable description of the major exchange rates. © 2001 Elsevier Science Ltd. © 2005 Elsevier Science B.V., Amsterdam. All rights reserved.","Chang, K.-H.; Kim, M.-J.",2001,10.1016/s0261-5606(01)00007-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041825343&doi=10.1016%2FS0261-5606%2801%2900007-9&partnerID=40&md5=fcf9dd0391f4978033d3a52d2a2777fc,scopus
84a95360c6c72c18,Kernel-Based Aggregating Learning System for Online Portfolio Optimization,"Recently, various machine learning techniques have been applied to solve online portfolio optimization (OLPO) problems. These approaches typically explore aggressive strategies to gain excess returns due to the existence of irrational phenomena in financial markets. However, existing aggressive OLPO strategies rarely consider the downside risk and lack effective trend representation, which leads to poor prediction performance and large investment losses in certain market environments. Besides, prediction with a single model is often unstable and sensitive to the noises and outliers, and the subsequent selection of optimal parameters also become obstacles to accurate estimation. To overcome these drawbacks, this paper proposes a novel kernel-based aggregating learning (KAL) system for OLPO. It includes a two-step price prediction scheme to improve the accuracy and robustness of the estimation. Specifically, a component price estimator is built by exploiting additional indicator information and the nonstationary nature of financial time series, and then an aggregating learning method is presented to combine multiple component estimators following different principles. Next, this paper conducts an enhanced tracking system by introducing a kernel-based increasing factor to maximize the future wealth of next period. At last, an online learning algorithm is designed to solve the system objective, which is suitable for large-scale and time-limited situations. Experimental results on several benchmark datasets from diverse real markets show that KAL outperforms other state-of-the-art systems in cumulative wealth and some risk-adjusted metrics. Meanwhile, it can withstand certain transaction costs.","Wang, Xin; Sun, Tao; Liu, Zhi",2020,10.1155/2020/6595329,None,wos
51c665f7817828bf,Kriging of financial term-structures,"Due to the lack of reliable market information, building financial term-structures may be associated with a significant degree of uncertainty. In this paper, we propose a new term-structure interpolation method that extends classical spline techniques by additionally allowing for quantification of uncertainty. The proposed method is based on a generalization of kriging models with linear equality constraints (market-fit conditions) and shape-preserving conditions such as monotonicity or positivity (no-arbitrage conditions). We define the most likely curve and show how to build confidence bands. The Gaussian process covariance hyper-parameters under the construction constraints are estimated using cross-validation techniques. Based on observed market quotes at different dates, we demonstrate the efficiency of the method by building curves together with confidence intervals for term-structures of OIS discount rates, of zero-coupon swaps rates and of CDS implied default probabilities. We also show how to construct interest-rate surfaces or default probability surfaces by considering time (quotation dates) as an additional dimension.","Cousin, Areski; Maatoukb, Hassan; Rullierea, Didier",2016,10.1016/j.ejor.2016.05.057,None,proquest
e63ce5fd8a54f209,LAND OF ADDICTS? AN EMPIRICAL INVESTIGATION OF HABIT-BASED ASSET PRICING MODELS,"This paper Studies the ability of a general class of habit-based asset pricing models to match the conditional moment restrictions implied by asset pricing theory. We treat the functional form of the habit as unknown, and estimate it along with the rest of the model's finite dimensional parameters. Using quarterly data on consumption growth, assets returns and instruments, our empirical results indicate that the estimated habit function is nonlinear, that habit formation is better described as internal rather than external, and the estimated time-preference parameter and the power utility parameter are sensible. In addition, the estimated habit function generates a positive stochastic discount factor (SDF) proxy and performs well in explaining cross-sectional stock return data. We find that an internal habit SDF proxy can explain a cross-section of size and book-market sorted portfolio equity returns better than (i) the Fama and French (1993) three-factor model, (ii) the Lettau and LUdvigson (2001b) scaled consumption CAPM model, (iii) an external habit SDF proxy, (iv) the classic CAPM, and (v) the classic consumption CAPM. Copyright (C) 2009 John Wiley & Sons, Ltd.","Chen, Xiaohong; Ludvigson, Sydney C.",2009,10.1002/jae.1091,None,wos
a0a865e10fc2c0c7,LASSO-Type Penalties for Covariate Selection and Forecasting in Time Series,"This paper studies some forms of LASSO-type penalties in time series to reduce the dimensionality of the parameter space as well as to improve out-of-sample forecasting performance. In particular, we propose a method that we call WLadaLASSO (weighted lag adaptive LASSO), which assigns not only different weights to each coefficient but also further penalizes coefficients of higher-lagged covariates. In our Monte Carlo implementation, the WLadaLASSO is superior in terms of covariate selection, parameter estimation precision and forecasting, when compared to both LASSO and adaLASSO, especially for a higher number of candidate lags and a stronger linear dependence between predictors. Empirical studies illustrate our approach for US risk premium and US inflation forecasting with good results. Copyright © 2016 John Wiley & Sons, Ltd. © 2022 Elsevier B.V., All rights reserved.","Konzen, E.; Ziegelmann, F.A.",2016,10.1002/for.2403,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958818333&doi=10.1002%2Ffor.2403&partnerID=40&md5=2a5fa664844d07fe52cdbc5e3abfda81,scopus
382f6ff8ac78ca7b,LSTM Framework Design and Volatility Research on Intelligent Forecasting Model for Solving the Parallel Dislocation Problem,"The yield of treasury bonds is the benchmark interest rate in the financial market which is worth predicting and judging. Based on the Long Short-Term Memory (LSTM) neural network model in deep learning, combined with the vector autoregression method (VAR), this paper creatively constructs the VAR-LSTM framework and uses the predicted values of macroeconomic variables and lagged value of the time sequence as input factors to solve the problem of “parallel dislocation” of the fitting results of the traditional LSTM model which significantly improves the prediction accuracy. In order to meet the requirements of active quantitative investment for high precision prediction of stock market index, adaptive noise complete ensemble empirical mode decomposition (EMD) is introduced into the modeling of stock market index prediction. Combined with the efficient modeling ability of long-term and short-term memory network for medium- and long-term dependence of complex series, using the idea of “decomposition-reorganization-prediction-integration”, an integrated prediction method of stock market index CEEMDAN-LSTM is proposed. CEEMDAN is used to decompose and reconstruct the index to obtain its high and low frequency components and trend items. The LSTM prediction models of each component are constructed respectively and the IMF reorganization mode of high frequency subseries is optimized. Then the overall predicted value of the index is obtained by adding and integrating the predicted values of each component. Taking five representative stock market indexes as test data, the prediction results of CEEMDAN-LSTM and mainstream financial time series machine learning modeling methods are compared systematically. The results show that for treasury bond yield series, the prediction accuracy of ARIMA model is higher than that of general LSTM method, while VAR-LSTM model is better than ARIMA model. The prediction error in the training set and the test set is reduced by about 55% and 50% respectively, and the prediction accuracy of the change direction is improved by about 5% and 8% respectively, which has higher application value. The prediction performance of CEEMDAN-LSTM is consistently better than that of existing modeling methods, and has less prediction error and lower lag.","Weng, Yiran; Wang, Zhiyi; Zhou, Longzhen",2021,10.1088/1742-6596/1982/1/012028,None,proquest
ddc382b4f2ebd189,LSTM–GARCH Hybrid Model for the Prediction of Volatility in Cryptocurrency Portfolios,"In the present work, the volatility of the leading cryptocurrencies is predicted through generalised autoregressive conditional heteroskedasticity (GARCH) models, multilayer perceptron (MLP), long short-term memory (LSTM), and hybrid models of the type LSTM and GARCH, where parameters of the GARCH family are included as features of LSTM models. The study period covered the scenario of the World Health Organization pandemic declaration around March 2020 at hourly frequency. We have found that the different variants of deep neural network models outperform those of the GARCH family in the sense of the hetorerocedastic error, and absolute and squared error (HSE). Under the sharpe ratio, the volatility forecasting of a uniform portfolio at long horizons systematically outperforms the stablecoin Tether, which is considered here as the risk-free asset. Also, including transaction volume helps reduce the value at risk or loss probability for the uniform portfolio. Moreover, in a minimum variance portfolio, it is observed that before the pandemic declaration, a large proportion of the capital was allocated to bitcoin (BTC). In contrast, after March 2020, the portfolio is more diversified with short positions for BTC. Moreover, the MLP models give the best predictive results, although not statistically different in accuracy compared to the LSTM and LSTM–GARCH versions under the Diebold–Mariano test. In sum, MLP models outperform most stylised financial models and are less computationally expensive than more complex neural networks. Therefore, simple learning models are suggested in highly non-linear time series volatility forecasts as it is the cryptocurrency market.",None,2024,10.1007/s10614-023-10373-8,None,proquest
7f77847f3cb759f0,"Labor Links, Comovement, and Predictable Returns","Using firms' online job postings, we identify economically related peer firms in the labor market. Firms' labor peers are vastly different from their industry peers, where the overlap is about 20%. Returns of labor-linked firms strongly comove, suggesting common responses to labor market shocks on average. However, industry shocks can affect firms outside the industry through the labor network, leading to substitution effects between labor peers. Lastly, we show that investors do not promptly incorporate news about labor-linked firms, leading to predictable subsequent returns. A long-short strategy exploiting this delay generates an average annualized excess return of 9%. © 2025 Elsevier B.V., All rights reserved.","Liu, Y.; Wu, X.",2025,10.1017/s0022109025101610,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006901938&doi=10.1017%2FS0022109025101610&partnerID=40&md5=bd128e8bf860437c6f596da829c7b48e,scopus
ec5f21caa1e911a1,Language Models Fine-Tuning for Automatic Format Reconstruction of SEC Financial Filings,"The analysis of financial reports is a crucial task for investors and regulators, especially the mandatory annual reports (10-K) required by the SEC (Securities and Exchange Commission) that provide crucial information about a public company in the American stock market. Although SEC suggests a specific document format to standardize and simplify the analysis, in recent years, several companies have introduced their own format and organization of the contents, making human-based and automatic knowledge extraction inherently more difficult. In this research work, we investigate different Neural language models based on Transformer networks (Bidirectional recurrence-based, Autoregressive-based, and Autoencoders-based approaches) to automatically reconstruct an SEC-like format of the documents as a multi-class classification task with 18 classes at the sentence level. In particular, we propose a Bidirectional fine-tuning procedure to specialize pre-trained language models on this task. We propose and make the resulting novel transformer model, named SEC-former, publicly available to deal with this task. We evaluate SEC-former in three different scenarios: 1) in terms of topic detection performances; 2) in terms of document similarity (TF-IDF Bag-of-words and Doc2Vec) achieved with respect to original and trustable financial reports since this operation is leveraged for portfolio optimization tasks; and 3) testing the model in a real use-case scenario related to a public company that does not respect the SEC format but provides a human-supervised reference to reconstruct it.",G. Lombardo; G. Trimigno; M. Pellegrino; S. Cagnoni,2024,10.1109/access.2024.3370444,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10445214,ieeexplore
fa741ee39590c1c0,Large data sets and machine learning: Applications to statistical arbitrage,"Machine learning algorithms and big data are transforming all industries including the finance and portfolio management sectors. While these techniques, such as Deep Belief Networks or Random Forests, are becoming more and more popular on the market, the academic literature is relatively sparse. Through a series of applications involving hundreds of variables/predictors and stocks, this article presents some of the state-of-the-art techniques and how they can be implemented to manage a long-short portfolio. Numerous practical and empirical issues are developed. One of the main questions beyond big data use is the value of information. Does an increase in the number of predictors improve the portfolio performance? Which features are the most important? A large number of predictors means, potentially, a high level of noise. How do the algorithms manage this? This article develops an application using a 22-year trading period, up to 300 U.S. large caps and around 600 predictors. The empirical results underline the ability of these techniques to generate useful trading signals for portfolios with important turnovers and short holding periods (one or five days). Positive excess returns are reported between 1993 and 2008. They are strongly reduced after accounting for transaction costs and traditional risk factors. When these machine learning tools were readily available in the market, excess returns turned into the negative in most recent times. Results also show that adding features is far from being a guarantee to boost the alpha of the portfolio. © 2019 Elsevier B.V., All rights reserved.","Huck, N.",2019,10.1016/j.ejor.2019.04.013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064846164&doi=10.1016%2Fj.ejor.2019.04.013&partnerID=40&md5=352bd849257f78318868f7b1b38825dd,scopus
0da0f4c7d8aadf7f,Learning Forecast-Efficient Yield Curve Factor Decompositions with Neural Networks,"Most factor-based forecasting models for the term structure of interest rates depend on a fixed number of factor loading functions that have to be specified in advance. In this study, we relax this assumption by building a yield curve forecasting model that learns new factor decompositions directly from data for an arbitrary number of factors, combining a Gaussian linear state-space model with a neural network that generates smooth yield curve factor loadings. In order to control the model complexity, we define prior distributions with a shrinkage effect over the model parameters, and we present how to obtain computationally efficient maximum a posteriori numerical estimates using the Kalman filter and automatic differentiation. An evaluation of the model’s performance on 14 years of historical data of the Brazilian yield curve shows that the proposed technique was able to obtain better overall out-of-sample forecasts than traditional approaches, such as the dynamic Nelson and Siegel model and its extensions. © 2022 Elsevier B.V., All rights reserved.","Kauffmann, P.C.; Takada, H.H.; Terada, A.T.; Stern, J.M.",2022,10.3390/econometrics10020015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128238593&doi=10.3390%2Feconometrics10020015&partnerID=40&md5=065080cdb62c05c804b818ccfed43282,scopus
d29dd67ecedbed99,Learning and forecasts about option returns through the volatility risk premium,"We use learning in an equilibrium model to explain the puzzling predictive power of the volatility risk premium (VRP) for option returns. In the model, a representative agent follows a rational Bayesian learning process in an economy under incomplete information with the objective of pricing options. We show that learning induces dynamic differences between probability measures P and Q, which produces predictability patterns from the VRP for option returns. The forecasting features of the VRP for option returns, obtained through our model, exhibit the same behaviour as those observed in an empirical analysis with S&P 500 index options. (C) 2017 Elsevier B.V. All rights reserved.","Bernales, Alejandro; Chen, Louisa; Valenzuela, Marcela",2017,10.1016/j.jedc.2017.06.007,None,wos
6e2ec2538db2f2c6,Leveraging latent representations for milk yield prediction and interpolation using deep learning,"In this study, we propose a lactation model that estimates the daily milk yield by using autoencoders to generate a latent representation of all milk yields observed during the entire lactation cycle, irrespective of the length of the time interval between the different measurements. More specifically, we propose a sequential autoencoder (SAE) to process the sequential data, extract and decode the low-dimensional representations and generate the milk yield sequences. The SAE is compared with a more traditional multilayer perceptron model (MLP) which uses herd and parity information and lagged milk yields as input. Results show that incorporating the recorded daily milk yields, lactation number, herd statistics as well as reproduction and health events the cow encountered during the lactation cycle results in the most qualitative latent representations. Moreover, by leveraging these low-dimensional encodings, the SAE reconstructed the entire milk yield curve with a higher accuracy than the MLP. Hence, we present a framework that is able to infer missing milk yields along the entire lactation curve which facilitates selection and culling decisions as well as the estimation of future earnings and costs. Furthermore, the model allows farmers to enhance their animal monitoring systems as it incorporates the sequence of health and reproduction events to forecast the cow's future productivity.","Liseune, Arno; Salamone, Matthieu; Van den Poel, Dirk; Van Ranst, Bonifacius; Hostens, Miel",2020,10.1016/j.compag.2020.105600,None,proquest
b43fdd1652b6f7bb,Leveraging multi-time-span sequences and feature correlations for improved stock trend prediction,"Accurate stock trend prediction is critical for informed investment decisions and the stability of financial markets. However, existing methodologies often overlook fine-grained stock price volatility and fail to incorporate a comprehensive spectrum of technical indicators, inadequately capturing the complex interrelationships fundamental to technical analysis. This paper proposes MSFCE, a novel framework for stock market trend prediction that enhances feature correlations across multi-time-span sequences. Specifically, MSFCE designs a multi-scale feature encoder to capture both intraday and daily features, which are processed through a Transformer-based dimensionally adaptive encoder. Furthermore, the framework leverages higher-order interactions among technical indicators via a graph attention network, dynamically modeling their interdependencies to improve prediction robustness in dynamic markets. Extensive experiments on the SSE50 and CSI300 datasets demonstrate that MSFCE significantly outperforms existing state-of-the-art methods, consistently exhibiting superior performance across multiple test periods and market conditions. Its strong prediction accuracy and risk management suggest practical applicability in trading strategies, yielding significant excess returns in empirical backtests. © 2024 Elsevier B.V., All rights reserved.","Li, Y.; Zhuang, M.; Wang, J.; Zhou, J.",2025,10.1016/j.neucom.2024.129218,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213080195&doi=10.1016%2Fj.neucom.2024.129218&partnerID=40&md5=34da531abdfb33b8628e81aa8a89243b,scopus
0bd417484ae81bb2,Likelihood inference for dynamic linear models with Markov switching parameters: on the efficiency of the Kim filter,"The Kim filter (KF) approximation is widely used for the likelihood calculation of dynamic linear models with Markov regime-switching parameters. However, despite its popularity, its approximation error has not yet been examined rigorously. Therefore, this study investigates the reliability of the KF approximation for maximum likelihood (ML) and Bayesian estimations. To measure the approximation error, we compare the outcomes of the KF method with those of the auxiliary particle filter (APF). The APF is a numerical method that requires a longer computing time, but its numerical error can be sufficiently minimized by increasing simulation size. According to our extensive simulation and empirical studies, the likelihood values obtained from the KF approximation are practically identical to those of the APF. Furthermore, we show that the KF method is reliable, particularly when regimes are persistent and sample size is small. From the Bayesian perspective, we show that the KF method improves the efficiency of posterior simulation. This study contributes to the literature by providing evidence to justify the use of the KF method in both ML and Bayesian estimations.","Kim, Young Min; Kang, Kyu Ho",2019,10.1080/07474938.2018.1514027,None,wos
6603d19b5d0f44e3,Likelihood-based scoring rules for comparing density forecasts in tails,"We propose new scoring rules based on conditional and censored likelihood for assessing the predictive accuracy of competing density forecasts over a specific region of interest, such as the left tail in financial risk management. These scoring rules can be interpreted in terms of Kullback-Leibler divergence between weighted versions of the density forecast and the true density. Existing scoring rules based on weighted likelihood favor density forecasts with more probability mass in the given region, rendering predictive accuracy tests biased toward such densities. Using our novel likelihood-based scoring rules avoids this problem. (C) 2011 Elsevier B.V. All rights reserved.","Diks, Cees; Panchenko, Valentyn; van Dijk, Dick",2011,10.1016/j.jeconom.2011.04.001,None,wos
dbc0a172a842c869,Likelihood-based specification analysis of continuous-time models of the short-term interest rate,"An extensive collection of continuous-time models of the short-term interest rate is evaluated over data sets that have appeared previously in the literature. The analysis, which uses the simulated maximum likelihood procedure proposed by Durham and Gallant (2002), provides new insights regarding several previously unresolved questions. For single factor models, I find that the volatility, not the drift, is the critical component in model specification. Allowing for additional flexibility beyond a constant term in the drift provides negligible benefit. While constant drift would appear to imply that the short rate is nonstationary, in fact, stationarity is volatility-induced. The simple constant elasticity of volatility model fits weekly observations of the three-month Treasury bill rate remarkably well but is easily rejected when compared with more flexible volatility specifications over daily data. The methodology of Durham and Gallant can also be used to estimate stochastic volatility models. While adding the latent volatility component provides a large improvement in the likelihood for the physical process, it does little to improve bond-pricing performance. (C) 2003 Elsevier B.V. All rights reserved.","Durham, GB",2003,10.1016/s0304-405x(03)00207-1,None,wos
23cd22560c926a1e,Limited information-processing capacity and asymmetric stock correlations,"Through an orthogonalized impulse-response analysis, I studied the relationship between the variance risk premium, market variance and stock correlations in the French stock market from September 2002 through September 2006, using high-frequency data-based measures. Variance risk premium is estimated using realized variances and index options-implied variances and used as a state vector to proxy investors perceived uncertainty. I found that a shock to variance risk premium causes long-lasting increases in the market variance pointing to the limitedness of investors information-processing capacity. At the same time, the shock generates consecutive increases in realized correlations between individual stocks and the market portfolio. I propose this as a possible explanation for the asymmetric/counter-cyclic behaviour of stock correlations. © 2019 Elsevier B.V., All rights reserved.","Ceylan, O.",2015,10.1080/14697688.2013.808374,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929133348&doi=10.1080%2F14697688.2013.808374&partnerID=40&md5=4cdf28a6de9803f2ca275da5d8c0647a,scopus
1bbee78dc006f8fe,Linear Gaussian affine term structure models with unobservable factors: Calibration and yield forecasting,"This paper provides a significant numerical evidence for out-of-sample forecasting ability of linear Gaussian interest rate models with unobservable underlying factors. We calibrate one, two and three factor linear Gaussian models using the Kalman filter oil two different bond yield data sets and compare their out-of-sample forecasting performance. One-step ahead as well as four-step ahead out-of-sample forecasts are analyzed based on the weekly data. When evaluating the one-step ahead forecasts, it is shown that a one factor model may be adequate when only the short-dated or only the long-dated yields are considered, but two and three factor models performs significantly better when the entire yield spectrum is considered. Furthermore, the results demonstrate that the predictive ability of multi-factor models remains intact far ahead out-of-sample, with accurate predictions available up to one year after the last calibration for one data set and up to three months after the last calibration for the second, more volatile data set. The experimental data denotes two different periods with different yield volatilities, and the stability of model parameters after calibration ill both the cases is deemed to be both significant and practically useful. When it comes to four-step ahead predictions, the quality of forecasts deteriorates for all models, as can be expected, but the advantage of using a multi-factor model as compared to a one factor model is still significant.In addition to the empirical study above, we also suggest a non-linear filter based on linear programming for improving the term structure matching at a given point in time. This method, when used in place of a Kalman filter update, improves the term structure fit significantly with a minimal added computational overhead. The improvement achieved with the proposed method is illustrated for out-of-sample data for both the data sets. This method call be used to model a parameterized yield curve consistently with the underlying short rate dynamics. (c) 2008 Elsevier B.V. All rights reserved.","Date, Paresh; Wang, Chieh",2009,10.1016/j.ejor.2008.01.035,None,wos
97d99bf76069f7fb,Linear and non-linear filtering in mathematical finance: a review,This paper presents a review of time series filtering and its applications in mathematical finance. A summary of results of recent empirical studies with market data are presented for yield curve modelling and stochastic volatility modelling. The paper also outlines different approaches to filtering of non-linear time series.,P. Date; K. Ponomareva,2011,10.1093/imaman/dpq008,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8133776,ieeexplore
3ea0c55e5317e324,Linear and nonlinear predictability in investment style factors: Multivariate evidence,"This paper studies the predictive performance of multivariate models at forecasting the (excess) returns of portfolios mimicking the Market, Size, Value, Momentum, and Low Volatility factors isolated in asset pricing research. We evaluate the accuracy of the point forecasts of a number of linear and regime-switching models in recursive, out-of-sample forecasting experiments. We assess the accuracy of the models using several measures of unbiasedness and predictive accuracy, and using Diebold and Mariano's approach to test whether differences in expected losses from all possible pairs of forecast models are statistically significant. We fail to find evidence that complex statistical models are uniformly more accurate than a naïve constant expected return model for factor-mimicking portfolio (excess) returns. However, we show that it is possible to build simple portfolio strategies that profit from the higher out-of-sample predictive accuracy of forecasting models with Markov switching in conditional mean coefficients. These results appear to be independent of the forecasting horizon and robust to changes in the loss function that captures the investors' objectives. © 2017 Elsevier B.V., All rights reserved.","Chincoli, F.; Guidolin, M.",2017,10.1057/s41260-017-0048-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018248298&doi=10.1057%2Fs41260-017-0048-5&partnerID=40&md5=5b890a8c51620f9b5b10a05c7bfc2bdc,scopus
1c7ef051f405988d,Linear regression versus backpropagation networks to predict: Quarterly stock market excess returns,"This paper compares a linear model to predict quarterly stock market excess returns to several backpropagation networks. Research findings suggest that quarterly stock market returns are to some extent predictable, but only marginal attention has been paid to possible nonlinearities in the return generating process. The paper discusses input selection, elaborates on how to generate out-of-sample predictions to estimate generalization performance, motivates the choice for a particular network, examines backpropagation training, and evaluates network performance. The out-of-sample predictions are used to calculate several performance metrics, and to determine added value when applying a straightforward tactical asset allocation policy. A nonparametric test is selected to evaluate generalization behavior, and sensitivity analysis examines the selected network's qualitative behavior. Strong nonlinear effects appear to be absent, but the proposed backpropagation network generates an asset allocation policy that outperforms the linear model. © 1996 Kluwer Academic Publishers. © 2018 Elsevier B.V., All rights reserved.","Hiemstra, Y.",1996,10.1007/bf00115692,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0043266837&doi=10.1007%2FBF00115692&partnerID=40&md5=44c0893012d125f91ad203a8be14cb41,scopus
b7b3d42a192ae0ce,Linear-price term structure models,"We characterize the term structure models in which the zero-coupon prices are linear functions of underlying factors. These models are called Linear-price Term Structure Models (LTSM). We provide two types of LTSM where the observable factors predict regimes which are not observed by the investor. These hidden regimes are represented by a Markov chain, which features either an exogenous, or an endogenous dynamics. We illustrate the possible term structure patterns, their evolutions, in particular their ability to stay close to a zero lower bound. © 2013 Elsevier B.V. © 2023 Elsevier B.V., All rights reserved.","Gouriéroux, C.; Monfort, A.",2013,10.1016/j.jempfin.2013.07.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883523553&doi=10.1016%2Fj.jempfin.2013.07.004&partnerID=40&md5=e34fe3bdc2f523b56b4b64e14ceb551c,scopus
5ab29547914291e7,"Liquidity shocks, business cycles and asset prices","In the aftermath of the Great Recession, macro models that feature financing constraints have attracted increasing attention. Among these, Kiyotaki et al. (2012) is a prominent example. In this paper, we investigate whether the liquidity shocks and financial frictions proposed by Kiyotaki et al. (2012) can improve the asset pricing predictions of the frictionless RBC model. We study the quantitative business cycle and asset pricing properties in an economy in which agents feature recursive preferences, are subject to a liquidity constraint, and suffer liquidity shocks. We find that the model predicts highly nonlinear time variation and levels of risk premia, which are driven by endogenous fluctuations in equity prices. However, the model fails to account for a basic fact: Periods of scarce liquidity are associated with high asset prices and low expected returns. © 2020 Elsevier B.V., All rights reserved.","Bigio, S.; Schneider, A.",2017,10.1016/j.euroecorev.2017.05.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021406771&doi=10.1016%2Fj.euroecorev.2017.05.004&partnerID=40&md5=7f22dc6c370cebd17926a00725e416ae,scopus
aa8630690d917199,"Liquidity, volume and volatility in US electricity futures: The case of Palo Verde","Previous research on liquidity has studied the relationships between liquidity, trading activity and volatility, mostly with data from US Treasury securities, stocks and foreign exchange spot markets. Liquidity in futures markets, especially electricity futures, has received little attention. However, liquidity in futures is expected to behave differently to that in spot markets because of the unique asymmetries in futures markets. Liquidity in electricity markets is of interest in countries where these markets are being deregulated. This study estimates these relationships for the Palo Verde electricity futures contract. The results show positive relations between all three pairs of key variables. © 2006 Elsevier B.V., All rights reserved.","Goss, B.",2006,10.1080/17446540500396974,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33744995794&doi=10.1080%2F17446540500396974&partnerID=40&md5=1fbf6045b943bee0079a5367dc3f2a90,scopus
0082a75f3674363a,Local currency bond risk premia: A panel evidence on emerging markets,"This paper investigates the sources of variation in emerging market (EM) local currency bond risk premium. We find that macroeconomic and financial variables contain valuable information in explaining local currency bond excess returns. Additionally, we extend our analysis to investigate how the influence of different factors change depending on the level of global risk appetite. Although macro fundamentals have an important role in explaining the risk premiums during tranquil times, investors pay less attention to changes in inflation forecast in times of high risk aversion. Positive credit rating changes decrease the bond risk premium in both regimes with a different magnitude. Also, the influence of exchange rate volatility is more pronounced during the time of market stress. © 2019 Elsevier B.V., All rights reserved.","Cepni, O.; Güney, I.E.",2019,10.1016/j.ememar.2019.01.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060970321&doi=10.1016%2Fj.ememar.2019.01.002&partnerID=40&md5=13091778147b29cc4c0611f40f380d9f,scopus
fff30e24c973cee6,Local lagged adapted generalized method of moments and applications,"In this work, an attempt is made for developing the local lagged adapted generalized method of moments (LLGMM). This proposed method is composed of: 1) development of the stochastic model for continuous-time dynamic process; 2) development of the discrete-time interconnected dynamic model for statistic process; 3) utilization of Euler-type discretized scheme for nonlinear and nonstationary system of stochastic differential equations; 4) development of generalized method of moment/observation equations by employing lagged adaptive expectation process; 5) introduction of the conceptual and computational parameter estimation problem; 6) formulation of the conceptual and computational state estimation scheme; and 7) definition of the conditional mean square epsilon -best sub-optimal procedure. The development of LLGMM is motivated by parameter and state estimation problems in continuous-time nonlinear and nonstationary stochastic dynamic model validation problems in biological, chemical, engineering, financial, medical, physical, and social sciences. The byproducts of LLGMM are the balance between model specification and model prescription of continuous-time dynamic process and the development of discrete-time interconnected dynamic model of local sample mean and variance statistic process (DTIDMLSMVSP). DTIDMLSMVSP is the generalization of statistic (sample mean and variance) drawn from the static dynamic population problems. Moreover, it is also an alternative approach to the GARCH (1,1) model and its many related variant models (e.g., EGARCH model, GJR GARCH model). It provides an iterative scheme for updating statistic coefficients in a system of generalized method of moment/observation equations. Furthermore, application of the LLGMM method to stochastic differential dynamic models for energy commodity price, U.S. Treasury bill yield interest rate U.S.-U.K. foreign exchange rate exhibits its unique role and scope.","Otunuga, Olusegun M; Ladde, Gangaram S; Ladde, Nathan G",2017,10.1080/07362994.2016.1213640,None,proquest
28798acb3ba870d9,Local lagged adapted generalized method of moments: An innovative estimation and forecasting approach and its applications,"In this work, an attempt is made to apply the Local Lagged Adapted Generalized Method of Moments (LLGMM) to estimate state and parameters in stochastic differential dynamic models. The development of LLGMM is motivated by parameter and state estimation problems in continuous-time nonlinear and non-stationary stochastic dynamic model validation problems in biological, chemical, engineering, energy commodity markets, financial, medical, military, physical sciences and social sciences. The byproducts of this innovative approach (LLGMM) are the balance between model specification and model prescription of continuous-time dynamic process and the development of discrete-time interconnected dynamic model of local sample mean and variance statistic process (DTIDMLSMVSP). Moreover, LLGMM is a dynamic non-parametric method. The DTIDMLSMVSP is an alternative approach to the GARCH(1,1) model, and it provides an iterative scheme for updating statistic coefficients in a system of generalized method of moment/observation equations. Furthermore, applications of LLGMM to energy commodities price, U.S. Treasury Bill interest rate and the U.S.-U.K. foreign exchange rate data strongly exhibit its unique role, scope and performance, in particular, in forecasting and confidence-interval problems in applied statistics. © 2019 Elsevier B.V., All rights reserved.","Otunuga, O.M.; Ladde, G.S.; Ladde, N.G.",2019,10.1515/jtse-2016-0024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060695794&doi=10.1515%2Fjtse-2016-0024&partnerID=40&md5=40c6e24628aa2141e4d8b7306439ce99,scopus
b86b59095cc0f715,Long memory affine term structure models,"We develop a Gaussian discrete time essentially affine term structure model with long, memory state variables. This feature reconciles the strong persistence observed in nominal yields and inflation with the theoretical implications of affine models, especially for long maturities. We characterize in closed form the dynamic and cross-sectional implications of long memory for our model. We explain how long memory can naturally arise within the term structure of interest rates, providing a theoretical underpinning for our model. Despite the infinite-dimensional structure that long memory implies, we show how to cast the model in state space and estimate it by maximum likelihood. An empirical application of our model is presented. (C) 2015 Elsevier B.V. All rights reserved.","Golinski, Adam; Zaffaroni, Paolo",2016,10.1016/j.jeconom.2015.09.006,None,wos
2097fbf52b7eeb1d,Long-range facility planning based on dynamic programming for optimum combined cost and probability paths,"Dynamic programming (DP)-based planning algorithms have been shown to be valuable tools since they provide a basis for sampling, enumeration, and optimization of options for long-range deployment of facilities. Previous applications of DP to optimize pipeline long-range facility planning problems based on either the least-cost path for the facility or the most-probable path for noncost constraints have been documented in the literature. Such applications, however, are faced with a challenge in selecting the optimum facility deployment path, as the least-cost path does not always necessarily coincide with the most-probable path. As a result, the selection of a path that combines both features has to be achieved through a subjective compromise and in a rather arbitrary manner. In the present paper, two new DP methods have been developed which are based on the concept of combining cost and probability to give a single-objective probability-adjusted cost. One method incorporated the probability of each arc in the DP architecture using a variation of the Black-Scholes partial differential equation. The solution of the resulting equation gave a probability-adjusted arc cost dependent on the year (or stage) the cost incurred, the overall probability of all constraints associated with this arc, and the risk-free rate. The other method was based on simply dividing the present value of each arc cost by its probability to give a single probability-adjusted cost. Both approaches were applied to a complex DP architecture composed of 10 stages and 10 different options at each stage in which all options were available at every stage in a directed manner. The optimum paths from the new approaches were compared to the least-cost options, and most-probable options, and were found to combine the two features. Finally, all options from all methods were found to lie on a Pareto front obtained from a multiobjective genetic algorithm. © 2010 ASCE. © 2011 Elsevier B.V., All rights reserved.","Botros, K.K.; Tchir, W.J.; Henderson, J.F.; Chmilar, B.",2010,10.1061/(asce)ps.1949-1204.0000052,https://www.scopus.com/inward/record.uri?eid=2-s2.0-82355181547&doi=10.1061%2F%28ASCE%29PS.1949-1204.0000052&partnerID=40&md5=3cd46f312ce4b7a4fd1f3059e79dc975,scopus
cd6be72e5f7ea777,Long-term fiscal implications of funding assisted reproduction: a generational accounting model for Spain,"The aim of this study was to assess the lifetime economic benefits of assisted reproduction in Spain by calculating the return on this investment. We developed a generational accounting model that simulates the flow of taxes paid by the individual, minus direct government transfers received over the individual's lifetime. The difference between discounted transfers and taxes minus the cost of either IVF or artificial insemination (AI) equals the net fiscal contribution (NFC) of a child conceived through assisted reproduction. We conducted sensitivity analysis to test the robustness of our results under various macroeconomic scenarios. A child conceived through assisted reproduction would contribute €370,482 in net taxes to the Spanish Treasury and would receive €275,972 in transfers over their lifetime. Taking into account that only 75% of assisted reproduction pregnancies are successful, the NFC was estimated at €66,709 for IVF-conceived children and €67,253 for AI-conceived children. The return on investment for each euro invested was €15.98 for IVF and €18.53 for AI. The long-term NFC of a child conceived through assisted reproduction could range from €466,379 to €-9,529 (IVF) and from €466,923 to €-8,985 (AI). The return on investment would vary between €-2.28 and €111.75 (IVF), and €-2.48 and €128.66 (AI) for each euro invested. The break-even point at which the financial position would begin to favour the Spanish Treasury ranges between 29 and 41 years of age. Investment in assisted reproductive techniques may lead to positive discounted future fiscal revenue, notwithstanding its beneficial psychological effect for infertile couples in Spain.The aim of this study was to assess the lifetime economic benefits of assisted reproduction in Spain by calculating the return on this investment. We developed a generational accounting model that simulates the flow of taxes paid by the individual, minus direct government transfers received over the individual's lifetime. The difference between discounted transfers and taxes minus the cost of either IVF or artificial insemination (AI) equals the net fiscal contribution (NFC) of a child conceived through assisted reproduction. We conducted sensitivity analysis to test the robustness of our results under various macroeconomic scenarios. A child conceived through assisted reproduction would contribute €370,482 in net taxes to the Spanish Treasury and would receive €275,972 in transfers over their lifetime. Taking into account that only 75% of assisted reproduction pregnancies are successful, the NFC was estimated at €66,709 for IVF-conceived children and €67,253 for AI-conceived children. The return on investment for each euro invested was €15.98 for IVF and €18.53 for AI. The long-term NFC of a child conceived through assisted reproduction could range from €466,379 to €-9,529 (IVF) and from €466,923 to €-8,985 (AI). The return on investment would vary between €-2.28 and €111.75 (IVF), and €-2.48 and €128.66 (AI) for each euro invested. The break-even point at which the financial position would begin to favour the Spanish Treasury ranges between 29 and 41 years of age. Investment in assisted reproductive techniques may lead to positive discounted future fiscal revenue, notwithstanding its beneficial psychological effect for infertile couples in Spain.","Matorras, R; Villoro, R; González-Domínguez, A; Pérez-Camarero, S; Hidalgo-Vega, A; Polanco, C",2015,10.1016/j.rbms.2016.04.001,None,proquest
478dbbeb2d89f44e,Long/Short Equity Risk Premia Parity Portfolios via Implicit Factors in Regularized Covariance Regression,"A robust time series basis decomposition and non-stationary trend extraction technique, known as Empirical Mode Decomposition (EMD), will be combined with Regularised Covariance Regression (RCR) to produce a novel covariance forecasting technique. EMD is designed for multiscale and adaptive time-frequency decomposition in nonstationary time series. EMD-RCR generates multi-time-frequency resolution adaptive forecasting models of predictive covariance forecasts for a universe of selected asset returns. This provides a unique method to obtain predictive covariance regression structures for the short-, mid-, and long-time-scale portfolio dynamics. EMD isolates structures in a frequency-hierarchical fashion (with automated sorting of structures through EMD-MDLP available) which allows this multi-time-frequency covariance forecasting framework that uses the structures isolated using EMD (referred to as IMFs: Intrinsic Mode Functions) as the explanatory variables in the RCR framework. Having developed these techniques, a case study is used for exposition for active portfolio asset management. The case study is based on a dynamic long/short equity and risk premia parity (or risk parity) portfolio-of-portfolios investment strategy using the 11 sectors dividing the 505 stocks of the S&P 500. Each of the 11 sector indices is constructed using a market capitalisation ratio of the companies within the respective sector. The portfolio will be reweighted monthly based on the covariance structure forecast using covariance regression, in which covariance regression factors will be obtained at multiple time-frequency scales endogenously from the ETF asset price returns from each sector. At the end of each month, the covariance is forecast for the next month or investment horizon. This is done using low-, mid-, and high-frequency IMFs isolated using EMD from the 11 sector indices over the previous year. The IMFs isolated from the 11 sector indices over the previous year are fitted against the daily logarithmic returns in the RCR model to make multi-frequency covariance forecasts. We construct long/short equity and risk premia parity portfolios using each different covariance forecast and review the results. The performance of the portfolios will be measured using multiple performance measures (the most relevant being risk-related measures with risk premia parity in focus) and contrasted against multiple benchmark portfolios using several well-known portfolio optimisation techniques such as PCA and multivariate GARCH extensions. This paper promotes what we term “implicit factor” extraction, empirical market factors, and RCR in portfolio optimisation, horizon-specific active portfolio optimisation, long/short equity portfolios, and risk parity portfolios.",C. Van Jaarsveldt; G. W. Peters; M. Ames; M. Chantler,2024,10.1109/access.2024.3444479,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10637332,ieeexplore
08bba97ee6005b87,MARKET MANIPULATION: A SURVEY,"Despite the significant attention that market manipulation has received in recent years many aspects of it are poorly understood. This article identifies from the theoretical and empirical literature what we do and do not know about market manipulation, and suggests directions for future research. We know that manipulation is possible and that it occurs in a wide variety of markets and circumstances. In contrast, we know little about how often manipulation occurs, its effects and how it responds to regulation. Suggested approaches for future research on these issues include: (1) collecting more comprehensive data sets of manipulation cases; (2) using detection controlled estimation methods to overcome sample selection and partial observability problems and (3) conducting controlled experiments. This article also constructs a novel and broad taxonomy of the different types of market manipulation and discusses approaches to defining manipulation.","Putnins, Talis J.",2012,10.1111/j.1467-6419.2011.00692.x,None,wos
12f321bad940f541,Machine learning algorithms applied to the estimation of liquidity: the 10-year United States treasury bond,"PurposeHaving defined liquidity, the aim is to assess the predictive capacity of its representative variables, so that economic fluctuations may be better understood.Design/methodology/approachConceptual variables that are representative of liquidity will be used to formulate the predictions. The results of various machine learning models will be compared, leading to some reflections on the predictive value of the liquidity variables, with a view to defining their selection.FindingsThe predictive capacity of the model was also found to vary depending on the source of the liquidity, in so far as the data on liquidity within the private sector contributed more than the data on public sector liquidity to the prediction of economic fluctuations. International liquidity was seen as a more diffuse concept, and the standardization of its definition could be the focus of future studies. A benchmarking process was also performed when applying the state-of-the-art machine learning models.Originality/valueBetter understanding of these variables might help us toward a deeper understanding of the operation of financial markets. Liquidity, one of the key financial market variables, is neither well-defined nor standardized in the existing literature, which calls for further study. Hence, the novelty of an applied study employing modern data science techniques can provide a fresh perspective on financial markets.","Luque Raya, Ignacio Manuel; Pablo Luque Raya",2024,10.1108/ejmbe-06-2022-0176,None,proquest
d6f098222fbb7a8d,Machine learning for US cross-industry return predictability under information uncertainty,"This paper investigates the association between industry information uncertainty and cross-industry return predictability using machine learning in a general predictive regression framework. We show that controlling for post-selection inference and performing multiple tests improves the in-sample predictive performance of cross-industry return predictability in industries characterized by high uncertainty. Ordinary least squares post-least absolute shrinkage and selection operator models incorporating lagged industry information uncertainty for the financial and commodity industries are critical to improving prediction performance. Furthermore, in-sample industry return forecasts establish heterogeneous predictability over US industries, in which excess returns are more predictable in sectors with medium or low uncertainty. © 2023 Elsevier B.V., All rights reserved.","Awijen, H.; Ben-Zaied, Y.; Ben Lahouel, B.; Khlifi, F.",2023,10.1016/j.ribaf.2023.101893,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147577512&doi=10.1016%2Fj.ribaf.2023.101893&partnerID=40&md5=982b6c1f6cf5e817b5b4628e63b106a5,scopus
a4339a705a7fa1f2,Machine learning models and cost-sensitive decision trees for bond rating prediction,"Since the outbreak of the financial crisis, the major global credit rating agencies have implemented significant changes to their methodologies to assess the sovereign credit risk. Therefore, bond rating prediction has become an interesting potential for investors and financial institutions. Previous research studies in this field have applied traditional statistical methods to develop models which provide prediction accuracy. However, no overall distinguished methods have been used in predicting bond ratings. Moreover, recent studies have suggested ensembles of classifiers that may be used in bond rating prediction. This article proposes an improved machine learning aimed to predict the rating of financial bonds. We empirically compare the classifiers ranging from logistic regression and discriminant analysis to nonparametric classifiers, such as support vector machine, neural networks, the cost-sensitive decision tree algorithm and deep neural networks. Three real-world bond rating data sets were selected to check the effectiveness and the viability of the set of the classifiers. The experimental results confirm that data mining methods can represent an alternative to the traditional prediction models of bond rating. © 2020 Elsevier B.V., All rights reserved.","Ben Jabeur, S.B.; Saadaoui, A.; Sghaier, A.; Aloui, R.",2020,10.1080/01605682.2019.1581405,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064715076&doi=10.1080%2F01605682.2019.1581405&partnerID=40&md5=e3791d5826922a1e07d61ea236e0eb79,scopus
fa3ff66abeee79a5,Machine learning portfolio allocation,"We find economically and statistically significant gains when using machine learning for portfolio allocation between the market index and risk-free asset. Optimal portfolio rules for time-varying expected returns and volatility are implemented with two Random Forest models. One model is employed in forecasting monthly excess returns with macroeconomic factors including payout yields. The second is used to estimate the prevailing volatility. Reward-risk timing with machine learning provides substantial improvements over the buy-and-hold in utility, risk-adjusted returns, and maximum drawdowns. This paper presents a unifying framework for machine learning applied to both return- and volatility-timing. © 2021 Elsevier B.V., All rights reserved.","Pinelis, M.; Ruppert, D.",2022,10.1016/j.jfds.2021.12.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122398619&doi=10.1016%2Fj.jfds.2021.12.001&partnerID=40&md5=da9f23a6b807a580ea95847d19e96657,scopus
1f70028241552730,Machine-Learning-Based Return Predictors and the Spanning Controversy in Macro-Finance,"We propose a two-step machine learning algorithm-the Supervised Adaptive Group LASSO (SAGLasso) method-that is suitable for constructing parsimonious return predictors from a large set of macro variables. We apply this method to government bonds and a set of 917 macro variables and construct a new, transparent, and easy-to-interpret macro variable with significant out-of-sample predictive power for excess bond returns. This new macro factor, termed the SAGLasso factor, is a linear combination of merely 30 selected macro variables out of 917. Furthermore, it can be decomposed into three sublevel factors: a novel housing factor, an employment factor, and an inflation factor. Importantly, the predictive power of the SAGLasso factor is robust to bond yields, namely, the SAGLasso factor is not spanned by bond yields. Moreover, we show that the unspanned variation of the SAGLasso factor cannot be attributed to yield measurement error or macro measurement error. The SAGLasso factor therefore provides a potential resolution to the spanning controversy in the macro-finance literature.","Huang, Jing-Zhi; Shi, Zhan",2023,10.1287/mnsc.2022.4386,None,proquest
592ae86c1ecb9d0b,Macro Factors and Bond Returns in China,"As a central issue in macro-finance studies, the spanning hypothesis has always been the focus of research. Previous studies have focused on whether this hypothesis holds true in developed markets, while paying little attention to that in emerging markets. Because of their unique monetary systems, governments in most emerging markets play a key role in bond returns. This study identifies macroeconomic factors for forecasting excess returns in emerging government bond markets under spanning hypothesis. We find that in previous research, government intervention factors employed in excess returns forecasting have no additional predictive ability, as they are already incorporated in current yields. Using dynamic factor analysis, we find that macroeconomic information, including pure macroeconomic activities and financial factors, has robust incremental predictive power for in-sample and out-of-sample bond excess returns. © 2022 Elsevier B.V., All rights reserved.","Li, X.; Yang, B.; Su, Y.; Qi, Y.; An, Y.",2022,10.1080/1540496x.2021.1941860,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109852085&doi=10.1080%2F1540496X.2021.1941860&partnerID=40&md5=4b6119268539038cc29dbe316dc7106a,scopus
333b098156476393,Macroeconomic Attention and Announcement Risk Premia,"We construct macroeconomic attention indexes (MAI), which are new measures of attention to different macroeconomic risks, including unemployment and monetary policy. Individual MAI tend to increase around related announcements and following changes in related fundamentals. Further, bad news raises attention more than good news. For unemployment and FOMC, attention predicts announcement risk premiums and implied volatility changes with large economic magnitudes. Our findings support theories of endogenous attention and announcement risk premiums, while demonstrating future research directions, including that announcements can raise new concerns. Macroeconomic announcements are important not only for contents and timing but also for attention.Authors have furnished an Internet Appendix, which is available on the Oxford University Press Web site next to the link to the final published paper online.","Fisher, Adlai; Martineau, Charles; Sheng, Jinfei",2022,10.1093/rfs/hhac011,None,proquest
0798f3bbdbaff551,Macroeconomic Models for Monetary Policy: A Critical Review from a Finance Perspective,"We provide a critical review of macroeconomic models used for monetary policy at central banks from a finance perspective. We review the history of monetary policy modeling, survey the core monetary models used by major central banks, and construct an illustrative model for those readers who are unfamiliar with the literature. Within this framework, we highlight several important limitations of current models and methods, including the fact that local-linearization approximations omit important nonlinear dynamics, yielding biased impulse-response analysis and parameter estimates. We also propose new features for the next generation of macrofinancial policy models, including a substantial role for the financial sector, the government balance sheet, and unconventional monetary policies; heterogeneity, reallocation, and redistribution effects;the macroeconomic impact of large nonlinear risk premium dynamics; time-varying uncertainty; financial sector and systemic risks; imperfect product market and markups; and further advances in solution, estimation, and evaluation methods for dynamic quantitative structural models. © 2020 Elsevier B.V., All rights reserved.","Dou, W.W.; Lo, A.W.; Muley, A.; Uhlig, H.",2020,10.1146/annurev-financial-012820-025928,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097430621&doi=10.1146%2Fannurev-financial-012820-025928&partnerID=40&md5=6c6933942ee847d97a6763f19dbc34d1,scopus
f8d976b8b744af6c,"Macroeconomic attention, economic policy uncertainty, and stock volatility predictability","This study adopts the newly constructed macroeconomic attention indices (MAI) and category-specific economic policy uncertainty (EPU) indices to predict stock volatility. Principal component analysis (PCA), scaled PCA (sPCA), and partial least squares (PLS) are used to extract the principal components from indicators. The results show that the combination of MAI and EPU indices can obtain additional information for predicting stock market volatility. In addition, the comprehensive index containing all indicator information (F-t(All)) has the strongest short-term forecasting ability, whereas the MAI show the most substantial forecasting ability in long-term forecasting.","Ma, Feng; Guo, Yangli; Chevallier, Julien; Huang, Dengshi",2022,10.1016/j.irfa.2022.102339,None,wos
aa8f3a5c48986db6,Macroeconomic factors and emerging market equity returns: A Bayesian model selection approach,"Macroeconomics figures prominently in analyses of emerging markets, both as an asset class and for allocations within emerging markets. However, the literature on the drivers of emerging markets equity returns generally pays little attention to macroeconomic factors. This paper investigates the predictive power of several candidate macroeconomic factors for emerging market equity returns using the Bayesian model selection approach developed in Cremers [Cremers, K.J.M., 2002. Stock return predictability: a Bayesian model selection perspective. The Review of Financial Studies 15, 1223-1249]. The results provide strong evidence against all of the macro factors considered with the exception of exchange rate changes and, consistent with the existing literature, provide strong support for several financial factors, but not beta, as significant predictors of excess returns. © 2004 Published by Elsevier B.V. © 2018 Elsevier B.V., All rights reserved.","Hooker, M.A.",2004,10.1016/j.ememar.2004.09.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-10644293253&doi=10.1016%2Fj.ememar.2004.09.001&partnerID=40&md5=a4db5f2ad33213b6bf3c83efe1967361,scopus
61421c153a5054b3,Macroeconomic impact on the risk management of offshore wind farms,"The present study aims to develop a risk model to analyse offshore wind projects based on operational and macroeconomic data. The study investigates the underlying parameters defining the project-specific risk premium attached to an offshore wind project. These parameters are modelled as stochastic variables, and a probabilistic financial analysis is conducted using Monte Carlo Simulation. To calculate an interest rate based on operational characteristics, the present study assumes that two net present value equations yielding the same result can be written where certainty equivalent cash flows discounted at the risk-free rate and b) expected cash flows discounted at the cost of capital. The project-related risk is then estimated by solving the resulting equation for the unknown cost of capital. The macroeconomic factors are also considered as they impact the uncertainty associated with revenue and operating expenditure. The model developed to calculate the cost of capital is validated by comparing it with the data obtained for publicly traded renewable energy companies worldwide. Finally, the developed model is demonstrated for a fictitious ageing offshore wind farm under different economic circumstances. The parametric study is conducted on the effect of critical project-specific parameters such as the number of offshore wind turbines, the life extension duration, and the degree of uncertainty related to cash flows. © 2023 Elsevier B.V., All rights reserved.","Yeter, B.; Garbatov, Y.; Brennan, F.; Kolios, A.",2023,10.1016/j.oceaneng.2023.115224,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163853313&doi=10.1016%2Fj.oceaneng.2023.115224&partnerID=40&md5=e3ba1273ef2d4c7cb232dbc4702c5d8a,scopus
b92002fe79b6fc1b,Making cost-benefit analysis a practical tool for evaluation,"A cost-benefit evaluation requires precise data on program out-comes. However, such data are unavailable when the analysis is prospective, and expensive and time-consuming to collect when the analysis is retrospective. This problem of uncertain data is partly solved by the revised version of the Treasury Board Benefit-Cost Analysis Guide (Watson & Mallory, 1997), which allows probabilistic estimates of program results to be used in the analysis. There are not yet many examples of this technique in practice. One is Transport Canada's evaluation of alternative requirements for small commercial vessels to carry emergency signaling equipment. This article describes that evaluation and assesses how well the methodology worked. Copyright © 2006 Canadian Evaluation Society. © 2024 Elsevier B.V., All rights reserved.","Watson, K.",2006,10.3138/cjpe.021.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250161650&doi=10.3138%2Fcjpe.021.003&partnerID=40&md5=0a455db4987c1230ae4a280f1d2da0f9,scopus
44be03948484da4f,Man versus Machine Learning Revisited,"Binsbergen, Han, and Lopez-Lira (2023) predict analysts' forecast errors using a random forest model. A strategy that trades against this model's predictions earns a monthly alpha of 1.54% ($ t $-value = 5.84). This estimate represents a large improvement over studies using classical statistical methods. We attribute the difference to a look-ahead bias. Removing the bias erases the alpha. Linear models yield as accurate forecasts and superior trading profits. Neither alternative machine learning models nor combinations thereof resurrect the predictability. We discuss the state of research into the term structure of analysts' forecasts and its causal relationship with returns.","Zhang, Yingguang; Zhu, Yandi; Linnainmaa, Juhani T.",2025,10.1093/rfs/hhaf066,None,wos
5b3ffa4249af3ca0,Market Efficiency and Equity Risk Premium Predictability,"This work examines equity risk premium predictability in periods of market efficiency and market inefficiency. Efficiency is measured by the return's degree of multifractality, calculated from the multifractal detrended fluctuation analysis method. For the S&P 500 index during the 1951–2022 period, the results show that market efficiency varies over time, with recurrent periods of statistically significant inefficiency (multifractality). Moments of inefficiency are associated with (i) a higher level of financial uncertainty—financial uncertainty Granger causes the degree of multifractality (inefficiency), (ii) a greater variability in the patterns of dependence of returns and also (iii) with periods of more relevant volatility clusters. In times of market inefficiency (efficiency), the use of financial (technical) indicators shows statistically significant in-sample and out-of-sample accuracy for equity risk premium prediction. When the market is efficient (inefficient), the use of financial (technical) indicators should be avoided due to the degradation of their predictive capacity. To build accurate and statistically significant predictions of the risk premium, thus enhancing decision-making processes, investors should monitor the informational efficiency status of the market before selecting financial and technical indicators as predictive variables. Finally, during market inefficiency periods, there is a greater polarisation of investors' opinions, with increased attention to fundamental variables for risk premium prediction, leading to a breakdown in price trend patterns, explaining the worst predictive capacity of technical indicators. © 2025 Elsevier B.V., All rights reserved.","Maciel, L.; da Silva, R.F.",2025,10.1002/ijfe.3058,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207528014&doi=10.1002%2Fijfe.3058&partnerID=40&md5=1ffdd4485e71ae8d511b671b1fd70f5e,scopus
cda1c91e62a7ddb3,Market Returns and a Tale of Two Types of Attention,"We provide novel evidence that aggregate investor attention to stocks predicts marketwide returns, but with a striking difference across investor clienteles. Daily aggregate retail attention (ARA) negatively predicts one-week-ahead market returns, is associated with aggregate retail order imbalance and flows to equity mutual funds, and exhibits a stronger predictability during periods of high marketwide uncertainty, poor liquidity, or more costly short selling. In contrast, aggregate institutional attention (AIA), when observed before major news announcements, positively predict future marketwide returns. In cross-sectional analysis, we show that the predictability is stronger for ARA among illiquid stocks and for AIA among high-beta stocks. The predictability results are robust out-of-sample and correspond to meaningful expected utility gains even for diversified investors. The findings are consistent with the idea that attention-driven retail buying can generate an aggregate price pressure on the stock market, whereas institutional attention precedes the resolution of marketwide uncertainty and the accrual of risk premiums.","Da, Zhi; Hua, Tian; Hung, Tim Chih-Ching; Peng, Lin",2025,10.1287/mnsc.2023.01294,None,wos
8e03ef7073e5ba57,Markov switching models in empirical finance,"I review the burgeoning literature on applications of Markov regime switching models in empirical finance. In particular, distinct attention is devoted to the ability of Markov Switching models to fit the data, filter unknown regimes and states on the basis of the data, to allow a powerful tool to test hypotheses formulated in light of financial theories, and to their forecasting performance with reference to both point and density predictions. The review covers papers concerning a multiplicity of subfields in financial economics, ranging from empirical analyses of stock returns, the term structure of default-free interest rates, the dynamics of exchange rates, as well as the joint process of stock and bond returns. Copyright © 2011 by Emerald Group Publishing Limited. © 2013 Elsevier B.V., All rights reserved.","Guidolin, M.",2011,10.1108/s0731-9053(2011)000027b004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872420543&doi=10.1108%2FS0731-9053%282011%29000027B004&partnerID=40&md5=f6c892890a65c56195475aa0f9c3021c,scopus
53a26b3792f39f00,Maximum Likelihood Estimation in Markov Regime-Switching Models With Covariate-Dependent Transition Probabilities,"This paper considers maximum likelihood (ML) estimation in a large class of models with hidden Markov regimes. We investigate consistency of the ML estimator and local asymptotic normality for the models under general conditions, which allow for autoregressive dynamics in the observable process, Markov regime sequences with covariate-dependent transition matrices, and possible model misspecification. A Monte Carlo study examines the finite-sample properties of the ML estimator in correctly specified and misspecified models. An empirical application is also discussed.","Pouzo, Demian; Psaradakis, Zacharias; Sola, Martin",2022,10.3982/ecta17249,None,wos
3b1e2230bdc21afd,Maximum likelihood estimation of non-affine volatility processes,"In this paper we develop a new estimation method for extracting non-affine latent stochastic volatility and risk premia from measures of model-free realized and risk-neutral integrated volatility. We estimate non-affine models with nonlinear drift and constant elasticity of variance and we compare them to the popular square-root stochastic volatility model. Our empirical findings are: (1) the square-root model is misspecified; (2) the inclusion of constant elasticity of variance and nonlinear drift captures stylized facts of volatility dynamics and (3) the square-root stochastic volatility model is explosive under the risk-neutral probability measure. All rights reserved, Elsevier","Chourdakis, K; Dotsis, G",2011,10.1016/j.jempfin.2010.10.006,None,proquest
5080e4a5f3be7be5,Maximum likelihood estimation of partially observed diffusion models,"This paper develops a maximum likelihood (ML) method to estimate partially observed diffusion models based on data sampled at discrete times. The method combines two techniques recently proposed in the literature in two separate steps. In the first step, the closed form approach of Ait-Sahalia (2008) is used to obtain a highly accurate approximation to the joint transition probability density of the latent and the observed states. In the second step, the efficient importance sampling technique of Richard and Zhang (2007) is used to integrate out the latent states, thereby yielding the likelihood function. Using both simulated and real data, we show that the proposed ML method works better than alternative methods. The new method does not require the underlying diffusion to have an affine structure and does not involve infill simulations. Therefore, the method has a wide range of applicability and its computational cost is moderate. (C) 2014 Elsevier B.V. All rights reserved.","Kleppe, Tore Selland; Yu, Jun; Skaug, Hans J.",2014,10.1016/j.jeconom.2014.02.002,None,wos
6e7428a05a102988,"Measurement error, skewness, and risk analysis: Coping with the long tail of the distribution","Probabilistic risk analyses often construct multistage chance trees to estimate the joint probability of compound events. If random measurement error is associated with some or all of the estimates, we show that resulting estimates of joint probability may be highly skewed. Joint probability estimates based on the analysis of multistage chance trees are more likely than not to be below the true probability of adverse events, but will sometimes substantially overestimate them. In contexts such as insurance markets for environmental risks, skewed distributions of risk estimates amplify the ""winner's curse"" so that the estimated risk premium for low-probability events is likely to be lower than the normative value. Skewness may result even in unbiased estimators of expected value from simple lotteries, if measurement error is associated with both the probability and pay-off terms. Further, skewness may occur even if the error associated with these two estimates is symmetrically distributed. Under certain circumstances, skewed estimates of expected value may result in risk-neutral decisionmakers exhibiting a tendency to choose a certainty equivalent over a lottery of equal expected value, or vice versa. We show that when distributions of estimates of expected value are positively skewed, under certain circumstances it will be optimal to choose lotteries with nominal values lower than the value of apparently superior certainty equivalents. Extending the previous work of Goodman (1960), we provide an exact formula for the skewness of products. © 2008 Elsevier B.V., All rights reserved.","Mumpower, J.L.; McClelland, G.",2002,10.1111/0272-4332.00027,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036093310&doi=10.1111%2F0272-4332.00027&partnerID=40&md5=e208b86abcf5d91cfe313e6fa5828657,scopus
97f84ada8039939e,Measuring ESG risk premia with contingent claims,"We propose a contingent claims approach for estimating ESG risk premia from market information and market participants' decisions. To this end, we infer the asset value dynamics via the structural model of Merton [1974, On the Pricing of Corporate Debt: The Risk Structure of Interest Rates. Journal of Finance 29: 449-470.] for a large panel of S&P 500 firms using an estimation algorithm that utilizes the information embedded in stock market prices, CDS spreads, and default probabilities. We find a statistically significant relationship between the ESG score and the volatility and drift terms of the asset value process, suggesting that ESG factors are structurally connected to the value of the firm. We establish a mapping between ESG scores and the cost of equity and debt as implied by firm's contingent claims, and derive estimates of the ESG risk premium across different ESG and leverage profiles. In addition, we break down the ESG risk premia by industry, and demonstrate how practitioners can adjust the weighed average cost of capital of ESG laggard firms for valuation and decision making purposes.","Michopoulos, Ioannis; Bougias, Alexandros; Episcopos, Athanasios; Livanis, Efstratios",2025,10.1080/1351847x.2024.2394550,None,wos
50f2b2d275365f3b,Measuring Economic Uncertainty in China†,"This study develops a new economic uncertainty (EU) index based on Chinese newspapers to address the media coverage bias of existing measures. We investigate how the EU affects China’s macroeconomy. Our results suggest that the EU reduces aggregate output. We find that uncertainty predicts fluctuations in economic activity and actual economic activity also predicts EU, but nonlinearly. Furthermore, we show that uncertainty in the United States leads to uncertainty in China, implying that negative EU on the Chinese economy is coming from the U.S. Finally, we conduct some asset-pricing tests, showing that EU can predict stock returns and commands risk premium. Our results are helpful for both researchers and policymakers to stabilize the economy and financial markets in China. © 2022 Elsevier B.V., All rights reserved.","Pan, W.-F.; Wang, X.; Wang, S.",2022,10.1080/1540496x.2021.1873764,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100533968&doi=10.1080%2F1540496X.2021.1873764&partnerID=40&md5=0e68f4835371abb9317f7969560367ff,scopus
00a73739f92c0789,Measuring Granger Causality in Quantiles,"We consider measures of Granger causality in quantiles, which detect and quantify both linear and nonlinear causal effects between random variables. The measures are based on nonparametric quantile regressions and defined as logarithmic functions of restricted and unrestricted expectations of quantile check loss functions. They can consistently be estimated by replacing the unknown expectations of check loss functions by their nonparametric kernel estimates. We derive a Bahadur-type representation for the nonparametric estimator of the measures. We establish the asymptotic distribution of this estimator, which can be used to build tests for the statistical significance of the measures. Thereafter, we show the validity of a smoothed local bootstrap that can be used in finite-sample settings to perform statistical tests. A Monte Carlo simulation study reveals that the bootstrap-based test has a good finite-sample size and power properties for a variety of data-generating processes and different sample sizes. Finally, we provide an empirical application to illustrate the usefulness of measuring Granger causality in quantiles. We quantify the degree of predictability of the quantiles of equity risk premium using the variance risk premium, unemployment rate, inflation, and the effective federal funds rate. The empirical results show that the variance risk premium and effective federal funds rate have a strong predictive power for predicting the risk premium when compared to that of the predictive power of the other two macro variables. In particular, the variance risk premium is able to predict the center, lower, and upper quantiles of the distribution of the risk premium; however, the effective federal funds rate predicts only the lower and upper quantiles. Nevertheless, unemployment and inflation rates have no effect on the risk premium. © 2021 Elsevier B.V., All rights reserved.","Song, X.; Taamouti, A.",2021,10.1080/07350015.2020.1739531,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083679836&doi=10.1080%2F07350015.2020.1739531&partnerID=40&md5=e9977f79be5e9c56482a636bb3b4d94d,scopus
f17ea1ec214a9104,Measuring Nonlinear Granger Causality in Mean,"We propose model-free measures for Granger causality in mean between random variables. Unlike the existing measures, ours are able to detect and quantify nonlinear causal effects. The new measures are based on nonparametric regressions and defined as logarithmic functions of restricted and unrestricted mean square forecast errors. They are easily and consistently estimated by replacing the unknown mean square forecast errors by their nonparametric kernel estimates. We derive the asymptotic normality of nonparametric estimator of causality measures, which we use to build tests for their statistical significance. We establish the validity of smoothed local bootstrap that one can use in finite sample settings to perform statistical tests. Monte Carlo simulations reveal that the proposed test has good finite sample size and power properties for a variety of data-generating processes and different sample sizes. Finally, the empirical importance of measuring nonlinear causality in mean is also illustrated. We quantify the degree of nonlinear predictability of equity risk premium using variance risk premium. Our empirical results show that the variance risk premium is a very good predictor of risk premium at horizons less than 6 months. We also find that there is a high degree of predictability at the 1-month horizon, that can be attributed to a nonlinear causal effect. Supplementary materials for this article are available online. © 2018 Elsevier B.V., All rights reserved.","Song, X.; Taamouti, A.",2018,10.1080/07350015.2016.1166118,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018176704&doi=10.1080%2F07350015.2016.1166118&partnerID=40&md5=19c7fae0c027a8832819bbcf997de9c1,scopus
bcd2cc2bd87fa5d9,Measuring Risk Premiums Using Financial Reports and Actuarial Disclosures,"Insurance companies increasingly augment their financial reports by releasing actuarial measures the so-called embedded value to supply information about the value of their life insurance activities. Both accounting and actuarial measures differ with respect to the timeliness of profit realisation and its reliability, and their performance in yielding information may differ. This paper asks if and how embedded values help in assessing risk premiums. We estimate multifactor market models in the spirit of Fama and French, and find that actuarial disclosures are superior to financial accounting in estimating these risk premiums. They further add information to financial reports as an estimator for growth opportunities.","Zimmermann, Jochen; Veith, Stefan; Schymczyk, Johannes",2015,10.1057/gpp.2014.17,None,wos
a0ae28c3f6db31b0,Measuring contagion effects between crude oil and Chinese stock market sectors,"The role of cross-market linkages in the occurrence of tail events in stock and energy markets has not yet been fully understood in the contagion literature. This paper investigates the contagion from oil prices to Chinese stock sectors by considering differences between extreme positive returns and extreme negative returns. We compute time-varying cut-offs by employing a generalized Pareto distribution (GPD) function to estimate excess returns. We then use a multinomial logit (MNL) model to examine the probability of Chinese stock sector co-exceedances associated with oil price exceedances. Our results indicate that, compared to common domestic factors, the contagion between oil price and stock sectors is relatively weak, but never negligible. We argue that faced with volatile oil prices during turbulent periods, the existence of any contagion weakens the benefits of portfolio diversification related to oil and Chinese stock sector investment. Based on our findings, investors holding a portfolio of oil and Chinese sector stocks should pay special attention to the extreme changes in crude oil prices and adopt hedging measures to protect their portfolio from extreme shocks to oil markets. © 2018 Elsevier B.V., All rights reserved.","Fang, S.; Egan, P.",2018,10.1016/j.qref.2017.11.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034079456&doi=10.1016%2Fj.qref.2017.11.010&partnerID=40&md5=d7590a7aff8c4cc31d0bc45a65327a35,scopus
3bf14016cea7e254,Measuring sovereign contagion in Europe,"This paper analyzes sovereign risk shift-contagion, i.e. positive and significant changes in the propagation mechanisms, using bond yield spreads for the major eurozone countries. By emphasizing the use of two econometric approaches based on quantile regressions (standard quantile regression and Bayesian quantile regression with heteroskedasticity) we find that the propagation of shocks in euro's bond yield spreads shows almost no presence of shift-contagion in the sample periods considered (2003-2006, Nov. 2008-Nov. 2011, Dec. 2011-Apr. 2013). Shock transmission is no different on days with big spread changes and small changes. This is the case even though a significant number of the countries in our sample have been extremely affected by their sovereign debt and fiscal situations. The risk spillover among these countries is not affected by the size or sign of the shock, implying that so far contagion has remained subdued. However, the US crisis does generate a change in the intensity of the propagation of shocks in the eurozone between the 2003-2006 pre-crisis period and the Nov. 2008-Nov. 2011 post-Lehman one, but the coefficients actually go down, not up! All the increases in correlation we have witnessed over the last years come from larger shocks and the heteroskedasticity in the data, not from similar shocks propagated with higher intensity across Europe. These surprising, but robust, results emerge because this is the first paper, to our knowledge, in which a Bayesian quantile regression approach allowing for heteroskedasticity is used to measure contagion. This methodology is particularly well-suited to deal with nonlinear and unstable transmission mechanisms especially when asymmetric responses to sign and size are suspected. (C) 2017 Elsevier B.V. All rights reserved.","Caporin, Massimiliano; Pelizzon, Loriana; Ravazzolo, Francesco; Rigobon, Roberto",2018,10.1016/j.jfs.2017.12.004,None,wos
8b8d203398039561,Measuring the Financial Value of Marketing Strategy with Excess Stock Market Return,"This paper proposes excess stock market return as a way to measure the impact of marketing strategy on firm value. First, it provides an overview of event study method. An event study examines the excess return to a firm's stock price after the release of information that is relevant to the firm's financial success. Second, it shows how excess return captures a marketing strategy's impact on firm value. It presents a model that illustrates how a marketing strategy impacts consumers, future cash flows, firm value, investor's expectations, and excess return. Third, a comparison shows that excess return stacks up well against standard marketing metrics. Excess return yields unbiased estimates, allows direct causal inference, is future oriented, includes all cash flows, accounts for opportunity costs, factors in risk, and takes into account the time value of money.","Lane, Vicki",2014,10.4018/ijrcm.2014100101,None,proquest
19c588a05711d2d3,Measuring the Level and Uncertainty of Trend Inflation,"Firmly anchored inflation expectations are widely viewed as playing a central role for the conduct of monetary policy. This paper presents estimates of trend inflation, based on information contained in monthly data on realized inflation, survey expectations, and the term structure of interest rates. In order to assess whether inflation expectations are anchored, a timevarying volatility of trend shocks is estimated as well. While there is some commonality in inflation- and survey-based estimates of trend inflation, yield-based trend estimates embed a highly persistent component orthogonal to trend inflation. Trimmed-mean inflation rates and survey forecasts are most indicative of trend inflation.","Mertens, Elmar",2016,10.1162/rest_a_00549,None,wos
2ca7dfdb8bc7cff3,Measuring the Macroeconomic Impact of Monetary Policy at the Zero Lower Bound,"This paper employs an approximation that makes a nonlinear term structure model extremely tractable for analysis of an economy operating near the zero lower bound for interest rates. We show that such a model offers an excellent description of the data compared to the benchmark model and can be used to summarize the macroeconomic effects of unconventional monetary policy. Our estimates imply that the efforts by the Federal Reserve to stimulate the economy since July 2009 succeeded in making the unemployment rate in December 2013 1% lower, which is 0.13% more compared to the historical behavior of the Fed. © 2016 Elsevier B.V., All rights reserved.","Wu, J.C.; Xia, F.D.",2016,10.1111/jmcb.12300,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962845380&doi=10.1111%2Fjmcb.12300&partnerID=40&md5=a52aebcac9facacc69f11196ac83a70d,scopus
4d23cc600c835687,Measuring the natural rate of interest,"The natural rate of interest-the real interest rate consistent with output equaling its natural rate and stable inflation-plays a central role in macroeconomic theory and monetary policy. Estimation of the natural rate of interest, however, has received little attention. We apply the Kalman filter to estimate jointly time-varying natural rates of interest and output and trend growth. We find a close link between the natural rate of interest and the trend growth rate, as predicted by theory. Estimates of the natural rate of interest, however, are very imprecise and subject to considerable real-time measurement error.","Laubach, T; Williams, JC",2003,10.1162/003465303772815934,None,wos
014d516a2e0c45b7,"Measuring the performance of government bond portfolios with index-based level, slope, and curvature factors","This paper introduces a three-factor interest rate risk model to improve the measurement of active bond fund performance. Traditional models assume a linear relationship between risk exposure and expected returns, leading to biases. By incorporating level, slope, and curvature factors derived from Treasury index returns, the proposed model better captures the nonlinear nature of bond returns. Empirical tests on passive and active US government bond portfolios confirm its accuracy in estimating passive style returns and active alpha. The study also provides the first performance analysis of fixed-income separate accounts, revealing their economic significance and superior value-added performance over mutual funds. © 2025 Elsevier B.V., All rights reserved.","Rohleder, M.",2025,10.1002/rfe.70024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014890422&doi=10.1002%2Frfe.70024&partnerID=40&md5=6803ce0a2bde3094c0a0d12da1441a18,scopus
8991d3ec333a8394,Measuring the risk of a non-linear portfolio with fat-tailed risk factors through a probability conserving transformation,"This paper presents a new heuristic for fast approximation of VaR (Value-at-Risk) and CVaR (conditional Value-at-Risk) for financial portfolios, where the net worth of a portfolio is a non-linear function of possibly non-Gaussian risk factors. The proposed method is based on mapping non-normal marginal distributions into normal distributions via a probability conserving transformation and then using a quadratic, i.e. Delta–Gamma, approximation for the portfolio value. The method is very general and can deal with a wide range of marginal distributions of risk factors, including non-parametric distributions. Its computational load is comparable with the Delta–Gamma–Normal method based on Fourier inversion. However, unlike the Delta–Gamma–Normal method, the proposed heuristic preserves the tail behaviour of the individual risk factors, which may be seen as a significant advantage. We demonstrate the utility of the new method with comprehensive numerical experiments on simulated as well as real financial data.",P. Date; R. Bustreo,2016,10.1093/imaman/dpu015,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8146531,ieeexplore
e5422404091a6856,Medical Extended Reality for Radiology Education and Training,"Medical extended reality (MXR), encompassing augmented reality, virtual reality, and mixed reality (MR), presents a novel paradigm in radiology training by offering immersive, interactive, and realistic learning experiences in health care. Although traditional educational tools in the field of radiology are essential, it is necessary to capitalize on the innovative and emerging educational applications of extended reality (XR) technologies. At the most basic level of learning anatomy, XR has been extensively used with an emphasis on its superiority over conventional learning methods, especially in spatial understanding and recall. For imaging interpretation, XR has fostered the concepts of virtual reading rooms by enabling collaborative learning environments and enhancing image analysis and understanding. Moreover, image-guided interventions in interventional radiology have witnessed an uptick in XR utilization, illustrating its effectiveness in procedural training and skill acquisition for medical students and residents in a safe and risk-free environment. However, there remain several challenges and limitations for XR in radiology education, including technological, economic, and ergonomic challenges and and integration into existing curricula. This review explores the transformative potential of MXR in radiology education and training along with insights on the future of XR in radiology education, forecasting advancements in immersive simulations, artificial intelligence integration for personalized learning, and the potential of cloud-based XR platforms for remote and collaborative training. In summation, MXR's burgeoning role in reshaping radiology education offers a safer, scalable, and more efficient training model that aligns with the dynamic healthcare landscape.Medical extended reality (MXR), encompassing augmented reality, virtual reality, and mixed reality (MR), presents a novel paradigm in radiology training by offering immersive, interactive, and realistic learning experiences in health care. Although traditional educational tools in the field of radiology are essential, it is necessary to capitalize on the innovative and emerging educational applications of extended reality (XR) technologies. At the most basic level of learning anatomy, XR has been extensively used with an emphasis on its superiority over conventional learning methods, especially in spatial understanding and recall. For imaging interpretation, XR has fostered the concepts of virtual reading rooms by enabling collaborative learning environments and enhancing image analysis and understanding. Moreover, image-guided interventions in interventional radiology have witnessed an uptick in XR utilization, illustrating its effectiveness in procedural training and skill acquisition for medical students and residents in a safe and risk-free environment. However, there remain several challenges and limitations for XR in radiology education, including technological, economic, and ergonomic challenges and and integration into existing curricula. This review explores the transformative potential of MXR in radiology education and training along with insights on the future of XR in radiology education, forecasting advancements in immersive simulations, artificial intelligence integration for personalized learning, and the potential of cloud-based XR platforms for remote and collaborative training. In summation, MXR's burgeoning role in reshaping radiology education offers a safer, scalable, and more efficient training model that aligns with the dynamic healthcare landscape.","Lang, Min; Ghandour, Samir; Rikard, Blaire; Balasalle, Eleni K; Rouhezamin, Mohammad R; Zhang, Haipeng; Uppot, Raul N",2024,10.1016/j.jacr.2024.05.006,None,proquest
465b71f382fbc310,Merchant Commodity Storage and Term-Structure Model Error,"Merchant operations involves valuing and hedging the cash flows of commodity- and energy-conversion assets as real options based on stochastic models that inevitably embed model error. In this paper we quantify how empirically calibrated model errors concerning the futures term structure affect the valuation and hedging of natural gas storage. We find that even small model errors-on the order of 1%-2% of the empirical futures price variance-can have a disproportionate impact on storage valuation and hedging. In particular, theoretically equivalent hedging strategies have very different sensitivities to model error, with one natural strategy exhibiting potentially catastrophic performance in the presence of small model errors. We propose effective approaches to mitigate the negative effect of futures term-structure model error on hedging, also taking into account futures contract illiquidity, and provide theoretical justification for some of these approaches. Beyond commodity storage, our analysis has relevance for other real and financial options that depend on futures term-structure dynamics, as well as for inventory, production, and capacity investment policies that rely on demand-forecast term structures.","Secomandi, Nicola; Lai, Guoming; Margot, Francois; Scheller-Wolf, Alan; Seppi, Duane J.",2015,10.1287/msom.2015.0518,None,wos
e16d12b73176b407,Metals: resources or financial assets? A multivariate cross-sectional analysis,"Metals are very important resources for industrial production, but recently they have attracted more and more attention from investors. While certainly industrial producers, consumers, and financial investors do have some influence on metal price development, the role of relevant price factors is not yet quite clear. Therefore, in this paper, we examine the explanatory power of various fundamental factors and characteristics known from financial markets, specifically on the expected returns in a unique data sample of 30 metals. We apply-to our knowledge for the first time in this context-the widely accepted method of characteristic-sorted portfolios, extended by the very recent method of two-way portfolio sorts as an alternative to classical multivariate regressions. This mostly nonparametric approach, combined with portfolio aggregation, provides very robust results. Our major finding is that the financial characteristics value and momentum have a very high predictive power for monthly returns of metal portfolios. Metal-specific fundamental factors like stocks, secondary production, apparent consumption, country concentration, mine production, or reserves perform depending on the interpretation moderately well or rather poorly, regarding some economically interpretable transformations and when using multivariate two-way sorts. Hence, from the perspective of expected returns, metals are predominantly assets, while fundamental metal-specific factors still play a non-negligible role. Thus, to a much lesser extent, metals can still be regarded as resources. Overall, the combination of financial characteristics and metal-specific fundamental factors yields the best results. With these robust results, we hope to contribute to a better understanding of metal prices and their underlying factors.","Lutzenberger, Fabian; Gleich, Benedikt; Mayer, Herbert G.; Stepanek, Christian; Rathgeber, Andreas W.",2017,10.1007/s00181-016-1162-9,None,wos
f092eceac06de796,Mind the gap: forecasting euro-area output gaps with machine learning,"In this paper, we use the Eurozone yield curve in an effort to forecast the deviations of the euro-area output (IPI) from its long-run trend. We use various short- and long-term interest rates spanning the period from 2004:9 to 2020:6 in monthly frequency. The interest rates are fed to three machine learning methodologies: Decision Trees, Random Forests, and Support Vector Machines (SVM). These Machine Learning methodologies are then compared to an Elastic-Net Logistic Regression (Logit) model from the area of Econometrics. According to the results, the optimal SVM model coupled with the RBF kernel outperforms the competition reaching an in-sample accuracy of 85.29% and an out-of-sample accuracy of 94.74%.","Sofianos, Emmanouil; Gogas, Periklis; Papadimitriou, Theophilos",2022,10.1080/13504851.2021.1963403,None,proquest
048eafcb2e26ee95,Minimax and Biobjective Portfolio Selection Based on Collaborative Neurodynamic Optimization,"Portfolio selection is one of the important issues in financial investments. This article is concerned with portfolio selection based on collaborative neurodynamic optimization. The classic Markowitz mean–variance (MV) framework and its variant mean conditional value-at-risk (CVaR) are formulated as minimax and biobjective portfolio selection problems. Neurodynamic approaches are then applied for solving these optimization problems. For each of the problems, multiple neural networks work collaboratively to characterize the efficient frontier by means of particle swarm optimization (PSO)-based weight optimization. Experimental results with stock data from four major markets show the performance and characteristics of the collaborative neurodynamic approaches to the portfolio optimization problems.",M. -F. Leung; J. Wang,2021,10.1109/tnnls.2019.2957105,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948344,ieeexplore
43f035f3fb505552,Misaligned expectations and bond term premium measures☆,"This paper shows that inflation expectations and those embedded in short-term interest rate expectations as reported in the Survey of Professional Forecasters show evidence of misaligned expectations. This misalignment seems to have been substantial in recent times, featuring a low correlation between inflation and the policy rate. This empirical evidence motivates an alternative explanation, based on uncertainty rather than risk, of the bond term premium measures found in the literature. This paper estimates an expectational term premium driven by misaligned short-term interest rate expectations from a behavioral DSGE model that introduces model uncertainty by assuming adaptive learning with discretionary beliefs. The estimated 10-year expectational term premium shares important features with the corresponding term premium measures obtained using no-arbitrage affine term structure models. Thus, the expectational term premium is sizable, highly persistent, mildly countercyclical, and highly correlated with those term premium measures in the most recent period studied. In short, a potential misalignment of short-term interest expectations with inflation expectations provides an important channel for explaining the bond premium lately.","Vazquez, Jesus",2025,10.1016/j.najef.2025.102442,None,wos
b883d647a8f20108,"Model misspecification, the equilibrium natural interest rate, and the equity premium","This paper analyzes the natural rate of interest and the equity premium in a nonlinear model where agents are uncertain over both future technology growth and the future course of monetary policy. I show that model uncertainty, and notably uncertainty on the future course of monetary policy, can give rise to a sizable precautionary savings motive. This result is potentially problematic for both the estimation of the natural rate and its use as a policy indicator. Monetary uncertainty can also contribute to amplify the equity premium, and to account for its apparent, positive link with inflation. © 2009 The Ohio State University. © 2012 Elsevier B.V., All rights reserved.","Tristani, O.",2009,10.1111/j.1538-4616.2009.00263.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349421148&doi=10.1111%2Fj.1538-4616.2009.00263.x&partnerID=40&md5=e79ed1d77fb7696770f3d1293d03fc42,scopus
6e6b601cc5aa10eb,Model of corporate bond spread based on improved neural network,"The reasons for credit spreads can be divided into enterprise-specific non-systematic risks and widespread macroeconomic systemic risks. The previous traditional research mainly focused on the perspective of unsystematic risk. However, at present, more and more scholars are beginning to focus on systemic risks. Based on the neural network algorithm, this paper constructs an improved neural network-based corporate bond spread model to explore the impact of macro systemic risks on credit spreads. Based on the multi-factor no-arbitrage model, the linear relationship between the credit spread and the risk premium of each factor is obtained. At the same time, based on previous research results and observations of the current market reality, this paper identifies five important macroeconomic factors: actual economic output factors, inflation factors, stock market volatility factors, stock market return factors and inter-bank funding factors. The research results show that the model constructed in this paper has excellent performance.","Luo, Qiaoshun; Liu, Xinping",2021,10.3233/jifs-189497,None,wos
f296d1ee3108d658,Model risk for European-style stock index options,"In empirical modeling, there have been two strands for pricing in the options literature, namely the parametric and nonparametric models. Often, the support for the nonparametric methods is based on a benchmark such as the Black-Scholes (BS) model with constant volatility. In this paper, we study the stochastic volatility (SV) and stochastic volatility random jump (SVJ) models as parametric benchmarks against feedforward neural network (FNN) models, a class of neural network models. Our choice for FNN models is due to their well-studied universal approximation properties of an unknown function and its partial derivatives. Since the partial derivatives of an option pricing formula are risk pricing tools, an accurate estimation of the unknown option pricing function is essential for pricing and hedging. Our findings indicate that FNN models offer themselves as robust option pricing tools, over their sophisticated parametric counterparts in predictive settings. There are two routes to explain the superiority of FNN models over the parametric models in forecast settings. These are normormality of return distributions and adaptive learning.","Gencay, Ramazan; Gibson, Rajna",2007,10.1109/tnn.2006.883005,None,wos
08344aa9e15b1cee,Model uncertainty in the cross-section of stock returns,"We develop a transparent Bayesian framework to measure uncertainty in asset pricing models. By assigning a modified class of g-priors to the risk prices of asset pricing factors, our method quantifies the trade-off between mean–variance efficiency and parsimony for asset pricing models to achieve high posterior probabilities. Model uncertainty is defined as the entropy of these model probabilities. We prove the model selection consistency property of our procedure, which is missing from the classic g-priors. Acknowledging the possibility of omitting true asset pricing factors in real applications, we also characterize the maximum degree of contamination that the omitted factors can introduce to our model uncertainty measure. Empirically, we find that model uncertainty escalates during major market events and carries a significantly negative risk premium of approximately half the magnitude of the market. Positive shocks to model uncertainty predict persistent outflows from US equity funds and inflows to Treasury funds. © 2025 Elsevier B.V., All rights reserved.",None,2025,10.1016/j.jeconom.2025.106066,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011139721&doi=10.1016%2Fj.jeconom.2025.106066&partnerID=40&md5=b5f82e65537b031a0ee7bbc1e2956ee4,scopus
32b55f82824693c7,Modeling Health Data Using Machine Learning Techniques Applied to Financial Management Predictions,"Health management has steadily improved in performance and accuracy using IT technology. Hospitals and health institutions hold an enormous number of data in their software applications, which can be used with Big Data methodologies to extract useful information. One of the most challenging aspects of health institutional management is financial management; billing prediction is a key aspect to maintain a predictable service level for patients, avoiding unpleasant surprises and anticipating treasury management. Using patient data from public patient databases and applying a machine learning approach, this article offers a model that helps to make more precise and detailed financial plans.","Rafael Leon Sanz; Rafael Leon Sanz; Leon-Sanz, Pilar",2022,10.3390/app122312148,None,proquest
0ae15ca252dbc816,Modeling Investor Responses to Green Bond Issuance: Multidimensional Perspectives and Evidence From China,"Although green bonds are rapidly growing to be a mature financing tool, the debate over whether there are benefits to be gained by issuers’ stocks has yet to be resolved, especially in the emerging market context. Issuing green bonds, as a financing procedure targeted to green engineering projects and demonstrating the issuers’ environmentally friendly attitude, does and how does it affect the issuers’ stock prices, liquidity, and risk? We address this issue by paying attention to the Chinese green bond issuance events. Utilizing the event study method, research shows that investors react positively to green bond issuance events. However, this reaction is only sensitive to green bond listing events, but not to announcements. Investor responses can be reflected in the abnormal changes in stock prices and liquidity. Both the stock systematic risk and idiosyncratic risk show little change after firms issue green bonds, which illustrates that green bond issuance cannot shape the inherent investors’ value judgments on issuer companies, thereby only producing temporary impacts. This study suggests that the green premium of corporate stocks induced by green bond issuance events may be sourced from investors’ optimistic predictions about green transformation, rather than investors’ subjective willingness to promote environmental sustainability.",T. Su; B. Lin,2025,10.1109/tem.2025.3538945,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10874181,ieeexplore
68f06a53f1504663,Modeling Multi-horizon Electricity Demand Forecasts in Australia: A Term Structure Approach,"The Australian Electricity Market Operator generates one-day ahead electricity demand forecasts for the National Electricity Market in Australia and updates these forecasts over time until the time of dispatch. Despite the fact that these forecasts play a crucial role in the decision-making process of market participants, little attention has been paid to their evaluation and interpretation. Using half-hourly data from 2011 to 2015 for New South Wales and Queensland, it is shown that the official half-hourly demand forecasts do not satisfy the econometric properties required of rational forecasts. Instead there is a relationship between forecasts and forecast horizon similar to a term structure model of interest rates. To study the term structure of demand forecasts, a factor analysis that uses a small set of latent factors to explain the common variation among multiple observables is implemented. A three-factor model is identified with the factors admitting interpretation as the level, slope and curvature of the term structure of forecasts. The validity of the model is reinforced by assessing the economic value of demand forecasts. It is demonstrated that simple adjustments to long-horizon electricity demand forecasts based on the three estimated factors can enhance the informational content of the official forecasts.","Hurn, Stan; Vance, Martin; Tian, Jing",2023,10.5547/01956574.44.2.shur,None,proquest
7333ecab1e4cef3e,Modeling and predicting historical volatility in exchange rate markets,"Volatility modeling and forecasting of currency exchange rate is an important task in several business risk management tasks; including treasury risk management, derivatives pricing, and portfolio risk evaluation. The purpose of this study is to present a simple and effective approach for predicting historical volatility of currency exchange rate. The approach is based on a limited set of technical indicators as inputs to the artificial neural networks (ANN). To show the effectiveness of the proposed approach, it was applied to forecast US/Canada and US/Euro exchange rates volatilities. The forecasting results show that our simple approach outperformed the conventional GARCH and EGARCH with different distribution assumptions, and also the hybrid GARCH and EGARCH with ANN in terms of mean absolute error, mean of squared errors, and Theil's inequality coefficient. Because of the simplicity and effectiveness of the approach, it is promising for US currency volatility prediction tasks. © 2021 Elsevier B.V., All rights reserved.","Lahmiri, S.",2017,10.1016/j.physa.2016.12.061,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007518089&doi=10.1016%2Fj.physa.2016.12.061&partnerID=40&md5=9b4dde2750886471bb75756b62a43d05,scopus
4a7f853347d7646b,Modeling spot rate using a realized stochastic volatility model with level effect and dynamic drift,"This paper proposes a class of realized stochastic volatility model based on both various realized volatility measures and spot rate. It applies the realized stochastic volatility model (Takahashi, Omori, & Watanabe, 2009, and Koopman & Scharth, 2013) to the spot rate model with dynamic drift and level effect setups (RSVL). A jointly approximated maximum likelihood procedure is used to estimate this model. The simulation results show that the RSVL model can be consistently estimated and noise-and-jump-robust realized volatility measures improve the accuracy of the estimation. This study empirically investigates the Chinese interbank repo market with RSVL model, which manifested the advantage of taking the level effect and nonlinear drift into consideration. The noise-and-jump-robust realized volatility measures (e.g. subsample realized volatility and threshold pre-average realized volatility) decrease the volatility fitting error. The nonparametric testing suggests that the RSVL model with noise-and-jump-robust realized volatility measures has more power on forecasting excess kurtosis and fat tails and predicting dynamics of higher order autocorrelations. (C) 2017 Elsevier Inc. All rights reserved.","Li, Shaoyu; Zheng, Tingguo",2017,10.1016/j.najef.2017.03.003,None,wos
7ebc71b7e07716e7,Modeling the Yield Curve of BRICS Countries: Parametric vs. Machine Learning Techniques,"We compare parametric and machine learning techniques (namely: Neural Networks) for in–sample modeling of the yield curve of the BRICS countries (Brazil, Russia, India, China, South Africa). To such aim, we applied the Dynamic De Rezende–Ferreira five–factor model with time–varying decay parameters and a Feed–Forward Neural Network to the bond market data of the BRICS countries. To enhance the flexibility of the parametric model, we also introduce a new procedure to estimate the time varying parameters that significantly improve its performance. Our contribution spans towards two directions. First, we offer a comprehensive investigation of the bond market in the BRICS countries examined both by time and maturity; working on five countries at once we also ensure that our results are not specific to a particular data–set; second we make recommendations concerning modelling and estimation choices of the yield curve. In this respect, although comparing highly flexible estimation methods, we highlight superior in–sample capabilities of the neural network in all the examined markets and then suggest that machine learning techniques can be a valid alternative to more traditional methods also in presence of marked turbulence. © 2022 Elsevier B.V., All rights reserved.","Castello, O.; Resta, M.",2022,10.3390/risks10020036,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124573638&doi=10.3390%2Frisks10020036&partnerID=40&md5=b73ed06482dce2f2b6ac91c5c94bb0ae,scopus
f6f2449e72e7b384,Modeling the density of US yield curve using Bayesian semiparametric dynamic Nelson-Siegel model,"This paper proposes the Bayesian semiparametric dynamic Nelson-Siegel model for estimating the density of bond yields. Specifically, we model the distribution of the yield curve factors according to an infinite Markov mixture (iMM). The model allows for time variation in the mean and covariance matrix of factors in a discrete manner, as opposed to continuous changes in these parameters such as the Time Varying Parameter (TVP) models. Estimating the number of regimes using the iMM structure endogenously leads to an adaptive process that can generate newly emerging regimes over time in response to changing economic conditions in addition to existing regimes. The potential of the proposed framework is examined using US bond yields data. The semiparametric structure of the factors can handle various forms of non-normalities including fat tails and nonlinear dependence between factors using a unified approach by generating new clusters capturing these specific characteristics. We document that modeling parameter changes in a discrete manner increases the model fit as well as forecasting performance at both short and long horizons relative to models with fixed parameters as well as the TVP model with continuous parameter changes. This is mainly due to fact that the discrete changes in parameters suit the typical low frequency monthly bond yields data characteristics better.","Çakmakli, Cem",2020,10.1080/07474938.2019.1690191,None,proquest
68e704365ecd74f1,Modeling the term structure from the on-the-run treasury yield curve,"We propose a new model to estimate the term structure of interest rates using observed on-the-run Treasury yields. The new model is an improvement over models that require a priori knowledge of the shape of the yield curve to estimate the term structure. The general form of the model is an exponential function that depends on the estimation of four parameters fit by nonlinear least squares and has straightforward interpretations. In comparing the proposed model with current yield-curve-smoothing models, we find that, for the data used, the proposed model does best overall in terms of pricing accuracy both in sample and out of sample. JEL classification: E43, G12. © The Southern Finance Association and the Southwestern Finance Association. © 2018 Elsevier B.V., All rights reserved.","Mansi, S.A.; Phillips, J.H.",2001,10.1111/j.1475-6803.2001.tb00830.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037790039&doi=10.1111%2Fj.1475-6803.2001.tb00830.x&partnerID=40&md5=b4245734dc46cc70b7f7dc5a6c901db8,scopus
4af1fb5d81fb748c,Modeling the time-varying volatility of the paper-bill spread,"The spread between the rates on commercial paper and Treasury bills has received considerable attention in the literature for its role as an indicator of real economic activity. In this paper we empirically examine what happens when the volatility of the spread changes over time. We estimate a nonlinear model that enables us to discern the asymmetric impact of negative and positive shocks to the spread. We find that a positive shock has a larger impact on the volatility of the spread than does a negative shock. © 2009 Elsevier Inc. All rights reserved. © 2024 Elsevier B.V., All rights reserved.","Malik, F.; Ewing, B.T.; Kruse, J.B.; Lynch, G.J.",2009,10.1016/j.jeconbus.2009.03.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650577177&doi=10.1016%2Fj.jeconbus.2009.03.002&partnerID=40&md5=2a88f73bc55ca9f949c5fbd33d3186de,scopus
2cde5aab7ff222dc,Modeling volatility changes in the 10-year Treasury,"This paper examines the daily volatility of changes in the 10-year Treasury note utilizing the iterated cumulative sums of squares algorithm [C. Inclan, G. Tiao, Use of cumulative sums of squares for retrospective detection of changes of variance, J. Am. Stat. Assoc. 89 (1994) 913-923]. The ICSS algorithm can detect regime shifts in the volatility of the interest rate changes. A general model allows for endogenously determined changes in variance while the more restrictive model forces the variance to follow the same process throughout the sample period. A comparison of the out-of-sample volatility forecasting performance of two competing models is made using asymmetric error measures. The asymmetric error statistics penalize models for under- or over-predicting volatility. The results shed light on the importance of ignoring volatility regime shifts when performing out-of-sample forecasts. The findings are important to financial market participants who require accurate forecasts of future volatility in order to implement and evaluate asset performance. (c) 2006 Elsevier B.V. All rights reserved.","Covarrubias, Guillermo; Ewing, Bradley T.; Hein, Scott E.; Thompson, Mark A.",2006,10.1016/j.physa.2006.01.074,None,wos
409f6a68e1b88100,Modelling Electricity Swaps with Stochastic Forward Premium Models,"We present a new model for pricing electricity swaps. Two general factors affect contracts but unique risk elements affect each contract. General factors are average swap prices and deterministic trend-seasonal components, and unique elements are forward premiums. Innovations follow MNIG distributions. We estimate the model with data from the European Energy Exchange. The model outperforms four competitors, both in in-sample valuation and in out-of-sample forecasting, and in fitting the term structure of volatilities by market segments. Competitor models are (i) diffusion spot prices, (ii) jump-diffusion spot prices with time dependent volatility, (iii) HJM-based and (iv) Levy multifactor model with NIG distributions. Value-at-Risk measures based on normality strongly underestimate tail risk but our model gives estimates that are more exact.Keywords: Electricity swaps; Stochastic forward premium; Multivariate Normal Inverse Gaussian distribution; Levy processes","Blanco, Iván; Peña, Juan Ignacio; Rodríguez, Rosa",2018,10.5547/01956574.39.2.ibla,None,proquest
a4e215a81aa0f6ae,Modelling and forecasting interest rates during stages of the economic cycle: A knowledge-discovery approach,"Modelling the structure of risk-free rates and their relation to other economic and financial variables during different stages of the economic cycles has attracted much interest from both the theoretical and practical perspectives. The previous literature has emphasized the deployment of expert systems and knowledge-discovery approaches motivated by the need to address the limitations of the econometric models. However, it has failed to address the interpretability aspects and, more importantly, the need to provide methodological support that allows the deployment of such techniques in a more systematic way. This approach entails the definition of a process that includes the usual steps taken by experts to address similar problems and allows the relative merits of different techniques in relation to common goals and objectives to be gauged. This paper addresses the interpretability and the lack of methodological support by proposing a knowledge-discovery methodology that includes a minimal common number of steps to model, analyse, evaluate and deploy different non-linear techniques and models. Furthermore, the interpretability is addressed through the use of open-box techniques, such as decision trees. The proposed methodology helps to discover and describe hidden patterns, allowing for the study and characterization of economic cycles, and economic cycle stages, as well as the description of the historic relationships between interest rates and other relevant economic variables. These patterns can also be used in the forecasting of economic cycle stages, interest rates and other related variables of concern. The output of the methodology can provide actionable information for market agents, such as monetary authorities, financial institutions, and individual investors, as well as for the academic community, to increase further the knowledge and understanding of financial markets, thus enriching and complementing existing financial theories. © 2015 Elsevier B.V., All rights reserved.","Díaz, D.; Theodoulidis, B.; Dupouy, C.",2016,10.1016/j.eswa.2015.09.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945251489&doi=10.1016%2Fj.eswa.2015.09.010&partnerID=40&md5=295b07c4bfb60217b7e945fbddbf99e7,scopus
febabd5bf9c00b9b,Modelling and management of mortality risk: a review,"In the first part of the paper, we consider the wide range of extrapolative stochastic mortality models that have been proposed over the last 15-20 years. A number of models that we consider are framed in discrete time and place emphasis on the statistical aspects of modelling and forecasting. We discuss how these models can be evaluated, compared and contrasted. We also discuss a discrete-time market model that facilitates valuation of mortality-linked contracts with embedded options. We then review several approaches to modelling mortality in continuous time. These models tend to be simpler in nature, but make it possible to examine the potential for dynamic hedging of mortality risk. Finally, we review a range of financial instruments (traded and over-the-counter) that could be used to hedge mortality risk. Some of these, such as mortality swaps, already exist, while others anticipate future developments in the market.","Cairns, Andrew J. G.; Blake, David; Dowd, Kevin",2008,10.1080/03461230802173608,None,wos
3e7e2117f4a117be,Modelling dependence structure with Archimedean copulas and applications to the iTraxx CDS index,"In this paper we model the dependence structure between credit default swap (CDS) and jump risk using Archimedean copulas. The paper models and estimates the different relationships that can exist in different ranges of behaviour. It studies the bivariate distributions of CDS index spreads and the kurtosis of equity return distribution. To take into account nonlinear relationships and different structures of dependency, we employ three Archimedean copula functions: Gumbel, Clayton, and Frank. We adopt nonparametric estimation of copula parameters and we find an extreme co-movement of CDS and stock market conditions. In addition, tail dependence indicates the extreme co-movements and the potential for a simultaneous large loss in stock markets and a significant default risk. Ignoring the tail dependence would lead to underestimation of the default risk premium. © 2010 Elsevier B.V. All rights reserved. © 2011 Elsevier B.V., All rights reserved.","Naifar, N.",2011,10.1016/j.cam.2010.10.047,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79251599155&doi=10.1016%2Fj.cam.2010.10.047&partnerID=40&md5=3494ea2f4e142ba65691f60966ea8084,scopus
bcd24f89245d5e16,Modelling financial time series with threshold nonlinearity in returns and trading volume,"This paper investigates the effect of past returns and trading volumes on the temporal behaviour of international market returns. We propose a class of nonlinear threshold time-series models with generalized autoregressive conditional heteroscedastic disturbances. Using Bayesian approach, an implementation of Markov chain Monte Carlo procedure is used to obtain estimates of unknown parameters. The proposed family of models incorporates changes in log of volumes in the sense of regime changes and asymmetric effects on the volatility functions. The results show that when differences of log volumes are involved in the system of log return and volatility models, an optimum selection can be achieved. In all the five markets considered, both mean and variance equations involve volumes in the best models selected. Our best models produce higher posterior-odds ratios than that in Gerlach et al.'s (Phys. A Statist. Mech. Appl. 2006; 360:422-444) models, indicating that our return-volume partition of regimes can offer extra gain in explaining return-volatility term structure.","So, Mike K P; Chen, Cathy W S; Chiang, Thomas C; Lin, Doris S Y",2007,10.1002/asmb.674,None,proquest
b1e9b249051157d6,Modelling nonlinearities in equity returns: the mean impact curve analysis,"A time-varying model of equity returns consisting of a volatility factor with time-varying loading, is specified to investigate the dynamical effects of shocks on expected returns. The proposed specification yields a nonlinear relationship between the conditional mean and the news, referred to as the mean impact curve (MIC). Applying this framework to the AORD, Hang Seng and Straits Times equity indexes yields estimated MICs with qualitatively similar nonlinear characteristics for each equity market. An important implication of the empirical results is that the relationship between the conditional mean and the news is found to be dependent upon the size of the shock, a result which is consistent with equity markets displaying mean aversion over short horizons and mean reversion over long horizons.","Martin, Vance L.; Sarkar, Saikat; Kanto, Antti Jaakko",2014,10.1515/snde-2012-0030,None,wos
49b43eda4b92602b,Modelling of Chinese corporate bond default - A machine learning approach,"We apply machine learning techniques to construct a series of models of corporate bond defaults. By combining Chinese accounting information and corporate bond data from January 2012 to December 2019, we construct an out-of-sample forecast that significantly improves the identification rate of corporate bond defaults, with an area under the receiver operating characteristics curve greater than 90 percent. Our models are robust to different machine learning models, including stacking, boosting, and bagging ensembling models. Our models consider cross-sectional heterogeneity, such as different ownership structures, accessibility to external finance, industry heterogeneity, different sample periods, and government policy impact.","Lu, Zhou; Zhuo, Zhuyao",2021,10.1111/acfi.12846,None,wos
c6defcabf94c2b1e,Modelling portfolio defaults using hidden Markov models with covariates,"We extend the hidden Markov Model for defaults of Crowder et al. (2005, Quantitative Finance 5, 27-34) to include covariates. The covariates enhance the prediction of transition probabilities from high to low default regimes. To estimate the model, we extend the EM estimating equations to account for the time varying nature of the conditional likelihoods due to sample attrition and extension. Using empirical U.S. default data, we find that GDP growth, the term structure of interest rates and stock market returns impact the state transition probabilities. The impact, however, is not uniform across industries. We only find a weak correspondence between industry credit cycle dynamics and general business cycles. Reprinted by permission of Blackwell Publishing","Banachewicz, Konrad; Lucas, André; Vaart, Aad van der",2008,10.1111/j.1368-423x.2008.00232.x,None,proquest
052c16a20382c1b6,Modelling the dependence structures of Australian iTraxx CDS index,"In contrast to market expectations, the correlation between credit default swap (CDS) spreads and their respective stock prices in Australia was found to be positive. The global financial crisis (GFC) affected the nonlinear association between the two asset classes with firms experiencing financial distress and stock prices plummeting. CDSs issuers reacted to such exogenous shocks by increasing their risk premiums on their spreads, reflecting the increased inherent risk. By splitting the data into pre- and post-GFC contexts and by employing the use of Archimedean copulas, we observe a negative co-movement in the post-GFC period. This finding is robust to several equity indices. Overall, such result is critical for investors engaging in arbitrageur activities. © 2013 Taylor & Francis. © 2013 Elsevier B.V., All rights reserved.","Fenech, J.-P.; Vosgha, H.; Shafik, S.",2014,10.1080/00036846.2013.849378,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887918664&doi=10.1080%2F00036846.2013.849378&partnerID=40&md5=e1bbd0d1c5a92b23deea51cdab6fda29,scopus
8fd13386d94ce678,Modelling the risk premium in the black-market zloty-dollar exchange rate,"This paper tests for the presence of nonlinear dependence in the black-market Polish zloty-dollar exchange rate. Using the GARCH-M model, we illustrate use of the Marquardt (Journal of the Society of Industrial and Applied Mathematics, 2, 1963) alternative to the Berndt (Annals of Economical Social Measurement, 4, 1974) iterative nonlinear algorithm for the estimation of such models, and discrimination between estimated models on the basis of the Brock and Potter (Handbook of Statistics, 11, 1993) test for so conditional variance misspecification. We find evidence of a time-varying risk premium such that foreign speculators are compensated for increased exchange rate risk by appreciation which increases the dollar value of zloty holdings, and which is able to account for all of the apparent nonlinearity in the zloty. © 2017 Elsevier B.V., All rights reserved.","McMillan, D.G.; Speight, A.E.H.",1999,10.1080/135048599353357,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0040964268&doi=10.1080%2F135048599353357&partnerID=40&md5=cee866fd77f492916ad145b02de8d1d1,scopus
2c7bb54560d01c08,Moment Risk Premia and Stock Return Predictability,"We study the predictive power of option-implied moment risk premia embedded in the conventional variance risk premium. We find that although the second-moment risk premium predicts market returns in short horizons with positive coefficients, the third-moment (fourth-moment) risk premium predicts market returns in medium horizons with negative (positive) coefficients. Combining the higher-moment risk premia with the second-moment risk premium improves the stock return predictability over multiple horizons, both in sample and out of sample. The finding is economically significant in an asset-allocation exercise and survives a series of robustness checks.","Fan, Zhenzhen; Xiao, Xiao; Zhou, Hao",2022,10.1017/s002210902000085x,None,wos
8a16f3a80a9ddf11,"Moments, shocks and spillovers in Markov-switching VAR models","To investigate how economies, financial markets or institutions can deal with stress, we often analyze the effects of shocks conditional on being in a recession or a bear market. MSVAR models are perfectly suited for such analyses because they combine gradual movements with sudden regime switches. In this paper, we develop a comprehensive methodology to conduct these analyses. We derive first and second moments conditional only on the regime distribution and propose impulse response functions for both moments. By formulating the MSVAR as an extended linear non-Gaussian VAR, all results are available in closed-form. We illustrate our methods with an application to stock and bond return predictability. We show how forecasts of means, volatilities and (auto-)correlations depend on the regimes. The effect of shocks becomes highly nonlinear, and they propagate via different channels. During bear markets, shocks have stronger effects on means and volatilities and die out more slowly. & COPY; 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).","Kole, Erik; van Dijk, Dick",2023,10.1016/j.jeconom.2023.105474,None,wos
fb0520b88e289b15,Monetary base and federal government debt in the long‐run: A non‐linear analysis,"Government bonds are usually traded between the financial institutions and the Fed during the open market operations. These operations impact the bank reserves, subsequently influencing the monetary base. The monetary base and government bonds may portray a common trend and government debt could potentially bind the central bank to debt monetization. This paper, using monthly data on federal government debt and the monetary base from 1947:1 to 2018:10, investigates the presence of a long‐run equilibrium relationship between the two variables and as to how the long‐run equilibrium relationship vary in the short‐run. Threshold cointegration tests find evidence of a long‐run equilibrium relationship. Estimates of the threshold vector error‐correction model find statistically significant evidence of contraction in the monetary base growth in the short‐run in regime 1. In regime 2, the growth in the monetary base does not adjust to accommodate faster government debt growth. These estimates find no evidence of debt monetization or otherwise in either of the regimes in the United States. The Fed, by reducing the monetary base, perhaps focuses more on the inflation target. The findings also suggest a potential scenario where the Fed and the fiscal authority are not conjoined with each other in their operations.",Haydory Akbar Ahmed,2020,10.1111/boer.12216,None,proquest
d22feefe1530ef71,Monetary policy document analysis for prediction of monetary policy board decision,"In terms of market capitalization, the bond market is larger than the stock market, and the bond market is affected by macroeconomic indicators. Despite this, there has been relatively little research, making it a good candidate for the use of data mining techniques. In this paper, a novel approach designed to predict the vote results of the Korean Monetary Policy Committee regarding the base interest rate was proposed. To predict sentence sentiment, prior monetary policy decision text was used as input for classification models. The sentence sentiment prediction model showed 83.7% performance when using a support vector machine. In addition, it was observed that the bigrams extracted from documents provided important descriptions of the Korean economy at the time. Finally, the document sentiment of monetary policy decision was calculated using aggregating sentence sentiment, and the vote results were predicted using this sentiment. As a result, when using the support vector machine to predict the Monetary Policy Committee vote results, the performance improved by 29.5% over the baseline model. Statistical tests confirmed whether there is a difference in document sentiments between unanimous and non-unanimous, and the null hypothesis was rejected at a significance level of 5%.In terms of market capitalization, the bond market is larger than the stock market, and the bond market is affected by macroeconomic indicators. Despite this, there has been relatively little research, making it a good candidate for the use of data mining techniques. In this paper, a novel approach designed to predict the vote results of the Korean Monetary Policy Committee regarding the base interest rate was proposed. To predict sentence sentiment, prior monetary policy decision text was used as input for classification models. The sentence sentiment prediction model showed 83.7% performance when using a support vector machine. In addition, it was observed that the bigrams extracted from documents provided important descriptions of the Korean economy at the time. Finally, the document sentiment of monetary policy decision was calculated using aggregating sentence sentiment, and the vote results were predicted using this sentiment. As a result, when using the support vector machine to predict the Monetary Policy Committee vote results, the performance improved by 29.5% over the baseline model. Statistical tests confirmed whether there is a difference in document sentiments between unanimous and non-unanimous, and the null hypothesis was rejected at a significance level of 5%.","Kim, Misuk; Cho, Sungzoon",2023,10.1016/j.heliyon.2023.e20696,None,proquest
3f8ab1bb9836d2d3,Monetary reforms and inflation expectations in Japan: Evidence from inflation-indexed bonds,"We assess the impact of news concerning recent Japanese monetary reforms on long-term inflation expectations using an arbitrage-free term structure model of nominal and real yields. Our model accounts for the value of deflation protection embedded in Japanese inflation-indexed bonds issued since 2013, which is sizable and time-varying. Our results suggest that Japanese long-term inflation expectations have remained pos-itive despite extensive spells of deflation, leaving inflation risk premia mostly negative during this period. Moreover, adjusting for deflation protection demonstrates that market responses to policy changes were not as inflationary as they appear under standard modeling procedures. Consequently, the reforms were less disappointingthan is widely perceived.(c) 2021 Elsevier B.V. All rights reserved.","Christensen, Jens H. E.; Spiegel, Mark M.",2022,10.1016/j.jeconom.2021.10.007,None,wos
d1e41e2300a4db31,Monte Carlo Simulations for Resolving Verifiability Paradoxes in Forecast Risk Management and Corporate Treasury Applications,"Forecast risk management is central to the financial management process. This study aims to apply Monte Carlo simulation to solve three classic probabilistic paradoxes and discuss their implementation in corporate financial management. The article presents Monte Carlo simulation as an advanced tool for risk management in financial management processes. This method allows for a comprehensive risk analysis of financial forecasts, making it possible to assess potential errors in cash flow forecasts and predict the value of corporate treasury growth under various future scenarios. In the investment decision-making process, Monte Carlo simulation supports the evaluation of the effectiveness of financial projects by calculating the expected net value and identifying the risks associated with investments, allowing more informed decisions to be made in project implementation. The method is used in reducing cash flow volatility, which contributes to lowering the cost of capital and increasing the value of a company. Simulation also enables more accurate liquidity planning, including forecasting cash availability and determining appropriate financial reserves based on probability distributions. Monte Carlo also supports the management of credit and interest rate risk, enabling the simulation of the impact of various economic scenarios on a company’s financial obligations. In the context of strategic planning, the method is an extension of decision tree analysis, where subsequent decisions are made based on the results of earlier ones. Creating probabilistic models based on Monte Carlo simulations makes it possible to take into account random variables and their impact on key financial management indicators, such as free cash flow (FCF). Compared to traditional methods, Monte Carlo simulation offers a more detailed and precise approach to risk analysis and decision-making, providing companies with vital information for financial management under uncertainty. This article emphasizes that the use of Monte Carlo simulation in financial management not only enhances the effectiveness of risk management, but also supports the long-term growth of corporate value. The entire process of financial management is able to move into the future based on predicting future free cash flows discounted at the cost of capital. We used both numerical and analytical methods to solve veridical paradoxes. Veridical paradoxes are a type of paradox in which the result of the analysis is counterintuitive, but turns out to be true after careful examination. This means that although the initial reasoning may lead to a wrong conclusion, a correct mathematical or logical analysis confirms the correctness of the results. An example is Monty Hall’s problem, where the intuitive answer suggests an equal probability of success, while probabilistic analysis shows that changing the decision increases the chances of winning. We used Monte Carlo simulation as the numerical method. The following analytical methods were used: conditional probability, Bayes’ rule and Bayes’ rule with multiple conditions. We solved truth-type paradoxes and discovered why the Monty Hall problem was so widely discussed in the 1990s. We differentiated Monty Hall problems using different numbers of doors and prizes.","Pavlik, Martin; Michalski Grzegorz",2025,10.3390/ijfs13020049,None,proquest
e148b89b6640d34c,Mortgage convexity,"Most home mortgages in the United States are fixed-rate loans with an embedded prepayment option. When long-term rates decline, the effective duration of mortgage-backed securities (MBS) falls due to heightened refinancing expectations. I show that these changes in MBS duration function as large-scale shocks to the quantity of interest rate risk that must be borne by professional bond investors. I develop a simple model in which the risk tolerance of bond investors is limited in the short run, so these fluctuations in MBS duration generate significant variation in bond risk premia. Specifically, bond risk premia are high when aggregate MBS duration is high. The model offers an explanation for why long-term rates could appear to be excessively sensitive to movements in short rates and explains how changes in MBS duration act as a positive-feedback mechanism that amplifies interest rate volatility. I find strong support for these predictions in the time series of US government bond returns. (C) 2014 Elsevier B.V. All rights reserved.","Hanson, Samuel G.",2014,10.1016/j.jfineco.2014.05.002,None,wos
79f5b96bb6a44999,Mortgage prepayment with an uncertain holding period,"A discrete-time-option pricing model is developed to value a mortgage and its embedded prepayment option when the effective life of the mortgage is a random variable with a probability distribution of known parameters. The model can be applied when the borrower's ex ante expectation of his tenure follows any probability distribution bounded to the left at zero. The Gamma distribution is used to illustrate the model.The pricing model is further applied to determine the conditions under which financially motivated prepayment is optimal. The results show that the certainty model understates the Interest Rate Differential needed to justify prepayment (IRD) for short Expected Holding Period (EHP) borrowers and overstates the IRD for long EHP borrowers. When the EHP is relatively long, the certainty model provides relatively good estimates of IRD during the beginning years of the mortgage life. Under most other conditions, the estimates of the certainty holding period model are biased.","Yang, TT; Maris, BA",1996,10.1007/bf00132266,None,wos
c918305dd72b66fb,Multi-Country and Multi-Horizon GDP Forecasting Using Temporal Fusion Transformers,"This paper applies a new artificial intelligence architecture, the temporal fusion transformer (TFT), for the joint GDP forecasting of 25 OECD countries at different time horizons. This new attention-based architecture offers significant advantages over other deep learning methods. First, results are interpretable since the impact of each explanatory variable on each forecast can be calculated. Second, it allows for visualizing persistent temporal patterns and identifying significant events and different regimes. Third, it provides quantile regressions and permits training the model on multiple time series from different distributions. Results suggest that TFTs outperform regression models, especially in periods of turbulence such as the COVID-19 shock. Interesting economic interpretations are obtained depending on whether the country has domestic demand-led or export-led growth. In essence, TFT is revealed as a new tool that artificial intelligence provides to economists and policy makers, with enormous prospects for the future.","Laborda, Juan; Laborda, Juan; Ruano, Sonia; Zamanillo, Ignacio",2023,10.3390/math11122625,None,proquest
0bb5683df1b01809,Multi-Factor Cox-Ingersoll-Ross Models of the Term Structure: Estimates and Tests from a Kalman Filter Model,"This paper presents a method for estimating multi-factor versions of the Cox-Ingersoll-Ross (1985b) model of the term structure of interest rates. The fixed parameters in one, two, and three factor models are estimated by applying an approximate maximum likelihood estimator in a state-space model using data for the U.S. treasury market. A nonlinear Kalman filter is used to estimate the unobservable factors. Multi-factor models are necessary to characterize the changing shape of the yield curve over time, and the statistical tests support the case for two and three factor models. A three factor model would be able to incorporate random variation in short term interest rates, long term rates, and interest rate volatility. © 2008 Elsevier B.V., All rights reserved.","Chen, R.-R.; Scott, L.",2003,10.1023/a:1024736903090,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037491892&doi=10.1023%2FA%3A1024736903090&partnerID=40&md5=4be8316ed69eeed051871feea9eb16d0,scopus
56f3840b8e773856,Multi-Period Portfolio Optimization with Investor Views under Regime Switching,"We propose a novel multi-period trading model that allows portfolio managers to perform optimal portfolio allocation while incorporating their interpretable investment views. This model’s significant advantage is its intuitive and reactive design that incorporates the latest asset return regimes to quantitatively solve managers’ question: how certain should one be that a given investment view is occurring? First, we describe a framework for multi-period portfolio allocation formulated as a convex optimization problem that trades off expected return, risk and transaction costs. Using a framework borrowed from model predictive control introduced by Boyd et al., we employ optimization to plan a sequence of trades using forecasts of future quantities, only the first set being executed. Multi-period trading lends itself to dynamic readjustment of the portfolio when gaining new information. Second, we use the Black-Litterman model to combine investment views specified in a simple linear combination based format with the market portfolio. A data-driven method to adjust the confidence in the manager’s views by comparing them to dynamically updated regime-switching forecasts is proposed. Our contribution is to incorporate both multi-period trading and interpretable investment views into one framework and offer a novel method of using regime-switching to determine each view’s confidence. This method replaces portfolio managers’ need to provide estimated confidence levels for their views, substituting them with a dynamic quantitative approach. The framework is reactive, tractable and tested on 15 years of daily historical data. In a numerical example, this method’s benefits are found to deliver higher excess returns for the same degree of risk in both the case when an investment view proves to be correct, but, more notably, also the case when a view proves to be incorrect. To facilitate ease of use and future research, we also developed an open-source software library that replicates our results. © 2023 Elsevier B.V., All rights reserved.","Oprisor, R.; Kwon, R.",2021,10.3390/jrfm14010003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165752842&doi=10.3390%2Fjrfm14010003&partnerID=40&md5=5f2b6dac5d316cc3ac5eb6c02e9b0cb2,scopus
893895957d5ecc26,Multifractality and the economic value of equity risk premium forecasts,"This paper presents novel evidence on the economic value of equity risk premium forecasts across varying degrees of market multifractality. The degree of multifractality in returns is measured to capture relevant nonlinear long-range autocorrelations. Risk premium forecasts are generated using economic indicators as predictors. Their economic value is assessed through a portfolio strategy that allocates between equities and risk-free assets based on these forecasts. The results show that higher levels of nonlinear long-range autocorrelations are associated with statistically significant out-of-sample risk premium forecasts. These periods also yield greater economic gains, underscoring the importance for investors of monitoring nonlinear dependencies when incorporating risk premium forecasts into portfolio decisions. © 2025 Elsevier B.V., All rights reserved.","Maciel, L.S.",2025,10.1080/13504851.2025.2498060,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003882998&doi=10.1080%2F13504851.2025.2498060&partnerID=40&md5=af289c71f5315456eb43d7eb26633d15,scopus
fc81822659444a59,Multiobjective Model Predictive Control for portfolio optimization with cardinality constraint,"Model Predictive Control has been shown to be adequate to solve portfolio optimization problems because of its ability to perform the dynamic readjustment of the portfolio considering the market expectations. To consider both wealth and risk and real issues imposed by the financial market, this work proposes a Multiobjective Model Predictive Control strategy with cardinality constraints, besides transaction costs, self-financing, and upper and lower limits. The objective functions are the expected portfolio wealth and the expected Variance and Conditional Value at Risk as the portfolio risk measures. The optimization is performed by a multiobjective genetic algorithm, with operators proposed to control the number of assets in each portfolio and respect the prediction horizon perspective. Finally, an insightful case study is designed using the Brazilian Stock Exchange data in 2019 and 2020. An in-sample analysis explores the relationship between prediction horizon length, cardinality, optimal portfolio composition, risk-free asset, and objective functions on performance. An out-of-sample analysis considers the cumulative wealth, Sharpe ratio, maximum Drawdown, and the monthly accumulated return. Numerical experiments indicate that the proposed strategy outperforms the myopic portfolio selection, beats the primary Brazilian benchmark, a modified Markowitz model, and some top Brazilian investment funds even in crisis times like during the COVID-19 pandemic. © 2022 Elsevier B.V., All rights reserved.","de Melo, M.K.; Cardoso, R.T.N.; Jesus, T.A.",2022,10.1016/j.eswa.2022.117639,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132322733&doi=10.1016%2Fj.eswa.2022.117639&partnerID=40&md5=826d77fde8a0fb668125cdcf76866e6d,scopus
7b86fe43643e030c,Multiple Structural Breaks in Vector Error Correction Models,"The analysis of structural breaks in vector error correction models is often confined to possible level shifts and trend breaks. In contrast, only rudimentary tools are available to deal with breaks in the cointegration matrix and the adjustment towards equilibrium. Particularly, the possibility of multiple structural breaks during long sampling periods is often ignored which can lead to inconsistently estimated coefficients. In this paper, we study a two-step estimator based on a penalized regression to determine the number of structural breaks, their timing, and estimate the model's coefficients for each regime. We focus on two important cases, namely, (i) constant dynamics but changing long-run equilibria, and (ii) convergence to new long-run equilibria with new adjustment dynamics. We use simulations to investigate the finite sample performance of the two-step estimator and provide an empirical illustration using data on the term structure of interest rates. © 2025 Elsevier B.V., All rights reserved.","Franjic, D.; Möβler, M.; Schweikert, K.",2025,10.1515/snde-2025-0009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012983996&doi=10.1515%2Fsnde-2025-0009&partnerID=40&md5=9a0223f5b81c98fa7a4ed698689f1332,scopus
bbe5ad1518e05078,Multiple yield curve modeling and forecasting using deep learning,"This manuscript introduces deep learning models that simultaneously describe the dynamics of several yield curves. We aim to learn the dependence structure among the different yield curves induced by the globalization of financial markets and exploit it to produce more accurate forecasts. By combining the self-attention mechanism and nonparametric quantile regression, our model generates both point and interval forecasts of future yields. The architecture is designed to avoid quantile crossing issues affecting multiple quantile regression models. Numerical experiments conducted on two different datasets confirm the effectiveness of our approach. Finally, we explore potential extensions and enhancements by incorporating deep ensemble methods and transfer learning mechanisms. © 2024 Elsevier B.V., All rights reserved.","Richman, R.; Scognamiglio, S.",2024,10.1017/asb.2024.26,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207006861&doi=10.1017%2Fasb.2024.26&partnerID=40&md5=af5466c8f0a797c696cf7812ccb4d0ea,scopus
1daafec2ef34610a,Multiplicative parameters and estimators: applications in economics and finance,"In this paper, we pay our attention to multiplicative parameters of random variables and their estimators. We study multiplicative properties of the multiplicative expectation and multiplicative variation as well as their estimators. For distributions having applications in finance and insurance we provide their multiplicative parameters and their properties. We consider, among others, heavy-tailed distributions such as lognormal and Pareto distributions, applied to the modelling of large losses. We discuss multiplicative models, in which the geometric mean and the geometric standard deviation are more natural than their arithmetic counterparts. We provide two examples from the Warsaw Stock Exchange in 1995-2009 and from a bid of 52-week treasury bills in 1992-2009 in Poland as an illustrative example.","Jasiulewicz, Helena; Kordecki, Wojciech",2016,10.1007/s10479-015-2035-x,None,proquest
cbb317c157af2d69,Multitrend Conditional Value at Risk for Portfolio Optimization,"Trend representation has been attracting more and more attention recently in portfolio optimization (PO) via machine learning methods. It adopts concepts and phenomena from the field of empirical and behavioral finance when little prior knowledge is obtained or strict statistical assumptions cannot be guaranteed. It is used mostly in estimating the expected asset returns, but hardly in measuring risk. To fill this gap, we propose a novel multitrend conditional value at risk (MT-CVaR), which embeds multiple trends and their influences in CVaR. Besides, we propose a novel PO model with this MT-CVaR as the risk metric and then design a solving algorithm based on the interior point method to compute the portfolio. Extensive experiments on six benchmark datasets from diverse financial markets with different frequencies show that MT-CVaR achieves the state-of-the-art investing performance and risk management.",Z. -R. Lai; C. Li; X. Wu; Q. Guan; L. Fang,2024,10.1109/tnnls.2022.3183891,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9805693,ieeexplore
c6a858641ba903a5,Multivariate CDS risk premium prediction with SOTA RNNs on MI[N]T countries,"In this study, CDS risk premiums of Mexico, Indonesia and Turkey were predicted by applying state-of-the-art forecasters in deep learning recurrent neural networks architectures which are the most recent ground-breaking predictors in the time series setting. The predictive power of each sota forecaster is compared, and the results are differentiated by country and type of sota predictors. While the long short-term memory model is better to predict Mexico's CDS risk premiums, the nonlinear autoregressive network with exogenous inputs model is found to be more suitable for Indonesia and Turkey. The results of Turkey model reached the highest forecast accuracy. © 2022 Elsevier B.V., All rights reserved.","Kutuk, Y.; Barokas, L.",2022,10.1016/j.frl.2021.102198,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107964009&doi=10.1016%2Fj.frl.2021.102198&partnerID=40&md5=308c6bc5add7af268f4e99f0c972824d,scopus
83686a7846be2d41,Multivariate tests of financial models. A new approach,"A variety of financial models are cast as nonlinear parameter restrictions on multivariate regression models, and the framework seems well suited for empirical purposes. Aside from eliminating the errors-in-the-variables problem which has plagued a number of past studies, the suggested methodology increases the precision of estimated risk premiums by as much as 76%. In addition, the approach leads naturally to a likelihood ratio test of the parameter restrictions as a test for a financial model. This testing framework has considerable power over past test statistics. With no additional variable beyond β, the substantive content of the CAPM is rejected for the period 1926-1975 with a significance level less than 0.001. © 1982. © 2014 Elsevier B.V., All rights reserved.","Gibbons, M.R.",1982,10.1016/0304-405x(82)90028-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750176969&doi=10.1016%2F0304-405X%2882%2990028-9&partnerID=40&md5=26284468277d35496a042e65f56a379d,scopus
9cf15666ac064bd7,Multivariate time-series modeling with generative neural networks,"Generative moment matching networks (GMMNs) are introduced as dependence models for the joint innovation distribution of multivariate time series (MTS). Following the popular copula–GARCH approach for modeling dependent MTS data, a framework based on a GMMN–GARCH approach is presented. First, ARMA–GARCH models are utilized to capture the serial dependence within each univariate marginal time series. Second, if the number of marginal time series is large, principal component analysis (PCA) is used as a dimension-reduction step. Last, the remaining cross-sectional dependence is modeled via a GMMN, the main contribution of this work. GMMNs are highly flexible and easy to simulate from, which is a major advantage over the copula–GARCH approach. Applications involving yield curve modeling and the analysis of foreign exchange-rate returns demonstrate the utility of the GMMN–GARCH approach, especially in terms of producing better empirical predictive distributions and making better probabilistic forecasts. © 2022 Elsevier B.V., All rights reserved.","Hofert, M.; Prasad, A.; Zhu, M.",2022,10.1016/j.ecosta.2021.10.011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119899540&doi=10.1016%2Fj.ecosta.2021.10.011&partnerID=40&md5=4c2db93c152de7fc06453d4c54c6c943,scopus
f7635ac88ef7da8e,Mutual Fund Liquidity Transformation and Reverse Flight to Liquidity,"We identify fixed-income mutual funds as an important contributor to the unusually high selling pressure in liquid asset markets during the COVID-19 crisis. We show that mutual funds experienced pronounced investor outflows amplified by their liquidity transformation. In meeting redemptions, funds followed a pecking order by first selling their liquid assets, including Treasuries and high-quality corporate bonds, which generated the most concentrated selling pressure in these markets. Overall, the estimated price impact of mutual funds was sizable at a third of the increase in Treasury yields and a quarter of the increase in corporate bond yields during the COVID-19 crisis.","Ma, Yiming; Xiao, Kairong; Zeng, Yao",2022,10.1093/rfs/hhac007,None,wos
16ddaf111ef36f96,Navigating Inflation Challenges: AI-Based Portfolio Management Insights,"After 2010, the consumer price index fell to a low level in the EU. In the euro area, it remained low between 2010 and 2020. The European Central Bank has even had to take action against the emergence of deflation. The situation changed significantly in 2021. Inflation jumped to levels not seen for 40 years in the EU. Our study aims to use artificial intelligence to forecast inflation. We also use artificial intelligence to forecast stock index changes. Based on the forecasts, we propose portfolio reallocation decisions to protect against inflation. The forecasting literature does not address the importance of structural breaks in the time series, which, among other things, can affect both the pattern recognition and prediction capabilities of various machine learning models. The novelty of our study is that we used the Zivot–Andrews unit root test to determine the breakpoints and partitioned the time series into training and testing datasets along these points. We then examined which database partition gives the most accurate prediction. This information can be used to re-balance the portfolio. Two different AI-based prediction algorithms were used (GRU and LSTM), and a hybrid model (LSTM–GRU) was also included to investigate the predictability of inflation. Our results suggest that the average error of the inflation forecast is a quarter of that of the stock market index forecast. Inflation developments have a fundamental impact on equity and government bond returns. If we obtain a reliable estimate of the inflation forecast, we have time to rebalance the portfolio until the inflation shock is incorporated into government bond returns. Our results not only support investment decisions at the national economy level but are also useful in the process of rebalancing international portfolios.","Bareith, Tibor; Tatay, Tibor; Tatay, Tibor; Vancsura, László",2024,10.3390/risks12030046,None,proquest
77517281b7cd1d39,Navigating the Complexity of Money Laundering: Anti–money Laundering Advancements with AI/ML Insights,"This study explores the fusion of artificial intelligence (AI) and machine learning (ML) methods within anti–money laundering (AML) frameworks using data from the US Treasury’s Financial Crimes Enforcement Network (FinCEN). ML and deep learning (DL) algorithms—such as random forest classifier, elastic net regressor, least absolute shrinkage and selection operator (LASSO) regression, gradient boosting regressor, linear regression, multilayer perceptron (MLP) classifier, convolutional neural network (CNN), random forest regressor, and K-nearest neighbor (KNN)—were used to forecast variables such as state, year, and transaction types (credit card and debit card). Hyperparameter tuning through grid search and randomized search was used to optimize model performance. The results demonstrated the efficacy of AI/ML algorithms in predicting temporal, spatial, and industry-specific money-laundering patterns. The random forest classifier achieved 99.99% average accuracy in state prediction, while the gradient boosting regressor and random forest classifier excelled in predicting year and state simultaneously, and credit card transactions, respectively. MLP and CNN showed promise in the context of debit card transactions. The gradient boosting regressor performed competitively with low mean squared error (MSE) (2.9) and the highest R-squared (R2) value of 0.24, showcasing its pattern-capturing proficiency. Logistic regression and random forest classifier performed well in predicting credit card transactions, with area under the receiver operating characteristic curve (ROC_AUC) scores of 0.55 and 0.53, respectively. For debit card prediction, MLP achieved a precision of 0.55 and recall of 0.42, while CNN showed a precision of 0.6 and recall of 0.54, highlighting their effectiveness. The study recommends interpretability, hyperparameter optimization, specialized models, ensemble methods, data augmentation, and real-time monitoring for improved adaptability to evolving financial crime patterns. Future improvements could include exploring the integration of blockchain technology in AML.","Gandhi, Hitarth; Tandon, Kevin; Gite, Shilpa; Pradhan, Biswajeet; Alamri, Abdullah",2024,10.2478/ijssis-2024-0024,None,proquest
d1cbe8bbd0caa6f9,Negative option values are possible: The impact of treasury bond futures on the cash US Treasury market,"This paper uses a unique financial instrument in the U.S. Treasury market to study the price behavior of the put option embedded in the November 2009-14 callable U.S. Treasury bond. We find that, beginning in August 1993, the estimated option value was persistently negative on nearly every day for the ensuing eight months. We show that the anomalous pricing behavior arose because the underlying callable bond became the cheapest to deliver issue against U.S. Treasury bond futures contracts. Hence, this paper provides direct evidence that derivative assets can significantly distort pricing in the primary asset market.","Jordan, BD; Kuipers, DR",1997,10.1016/s0304-405x(97)00025-1,None,wos
eddff9ceb55591e5,Network Centrality and Managerial Market-Timing Ability,"We document that long-run excess returns following announcements of share buyback authorizations and insider purchases are a U-shaped function of firm centrality in the input-output trade-flow network. These results conform to a model of investors endowed with a large but finite capacity for analyzing firms. Additional links weaken insiders' informational advantage in peripheral firms (simple firms whose cash flows depend on few economic links), provided investors' capacity is large enough, but eventually amplify that advantage in central firms (firms with many links) as a result of investors' limited capacity. These findings shed light on the sources of managerial market-timing ability.","Evgeniou, Theodoros; Peress, Joel; Vermaelen, Theo; Yue, Ling",2022,10.1017/s0022109021000016,None,wos
0e8c12740794a640,"Neural Networks, the Treasury Yield Curve, and Recession Forecasting","The authors use neural networks to examine the power of Treasury term spreads and other macro-financial variables to forecast US recessions and compare them with probit regression. They propose a novel three-step econometric method for cross-validating and conducting statistical inference on machine learning classifiers and explaining forecasts. They find that probit regression does not underperform a neural network classifier in the present application, which stands in contrast to a growing body of literature demonstrating that machine learning methods outperform alternative classification algorithms. That said, neural network classifiers do identify important features of the joint distribution of recession over term spreads and other macro-financial variables that probit regression cannot. The authors discuss some possible reasons for their results and use their procedure to study US recessions over the post-Volcker period, analyzing feature importance across business cycles. © 2022 Elsevier B.V., All rights reserved.","Puglia, M.; Tucker, A.",2021,10.3905/jfds.2021.1.061,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127450588&doi=10.3905%2Fjfds.2021.1.061&partnerID=40&md5=abf79b5fec58c545a98983f579b5062c,scopus
11848a5aa1999a9c,Neural Ordinary Differential Equation Networks for Fintech Applications Using Internet of Things,"The Internet of Things (IoT) technology is becoming increasingly pivotal in the financial services sector, with a growing number of algorithms being employed in high-frequency trading. High-frequency prediction in financial time series prediction presents a promising avenue of research. From convolutional neural networks to recurrent neural networks, deep learning have demonstrated exceptional capabilities in capturing the nonlinear characteristics of stock markets, thereby achieving high performance in stock index prediction. In this article, we employ ODE-LSTM model for high-frequency price forecasting, predicting stock price data across various time scales, including 1-, 5-, and 30-min frequencies. This approach introduces a novel concept, wherein the long short-term memory (LSTM) model is integrated with Neural ordinary differential equations (ODEs) to manage the hidden state and augment model interpretability. Over the course of 7 months, we achieved a 41.79% excess return on a simulated trading platform, with a daily average excess return of 0.30%, showcasing the commendable performance of our model and strategy.",J. Li; W. Chen; Y. Liu; J. Yang; D. Zeng; Z. Zhou,2024,10.1109/jiot.2024.3376748,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10472330,ieeexplore
ba079377e3074c1e,Neural forecasting of the Italian sovereign bond market with economic news,"In this paper, we employ economic news within a neural network framework to forecast the Italian 10‐year interest rate spread. We use a big, open‐source, database known as Global Database of Events, Language and Tone to extract topical and emotional news content linked to bond markets dynamics. We deploy such information within a probabilistic forecasting framework with autoregressive recurrent networks (DeepAR). Our findings suggest that a deep learning network based on long short‐term memory cells outperforms classical machine learning techniques and provides a forecasting performance that is over and above that obtained by using conventional determinants of interest rates alone.","Consoli, Sergio; Luca Tiozzo Pezzoli; Tosetti, Elisa",2022,10.1111/rssa.12813,None,proquest
c828201ee931a14e,Neural network and machine learning use cases: Indian bond market predictions,"This study examines machine learning techniques to investigate how artificial intelligence (AI) affects predicting future trends in the bond market. The bond market offers a global perspective on capital costs for a business by establishing the fair value of the bond issue, which is based on multiple factors. The asset price market, which has employed machine learning (ML) and deep learning (DL) techniques to address the primary forecasting difficulty, surprisingly plays a significant role in predicting fut ure bond market returns. As an outcome, if this gap can be forecast, it can act as the bond market's data-driven long-term direction and yield additional profits. Daily securityspecific data for the 10-to-3-year Indian Treasury Bond (ITB) was gathered from 2013 to 2022 and is available in the global government bonds database. The researchers looked at how well the auto-regressive integrated moving average (ARIMA), linear regression, and deep recurrent neural network-long short-term memory (DLSTM) models could predict bond yields and returns in future bond markets. The empirical results demonstrate that the DLSTM models most fairly predict the price of government bonds over both the short and longer horizons when compared to ARIMA and linear regression. © 2024 Elsevier B.V., All rights reserved.","Antony, J.M.; Sundaram, S.",2024,10.18488/29.v11i1.3667,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195129902&doi=10.18488%2F29.V11I1.3667&partnerID=40&md5=5da04c48a69be5670e5f5b563929cbfc,scopus
62c5869d03cd0ee0,Neural network forecasting in prediction Sharpe ratio: Evidence from EU debt market,"This study analyzes a neural networks model that forecast Sharpe ratio. The developed neural networks model is successful to predict the position of the investor who will be rewarded with extra risk premium on debt securities for the same level of portfolio risk or a greater risk premium than proportionate growth risk. The main purpose of the study is to predict highest Sharpe ratio in the future. Study grouped the data on yields of debt instruments in periods before, during and after world crisis. Results shows that neural networks is successful in forecasting nonlinear time lag series with accuracy of 82% on test cases for the prediction of Sharpe-ratio dynamics in future and investor‘s portfolio position. © 2021 Elsevier B.V., All rights reserved.","Vuković, D.; Vyklyuk, Y.; Matsiuk, N.; Maiti, M.",2020,10.1016/j.physa.2019.123331,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078116317&doi=10.1016%2Fj.physa.2019.123331&partnerID=40&md5=15556954c997b409a337691856374b6f,scopus
5920e8d1ce205148,Neural network prediction of crude oil futures using B-splines,"We propose two ways to improve the forecasting accuracy of a focused time-delay neural network (FTDNN) that forecasts the term structure of crude oil futures. Our results show that a convergence based FTDNN makes consistently more accurate predictions than the fixed-epoch FTDNN in Barunik and Malinska (2016). Further, we suggest using basis splines (B-splines), instead of Nelson-Siegel functions, to fit the term structure curves. The empirical results show that the B-spline expansions lead to consistently better 1 and 3 months ahead predictions compared to the convergence based FTDNN. We also explore conditions under which the B-spline based approach may be better for longer-term predictions.","Butler, Sunil; Kokoszka, Piotr; Miao, Hong; Shang, Han Lin",2021,10.1016/j.eneco.2020.105080,None,proquest
b28e94345d9b2a0a,Neural networks in financial engineering: a study in methodology,"Neural networks have shown considerable successes in modeling financial data series. However, a major weakness of neural modeling is the lack of established procedures for performing tests for misspecified models, and tests of statistical significance for the various parameters that have been estimated. This is a serious disadvantage in applications where there is a strong culture for testing not only the predictive power of a model or the sensitivity of the dependent variable to changes in the inputs but also the statistical significance of the finding at a specified level of confidence. Rarely is this more important than in the case of financial engineering, where the data generating processes are dominantly stochastic and only partially deterministic. Partly a tutorial, partly a review, this paper describes a collection of typical applications in options pricing, cointegration, the term structure of interest rates and models of investor behavior which highlight these weaknesses and propose and evaluate a number of solutions. We describe a number of alternative ways to deal with the problem of variable selection, show how to use model misspecification tests, we deploy a novel way based on cointegration to deal with the problem of nonstationarity, and generally describe approaches to predictive neural modeling which are more in tune with the requirements for modeling financial data series.",A. . -P. N. Refenes; A. N. Burgess; Y. Bentz,1997,10.1109/72.641449,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=641449,ieeexplore
2576c128066ee3ce,New frontiers for arch models,"In the 20 years following the publication of the ARCH model, there has been a vast quantity of research uncovering the properties of competing volatility models. Wide-ranging applications to financial data have discovered important stylized facts and illustrated both the strengths and weaknesses of the models. There are now many surveys of this literature. This paper looks forward to identify promising areas of new research. The paper lists five new frontiers. It briefly discusses three-high-frequency volatility models, large-scale multivariate ARCH models, and derivatives pricing models. Two further frontiers are examined in more detail-application of ARCH models to the broad class of non-negative processes, and use of Least Squares Monte Carlo to examine non-linear properties of any model that can be simulated. Using this methodology, the paper analyses more general types of ARCH models, stochastic volatility models, long-memory models and breaking volatility models. The volatility of volatility is defined, estimated and compared with option-implied volatilities. Copyright (C) 2002 John Wiley Sons, Ltd.","Engle, R",2002,10.1002/jae.683,None,wos
b76792256cc74dfa,New results on the predictive value of crude oil for US stock returns,"PurposeThe purpose of this study is to clarify the nature of the predictive relationship between crude oil and the US stock market, with particular attention to whether this relationship is driven by time-varying risk premia.Design/methodology/approachThe authors formulate the predictive regression as a state-space model and estimate the time-varying coefficients via the Kalman filter and prediction-error decomposition.FindingsThe authors find that the nature of the predictive relationship between crude oil and the US stock market changed in the latter half of 2008. After mid-2008, the predictive relationship switched signs and exhibited characteristics which make it much more likely that the predictive relationship is due to time-varying risk premia rather than a market inefficiency.Originality/valueThe authors apply a state-space approach to modeling the predictive relationship. This allows one to watch the evolution of the predictive relationship over time. In particular, the authors identify a dramatic shift in the relationship around August 2008. Prior research has not been able to identify shifts in the relationship.","Brigida, Matt",2018,10.1108/sef-01-2017-0020,None,proquest
4717510223fcce48,News Media and Attention Spillover across Energy Markets: A Powerful Predictor of Crude Oil Futures Prices,"We develop two news-based investor attention measures from the news trends function of the Bloomberg terminal and investigate their predictive power for returns on crude oil futures contracts with various maturities. Our main results after controlling for relevant macroeconomic variables show that the Oil-based Institutional Attention Index is useful in predicting oil futures returns, especially during price downturn periods, while the forecasting accuracy is further improved when the Commodity Market Institutional Attention Index is used. This forecasting accuracy decreases, however, with the maturity of oil futures contracts. Moreover, we find some evidence of Granger-causality and regime-dependent interactions between investor attention measures and oil futures returns. Finally, variable selection algorithms matter before making predictions since they create the best forecasting results in many cases considered. These findings are important for informed traders and policymakers to better understand the price dynamics of the oil markets.","Cepni, Oguzhan; Duc Khuong Nguyen; Sensoy, Ahmet",2022,10.5547/01956574.43.si1.ocep,None,wos
7c3de2cb255ed663,News implied volatility and aggregate economic activity: evidence from the Japanese government bond market,"Because options on 10-year Japanese government bond (JGB) futures are relatively new in the market, their implied volatility, JGB-VIX, is not available before 2007. For the period when JGB-VIX is available, we conduct supervised learning by using the daily newspaper articles as input and JGB-VIX as output. We then construct a new JGB market uncertainty measure, which we called JGB-NU, based on the predicted values of JGB-VIX from the estimated model and contents of the newspaper articles from 1981 to 2021. In the VAR analysis with JGB-NU, we confirm that JGB market uncertainty shocks have a negative impact on real economic activities in Japan. © 2024 Elsevier B.V., All rights reserved.","Goshima, K.; Ishijima, H.; Shintani, M.",2024,10.1080/13504851.2022.2140751,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141618967&doi=10.1080%2F13504851.2022.2140751&partnerID=40&md5=b1683f478f389f1a0e766902a8fed6b6,scopus
636a11ccd9e2eab8,"Nominal US Treasuries Embed Liquidity Premiums, Too","A novel arbitrage-free model of nominal U.S. Treasuries that decomposes yields into frictionless expected rates, frictionless term premiums, and liquidity premiums produces four key results from Jan. 1987 to Aug. 2023. First, liquidity loadings are larger than for the slope and higher-order principal components. Second, the countercyclicality of required nominal Treasury returns owes to liquidity, if anything, not frictionless term premiums. Third, Federal Reserve large-scale asset purchases generally work through expected rates and frictionless term premiums, not liquidity premiums. Fourth, given similar estimates using TIPS, inflation expectations are less moored around the Federal Reserve's price objectives than other models say.","Durham, J. Benson",2025,10.1017/s0022109023001345,None,wos
99693fcac2d04cb6,Non-invasive evaluation of neonatal cerebral status in the newborns of mothers addicted to alcohol and drugs,"The present study aims to assess the effects of alcohol and drug consumption on the cerebral status of a newborn with risk. Although there is a vast literature on the quality of life in terms of health, there is no uniform point of view, since the well-being of a person implies other elements that consider not only health but also the economic and educational environment in which the individual evolves and often these factors are connected. Besides, there is no valid instrument for measuring the quality of life either for an adult or for a child. In most cases, alcohol consumption intensifies in time, significantly decresing the quality of life for the mother and especially for the conception product. The study focuses on showing the The study focuses on highlighting the psychosocial and pharmacological aspects relevant to the diagnosis and management of neonatal cerebral status. The study participants, whose responses were the base for the quantitative analyzes, were individually interviewed using a standardized interview protocol. The interviews were conducted between October 2015 and September 2017. The interview protocol included three sections, in this chapter focusing our attention on the following sections: a) socio-demographic characteristics: age of gestation, sex of the newborn; b) clinical data: Presentation, Weight at Birth, Apgar Score, Cerebral Saturation (rSO<inf>2</inf>), Peripheral saturation (SpO<inf>2</inf>), The extraction fraction (FTOE), Parameters harvested from the umbilical cord at birth (pH, Base excess (BE), pCO<inf>2</inf>, pO<inf>2</inf>, MetHb, COHb), c) risk profile: mother’s alcohol consumption, including during pregnancy and drug use. The study group consisted of 90 infants born full term in Elena Doamna Maternity Hospital in Iasi, between 2015-2017, included in the programme of follow-up of the newborn with risk with the purpose of performing an non-invasive assessment of the fetal and neonatal cerebral status, in order to prevent and establish treatment methods for perinatal asphyxia. Based on the information obtained through the preliminary documentation, 30 newborns with alcohol and / or drug-consuming mothers and 60 neonates with risk-free mothers were selected - the control batch, who accepted to participate in the study.The cases studied showed the homogeneity of the groups depending on the mother’s age and gestational age, as well as the sex of the newborn and the weight at birth (p>0.05). In neonates from mothers at risk, the under-reference level of 1-minute brain saturation, combined with a lower gestational age and the 62.5% probability of performing a caesarean section at low levels of cerebral saturation was noted in 66.7% of newborns.The cut off value of SpO<inf>2</inf>, was established at 70 mL/ 100g/1 min, with a sensitivity of 50.9% and a specificity of 51.3%, after reading the coordinates of ROC curve, but the prediction was not significant from the statistical point of view (p=0.670). The mean level of base excess was al excesului de baze was slightly lower in newborns with the extraction fraction below the cut off value (-4.64 vs -4.18; p=0.560). According to the cases studied, 1 min after birth, 23.3% of the newborns showed an increased level of pCO<inf>2</inf> associated with a reduced level of peripheral saturation (r= -0.231; p=0.05). The correlation between the pO<inf>2</inf> level and the cerebral saturation, recorded 1 min after birth, was direct, but reduced as intensity (r= +0.295; p=0.049). About 27% of the newborns associated increased values of pO<inf>2</inf> with reduced values of the extraction fraction (r=-0.272; p=0.047). The newborns with an extraction fraction over the cut off value had a level of COHb below 1% (p=0.756) more frequently. Newborns from mothers who have consumed alcohol and / or drugs, including during pregnancy, show a reduced level of cerebral saturation and peripheral saturation 1 minute after birth. In 16.7% of newborns, the extraction limit was below the baseline 1 minute after birth. © 2020 Elsevier B.V., All rights reserved.","Crauciuc, D.V.; Crauciuc, E.G.; Iov, C.J.; Furnica, C.; Iov, T.",2018,10.37358/rc.18.11.6708,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062692954&doi=10.37358%2Frc.18.11.6708&partnerID=40&md5=f4546e0e9b4122f43f1e0a1afd543e0f,scopus
3227b5dbadd1f5b3,Non-invasive prenatal testing: A diagnostic innovation shaped by commercial interests and the regulation conundrum,"Non-invasive prenatal testing (NIPT) is grounded in the analysis of free circulating fetal DNA (cfDNA) in pregnant women's blood. The rolling out of this screening method was in large part driven by commercial firms, which hoped to reach a huge potential market by offering a test that was expected to be risk-free, reliable, inexpensive, and able to detect a wide range of genetic traits of the future child. To date, most predictions about the scope and uses of NIPT have not materialized: in 2020 NIPT detects only a limited number of genetic anomalies, while results have to be confirmed by amniocentesis. NIPT has become a commercial success. Nevertheless the implementation of NIPT has tended to diverge across different national settings. In countries that already have state-sponsored screening for Down risk, NIPT has been offered by the state health insurance to women defined as “high risk”, using a variant of the test that detects only three autosomal aneuploidies: trisomy 21, 13 and 18. These countries effectively regulate the supply of NIPT on grounds of cost-effectiveness and reliability. In countries without state-sponsored screening for Down risk, in contrast, multiple versions of NIPT covering a wider range of birth defects are commonly available on the free market, and purchased by women at low as well as high risk of having an affected child. Market-based healthcare systems tend to present women who can afford to pay for NIPT with a largely unregulated choice of technologies – though reimbursement rules imposed by private insurance providers may serve in effect to regulate use by those consumers who cannot afford to pay for tests from their own pockets. This regulatory divergence is shaped by the presence or absence of prior state-sponsored screening programs for Down risk. © 2022 Elsevier B.V., All rights reserved.","Löwy, I.",2022,10.1016/j.socscimed.2020.113064,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086363099&doi=10.1016%2Fj.socscimed.2020.113064&partnerID=40&md5=d7d7b2854549e2fa4d78b2fdc0ca34d0,scopus
165e2551d6afcbb2,Non-linear and asymmetric linkages between real growth in the Euro area and global financial market conditions: new evidence,"This paper deals with transition mechanisms through which financial market conditions affect real economic growth in the Euro area. The informational content of financial variables for predicting real economic growth is assessed, allowing for asymmetric responses to shocks. A nonlinear framework is developed based on a smooth transition model for which the effects of shocks can vary across business cycles when financial indicators modify both the endogenous and state variables. Global financial variables are shown to significantly affect real growth in the Euro area, particularly during periods of recession. Changes in stock market index and yield slope have asymmetric effects on real growth. In recessionary periods, the slope of the US yield curve does not have a significant impact on growth in the Euro area. All rights reserved, Elsevier","Mili, Mehdi; Sahut, Jean-Michel; Teulon, Frédéric",2012,10.1016/j.econmod.2012.01.008,None,proquest
6d1f179bacc01371,Non-linearities in the relationship of agricultural futures prices,"The movement of food prices remains a controversial issue owing to the intense rise in volatility that has been observed in recent years. Agricultural futures markets have experienced a similar pattern and simplistic linear models seem to be no longer reliable when analysing their functions. Against this background, this study contributes to the literature by adopting a non-linear smooth transition approach to examine the relationship between prices for first and second nearby futures contracts of seven agricultural commodities. Our main objective is to distinguish between contango and backwardation regimes when analysing the relationship between the futures spread and changes in the first nearby futures price. Our findings reveal that a linear framework neglects important dynamics, as futures prices adjust only under specific circumstances, and that the predictive power of the futures spread is much stronger during backwardation regimes.","Beckmann, Joscha; Czudaj, Robert",2014,10.1093/erae/jbt015,None,wos
3304d99c523318c7,Nonlinear Kalman Filtering in Affine Term Structure Models,"The extended Kalman filter, which linearizes the relationship between security prices and state variables, is widely used in fixed-income applications. We investigate whether the unscented Kalman filter should be used to capture nonlinearities and compare the performance of the Kalman filter with that of the particle filter. We analyze the cross section of swap rates, which are mildly nonlinear in the states, and cap prices, which are highly nonlinear. When caps are used to filter the states, the unscented Kalman filter significantly outperforms its extended counterpart. The unscented Kalman filter also performs well when compared with the much more computationally intensive particle filter. These findings suggest that the unscented Kalman filter may be a good approach for a variety of problems in fixed-income pricing.","Christoffersen, Peter; Dorion, Christian; Jacobs, Kris; Karoui, Lotfi",2014,10.1287/mnsc.2013.1870,None,wos
44636fa0fc84cad0,Nonlinear adjustments in deviations from the law of one price for wholesale hog prices,"This article applies the Band-Threshold Autoregression (Band-TAR) model to investigate whether the law of one price (LOOP) holds in Taiwanese wholesale hog markets during the period from May 1987 through December 2003. We find evidence of a nonlinear mean reversion in deviations from the LOOP for relative hog prices. Our empirical study confirms the presence of thresholds and provides strong evidence in support of the view that the regional hog markets have been tightly integrated in Taiwan and that the wholesale hog market in Taiwan is an efficient market economy. Furthermore, the estimated half-lives from the nonlinear generalized impulse response analysis are as short as four months.","Chen, Pei-Fen; Lee, Chien-Chiang",2008,10.1111/j.1574-0862.2008.00320.x,None,wos
77f546f93221829e,Nonlinear autoregressive model with stochastic volatility innovations: Semiparametric and Bayesian approach,"The first-order nonlinear autoregressive model with the stochastic volatility as the model of dependent innovations is considered and a semiparametric method is proposed to estimate the unknown function. Optimal filtering technique based on sequential Monte Carlo perspective is used for estimation of the hidden log-volatility in this model. Bayesian paradigm is applied for estimation of both the unknown parameters and hidden process using particle marginal Metropolis–Hastings scheme. Furthermore, an empirical application on simulated data and on the monthly excess returns of S&P 500 index is presented to study the performance of the schemes implemented. © 2018 Elsevier B.V., All rights reserved.","Hajrajabi, A.; Yazdanian, A.R.; Farnoosh, R.",2018,10.1016/j.cam.2018.05.036,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047786510&doi=10.1016%2Fj.cam.2018.05.036&partnerID=40&md5=02e79d768d049c5f4dbb0017d24c72aa,scopus
df4201d91d38dc14,Nonlinear dynamics in foreign exchange rates,"This paper investigates whether the behavior of real and nominal foreign exchange rates as well as interest rates are governed by nonlinear dynamics; it also explores whether observed deviations from parity conditions exhibit nonlinear dependence. Standard statistical tests for randomness, such as autocorrelation tests, have low power against a large class of deterministic, nonlinear processes. Discerning nonrandomness of innovations in exchange rates is important for a variety of reasons. For example, many models of international asset pricing assume exchange rates to follow a random walk. Furthermore, nonlinear patterns in deviations from various exchange rate parities have implications for the existence of a time-varying foreign exchange risk premium. With the use of the BDS statistic and a correlation dimension analysis, this paper's primary findings are that (1) foreign exchange markets have become increasingly complex and therefore less amenable to forecasting over time; (2) although forward exchange risk premia are statistically significant and display a deterministic structure, this structure is complex and therefore not easily discernible; and (3) innovations in real exchange rates are consistent with a Purchasing Power Parity equilibrium. © 1999 Elsevier Science Inc. © 2018 Elsevier B.V., All rights reserved.","Mahajan, A.; Wagner, A.J.",1999,10.1016/s1044-0283(99)00002-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042597353&doi=10.1016%2FS1044-0283%2899%2900002-2&partnerID=40&md5=3947c7aa0039abb36b482bdda7e1902f,scopus
c362129692c13803,Nonlinear equilibrium adjustment dynamics and predictability of the term structure of interest rates,"We analyze money market dynamics under a long-run equilibrium framework where commonly-monitored spreads serve as error correction terms, derived from a structural model incorporating autocorrelated risk premia, interest rate smoothing and monetary policy feedback. Using a dataset of monthly observations of the spot next and four-, thirteen-, twenty six- and fifty two-week Treasury Bills rates for the United States, Germany and United Kingdom from January 1999 to April 2016, we investigate the power of the expectations hypothesis theory of interest rates taking into account long-run deviations from equilibrium and inherent nonlinearities. We reveal short-run dynamic adjustments for the term structure of the USA, Germany and the UK, which are subject to regime switches. When forecastability is tested during May 2016–October 2017, the MSIH-VECM outperforms systematically the VECM. This is the first attempt to explore the possibility of parameter instability as a crucial factor in deriving the rejection of the restricted version of the cointegration space. Moreover, we investigate the dynamic out-of-sample forecasts of the term structure to assess the effectiveness of nonlinear MS-VECM modeling in capturing the after-effects of the global crisis. Overall, our results suggest that regime shifts in the mean and variance of the term structure may be intertwined with changes in fundamentals, that play a role in driving interest rate regimes, in particular business cycle and inflation fluctuations. © 2017 Elsevier B.V., All rights reserved.","Bekiros, S.; Avdoulas, C.; Hassapis, C.",2018,10.1016/j.irfa.2017.11.009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037364609&doi=10.1016%2Fj.irfa.2017.11.009&partnerID=40&md5=fbbb976cfd76f77641d8202840001708,scopus
f8be887256aa2835,Nonlinear error correction model and multiple-threshold cointegration,"As an extension of linear cointegration, threshold cointegration has been a vibrant research topic in finance and statistics. Existing estimation procedures of threshold cointegration are usually based on the threshold vector error correction model (TVECM); however, only one threshold cointegration is considered. In this paper, we investigate estimation of the multiple-threshold cointegration that is more widely used in application. Two proposed methods, the LSE and the Smoothed LSE are studied, via the multiple-regime TVECM. The convergence rate of the LSE is obtained and the limiting distribution of the smoothed LSE is developed. To assess the performance of these estimators, a simulation study was conducted, in which the results support the asymptotic theories. As an example, we study the term structure of interest rates by a two-threshold cointegration model. © 2023 Elsevier B.V., All rights reserved.","Wang, M.; Chan, N.H.; Yau, C.Y.",2016,10.5705/ss.2014.219t,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011856669&doi=10.5705%2Fss.2014.219t&partnerID=40&md5=777e1a0aa7630414aad0d4e9f0221332,scopus
312d50c1dc9212da,Nonlinear least squares estimator for generalized diffusion processes with reflecting barriers,"In this paper, we investigate the parameter estimation problem for generalized diffusion processes with two-sided reflected barriers. The estimator is obtained using the nonlinear least squares method based on discretely observed processes. Under certain regularity conditions, we obtain consistency and establish the asymptotic normality of the proposed estimator. Our method can be readily applied to the one-sided reflected diffusion processes. Numerical results, including a two-factor financial model, show that the proposed estimator performs well with large sample sizes. The U.S. treasury rate data is used to illustrate the theoretical results.","Han, Yuecai; Zhang, Dingwen",2025,10.1080/17442508.2024.2393257,None,proquest
c7fd78690dca87ae,Nonlinear mean reversion in stock prices,"This paper provides new evidence on the time-series predictability of stock market returns by introducing a test of nonlinear mean reversion. The performance of extreme daily returns is evaluated in terms of their power to predict short- and long-horizon returns on various stock market indices and size portfolios. The paper shows that the speed of mean reversion is significantly higher during the large falls of the market. The parameter estimates indicate a negative and significant relation between the monthly portfolio returns and the extreme daily returns observed over the past one to eight months. Specifically, in a quarter in which the minimum daily return is -2% the expected excess return is 37 basis points higher than in a month in which the minimum return is only -1%. This result holds for the value-weighted and equal-weighted stock market indices and for each of the size decile portfolios. The findings are also robust to different sample periods, different indices, and investment horizons. All rights reserved, Elsevier","Bali, Turan G; Demirtas, K O; Levy, H",2008,10.1016/j.jbankfin.2007.05.013,None,proquest
8fbc26d4a8606d0f,Nonlinear mean reversion in the term structure of interest rates,"The expectations hypothesis implies that the yield curve provides information on the future change in the short-term interest rate. However, transaction costs exist in the financial market, which prevent investors from realizing the arbitrage opportunity, when the arbitrage does not fully cover the transaction costs. The purpose of this paper is to assess the effect of transaction costs on the predictability of the term structure by using the threshold vector error correction model, which allows for the nonlinear adjustment to the long-run equilibrium relationship. A significant amount of threshold effect is found, and the adjustment coefficients are regime-dependent. The empirical result supports the nonlinear mean reversion in the term structure of interest rates. © 2002 Elsevier Science B.V. All rights reserved. © 2004 Elsevier Science B.V., Amsterdam. All rights reserved.","Seo, B.",2003,10.1016/s0165-1889(02)00124-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038330312&doi=10.1016%2FS0165-1889%2802%2900124-0&partnerID=40&md5=9658712d925b977d5436dcf9eb640c5b,scopus
08f7e1c21ff490c4,Nonlinear predictability of stock returns using financial and economic variables,"Inspired by the linear predictability and nonlinearity found in the finance literature, this article examines the nonlinear predictability of the excess returns. The relationship between the excess returns and the predicting variables is recursively modeled by a neural-network model, which is capable of performing flexible nonlinear functional approximation. The nonlinear neural-network model is found to have better in-sample fit and out-of-sample forecasts compared to its linear counterpart. Moreover, the switching portfolio based on the recursive neural-network forecasts generates higher profits with lower risks than both the buy-and-hold market portfolio and the switching portfolio based on linear recursive forecasts. © 2017 Elsevier B.V., All rights reserved.","Qi, M.",1999,10.1080/07350015.1999.10524830,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033435319&doi=10.1080%2F07350015.1999.10524830&partnerID=40&md5=5168aa09c44a851bad6e254e59934493,scopus
686f825c1c5611f7,Nonlinear structural estimation of corporate bond liquidity,"We estimate the term structure of corporate bond liquidity premiums using a dual estimation technique. Our estimates reveal that the term structures of the liquidity premiums were positively sloped and concave for each category of creditworthiness and in three economic epochs. As the macroeconomy transitioned from a pre-crisis to a crisis period, liquidity premiums elevated across time to maturity for both investment grade and speculative grade bonds. With the migration of the financial system from stress to relative calm, the premiums on both grades of debt declined for all maturities.",None,2025,10.1007/s11156-024-01323-y,None,proquest
0b74a66f5bfe27e3,Nonlinear support vector machines can systematically identify stocks with high and low future returns,"This paper investigates the profitability of a trading strategy based on training a model to identify stocks with high or low predicted returns. A tail set is defined to be a group of stocks whose volatility-adjusted price change is in the highest or lowest quantile, for example the highest or lowest 5%. Each stock is represented by a set of technical and fundamental features computed using CRSP and Compustat data. A classifier is trained on historical tail sets and tested on future data. The classifier is chosen to be a nonlinear support vector machine (SVM) due to its simplicity and effectiveness. The SVM is trained once per month, in order to adjust to changing market conditions. Portfolios are formed by ranking stocks using the classifier output. The highest ranked stocks are used for long positions and the lowest ranked ones for short sales. The Global Industry Classification Standard is used to build a model for each sector such that a total of 8 long-short portfolios for Energy, Materials, Industrials, Consumer Discretionary, Consumer Staples, Health Care, Financials, and Information Technology are formed. The data range from 1981 to 2010. Without measuring trading costs, but using 91 day holding periods to minimize these, the strategy leads to annual excess returns (Jensen alpha) of 15% with volatilities under 8% using the top 25% of the stocks of the distribution for training long positions and the bottom 25% for the short ones. © 2015 Elsevier B.V., All rights reserved.","Huerta, R.; Corbacho, F.; Elkan, C.",2013,10.3233/af-13016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921366265&doi=10.3233%2FAF-13016&partnerID=40&md5=2deab8efb093476e3de638f71535fbd5,scopus
62ca100ade73914d,"Nonlinear term structure dependence: Copula functions, empirics, and risk implications","This paper documents nonlinear cross-sectional dependence in the term structure of US-Treasury yields and points out risk management implications. The analysis is based on a Kalman filter estimation of a two-factor affine model which specifies the yield curve dynamics. We then apply a broad class of copula functions for modeling dependence in factors spanning the yield curve. Our sample of monthly yields in the 1982-2001 period provides evidence of upper tail dependence in yield innovations; i.e., large positive interest rate shocks tend to occur under increased dependence. In contrast, the best-fitting copula model coincides with zero lower tail dependence. This asymmetry has substantial risk management implications. We give an example in estimating bond portfolio loss quantiles and report the biases which result from an application of the normal dependence model. © 2005 Elsevier B.V. All rights reserved. © 2006 Elsevier B.V., All rights reserved.","Junker, M.; Szimayer, A.; Wagner, N.",2006,10.1016/j.jbankfin.2005.05.014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33645876764&doi=10.1016%2Fj.jbankfin.2005.05.014&partnerID=40&md5=32ab47b0aeff8bdd8f432aa07d529247,scopus
35cf911ff0798991,Nonlinear time‐series analysis of stock volatilities,"The absolute value of the mean‐corrected excess return is used in this paper to measure the volatility of stock returns. We apply various nonlinearity tests available in the literature to show that such volatility series are strongly nonlinear. We then explore the use of threshold autoregressive (TAR) models in describing monthly volatility series. The models built suggest that the volatility series exhibit significant lower‐order serial correlations when the volatility is large, indicating certain volatility clustering in stock returns. Out‐of‐sample forecasts are used to compare the TAR models with linear ARMA models and nonlinear GARCH and EGARCH models. Based on mean squared error and average absolute deviation, the comparisons show that (a) the TAR models consistently outperform the linear ARMA models in multi‐step ahead forecasts for large stocks, (b) the TAR models provide better forecasts than the GARCH and EGARCH models also for the volatilities of large stock returns, and (c) the EGARCH model gives the best long‐horizon volatility forecasts for small stock returns. Copyright © 1992 John Wiley & Sons, Ltd. © 2016 Elsevier B.V., All rights reserved.","Cao, C.Q.; Tsay, R.S.",1992,10.1002/jae.3950070512,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986414605&doi=10.1002%2Fjae.3950070512&partnerID=40&md5=ccecaf8680144f56020bdb3e20ff479f,scopus
11f7754968771687,Nonlinear trading models through Sharpe Ratio maximization,"While many trading strategies are based on price prediction, traders in financial markets are typically interested in optimizing risk-adjusted performance such as the Sharpe Ratio, rather than the price predictions themselves. This paper introduces an approach which generates a nonlinear strategy that explicitly maximizes the Sharpe Ratio. It is expressed as a neural network model whose output is the position size between a risky and a risk-free asset. The iterative parameter update rules are derived and compared to alternative approaches. The resulting trading strategy is evaluated and analyzed on both computer-generated data and real world data (DAX, the daily German equity index). Trading based on Sharpe Ratio maximization compares favorably to both profit optimization and probability matching (through cross-entropy optimization). The results show that the goal of optimizing out-of-sample risk-adjusted profit can indeed be achieved with this nonlinear approach.While many trading strategies are based on price prediction, traders in financial markets are typically interested in optimizing risk-adjusted performance such as the Sharpe Ratio, rather than the price predictions themselves. This paper introduces an approach which generates a nonlinear strategy that explicitly maximizes the Sharpe Ratio. It is expressed as a neural network model whose output is the position size between a risky and a risk-free asset. The iterative parameter update rules are derived and compared to alternative approaches. The resulting trading strategy is evaluated and analyzed on both computer-generated data and real world data (DAX, the daily German equity index). Trading based on Sharpe Ratio maximization compares favorably to both profit optimization and probability matching (through cross-entropy optimization). The results show that the goal of optimizing out-of-sample risk-adjusted profit can indeed be achieved with this nonlinear approach.","Choey, M; Weigend, A S",1997,10.1142/s0129065797000410,None,proquest
335a8fbd8ef67621,Nonlinearities in the black market zloty-dollar exchange rate: Some further evidence,"This study reappraises the evidence for nonlinear dependence in the monthly black market exchange returns of the Polish zloty, 1955-1990. Predictive asymmetry is reported in conditional variance such that depreciatory shocks have a greater impact on subsequent volatility than appreciatory shocks, jointly with conditional mean nonlinearity of smooth transition between regimes which suggests a simple trading strategy capable of generating positive profit over the sample period. However, support is also found for a competing variance-in-mean model consistent with a time-varying risk premium that is able to rationalize the presence of unexploited profit opportunities, particularly over the latter half of the sample. © 2007 Elsevier B.V., All rights reserved.","McMillan, D.G.; Speight, A.E.H.",2001,10.1080/096031001750071604,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035084341&doi=10.1080%2F096031001750071604&partnerID=40&md5=167b5291532c6c9ef646e89ed01d7817,scopus
d67898e84b4d8939,Nonlinearities in the relation between the equity risk premium and the term structure,"This paper investigates the relation between the conditional expected equity risk premium and the slope of the term structure of interest rates. Theoretically, these variables are linked, the relation may be nonlinear, and negative risk premiums are consistent with equilibrium. Given these implications, we employ a nonparametric estimation technique to document the empirical relation between the risk premium and the slope of the term structure using almost two hundred years of data. Of particular interest, the risk premium is increasing in the term structure slope; however, for either small or negative slopes, the risk premium is much more sensitive to changes in interest rates. In addition, the empirical results imply negative expected equity risk premiums for some inverted term structures. Finally, variations in the risk premium do not appear to be related to variations in the variance of equity returns. We illustrate these features in a stylized consumption-based model, and provide the economic intuition behind the results. © 2017 Elsevier B.V., All rights reserved.","Boudoukh, J.; Richardson, M.; Whitelaw, R.F.",1997,10.1287/mnsc.43.3.371,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031096836&doi=10.1287%2Fmnsc.43.3.371&partnerID=40&md5=f1a811b5a39a8ccd4a9ef7c511499e9a,scopus
e34634e5005df2ed,Nonlinearity and Flight‐to‐Safety in the Risk‐Return Trade‐Off for Stocks and Bonds,"We document a highly significant, strongly nonlinear dependence of stock and bond returns on past equity market volatility as measured by the VIX. We propose a new estimator for the shape of the nonlinear forecasting relationship that exploits variation in the cross‐section of returns. The nonlinearities are mirror images for stocks and bonds, revealing flight‐to‐safety: expected returns increase for stocks when volatility increases from moderate to high levels while they decline for Treasuries. These findings provide support for dynamic asset pricing theories in which the price of risk is a nonlinear function of market volatility.","Tobias, Adrian; Crump, Richard K; Vogt, Erik",2019,10.1111/jofi.12776,None,proquest
e5a5404c5febe25f,"Nonparametric conditional density estimation of short-term interest rate movements: procedures, results and risk management implications","This article shows how to estimate the conditional density of daily changes in the 3-month T-bill rate, using an extension of the kernel-based estimator proposed by Rosenblatt (1969). The shape of the estimated density is allowed to vary with both the level and the lagged change in rates. Due to the nonparametric character of the estimation procedure, the model produces conditional quantile estimates that are based only on the data and are independent of the modellers' assumptions. The obtained results do not support the assumption of systematically mean-reverting behaviour underlying some theoretical models of short-term interest rate dynamics. However, they clearly indicate the presence of nonlinear first-order autocorrelation and volatility clustering effects, as well as a positive relationship between yield volatility and level. Reprinted by permission of Routledge, Taylor and Francis Ltd.","Kalda, Ankit; Siddiqui, Sikandar",2013,10.1080/09603107.2012.741677,None,proquest
9d6021375ec7e4f4,Nonparametric long term prediction of stock returns with generated bond yields,"Recent empirical approaches in forecasting equity returns or premiums found that dynamic interactions among the stock and bond are relevant for long term pension products. Automatic procedures to upgrade or downgrade risk exposure could potentially improve long term performance for such products. The risk and return of bonds is more easy to predict than the risk and return of stocks. This and the well known stock-bond correlation motivates the inclusion of the current bond yield in a model for the prediction of excess stock returns. Here, we take the actuarial long term view using yearly data, and focus on nonlinear relationships between a set of covariates. We employ fully nonparametric models and apply for estimation a local-linear kernel smoother. Since the current bond yield is not known, it is predicted in a prior step. The structure imposed this way in the final estimation process helps to circumvent the curse of dimensionality and reduces bias in the estimation of excess stock returns. Our validated stock prediction results show that predicted bond returns improve stock prediction significantly. © 2018 Elsevier B.V., All rights reserved.","Scholz, M.; Sperlich, S.; Nielsen, J.P.",2016,10.1016/j.insmatheco.2016.04.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969264273&doi=10.1016%2Fj.insmatheco.2016.04.007&partnerID=40&md5=17bf2ebd89d43d3a897d4e7079a14d3f,scopus
bf41f43cc6cb3759,Nonparametric model validations for hidden Markov models with applications in financial econometrics,"We address the nonparametric model validation problem for hidden Markov models with partially observable variables and hidden states. We achieve this goal by constructing a nonparametric simultaneous confidence envelope for transition density function of the observable variables and checking whether the parametric density estimate is contained within such an envelope. Our specification test procedure is motivated by a functional connection between the transition density of the observable variables and the Markov transition kernel of the hidden states. Our approach is applicable for continuous-time diffusion models, stochastic volatility models, nonlinear time series models, and models with market microstructure noise. (C) 2011 Elsevier B.V. All rights reserved.","Zhao, Zhibiao",2011,10.1016/j.jeconom.2011.01.002,None,wos
c2c226c46dd988d9,Nonparametric modeling and analysis of association between huntington's disease onset and CAG repeats,"Huntington's disease (HD) is a neurodegenerative disorder with a dominant genetic mode of inheritance caused by an expansion of CAG repeats on chromosome 4. Typically, a longer sequence of CAG repeat length is associated with increased risk of experiencing earlier onset of HD. Previous studies of the association between HD onset age and CAG length have favored a logistic model, where the CAG repeat length enters the mean and variance components of the logistic model in a complex exponential-linear form. To relax the parametric assumption of the exponential-linear association to the true HD onset distribution, we propose to leave both mean and variance functions of the CAG repeat length unspecified and perform semiparametric estimation in this context through a local kernel and backfitting procedure. Motivated by including family history of HD information available in the family members of participants in the Cooperative Huntington's Observational Research Trial (COHORT), we develop the methodology in the context of mixture data, where some subjects have a positive probability of being risk free. We also allow censoring on the age at onset of disease and accommodate covariates other than the CAG length. We study the theoretical properties of the proposed estimator and derive its asymptotic distribution. Finally, we apply the proposed methods to the COHORT data to estimate the HD onset distribution using a group of study participants and the disease family history information available on their family members. © 2013 John Wiley & Sons, Ltd. © 2013 John Wiley & Sons, Ltd. © 2014 Elsevier B.V., All rights reserved.","Ma, Y.; Wang, Y.",2014,10.1002/sim.5971,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896717351&doi=10.1002%2Fsim.5971&partnerID=40&md5=8093cb412464361671de561844e3824e,scopus
d719150f17781855,"Nutritional value, elemental bioaccumulation and antioxidant activity of fruiting bodies and mycelial cultures of an unrecorded wild Lactarius hatsudake from Nanyue mountainous region in China","An unrecorded wild mushroom Lactarius hatsudake from Nanyue mountainous region in China was identified. Subsequently, comparative investigation on the nutritional value, elemental bioaccumulation, and antioxidant activity was performed in the fruiting body (FB) and mycelium (MY) samples of this species. It revealed that the contents of moisture (87.66 ± 0.16 g/100 g fw) and ash (6.97 ± 0.16 g/100 g dw) were significantly higher in FB, and the total carbohydrate, fat, and protein concentrations of FB were similar to those in MY. Among nutritionally important elements, FB possessed higher concentrations of potassium (37808.61 ± 1237.38 mg/kg dw), iron (470.69 ± 85.54 mg/kg dw), and zinc (136.13 ± 5.16 mg/kg dw), whereas MY was a better source of magnesium (1481.76 ± 18.03 mg/kg dw), calcium (2203.87 ± 69.61 mg/kg dw), and sodium (277.44 ± 22.93 mg/kg dw). According to the health risk estimation, FB might pose an aluminum-related health problem when a prolonged period of exposure, while MY was risk-free for consumers. The results of antioxidant capacity (1,1-diphenyl-2-picrylhydrazyl (DPPH) and 2,2'-Azino-bis (3-ethylbenzothiazoline-6-sulfonic acid) diammonium salt (ABTS) assays) in FB and MY were within the range of 104.19 ± 5.70 mg ascorbic acid equivalents (AAE)/g to 169.50 ± 4.94 mg AAE/g, and half maximal effective concentration EC50 values ranged from 0.23 ± 0.01 mg/mL to 0.62 ± 0.05 mg/mL. The aqueous extracts of MY demonstrated a strong ABTS radical scavenging capacity with the highest AAE value.An unrecorded wild mushroom Lactarius hatsudake from Nanyue mountainous region in China was identified. Subsequently, comparative investigation on the nutritional value, elemental bioaccumulation, and antioxidant activity was performed in the fruiting body (FB) and mycelium (MY) samples of this species. It revealed that the contents of moisture (87.66 ± 0.16 g/100 g fw) and ash (6.97 ± 0.16 g/100 g dw) were significantly higher in FB, and the total carbohydrate, fat, and protein concentrations of FB were similar to those in MY. Among nutritionally important elements, FB possessed higher concentrations of potassium (37808.61 ± 1237.38 mg/kg dw), iron (470.69 ± 85.54 mg/kg dw), and zinc (136.13 ± 5.16 mg/kg dw), whereas MY was a better source of magnesium (1481.76 ± 18.03 mg/kg dw), calcium (2203.87 ± 69.61 mg/kg dw), and sodium (277.44 ± 22.93 mg/kg dw). According to the health risk estimation, FB might pose an aluminum-related health problem when a prolonged period of exposure, while MY was risk-free for consumers. The results of antioxidant capacity (1,1-diphenyl-2-picrylhydrazyl (DPPH) and 2,2'-Azino-bis (3-ethylbenzothiazoline-6-sulfonic acid) diammonium salt (ABTS) assays) in FB and MY were within the range of 104.19 ± 5.70 mg ascorbic acid equivalents (AAE)/g to 169.50 ± 4.94 mg AAE/g, and half maximal effective concentration EC50 values ranged from 0.23 ± 0.01 mg/mL to 0.62 ± 0.05 mg/mL. The aqueous extracts of MY demonstrated a strong ABTS radical scavenging capacity with the highest AAE value.","Zhu, Hanyu; Chen, Zheng; Hu, Yujing; Li, Geqing; Yao, Xiaoqian; Cao, Limin",2023,10.1016/j.foodres.2023.113358,None,proquest
13233d94f34ea253,OP73 Human and financial costs of six early years disadvantages in the UK and Bradford: a birth cohort microsimulation study,"BackgroundEarly childhood disadvantages (up to age 5) can have life-long effects on health and wellbeing. Methods of birth cohort microsimulation can capture these long-term effects and the associated public cost savings, which are hard to estimate using conventional methods (e.g. trials) because the effects may take decades to manifest. We aimed to quantify the long-term effects and public costs of six different early years disadvantages up to age 17 in the UK and Bradford, a multi-ethnic deprived local authority, using a microsimulation model based on the UK Millennium Cohort Study.MethodsUsing a cohort of 15,380 children from the Millenium Cohort Study (MCS) we model early years risk factors (conception to age 5) and subsequent outcomes up to age 17. We choose six risk factors: having a teenage mother, preterm birth, low birthweight (for gestational age), low height (age 5); disability (age 5), and school readiness (age 5). The causal effect parameters used in our microsimulation model are estimated using regressions based on Directed Acyclic Graphs (DAGs) which clearly set out our causal inference assumptions. We quantify a set of policy-relevant outcomes and their annual public costs for the UK and calibrate to Bradford based on local prevalence and population data. We assess the robustness of our findings to alternative assumptions and measures.ResultsThe public cost up to age 17 ranged between £86,058 [44,114–128,002] per 1,000 children for having a teenage mother, or £58,544 for each annual Bradford cohort to £432,920 [263,733–600,108] for school readiness or £1,872,265 for each Bradford cohort. The wellbeing impact ranged from 21 [-37–78] WELLBYs per 1,000 children for low birth weight or 20 per Bradford cohort, to 268 [245–290] for school readiness or 1,160 per Bradford cohort. Each WELLBY is valued by the UK Treasury at £13,000.ConclusionImproving school readiness yielded a larger wellbeing gain and public cost savings per child beneficiary than eliminating any of the other disadvantages we examined, but less than reducing early childhood poverty by moving families from the bottom income quintile to the next. When combined with evidence on short term effects of interventions, comparative long-term estimates of this kind may help policymakers prioritise and justify early years investments.We will report full results for the Uk and Bradford at the meeting, including a ready reckoner table of the long-term benefits and costs of reducing each childhood disadvantage.","Shrathinth, Venkatesh; Skarda Ieva; Villadsen Aase; Warburton, Matthew; Mansukoski Liina; Miqdad, Asaria; Williams, Mark Mon; Cookson, Richard",2025,10.1136/jech-2025-ssmabstracts.73,None,proquest
1475fced39bb3621,OPTIMAL ASSET ALLOCATION WITH MULTIVARIATE BAYESIAN DYNAMIC LINEAR MODELS,"We introduce a fast, closed-form, simulation-free method to model and forecast multiple asset returns and employ it to investigate the optimal ensemble of features to include when jointly predicting monthly stock and bond excess returns. Our approach builds on the Bayesian dynamic linear models of West and Harrison (Bayesian Forecasting and Dynamic Models (1997) Springer), and it can objectively determine, through a fully automated procedure, both the optimal set of regressors to include in the predictive system and the degree to which the model coefficients, volatilities and covariances should vary over time. When applied to a portfolio of five stock and bond returns, we find that our method leads to large forecast gains, both in statistical and economic terms. In particular, we find that relative to a standard no-predictability benchmark, the optimal combination of predictors, stochastic volatility and time-varying covariances increases the annualized certainty equivalent returns of a leverage-constrained power utility investor by more than 500 basis points.","Fisher, Jared D.; Pettenuzzo, Davide; Carvalho, Carlos M.",2020,10.1214/19-aoas1303,None,wos
00fd43d7d419402b,Objective Black-Litterman views through deep learning: A novel hybrid model for enhanced portfolio returns,"The Black-Litterman Model is a sophisticated approach to portfolio optimization that integrates investor views with market data. However, the model's effectiveness is highly dependent on the quality of its inputs and is often challenged by subjective or biased views. Recent advancements in deep learning have enabled the generation of more objective, data-driven views, significantly enhancing the model's accuracy and reliability. In this study, we propose a novel CGL-BL Model, which employs a hybrid deep learning approach—CEEMDAN-GLSTM-LSTM (CGL)—to generate investor views. The CGL model leverages the CEEMDAN algorithm for return-based time series decomposition, a Genetic Algorithm-optimized LSTM network to enhance prediction accuracy, and an additional LSTM network for nonlinear aggregation of prediction results. The proposed CGL-BL model was evaluated on both the SSE 50 Index in China and the DJIA in the United States. Empirical results show that the proposed CGL-BL model outperforms all benchmark portfolios in terms of excess return, Sharpe ratio, and maximum drawdown when applied with a short-term rebalancing strategy on the SSE 50 Index and a medium-to-long-term strategy on the DJIA, demonstrating strong potential for practical application in financial markets. © 2025 Elsevier B.V., All rights reserved.","Su, X.; Lu, K.; Yen, J.",2026,10.1016/j.eswa.2025.128868,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009900832&doi=10.1016%2Fj.eswa.2025.128868&partnerID=40&md5=b27f0493fa3bcfd8ab0088a189292bd7,scopus
286e16d3c623fe9c,Oil price dynamics and speculation: A multivariate financial approach,"This paper assesses empirically whether speculation affects oil price dynamics. The growing presence of financial operators in the oil markets has led to the diffusion of trading techniques based on extrapolative expectations. Strategies of this kind foster feedback trading that may cause considerable departures of prices from their fundamental values. We investigate this hypothesis using a modified CAPM following Shiller (1984) and Sentana and Wadhwani (1992). First, a univariate GARCH(1,1)-M is estimated assuming the risk premium to be a function of the conditional oil price volatility. The single factor model, however, is outperformed by the multifactor ICAPM (Merton, 1973), which takes into account a larger investment opportunity set. Analysis is then carried out using a trivariate CCC GARCH-M model with complex nonlinear conditional mean equations where oil price dynamics are associated with both stock market and exchange rate behavior. We find strong evidence that oil price shifts are negatively related to stock price and exchange rate changes and that a complex web of time-varying first and second order conditional moment interactions affects both the CAPM and feedback trading components of the model. Despite the difficulties, we identify a significant role played by speculation in the oil market, which is consistent with the observed large daily upward and downward shifts in prices - a clear evidence that it is not a fundamental-driven market. Thus, from a policy point of view - given the impact of volatile oil prices on global inflation and growth - actions that monitor speculative activities on commodity markets more effectively are to be welcomed. [Copyright Elsevier B.V.]","Cifarelli, Giulio; Paladino, Giovanna",2010,10.1016/j.eneco.2009.08.014,None,proquest
7bff3f5daef33b24,Oil volatility risk and stock market volatility predictability: Evidence from G7 countries,"Academic research relies extensively on stock market information to forecast oil volatility, with relatively little attention paid to the reverse evidence. Our paper fills this gap by investigating the predictive ability of oil volatility risk to forecast stock market volatility. Using oil volatility risk premium (oil VRP) as the predictor, we find that oil VRP does exhibit statistically and economically significant in-sample and out-of-sample forecasting power for G7 countries, even controlling for some popular macroeconomic variables. These findings are robust when using alternative proxies for volatilities of stock and oil. Furthermore, the strength of the predictive evidence is substantial during relatively high and low level of stock market, while is substantially higher for recessions vis-á-vis expansions. Oil VRP can also contains additional information for predicting a series of macroeconomic variables, which serves as an available explanation for its forecasting ability. © 2017 Elsevier B.V., All rights reserved.","Feng, J.; Wang, Y.; Yin, L.",2017,10.1016/j.eneco.2017.09.023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033474517&doi=10.1016%2Fj.eneco.2017.09.023&partnerID=40&md5=a075dd9efe8a8e5ec98bf304a551f6af,scopus
d36b44e60b0bcc27,"On Crop Biodiversity, Risk Exposure, and Food Security in the Highlands of Ethiopia","This paper investigates the effects of crop genetic diversity on farm productivity and production risk in the highlands of Ethiopia. Using a moment‐based approach, the analysis uses a stochastic production function capturing mean, variance, and skewness effects. Welfare implications of diversity are evaluated using a certainty equivalent, measured as expected income minus a risk premium (reflecting the cost of risk). We find that the effect of diversity on skewness dominates its effect on variance, meaning that diversity reduces the cost of risk. The analysis also shows that the beneficial effects of diversity become of greater value in degraded land.","Di Falco, Salvatore; Chavas, Jean‐Paul",2009,10.1111/j.1467-8276.2009.01265.x,None,proquest
ebf6d44f3b36d6fb,On Gaussian HJM framework for Eurodollar Futures,"One of the standard tools for the theoretical analysis of fixed income securities and their associated derivatives is the term structure model of Heath, Jarrow and Morton. In this paper the question, what specific HJM model is consistent with the observed price of an Eurodollar Futures contract? is discussed. Eurodollar Futures, apart from being the most heavily traded futures are connected to London Inter Bank Offered Rate (LIBOR) and to domestic monetary conditions. The answer to the above question will help in pricing any new derivative on Eurodollar Futures or the one that is not heavily traded. A simple tool to measure the adequacy of different HJM structures that may be used to model Eurodollar Futures price process is suggested. Moreover, the question of estimation of parameters of these models by different methods-method of realized volatility, method of maximum likelihood (ML) and a two-stage method that combines both the realized volatility and ML-is addressed. Although it sounds like a typical statistical procedure, one must be careful in applying standard statistical techniques that are not suitable under arbitrage theory, in particular, ML method. Copyright © 2010 John Wiley & Sons, Ltd. © 2011 Elsevier B.V., All rights reserved.","Raman, B.; Pozdnyakov, V.",2011,10.1002/asmb.845,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051734977&doi=10.1002%2Fasmb.845&partnerID=40&md5=0fae9ebfb31357f6d62e923e89e64c32,scopus
180c87337b9c2b66,On LASSO for predictive regression,"Explanatory variables in a predictive regression typically exhibit low signal strength and various degrees of persistence. Variable selection in such a context is of great importance. In this paper, we explore the pitfalls and possibilities of the LASSO methods in this predictive regression framework. In the presence of stationary, local unit root, and cointegrated predictors, we show that the adaptive LASSO cannot asymptotically eliminate all cointegrating variables with zero regression coefficients. This new finding motivates a novel post-selection adaptive LASSO, which we call the twin adaptive LASSO (TAlasso), to restore variable selection consistency. Accommodating the system of heterogeneous regressors, TAlasso achieves the well-known oracle property. In contrast, conventional LASSO fails to attain coefficient estimation consistency and variable screening in all components simultaneously. We apply these LASSO methods to evaluate the short- and long-horizon predictability of S&P 500 excess returns.","Lee, Ji Hyung; Shi, Zhentao; Gao, Zhan",2022,10.1016/j.jeconom.2021.02.002,None,proquest
01c47e420fd781a1,On a constrained mixture vector autoregressive model,"A mixture vector autoregressive model has recently been introduced to the literature. Although this model is a promising candidate for nonlinear multiple time series modeling, high dimensionality of the parameters and lack of method for computing the standard errors of estimates limit its application to real data. The contribution of this paper is threefold. First, a form of parameter constraints is introduced with an efficient EM algorithm for estimation. Second, an accurate method for computing standard errors is presented for the model with and without parameter constraints. Lastly, a hypothesis-testing approach based on likelihood ratio tests is proposed, which aids in the selection of unnecessary parameters and leads to the greater efficiency at the estimation. A case study employing U.S. Treasury constant maturity rates illustrates the applicability of the mixture vector autoregressive model with parameter constraints, and the importance of using a reliable method to compute standard errors. © 2013 IMACS. Published by Elsevier B.V. All rights reserved. © 2017 Elsevier B.V., All rights reserved.","Wong, C.S.",2013,10.1016/j.matcom.2013.05.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027926931&doi=10.1016%2Fj.matcom.2013.05.001&partnerID=40&md5=5e71ec085d88b327a249856779217765,scopus
3ca42c57cf880dd3,On credit spread change of Chinese corporate bonds: credit risk or asset allocation effect?,"Purpose – Credit spread change is a key issue for investors to earn the excess return from corporate bonds. Generally, there are two kinds of different effects that support the changing of credit spread: asset allocation effect and credit risk change effect. The existing literature based on US data supports credit spread change is driven by credit risk change; however, this issue based on Chinese market data has not been investigated clearly. This paper seeks to address this issue. Design/methodology/approach – The authors adopt Markov regime switching model to investigate the changing mode of the credit spread in the Chinese bond market. They select three kinds of variables: the credit risk variables, the asset allocation variables and the liquidity condition variables. With ML estimators, the authors can find the changing mode and further they study the relationship between the regime switching and some observed variables, such as macro economy variables and turnover of stock market. Findings – The authors find it is driven by asset allocation effect in most time and by credit risk change only in shorter period. Empirical results show that the switching of dominance from one effect to another isn't closely related with macro-economy variables, but related with the turnover of stock market. Practical implications – These results indicate that in China the credit risk of corporate bonds is relatively low and the corporate bonds are still auxiliary asset for investors. Originality/value – In this paper, the authors have the following two contributions: first, they discuss the asset allocation effect in the Chinese bond market and introduce the stock market variables and bank credit variable to describe the asset allocation effect; second, based on Chinese bond market data, they find different findings from the existing literature about US and European bond markets, showing that the changing of credit spread is mostly related with asset allocation effect but not credit risk change. © 2017 Elsevier B.V., All rights reserved.","Cui, C.; Liu, H.; Zhang, Y.",2013,10.1108/cfri-02-2012-0020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015670143&doi=10.1108%2FCFRI-02-2012-0020&partnerID=40&md5=702c717b284c0dcc395735c4a2685d52,scopus
6c8e3fca2c525e30,On estimability of parsimonious term structure models: An experiment with the Nelson-Siegel specification,"This study addresses operational issues in estimation of parsimonious term structure models. When using price errors, objective function in term structure estimation is a nonlinear function of the model parameters. This necessarily entails using numerical optimization techniques for estimation, which brings to fore the issue of (sensitivity of final results to) the choice of initialization of the optimization routine. This study assesses the sensitivity of the final objective function value and the final parameter vector to the choice of the 'initial guess' during the estimation of the popular Nelson-Siegel model. It turns out that there exist regions in the shape of the objective function where a slight change in (seemingly reasonable) initial vector takes one far from optimum. Choice of the (range of) 'best' starting vector turns out to be an empirical matter. Grid search is recommended. One must first get to a subset of initial values that results in the objective function value near a minimum and then assess the sensitivity of the final parameter vector to those relevant (subset of) initial values. The study illustrates the process using a typical trading day's data. © 2012 Copyright Taylor and Francis Group, LLC. © 2012 Elsevier B.V., All rights reserved.","Virmani, V.",2012,10.1080/13504851.2012.657343,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863492248&doi=10.1080%2F13504851.2012.657343&partnerID=40&md5=759a05b89376f52765cdf960acd72789,scopus
a174f9343be6fc86,On filtering in Markovian term structure models: An approximation approach,"We consider a parametrization of the Heath-Jarrow-Morton (HJM) family of term structure of interest rate models that allows a finite-dimensional Markovian representation of the stochastic dynamics. This parametrization results from letting the volatility function depend on time to maturity and on two factors: the instantaneous spot rate and one fixed-maturity forward rate. Our main purpose is an estimation methodology for which we have to model the observations under the historical probability measure. This leads us to consider as an additional third factor the market price of interest rate risk, that connects the historical and the HJM martingale measures. Assuming that the information comes from noisy observations of the fixed-maturity forward rate, the purpose is to estimate recursively, on the basis of this information, the three Markovian factors as well as the parameters in the model, in particular those in the volatility function. This leads to a nonlinear filtering problem, for the solution of which we describe an approximation methodology, based on time discretization and quantization. We prove the convergence of the approximate filters for each of the observed trajectories. © 2005 Elsevier Science B.V., Amsterdam. All rights reserved.","Chiarella, C.; Pasquali, S.; Runggaldier, W.J.",2001,10.1239/aap/1011994030,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035710457&doi=10.1239%2Faap%2F1011994030&partnerID=40&md5=354532f209d840951e8d6199d8470815,scopus
f54835efc01a2af6,On modeling IPO failure risk,"This paper offers a novel framework, combining firm operational risk, IPO pricing risk, and market risk, to model IPO failure risk. By analyzing nearly a thousand variables, we observe that prior IPO failure risk models have suffered from a major missing-variable problem. Evidence reveals several key new firm-level determinants, e.g., the volatility operating performance, the size of its accounts payable, pretax income to common equity, total short-term debt, and a few macroeconomic variables such as treasury bill rate, and book-to-market of the DJIA index. These findings have major economic implications. The total value loss from not predicting the imminent failure of an IPO is significantly lower with this proposed model compared to other established models. The IPO investors could have saved around $18billion over the period between 1994 and 2016 by using this model. © 2022 Elsevier B.V., All rights reserved.","Colak, G.; Fu, M.; Hasan, I.",2022,10.1016/j.econmod.2022.105790,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124421011&doi=10.1016%2Fj.econmod.2022.105790&partnerID=40&md5=f16401aacf4f384db51620d5c6763e73,scopus
0ee54a8376616768,On multicollinearity and the value of the shape parameter in the term structure Nelson-Siegel model,"This paper investigates the sensitivity of the dynamic Nelson-Siegel factor loadings to the value of the shape parameter, λ. It also analyses the multicollinearity problem and addresses how to mitigate this issue in the estimation process. First, we find that the selection of a fixed λ is not optimal due to the collinearity problems. Second, we observe a substantial difference between the forecasting performance of the traditional estimation procedures and that of the ridge regression approach. Finally, we implement a Monte Carlo simulation exercise in order to study the statistical distribution of the estimates of the model parameters and thus determine the extent to which they differ from the real values. Furthermore, we find that multicollinearity between the factors of the NS model can, in the case of ordinary least squares estimation with a fixed parameter λ, result in greater differences between the estimates and the actual parameter values. Ridge regression corrects such differences and produces more stable estimates than the ordinary linear and nonlinear least squares methods.","León, Angel; Rubia, Antonio; Sanchis-Marco, Lidia",2018,10.5605/ieb.16.1,None,proquest
7cf8480c0b3c77f9,On some filtering problems arising in mathematical finance,"Three situations in which filtering theory is used in mathematical finance are illustrated at different levels of detail. The three problems originate from the following different works: (1) On estimating the stochastic volatility model from observed bilateral exchange rate news, by Mahieu and Schotman (1997). (2) A state space approach to estimate multi-factors CIR models of the term structure of interest rates, by Geyer and Pichler (1996). (3) Risk-minimizing hedging strategies under partial observation in pricing financial derivatives, by Fischer et al. (1996). In the first problem we propose to use a recent nonlinear filtering technique based on geometry to estimate the volatility time series from observed bilateral exchange rates. The model used here is the stochastic volatility model. The filters that we propose are known as projection filters, and a brief derivation of such filters is given. The second problem is introduced in detail, and a possible use of different filtering techniques is hinted at. In fact the filters used for this problem in (2) and part of the literature can be interpreted as projection filters and we will make some remarks on how more general and possibly more suitable projection filters can be constructed. The third problem is only presented briefly. © 1998 Elsevier Science B.V. All rights reserved. © 2018 Elsevier B.V., All rights reserved.","Brigo, D.; Hanzon, B.",1998,10.1016/s0167-6687(98)00008-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032523514&doi=10.1016%2FS0167-6687%2898%2900008-0&partnerID=40&md5=f63a02c53a85f528403e3d4c8fbf372d,scopus
c2c3870c724130ae,"On the construction of monthly term structures of U.S. interest rates, 1919-1930","This paper presents the methodology used to construct reliable estimates of the term structure of interest rates for the United States during 1919-1930. These monthly term structures are based on individual corporate bonds' price quotations for the majority of U.S. railroad corporations' issues of that era. McCulloch's cubic spline methodology, coupled with Nelson and Siegel's parsimonious estimator, is used to derive curves for three investment-grade risk classes. These estimates compare favorably with Durand's hand-smoothed estimates as well as earlier annual estimates generated by Thies. They provide a consistent basis for a wide range of monetary and financial research on this period. © 1992 Kluwer Academic Publishers. © 2007 Elsevier B.V., All rights reserved.","Baum, C.F.; Thies, C.F.",1992,10.1007/bf00426761,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34249832297&doi=10.1007%2FBF00426761&partnerID=40&md5=29e06ba6e17845fda2889a492cb90335,scopus
ad0a338018943161,On the nonlinear predictability of stock returns using financial and economic variables,"In a recent article by Qi, neural networks trained by Bayesian regularization were used to predict excess returns on the S&P 500. The article concluded that the switching portfolio based on the recursive neural-network forecasts generates higher accumulated wealth with lower risks than that based on linear regression. Unfortunately, attempts to replicate the results were unsuccessful. Replicated results using the same software, approach and data detailed by Qi indicate that, in fact, the switching portfolio based on the recursive neural-network forecasts generates lower accumulated wealth with higher risks than that based on linear regression. © 2005 Elsevier Science B.V., Amsterdam. All rights reserved.","Racine, J.",2001,10.1198/073500101681019927,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035638655&doi=10.1198%2F073500101681019927&partnerID=40&md5=2f633ec6cfbf429ce536720d0c842b79,scopus
cc726ef76b042dc2,On the nonlinear specifications of short-term interest rate behavior: Evidence from euro-currency markets,"This paper presents a coherent nonlinear interest rate model that incorporates the dynamics of the error correction specification into the traditional term structure model. The joint tests based on six Euro-Currency rates indicate that the linear specification should be rejected. The estimated equation suggests that the linear components - the change of the long-term interest rate and the error correcting term are highly significant. The nonlinear components involving the higher order of the independent variables, the cross products, the lagged error squares, and/or the ARCH effect also present significant explanatory power for predicting short-term Euro-Currency rate changes, confirming the non-linear specifications. © 1999 Kluwer Academic Publishers,. © 2018 Elsevier B.V., All rights reserved.","Chiang, T.C.; Jeanette Chiang, J.I.N.",1999,10.1023/a:1008302525246,https://www.scopus.com/inward/record.uri?eid=2-s2.0-53149100134&doi=10.1023%2FA%3A1008302525246&partnerID=40&md5=7fbdb4800e1097cff8e0bd382f9120ca,scopus
84a97f8c3afab555,On the role of liquidity in emerging markets stock prices,"This paper investigates the impact of liquidity on emerging markets' stock prices. Particular attention is given to the estimation of Jensen's alpha and the quantity of risk. Our empirical analysis gives rise to two main issues. The first is related to the presence of an extra premium, i.e. ""alpha puzzle"". The second is the time-varying component of the quantity of risk, i.e. ""beta puzzle"". We find that local liquidity factors do not explain the presence of positive and statistically significant alphas. This puzzle is solved by means of transaction costs. In addition, we show that global liquidity factors, such as VIX and Open Interest, statistically affect the market price of risk. Our empirical finding proves the time varying nature of the global risk factors. Finally, we argue that standard asset pricing models cannot solve the two puzzles simultaneously. © 2012 University of Venice. © 2012 Elsevier B.V., All rights reserved.","Donadelli, M.; Prosperi, L.",2012,10.1016/j.rie.2012.06.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867668206&doi=10.1016%2Fj.rie.2012.06.001&partnerID=40&md5=c2b54628c2c2ef4bebe943d2271295e9,scopus
23e04bea77ea6c28,On the significance testing of fuzzy regression applied to the CAPM: Canadian commodity futures evidence,"This paper is written with two congruent objectives. The first is to develop a framework for individual tests of significance of a fuzzy regression model by employing a simple probabilistic estimation procedure. The proposed test, based on two-phase fuzzy regression estimates, is simple and robust. The capital asset pricing model (CAPM), with induction of price limits, serves as the essential component of our analysis, due to its ability to illuminate and determine the risk premiums in a commodity futures market. The second objective is to estimate and test for the significance of the systematic risk of Canadian commodity futures and to illustrate the benefits of the significancetesting approach. Copyright © 2013 Inderscience Enterprises Ltd. © 2020 Elsevier B.V., All rights reserved.","Smimou, K.",2013,10.1504/ijams.2013.053710,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877272226&doi=10.1504%2FIJAMS.2013.053710&partnerID=40&md5=b1910293cf57fa1c92dc80288a597b51,scopus
8c483dd1af8aab26,On the specification of the drift and diffusion functions for continuous-time models of the spot interest rate,This paper explores the specification of drift and diffusion functions for continuous-time short-term interest rate models. Various forms for the drift and diffusion of 7-day Eurodollar rates are proposed and then estimated by discrete maximum-likelihood. The results suggest that a nonparametric specification of drift and volatility in terms of orthogonal polynomial expansions is effective in eliminating problems of parameter identification encountered previously. Some evidence is found to support the claim that the drift of the short term interest rate is nonlinear.,"Hurn, AS; Lindsay, KA",2002,10.1111/1468-0084.00277,None,wos
e4db19deb8251edb,On the time-varying relation between monetary policy uncertainty and bond risk premia,"This paper examines the time-varying relationship between monetary policy uncertainty (MPU) and bond excess returns. To do so, we introduce a nonparametric time-varying coefficient predictive regression model for bond returns, and employ a kernel-based two-step method to estimate the time-varying coefficients. Next, we apply the methodologies to analyze the dynamic forecasting relationship between zero-coupon bond returns and MPU from 1985 to 2022. We find that MPU significantly and positively predicts bond returns in over 75% of the sample period, with the strongest effect observed in 2005. Thus, the expectations hypothesis is only transiently valid. After controlling for the shape of the yield curve, MPU still retains its ability to predict bond returns in 50% to 80% of the sample period. Our conclusions are robust to the so-called embedded endogeneity. Additionally, we find that bond excess returns are less responsive to MPU during periods of high economic activities and are more responsive during periods of low economic activities.","Li, Luyang; Yin, Ximing; Yu, Deshui",2025,10.1016/j.irfa.2025.104465,None,wos
fe0b869162d09c8f,One idea of portfolio risk control for absolute return strategy risk adjustments by signals from correlation behavior,"Absolute return strategy provided from fund of funds (FOFs) investment schemes is the focus in Japanese Financial Community. FOFs investment mainly consists of hedge fund investment and it has two major characteristics which are low correlation against benchmark index and little impact from various external changes in the environment given maximizing return. According to the historical track record of survival hedge funds in this business world, they maintain a stable high return and low risk. However, one must keep in mind that low risk would not be equal to risk free. The failure of Long-term capital management (LTCM) that took place in the summer of 1998 was a symbolized phenomenon. The summer of 1998 exhibited a certain limitation of traditional value at risk (VaR) and some possibility that traditional VaR could be ineffectual to the nonlinear type of fluctuation in the market. In this paper, I try to bring self-organized criticality (SOC) into portfolio risk control. SOC would be well known as a model of decay in the natural world. I analyzed nonlinear type of fluctuation in the market as SOC and applied SOC to capture complicated market movement using threshold point of SOC and risk adjustments by scenario correlation as implicit signals. Threshold becomes the control parameter of risk exposure to set downside floor and forecast extreme nonlinear type of fluctuation under a certain probability. Simulation results would show synergy effect of portfolio risk control between SOC and absolute return strategy. © 2001 Elsevier Science B.V. All rights reserved. © 2004 Elsevier Science B.V., Amsterdam. All rights reserved.","Nishiyama, N.",2001,10.1016/s0378-4371(01)00411-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035576026&doi=10.1016%2FS0378-4371%2801%2900411-3&partnerID=40&md5=d03382ca37a1fbaacc14f9cfe5da4686,scopus
ddc4b136e932c688,Online Investor Sentiment via Machine Learning,"In this paper, we propose utilizing machine learning methods to determine the expected aggregated stock market risk premium based on online investor sentiment and employing the multifold forward-validation method to select the relevant hyperparameters. Our empirical studies provide strong evidence that some machine learning methods, such as extreme gradient boosting or random forest, show significant predictive ability in terms of their out-of-sample performances with high-dimensional investor sentiment proxies. They also outperform the traditional linear models, which shows a possible unobserved nonlinear relationship between online investor sentiment and risk premium. Moreover, this predictability based on online investor sentiment has a better economic value, so it improves portfolio performance for investors who need to decide the optimal asset allocation in terms of the certainty equivalent return gain and the Sharpe ratio.","Cai, Zongwu; Chen, Pixiong; Chen, Pixiong",2024,10.3390/math12203192,None,proquest
c9bb2437e26f8d84,Optimal Filtering of Jump Diffusions: Extracting Latent States from Asset Prices,"This paper provides an optimal filtering methodology in discretely observed continuous-time jump-diffusion models. Although the filtering problem has received little attention, it is useful for estimating latent states, forecasting volatility and returns, computing model diagnostics such as likelihood ratios, and parameter estimation. Our approach combines time-discretization schemes with Monte Carlo methods. It is quite general, applying in nonlinear and multivariate jump-diffusion models and models with nonanalytic observation equations. We provide a detailed analysis of the filter's performance, and analyze four applications: disentangling jumps from stochastic volatility, forecasting volatility, comparing models via likelihood ratios, and filtering using option prices and returns. (JEL C11, C13, C15, C51, C52, G11, G12, G17)","Johannes, Michael S.; Polson, Nicholas G.; Stroud, Jonathan R.",2009,10.1093/rfs/hhn110,None,wos
429dc98f1a74b78f,Optimal Time Varying Parameters in Yield Curve Modeling and Forecasting: A Simulation Study on BRICS Countries,"The term structure of interest rates is a fundamental decision-making tool for various economic activities. Despite the huge number of contributions in the field, the development of a reliable framework for both fitting and forecasting under various market conditions (either stable or very volatile) still remains a topical issue. Motivated by this problem, this study introduces a methodology relying on optimal time-varying parameters for three and five factor models in the Nelson-Siegel class that can be employed for an effective in-sample fitting and out-of-sample forecasting of the term structure. In detail, for the in-sample fitting we discussed a two-step estimation procedure leading to optimal models parameters and evaluated the performances of this approach in terms of flexibility and fitting accuracy gains. For what it concerns the forecasting, we suggest an approach overcoming the well-known issue between the stability of factor models' parameters and the optimal dynamic decay terms. To such aim, we use either autoregressive or machine learning techniques as local data generating processes based on the optimal parameters time series derived in the in-line fitting step. The so-obtained values are then employed to get day-ahead predictions of the yield curve. We assessed the proposed framework on daily spot rates of the BRICS (Brazil, Russia, India, China and South Africa) bond market. The experimental analysis illustrated that (i) time-varying parameters ensure a significant boost in the models fitting power and a more faithful representation of the yield curves dynamics; (ii) the proposed approach provides also stable and accurate predictions.","Castello, Oleksandr; Resta, Marina",2025,10.1007/s10614-024-10619-z,None,wos
61ddf22073d6a62b,Optimal asset allocation and nonlinear return predictability from the dividend-price ratio,"We study non-linear predictability of stock returns arising from the dividend-price ratio and its implications for asset allocation decisions. Using data from five countries — U.S., U.K., France, Germany and Japan — we find empirical evidence supporting non-linear and time-varying models for the equity risk premium. Building on this, we examine several model specifications that can account for non-linear return predictability, including Markov switching models, regression trees, random forests and neural networks. Although in-sample return regressions and portfolio allocation results support the use of non-linear predictability models, the out-of-sample evidence is notably weaker, highlighting the difficulty in exploiting non-linear predictability in real time. © 2025 Elsevier B.V., All rights reserved.","Ghezzi, F.; Sarkar, A.; Pedersen, T.Q.; Timmermann, A.",2025,10.1007/s10479-024-06332-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001086702&doi=10.1007%2Fs10479-024-06332-7&partnerID=40&md5=dd0ef7ddf17b2e69e5c4a37d7cf1969f,scopus
81128145148cb45a,Optimal credit allocation under regime uncertainty with sensitivity analysis,"We consider the problem of credit allocation in a regime-switching model. The global evolution of the credit market is driven by a benchmark, the drift of which is given by a two-state continuous-time hidden Markov chain. We apply filtering techniques to obtain the diffusion of the credit assets under partial observation and show that they have a specific excess return with respect to the benchmark. The investor performs a simple mean-variance allocation on credit assets. However, returns and variance matrix have to be computed by a numerical method such as Monte Carlo, because of the dynamics of the system and the non-linearity of the asset prices. We use the theory of Dirichlet forms to deal with the uncertainty on the excess returns. This approach provides an estimation of the bias and the variance of the optimal allocation, and return. We propose an application in the case of a sectorial allocation with Credit Default Swaps (CDS), fully calibrated with observable data or direct input given by the portfolio manager. Reprinted by permission of World Scientific Publishing","Bernis, Guillaume; Carassus, Laurence; Docq, Grégoire; Scotti, Simone",2015,10.1142/s0219024915500028,None,proquest
b7733e59a767a900,Optimal hedging of commodity price risks in highway contracts,"Macroeconomic conditions, such as commodity prices, labor wages, and inflation rates, affect the cost of construction projects. In a volatile market environment, highway agencies often pass such risks to contractors by using fixed-price contracts. In turn, contractors respond by adding premiums in bid prices. How much of this risk highway agencies should pass to contractors is the topic of this paper. More specifically, the objective of this paper is to develop a model that can help highway agencies manage cost risks associated with commodity prices. The weighted least squares regression model is used to estimate the risk premium; the solution to a multiobjective optimization formulation considers a genetic algorithm approach to nonconvex optimization. Crude oil prices are used as an example of volatile commodities. The results of this study suggest that the optimal risk mitigation actions are conditional on owners' risk preferences. © 2023 Elsevier B.V., All rights reserved.","Zhou, X.; Damnjanović, I.D.",2011,10.3141/2228-03,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80155159114&doi=10.3141%2F2228-03&partnerID=40&md5=2c006c7e567e45da4d1cba2011fb7b10,scopus
70d6446af9a229d8,Optimal profit-making strategies in stock market with algorithmic trading,"Machine learning (ML) techniques are being increasingly applied to financial markets for analyzing trends and predicting stock prices. In this study, we compared the price prediction and profit-making performance of various ML algorithms embedded into stock trading strategies. The dataset comprised daily data from the CSI 300 Index of the China stock market spanning approximately 17 years (2006-2023). We incorporated investor sentiment indicators and relevant financial elements as features. Our trained models included support vector machines (SVMs), logistic regression, and random forest. The results show that the SVM model outperforms the others, achieving an impressive 60.52% excess return in backtesting. Furthermore, our research compared standard prediction models (such as LASSO and LSTM) with the proposed approach, providing valuable insights for users selecting ML algorithms in quantitative trading strategies. Ultimately, this work serves as a foundation for informed algorithm choice in future financial applications. © 2024 Elsevier B.V., All rights reserved.","Wang, H.; Xie, D.",2024,10.3934/qfe.2024021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205123614&doi=10.3934%2FQFE.2024021&partnerID=40&md5=02b39feb6c9d88a93900c795feb2dade,scopus
3fb4d3ed2d71f0ec,Optimal supplier testing and tolerance strategies for genetically modified (GM) wheat,"AbstractA stochastic optimization model was developed to determine optimal testing strategies, costs, and risks for dual marketing of genetically modified (GM) and non-GM wheat in an export supply chain. The optimal testing strategy is derived that minimizes disutility of additional system costs due to testing and quality loss. Cost components were estimated including those related to testing, quality loss, and a risk premium to induce shippers to undertake dual marketing as opposed to handling only non-GM crops. Uncertainties were incorporated for adventitious presence and commingling, variety declaration, and test accuracy. Sensitivities were performed for effects of variety risks and declaration, penalty differentials, buyer tolerances, risk aversion, and GM adoption. Results indicate testing and segregation can be performed at a relatively low cost and risk to buyers.","Wilson, William W; Dahl, Bruce L; Jabs, Eric",2007,10.1111/j.1574-0862.2007.00175.x,None,proquest
06584a65bc1a10e7,Optimizing filter rule parameters with genetic algorithm and stock selection with artificial neural networks for an improved trading: The case of Borsa Istanbul,"Filter rule along with other trading algorithms is used to identify potentially profitable trading points in stock markets. In this study, the scope of the filter rule has been expanded to include different moving average types. The filter rule parameters that will provide the highest return for each of the stocks listed in Borsa Istanbul have been optimized by using genetic algorithm. A number of 357 stocks traded in Borsa Istanbul is included in the dataset of the study between 06-07-2012 and 31-03-2020 period. To improve the poor performance in out-of-sample sets of optimal rules, the stock selection process was performed by means of artificial neural networks. The artificial neural network model predicts the performance of the stock in the test set by using the performance values in the training set. Results indicate that the returns of the selected stocks are significantly higher than the returns of the buy and hold strategy. Parameter optimization of filter rule with genetic algorithms and stock selection with the artificial neural networks can be used as a decision support system for investors, where they can make a profit above the market return. When only the genetic algorithm results are taken into account, it can be stated that Borsa Istanbul is a weak form efficient market. However, selecting the stocks with the assistance of artificial neural networks made it possible to obtain excess returns over the market. © 2022 Elsevier B.V., All rights reserved.","Özçalıcı, M.; Bumin, M.",2022,10.1016/j.eswa.2022.118120,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134630841&doi=10.1016%2Fj.eswa.2022.118120&partnerID=40&md5=4ccc46612a7b221c336ef63c952ea36c,scopus
4c6402a19fd533ec,Option Pricing Under a Stochastic Interest Rate and Volatility Model with Hidden Markovian Regime-Switching,"In this paper we discuss an option pricing problem in a hidden Markovian regime-switching model with a stochastic interest rate and volatility. Regime switches are attributed to structural changes in an hidden economic environment and are described by a continuous-time, finite-state, unobservable Markov chain. The model is then applied to the valuation of a standard European option. By means of the standard separation principle, filtering and option valuation problems are separated. Robust filters for the hidden states of the economy and their robust filtered estimates of unknown parameters from the expectation maximization algorithm are presented based on standard techniques in filtering theory. Then an explicit expression of a conditional characteristic function relevant to option pricing is presented and the valuation of the option is discussed using the inverse Fourier transformation approach. Using the limiting behavior of the conditional characteristic function, an efficient implementation of the transform inversion integral is considered. Numerical experiments are given to illustrate the flexibility of filtering algorithms and the significance of regime-switching in option pricing.","Zhu, Dong-Mei; Lu, Jiejun; Ching, Wai-Ki; Siu, Tak-Kuen",2019,10.1007/s10614-017-9754-9,None,wos
106e9eb0ed46aba0,Option Pricing With Modular Neural Networks,"This paper investigates a nonparametric modular neural network (MNN) model to price the S&P-500 European call options. The modules are based on time to maturity and moneyness of the options. The option price function of interest is homogeneous of degree one with respect to the underlying index price and the strike price. When compared to an array of parametric and nonparametric models, the MNN method consistently exerts superior out-of-sample pricing performance. We conclude that modularity improves the generalization properties of standard feedforward neural network option pricing models (with and without the homogeneity hint).",N. Gradojevic; R. Gencay; D. Kukolj,2009,10.1109/tnn.2008.2011130,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4798200,ieeexplore
fa78322f5e748063,Option price sensitivities through fuzzy numbers,"The main motivation in using fuzzy numbers in finance lies in the need for modelling the uncertainty and vagueness that are implicit in many situations. However, the fuzzy approach should not be considered as a substitute for the probabilistic approach but rather as a complementary way to describe the model peculiarities. Here, we consider, in particular, the Black and Scholes model for option pricing, and we show that the fuzzification of some key parameters enables a sensitivity analysis of the option price with respect to the risk-free interest rate, the final value of the underlying stock price, the volatility, and also better forecasts (see Thavaneswaran etaaal. (2009) for details). The sensitivities with respect to the variables of the model are represented by different letters of the Greek alphabet and they play an important role in the definition of the shape of the fuzzy option price.","Letizia Guerra, Maria; Sorini, Laerte; Stefanini, Luciano",2011,10.1016/j.camwa.2010.11.024,None,proquest
8cbff7cf8ed64b21,Option-Based Estimation of the Price of Coskewness and Cokurtosis Risk,"We show that the prices of risk for factors that are nonlinear in the market return can be obtained using index option prices. The price of coskewness risk corresponds to the market variance risk premium, and the price of cokurtosis risk corresponds to the market skewness risk premium. Option-based estimates of the prices of risk lead to reasonable values of the associated risk premia. An analysis of factor models with coskewness risk indicates that the new estimates of the price of risk improve the models' performance compared with regression-based estimates.","Fournier, Mathieu; Jacobs, Kris; Karoui, Mehdi; Christoffersen, Peter",2021,10.1017/s002210902000023x,None,proquest
624b406f55b3ee95,Option-implied correlation between iTraxx Europe Financials and Non-Financials Indexes: A measure of spillover effect in European debt crisis,"This paper proposes an analytic method to estimate the option-implied correlation embedded in options on the iTraxx Europe CDS indexes. The option-implied correlation is suggested as a measure of the spill-over effect of default risk between the financial and corporate sectors in Europe. In particular, the correlation between the iTraxx Financials and Non-Financials sub-indexes is estimated from options on the iTraxx Main Index, which is considered as a basket option with the two sub-indexes being its underlyings. The abrupt changes of the realized correlation anticipated information of the corresponding option prices. The sovereign default risk, funding liquidity risk, level of risk aversion, and equity market performance are identified to be significant determinants of the option-implied correlation, implying interdependence amongst various markets during the European debt crisis. (C) 2013 Elsevier B.V. All rights reserved.","Hui, Cho-Hoi; Lo, Chi-Fai; Lau, Chun-Sing",2013,10.1016/j.jbankfin.2013.05.030,None,wos
a6849cec0ad130d5,"Option-implied preferences adjustments, density forecasts, and the equity risk premium","The main objective of this paper is to analyse the value of information contained in prices of options on the IBEX 35 index at the Spanish Stock Exchange Market. The forward looking information is extracted using implied risk-neutral density functions estimated by a mixture of two-lognormals and several alternative risk adjustments. Our results show that, between October 1996 and March 2000, we can reject the hypothesis that the risk-neutral densities provide accurate predictions of the distributions of future realisations of the IBEX 35 index at 4- and 8-week horizons. When forecasting through risk-adjusted densities the performance of this period is statistically improved and we no longer reject that hypothesis. We show that risk adjustments based on a power specification for the stochastic discount factor-which is the approach used so far in the literature that derives the objective density function from option prices- generates an excessive volatility of risk premia. We use alternative risk adjustments and find that the forecasting performance of the distribution improves slightly in some cases when risk aversion is allowed to be time-varying. Finally, from October 1996 to December 2004, the ex-ante risk premium perceived by investors and that are embedded in option prices is between 12 and 18% higher than the premium required to compensate the same investors for the realised volatility in stock market returns.","Alonso, Francisco; Blanco, Roberto; Rubio, Gonzalo",2009,10.1007/s10108-008-9049-3,None,wos
4f8ea2176a7d1090,Option-implied skewness: Insights from ITM-options,"While the standard to calculate model-free option-implied skewness (MFIS) relies on out-of-the-money (OTM) options, we examine the empirical and economic implications of using in-the-money (ITM) options. We find that the positive short-term return predictability of OTM-based MFIS significantly reverses if ITM-options are used instead. While this reversal is inconsistent with an explanation based on skewness preferences, MFIS apparently reflects information that is not timely incorporated in stock prices due to market frictions. Based on these insights, we introduce Delta MFIS as a new measure of additional option-embedded information that significantly predicts subsequent returns beyond a large range of other option-based return predictors. (C) 2021 Elsevier B.V. All rights reserved.","Mohrschladt, Hannes; Schneider, Judith C.",2021,10.1016/j.jedc.2021.104227,None,wos
b3a10d9772e08e18,"Oracle Properties, Bias Correction, and Bootstrap Inference for Adaptive Lasso for Time Series M-Estimators","We derive new theoretical results on the properties of the adaptive least absolute shrinkage and selection operator (adaptive lasso) for possibly nonlinear time series models. In particular, we investigate the question of how to conduct inference on the parameters given an adaptive lasso model. Central to this study is the test of the hypothesis that a given adaptive lasso parameter equals zero, which therefore tests for a false positive. To this end, we introduce a recentered bootstrap procedure and show, theoretically and empirically through extensive Monte Carlo simulations, that the adaptive lasso can combine efficient parameter estimation, variable selection, and inference in one step. Moreover, we analytically derive a bias correction factor that is able to significantly improve the empirical coverage of the test on the active variables. Finally, we apply the adaptive lasso and the recentered bootstrap procedure to investigate the relation between the short rate dynamics and the economy, thereby providing a statistical foundation (from a model choice perspective) for the classic Taylor rule monetary policy model.","Audrino, Francesco; Camponovo, Lorenzo",2018,10.1111/jtsa.12270,None,wos
1f01b1f36c35911a,Out-of-Sample Predictability of the Equity Risk Premium,"A large set of macroeconomic variables have been suggested as equity risk premium predictors in the literature. Acknowledging the different predictability of the equity premium in expansions and recessions, this paper proposes an approach that combines equity premium forecasts from two-state regression models using an agreement technical indicator as the observable state variable. A comprehensive out-of-sample forecast evaluation exercise based on statistical and economic loss functions demonstrates the superiority of the proposed approach versus combined forecasts from linear models or Markov switching models and forecasts from machine learning methods such as random forests and gradient boosting. The parsimonious state-dependent aspect of risk premium forecasts delivers large improvements in forecast accuracy. The results are robust to sub-period analyses and different investors’ risk aversion levels.","de Almeida, Daniel; de Almeida, Daniel; Ana-Maria Fuertes; Ana-Maria Fuertes; Hotta, Luiz Koodi; Hotta, Luiz Koodi; Hotta, Luiz Koodi",2025,10.3390/math13020257,None,proquest
b9e208171342ca97,Out-of-sample forecasts and nonlinear model selection with an example of the term structure of interest rates,"It is well known that goodness-of-fit measures lead to overfilling. We compare the small-sample properties of linear and several nonlinear models using a Monte Carlo study. A large number of linear series are generated and conventional methods of fitting nonlinear models are applied to each. The best linear and nonlinear models are compared using in-sample and out-of-sample criteria. Out-of-sample forecasts are shown to be superior for selecting the proper specification. The experiment is repeated using a nonlinear model and the in-sample fit and forecasts of the various models are compared. An example is provided using the term structure of interest rates. © 2018 Elsevier B.V., All rights reserved.","Liu, Y.; Enders, W.",2003,10.2307/1061692,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037280360&doi=10.2307%2F1061692&partnerID=40&md5=d77d1d9208071e7118c7356f32f054cf,scopus
f2eb271685e466d0,PARAMETRIC SPECIFICATION TEST FOR NONLINEAR AUTOREGRESSIVE MODELS,"The paper considers testing parametric assumptions on the conditional mean and variance functions for nonlinear autoregressive models. To this end, we compare the kernel density estimate of the marginal density of the process with a convolution-type density estimate. It is shown that, interestingly, the latter estimate has a parametric (root n) rate of convergence, thus substantially improving the classical kernel density estimates whose rates of convergence are much inferior. Our results are confirmed by a simulation study for threshold autoregressive processes and autoregressive conditional heteroskedastic processes.","Kim, Kun Ho; Zhang, Ting; Wu, Wei Biao",2015,10.1017/s0266466614000681,None,wos
9e28d710498e479b,PHANGS-JWST First Results: Dust-embedded Star Clusters in NGC 7496 Selected via 3.3 μm PAH Emission,"The earliest stages of star formation occur enshrouded in dust and are not observable in the optical. Here we leverage the extraordinary new high-resolution infrared imaging from JWST to begin the study of dust-embedded star clusters in nearby galaxies throughout the Local Volume. We present a technique for identifying dust-embedded clusters in NGC 7496 (18.7 Mpc), the first galaxy to be observed by the PHANGS-JWST Cycle 1 Treasury Survey. We select sources that have strong 3.3 mu m PAH emission based on a F300M - F335M color excess and identify 67 candidate embedded clusters. Only eight of these are found in the PHANGS-HST optically selected cluster catalog, and all are young (six have SED fit ages of similar to 1 Myr). We find that this sample of embedded cluster candidates may significantly increase the census of young clusters in NGC 7496 from the PHANGS-HST catalog; the number of clusters younger than similar to 2 Myr could be increased by a factor of 2. Candidates are preferentially located in dust lanes and are coincident with the peaks in the PHANGS-ALMA CO (2-1) maps. We take a first look at concentration indices, luminosity functions, SEDs spanning from 2700 angstrom to 21 mu m, and stellar masses (estimated to be between similar to 10(4) and 10(5) M (circle dot)). The methods tested here provide a basis for future work to derive accurate constraints on the physical properties of embedded clusters, characterize the completeness of cluster samples, and expand analysis to all 19 galaxies in the PHANGS-JWST sample, which will enable basic unsolved problems in star formation and cluster evolution to be addressed.","Rodriguez, M. Jimena; Lee, Janice C.; Whitmore, B. C.; Thilker, David A.; Maschmann, Daniel; Chandar, Rupali; Deger, Sinan; Boquien, Mederic; Dale, Daniel A.; Larson, Kirsten L.; Williams, Thomas G.; Kim, Hwihyun; Schinnerer, Eva; Rosolowsky, Erik; Leroy, Adam K.; Emsellem, Eric; Sandstrom, Karin M.; Kruijssen, J. M. Diederik; Grasha, Kathryn; Watkins, Elizabeth J.; Barnes, Ashley. T.; Sormani, Mattia C.; Kim, Jaeyeon; Anand, Gagandeep S.; Chevance, Melanie; Bigiel, F.; Klessen, Ralf S.; Hassani, Hamid; Liu, Daizhong; Faesi, Christopher M.; Cao, Yixian; Belfiore, Francesco; Pessa, Ismael; Kreckel, Kathryn; Groves, Brent; Pety, Jerome; Indebetouw, Remy; Egorov, Oleg V.; Blanc, Guillermo A.; Saito, Toshiki; Hughes, Annie",2023,10.3847/2041-8213/aca653,None,wos
d501874745d997c5,PMCMC for Term Structure of Interest Rates under Markov Regime Switching and Jumps,"A parameter estimation method, called PMCMC in this paper, is proposed to estimate a continuous-time model of the term structure of interests under Markov regime switching and jumps. There is a closed form solution to term structure of interest rates under Markov regime. However, the model is extended to be a CKLS model with non-closed form solutions which is a typical nonlinear and non-Gaussian state-space model(SSM) in the case of adding jumps. Although the difficulty of parameter estimation greatly prevents from researching models, we prove that the nonlinear and non-Gaussian state-space model has better performances in studying volatility. The method proposed in this paper will be implemented in simulation and empirical study for SHIBOR. Empirical results illustrate that the PMCMC algorithm has powerful advantages in tackling the models. © 2023 Elsevier B.V., All rights reserved.","Liu, X.; Li, X.; Zheng, S.; Qian, H.",2020,10.21078/jssi-2020-159-11,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151287143&doi=10.21078%2FJSSI-2020-159-11&partnerID=40&md5=c49a814702a6f8c4d212641b9b08fbb4,scopus
80d155e7f0df34e2,PREDICTING STOCK RETURNS AND VOLATILITY WITH INVESTOR SENTIMENT INDICES: A RECONSIDERATION USING A NONPARAMETRIC CAUSALITY-IN-QUANTILES TEST,"Evidence of monthly stock returns predictability based on popular investor sentiment indices, namely SBW and SPLS as introduced by Baker and Wurgler (2006, 2007) and Huang et al. (2015) respectively are mixed. While, linear predictive models show that only SPLS can predict excess stock returns, nonparametric models (which accounts for misspecification of the linear frameworks due to nonlinearity and regime changes) finds no evidence of predictability based on either of these two indices for not only stock returns, but also its volatility. However, in this paper, we show that when we use a more general nonparametric causality-in-quantiles model of Balcilar et al., (forthcoming), in fact, both SBW and SPLS can predict stock returns and its volatility, with SPLS being a relatively stronger predictor of excess returns during bear and bull regimes, and SBW being a relatively powerful predictor of volatility of excess stock returns, barring the median of the conditional distribution. © 2018 Elsevier B.V., All rights reserved.","Balcilar, M.; Gupta, R.; Kyei, C.",2018,10.1111/boer.12119,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018969715&doi=10.1111%2Fboer.12119&partnerID=40&md5=ad35656b372c4c8565d3b24a65a4d8f0,scopus
93fd092bafa0fe9d,PROPERTY AND NUMERICAL SIMULATION OF THE AIT-SAHALIA-RHO MODEL WITH NONLINEAR GROWTH CONDITIONS,"The Ait-Sahalia-Rho model is an important tool to study a number of financial problems, including the term structure of interest rate. However, since the functions of this model do not satisfy the linear growth condition, we cannot study the properties for the solution of this model by using the traditional techniques. In this paper we overcome the mathematical difficulties due to the nonlinear growth condition by using numerical simulation. Thus we first discuss analytical properties of the model and the convergence property of numerical solutions in probability for the Ait-Sahalia-Rho model. Finally, an example for option pricing is given to illustrate that the numerical solution is an effective method to estimate the expected payoffs.","Jiang, Feng; Yang, Hua; Tian, Tianhai",2017,10.3934/dcdsb.2017005,None,wos
85ea7436fd04653c,Package CovRegpy: Regularized covariance regression and forecasting in Python,"This paper will outline the functionality available in the CovRegpy package which was written for actuarial practitioners, wealth managers, fund managers, and portfolio analysts in the language of Python 3.11. The objective is to develop a new class of covariance regression factor models for covariance forecasting, along with a library of portfolio allocation tools that integrate with this new covariance forecasting framework. The novelty is in two stages: the type of covariance regression model and factor extractions used to construct the covariates used in the covariance regression, along with a powerful portfolio allocation framework for dynamic multi-period asset investment management. The major contributions of package CovRegpy can be found on the GitHub repository for this library in the scripts: CovRegpy.py, CovRegpy_DCC.py, CovRegpy_RPP.py, CovRegpy_SSA.py, CovRegpy_SSD.py, and CovRegpy_X11.py. These six scripts contain implementations of software features including multivariate covariance time series models based on the regularized covariance regression (RCR) framework, dynamic conditional correlation (DCC) framework, risk premia parity (RPP) weighting functions, singular spectrum analysis (SSA), singular spectrum decomposition (SSD), and X11 decomposition framework, respectively. These techniques can be used sequentially or independently with other techniques to extract implicit factors to use them as covariates in the RCR framework to forecast covariance and correlation structures and finally apply portfolio weighting strategies based on the portfolio risk measures based on forecasted covariance assumptions. Explicit financial factors can be used in the covariance regression framework, implicit factors can be used in the traditional explicit market factor setting, and RPP techniques with long/short equity weighting strategies can be used in traditional covariance assumption frameworks. We examine, herein, two real-world case studies for actuarial practitioners. The first of these is a modification (demonstrating the regularization of covariance regression) of the original example from Hoff & Niu ((2012). Statistica Sinica, 22(2), 729-753) which modeled the covariance and correlative relationship that exists between forced expiratory volume (FEV) and age and FEV and height. We examine this within the context of making probabilistic predictions about mortality rates in patients with chronic obstructive pulmonary disease. The second case study is a more complete example using this package wherein we present a funded and unfunded UK pension example. The decomposition algorithm isolates high-, mid-, and low-frequency structures from FTSE 100 constituents over 20 years. These are used to forecast the forthcoming quarter’s covariance structure to weight the portfolio based on the RPP strategy. These fully funded pensions are compared against the performance of a fully unfunded pension using the FTSE 100 index performance as a proxy. © 2024 Elsevier B.V., All rights reserved.","van Jaarsveldt, C.; Peters, G.; Ames, M.; Chantler, M.",2024,10.1017/s1748499524000101,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193064038&doi=10.1017%2FS1748499524000101&partnerID=40&md5=44609d79e4c0defef3678b5fb8df5c39,scopus
9a9d7a03be6464dd,Pairs selection and outranking: An application to the S&P 100 index,Pairs trading is a popular quantitative speculation strategy. This article proposes a general and flexible framework for pairs selection. The method uses multiple return forecasts based on bivariate information sets and multi-criteria decision techniques. Our approach can be seen as a sort of forecast combination but the output of the method is a ranking. It helps to detect potentially under- and overvalued stocks. A first application with S&P 100 index stocks provides promising results in terms of excess return and directional forecasting. (C) 2008 Elsevier B.V. All rights reserved.,"Huck, Nicolas",2009,10.1016/j.ejor.2008.03.025,None,wos
f6f95c3a073ff11d,Parameter Estimations of Heston Model Based on Consistent Extended Kalman Filter,"Heston model is widely applied to financial institutions, while there still exist difficulties in estimating the parameters and volatilities of this model. In this paper, the pseudo Maximum Likelihood Estimation and consistent extended Kalman filter (PMLE-CEKF) are implemented synchronously to estimate the Heston model. For parameter estimations, PMLE for the state equation and the measurement equation of the Heston model are conducted independently. For volatility estimations, the consistent extended Kalman filter (CEKF) algorithm is introduced to ensure the volatility to be well evaluated. Additionally, the estimation results of the Heston model are compared between PMLE-CEKF and PMLE-EKF algorithm. The numerical simulations illustrate that PMLE-CEKF algorithm works more efficiently than PMLE-EKF algorithm. Application of the PMLE-CEKF to S&P 500 shows the utility of the proposed algorithm. (C) 2017, IFAC (International Federation of Automatic Control) Hosting by Elsevier Ltd. All rights reserved.","Wang, Ximei; He, Xingkang; Zhao, Yanlong; Zuo, Zhiqiang",2017,10.1016/j.ifacol.2017.08.1850,None,wos
f7928e8fe95d86ae,"Particle filtering, learning, and smoothing for mixed-frequency state-space models","A particle filter approach for general mixed-frequency state-space models is considered. It employs a backward smoother to filter high-frequency state variables from low-frequency observations. Moreover, it preserves the sequential nature of particle filters, allows for non-Gaussian shocks and nonlinear state-measurement relation, and alleviates the concern over sample degeneracy. Simulation studies show that it outperforms the commonly used state-augmented approach for mixed-frequency data for filtering and smoothing. In an empirical exercise, predictive mixed-frequency regressions are employed for Treasury bond and US dollar index returns with quarterly predictors and monthly stochastic volatility. Stochastic volatility improves model inference and forecasting power in a mixed-frequency setup but not for quarterly aggregate models. © 2019 Elsevier B.V., All rights reserved.","Leippold, M.; Yang, H.",2019,10.1016/j.ecosta.2019.07.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070197669&doi=10.1016%2Fj.ecosta.2019.07.001&partnerID=40&md5=4f3f599d8db72b3c54cacc8133757f86,scopus
7b3f1098ac1d9f11,Penalized Averaging of Parametric and Non-Parametric Quantile Forecasts,"We propose a hybrid penalized averaging for combining parametric and non-parametric quantile forecasts when faced with a large number of predictors. This approach goes beyond the usual practice of combining conditional mean forecasts from parametric time series models with only a few predictors. The hybrid methodology adopts the adaptive LASSO regularization to simultaneously reduce predictor dimension and obtain quantile forecasts. Several recent empirical studies have considered a large set of macroeconomic predictors and technical indicators with the goal of forecasting the S&P 500 equity risk premium. To illustrate the merit of the proposed approach, we extend the mean-based equity premium forecasting into the conditional quantile context. The application offers three main findings. First, combining parametric and non-parametric approaches adds quantile forecast accuracy over and above the constituent methods. Second, a handful of macroeconomic predictors are found to have systematic forecasting power. Third, different predictors are identified as important when considering lower, central and upper quantiles of the equity premium distribution. © 2020 Elsevier B.V., All rights reserved.","De Gooijer, J.G.; Zerom, D.",2020,10.1515/jtse-2019-0021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077739820&doi=10.1515%2Fjtse-2019-0021&partnerID=40&md5=55add6393cbc0da4186bc41ac893f6c4,scopus
008bfdd1c354cda8,Permutation betting markets: Singleton betting with extra information,"We study permutation betting markets, introduced by Chen et al. (Proceedings of the ACM Conference on Electronic Commerce, 2007). For these markets, we consider subset bettings in which each trader can bet on a subset of candidates ending up in a subset of positions. We consider the revenue maximization problem for the auctioneer in two main frameworks: the risk-free revenue maximization (studied in Chen et al., Proceedings of the ACM Conference on Electronic Commerce, 2007), and the probabilistic revenue maximization. We also explore the use of some certain knowledge or extra information about the possible outcomes of the market. We first show that finding the optimal revenue in the risk-free model for the subset betting problem is inapproximable. This resolves an open question posed by Chen et al. (Proceedings of the ACM Conference on Electronic Commerce, 2007). In order to identify solvable variants of the problem, we propose the singleton betting language which allows traders to bet an arbitrary value on one candidate for one position. For singleton bettings, we first provide a linear-time implementable necessary and sufficient condition for existence of a solution with positive revenue for any possible outcome. Furthermore, we develop an LP-based polynomial-time algorithm to find the optimum solution of this problem. In addition, we show how to extend this LP-based method to handle some extra information about the possible outcomes. Finally, we consider the revenue maximization problem in a probabilistic setting. For this variant, we observe that the problem of maximizing the expected revenue is polynomial-time solvable, but we show that maximizing the probability of achieving a pre-specified revenue is #P-Complete. © 2009 Springer Science+Business Media, LLC. © 2012 Elsevier B.V., All rights reserved.","Ghodsi, M.; Mahini, H.; Mirrokni, V.S.; Zadimoghaddam, M.",2011,10.1007/s00453-009-9378-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959223300&doi=10.1007%2Fs00453-009-9378-0&partnerID=40&md5=50e50d408bf76c116353904d5f36e299,scopus
dde88ce8c7f12863,Physical vs. Transition climate risks: Asymmetric effects on stock return predictability,"This paper examines the predictive role of two dominant climate risk categories-physical and transition risks-in forecasting U.S. equity market risk premiums. The results reveal a pronounced asymmetry: physical climate risk significantly and negatively predicts stock returns both in-sample and out-of-sample, whereas transition climate risk demonstrates insignificant forecasting ability. This superior performance of physical risk delivers greater economic gains to investors and remains robust even after controlling for widely used economic predictors. However, its predictability is state-dependent, weakening during economic disruptions and strengthening following the COP21 Agreement. Further analysis shows that the cash flow and sentiment channels potentially drive the strong predictability of physical risk. Overall, our findings underscore the importance of incorporating physical climate risk into equity return forecasting models, offering actionable insights for financial decision-making processes.","Zhou, Mingtao; Ma, Yong",2025,10.1016/j.irfa.2025.104266,None,wos
ea1a6443c4789db2,Political uncertainty and financial market reactions: A new test,"Recent literature highlights the crucial role of understanding the mechanism between political uncertainty and financial market reactions. Along the lines of this topic, our study stresses a clear causal framework. Exploiting one unique natural experiment of the Taiwan Strait Crisis (1995-96), we provide a simple testing strategy which could precisely quantify the effects of political shocks on stock markets. This approach combines the features of one innovative panel estimator and new statistical learning methods for causal inference. Our results indicate, separating true signal from noise via the optimal benchmark, the political crisis had a substantial and significant negative impact on Taiwan's stock prices. This finding is consistent with the empirical evidence of risk premium in recent studies. Moreover, the optimal counterfactual could be an alternative option for the ceteris paribus assumption in non-lab controlled settings. Finally, this study shows predictor selection is needed for a convincing causal estimate in counterfactual studies. © 2019 Elsevier B.V., All rights reserved.","Wang, H.; Boatwright, A.L.",2019,10.1016/j.inteco.2019.07.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075956787&doi=10.1016%2Fj.inteco.2019.07.004&partnerID=40&md5=7644f7e70f84f5bfd12bd3d90c207b0f,scopus
930290da6c89d1d2,Portfolio Selection and Optimization through Neural Networks and Markowitz Model: A Case of Pakistan Stock Exchange Listed Companies,"This paper used artificial neural networks (ANNs) time series predictor for approximating returns of Pakistan Stock Exchange (PSX) listed 100 companies. These projected returns are then substituted into expected returns in the Markowitz’s Mean Variance (MV) portfolio Model. For comparison empirical data used is closing prices of PSX listed stocks, Karachi Inter Bank Offer Rates (KIBOR) as risk free rate and KSE-all share index as benchmark. The Portfolio returns are compared for two datasets by employing various constraints like budget, transaction costs, and turnover constraints. The value of portfolios is measured through Sharpe ratio and Information ratio. Both Sharpe and Information ratios support use of ANNs as return predictor and optimisation tool over simple MV model implemented for empirical data as well as predicted data. ANNs framework performed better in both Long and Short positions and its portfolio returns are significantly higher as compared with MV.","Iqbal, Javed; Moeed Ahmad Sandhu; Amin, Shaheera; Manzoor, Alia",2019,10.26710/reads.v5i1.354,None,proquest
b6af4763daadded6,Portfolio creation using artificial neural networks and classification probabilities: a Canadian study,"This study aims to verify whether using artificial neural networks (ANNs) to establish classification probabilities generates portfolios with higher excess returns than using ANNs in their traditional role of predicting portfolio returns. Our sample includes all companies listed on the Toronto Stock Exchange from 1994 to 2014 with a monthly average of 16,324 company-month observations. Results indicate that portfolios based on the classification probabilities yield mean returns ranging from 7.81 to 14.40% annually over a 16-year period and that portfolios based on both predicted returns and classification probabilities generate returns that are superior to the market index. In addition, there is evidence that ranking securities based on their probability of beating the market has some benefit. © 2020 Elsevier B.V., All rights reserved.","Morris, T.; Comeau, J.",2020,10.1007/s11408-020-00350-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083775124&doi=10.1007%2Fs11408-020-00350-8&partnerID=40&md5=6e1777fb9bc75bc769cdc7de72b223df,scopus
df698990aeb42d1d,Portfolio optimization in the presence of tail correlation,"We investigate the relative performance of optimal versus naive portfolio strategies. The accepted status on this question is that naive diversification outperforms optimal strategies. We revisit this question using U.S. data for equity, Treasury bonds, Gold and Crude Oil between 2002 and 2022 by analyzing the portfolio of investors displaying constant relative risk aversion who also consider tail behavior in the dynamics of assets. We use moment generating functions applied to non-Gaussian processes to obtain accurate model estimation as well as an efficient control variate for the utility maximization problem. Our results show that risk-averse investors that are aware of tail dynamics consistently outperform the most standard portfolio strategies. In particular, highly risk-averse investors substantially outperform the so-called naive 1/N portfolio in both pre-COVID-19 and post-COVID-19 periods. Thus, true portfolio diversification requires considering both the complexity of asset dynamics and realistic risk aversion structures. © 2023 Elsevier B.V., All rights reserved.","Ben Abdelaziz, F.; Chibane, M.",2023,10.1016/j.econmod.2023.106235,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149471432&doi=10.1016%2Fj.econmod.2023.106235&partnerID=40&md5=35edc3923027f51972407c1948146451,scopus
2614c15f385e0a14,Positive forward rates in the maximum smoothness framework,In this paper we present a nonlinear dynamic programming algorithm for the computation of forward rates within the maximum smoothness framework. The algorithm implements the forward rate positivity constraint for a one-parametric family of smoothness measures and it handles price spreads in the constraining data set. We investigate the outcome of the algorithm using the Swedish Bond market showing examples where the absence of the positive constraint leads to negative interest rates. Furthermore we investigate the predictive accuracy of the algorithm as we move along the family of smoothness measures. Among other things we observe that the inclusion of spreads not only improves the smoothness of forward curves but also significantly reduces the predictive error.,"Manzano, J; Blomvall, J",2004,10.1088/1469-7688/4/2/011,None,wos
8a75482548bbd8de,Post-deregulation bank-deposit-rate pricing: The multivariate dynamics,"The relationship between wholesale and retail interest rates since deregulation is of substantial interest to economists and policymakers, because the predictability of the monetary aggregates and their relationship to bank reserves depend on adjustment patterns in the wholesale and retail money markets. We provide evidence on the nature of wholesale-retail interest rate relationships by examining the dynamic interactions among two wholesale interest rates (federal funds and six-month treasury bills) and three retail deposit rates (six-month consumer certificates of deposit, money market deposit accounts, and super NOW’s). We perform a multivariate time series analysis, with particular attention paid to causal patterns and the shapes of impulse- response functions. A number of stylized facts, related to size of adjustment, speed of adjustment, and pattern of adjustment, are established for the response of retail rates to unanticipated shocks in wholesale rates. © 1990 American Statistical Association. © 2016 Elsevier B.V., All rights reserved.","Diebold, F.X.; Sharpe, S.A.",1990,10.1080/07350015.1990.10509799,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0002423521&doi=10.1080%2F07350015.1990.10509799&partnerID=40&md5=8d5caf65bff06c5f7bf019341d859000,scopus
1d531db1659c660e,Practical Bayesian support vector regression for financial time series prediction and market condition change detection,"Support vector regression (SVR) has long been proven to be a successful tool to predict financial time series. The core idea of this study is to outline an automated framework for achieving a faster and easier parameter selection process, and at the same time, generating useful prediction uncertainty estimates in order to effectively tackle flexible real-world financial time series prediction problems. A Bayesian approach to SVR is discussed, and implemented. It is found that the direct implementation of the probabilistic framework of Gao et al. returns unsatisfactory results in our experiments. A novel enhancement is proposed by adding a new kernel scaling parameter μ to overcome the difficulties encountered. In addition, the multi-armed bandit Bayesian optimization technique is applied to automate the parameter selection process. Our framework is then tested on financial time series of various asset classes (i.e. equity index, credit default swaps spread, bond yields, and commodity futures) to ensure its flexibility. It is shown that the generalization performance of this parameter selection process can reach or sometimes surpass the computationally expensive cross-validation procedure. An adaptive calibration process is also described to allow practical use of the prediction uncertainty estimates to assess the quality of predictions. It is shown that the machine-learning approach discussed in this study can be developed as a very useful pricing tool, and potentially a market condition change detector. A further extension is possible by taking the prediction uncertainties into consideration when building a financial portfolio. © 2017 Elsevier B.V., All rights reserved.","Law, T.; Shawe- Taylor, J.",2017,10.1080/14697688.2016.1267868,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014617588&doi=10.1080%2F14697688.2016.1267868&partnerID=40&md5=c7c6bf60d97eacfc0bafb852768ddf4a,scopus
a316a8dab4798b82,Predictability and Financial Sufficiency of Health Insurance in Colombia: An Actuarial Analysis With a Bayesian Approach,"Every year, the Colombian government provides a prospective premium, known as the capitation payment unit (CPU), for each affiliated person (according to sex, region, and age) to each health insurance company, in order to manage the corresponding risk in health. This article studies the prediction capacity for the health expenditure for the more than 20 million affiliates to the contributory regime of health, as well as the CPU's financial sufficiency, using an actuarial approach. Using the pure risk premium method and generalized linear models, both classic and Bayesian, the CPU is estimated; these results are compared to actual expenditure by an index of forecasting ability. It is concluded that the use of historical information about expenditure on health, as well as the Bayesian inference, among the other methodological innovations developed, provides an advantage for obtaining more accurate prospective values. These technical recommendations seek to support an improvement in the public budget allocation of more than 6 billion dollars per year to the Colombian health system.","Espinosa, Oscar; Bejarano, Valeria; Ramos, Jeferson",2024,10.1080/10920277.2023.2197475,None,wos
c1bf075f530f6e7a,Predictability and habit persistence,"This paper highlights the role of persistence in explaining predictability of excess returns. To this end, we develop a CCAPM model with habit formation when the growth rate of endowments follows a first order Gaussian autoregression. We provide a closed form solution of the price-dividend ratio and determine conditions that guarantee the existence of a bounded equilibrium. The habit stock model is found to possess internal propagation mechanisms that increase persistence. It outperforms the time separable and a 'Catching up with the Joneses' version of the model in terms of predictability therefore highlighting the role of persistence in explaining the puzzle. (c) 2005 Elsevier B.V. All rights reserved.","Collard, Fabrice; Feve, Patrick; Ghattassi, Imen",2006,10.1016/j.jedc.2005.06.016,None,wos
1fbbbf6449f5cb97,"Predictability and pricing efficiency in forward and spot, developed and emerging currency markets","We study the predictability of forward and spot exchange rates of currencies of emerging and developed economies from 1994 to 2016. Our purpose is to shed light on the efficiency of currency markets and how and why it has evolved over this time. For the currencies of emerging economies, our analysis of rates of return on forward contracts finds some evidence of excess-predictability, especially in the earlier parts of the sample period, consistent with the view that this portion of the foreign exchange market has only become efficient in recent times. When we turn our attention to excess-returns computed from spot exchange rates and spot interest rates, however, we find much less predictability. In particular, over our full sample period, we find no evidence of excess-predictability, in contrast with the results reported by Hsu et al. (2016) but in agreement with Kuang et al. (2014). The different predictability of spot excess-returns and rates of return on forward contracts is a manifestation of the widespread violation of covered interest parity which emerged with the onset of the 2008 financial crisis. © 2020 Elsevier B.V., All rights reserved.","Poti, V.; Levich, R.; Conlon, T.",2020,10.1016/j.jimonfin.2020.102223,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087713148&doi=10.1016%2Fj.jimonfin.2020.102223&partnerID=40&md5=694062d698f7310f40c42b54960ef8e1,scopus
daa22f7f68680d55,Predictability of HK-REITs returns using artificial neural network,"Purpose: The purpose of this paper is to determine if artificial neural network (ANN) works better than linear regression in predicting Hong Kong real estate investment trusts’ (REITs) excess return. Design/methodology/approach: Both ANN and the regression were applied in this study to forecast the Hong Kong REITs’ (HK-REITs) return using the capital asset pricing model and Fama and French’s three-factor models. Each result was further split into annual time series as a measure to investigate the consistency of the performance across time. Findings: ANN had produced a better forecasting results than the regression based on their trading performance. However, the forecasting performance varied across individual REITs and time periods. Practical implications: ANN should be considered for use when one were to attempt forecasting the HK-REITs excess returns. However, the trading performance should be always compared with buy and hold strategy prior to make any investment decisions. Originality/value: This paper tested the predicting power of ANN on the HK-REITs and the consistency of its predicting power. © 2021 Elsevier B.V., All rights reserved.","Loo, W.K.",2020,10.1108/jpif-07-2019-0090,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075160296&doi=10.1108%2FJPIF-07-2019-0090&partnerID=40&md5=dd4d84e73e04fa2b017a3e756beadbe1,scopus
559a1b5288affd81,Predictability of bull and bear markets: A new look at forecasting stock market regimes (and returns) in the US,"The empirical literature of stock market predictability mainly suffers from model uncertainty and parameter instability. To meet this challenge, we propose a novel approach that combines dimensionality reduction, regime-switching models, and forecast combination to predict excess returns on the S&P 500. First, we aggregate the weekly information of 146 popular macroeconomic and financial variables using different principal component analysis techniques. Second, we estimate Markov-switching models with time-varying transition probabilities using the principal components as predictors. Third, we pool the models in forecast clusters to hedge against model risk and to evaluate the usefulness of different specifications. Our weekly forecasts respond to regime changes in a timely manner to participate in recoveries or to prevent losses. This is also reflected in an improvement of risk-adjusted performance measures as compared to several benchmarks. However, when considering stock market returns, our forecasts do not outperform common benchmarks. Nevertheless, they do add statistical and, in particular, economic value during recessions or in declining markets. © 2023 Elsevier B.V., All rights reserved.","Haase, F.; Neuenkirch, M.",2023,10.1016/j.ijforecast.2022.01.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125423203&doi=10.1016%2Fj.ijforecast.2022.01.004&partnerID=40&md5=2a9da8940804b1ea4ce1e3e635eb98ee,scopus
08de0707b6b53ba7,Predictability of sugar futures: evidence from the Indian commodity market,"Purpose – The forecasting power of commodity futures is a matter of intensive research as evidenced by a number of related publications. The purpose of this paper is to illustrate how advanced forecasting techniques improve the predictability of sugar futures in the Indian commodity market. Design/methodology/approach – The forward premium is estimated using ordinary least square regression technique. Different linear and nonlinear models are used to forecast the sugar future spot prices from the futures prices. The forecasting accuracy of each pair of models is then compared by estimating the corresponding Diebold-Mariano test statistics. Findings – From the estimated forward premiums, it is found that there is more volatility toward the date of maturity for a three-month horizon compared to six-month, and 12-month horizons. It is established that the futures prices of sugar, when used in a model, are able to generate better forecasts for the future spot prices. Moreover, the forecasting accuracy is found to be better for a shorter futures horizon. Research limitations/implications – The present study is restricted only to sugar. If sufficient data are available, the same study could be extended to other commodities as well. The findings imply that technical traders would benefit by using advanced forecasting techniques along with futures prices of sugar to determine the expected future spot prices. Practical implications – The findings in this paper suggest that though simple statistical models may be adopted to relate future spot prices to futures prices, more accurate prediction of the price behavior is possible with advanced forecasting methods like the artificial neural network. Social implications – The findings will help market participants such as traders to be better informed about the future spot prices and hence get a better deal. Originality/value – This is one of the first investigations to assess the predictability of commodity futures by employing advanced forecasting techniques.","Prabhati Kumari Misra; Goswami, Kishor",2015,10.1108/afr-02-2014-0002,None,proquest
27f7eabc787858e0,Predictable variation and profitable trading of US equities: A trading simulation using neural networks,"A switching rule conditioned on out-of-sample one-step-ahead predictions of returns is used to establish investment positions in either stocks or Treasury bills. The economic significance of any discernible patterns of predictability is assessed by incorporating transaction costs in the simulated trading strategies. We find that ANN models produce switching signals that could have been exploited by investors in an out-of-sample context to achieve superior cumulative and risk-adjusted returns when compared to either regression or a simple buy-and-hold strategy in the market indices. The robustness of these results across a large number of stock market indices is encouraging. Scope and purpose A large body of evidence has accumulated suggesting that stock returns are predictable by means of publicly available information on a number of financial and macroeconomic variables with an important business cycle component. Previous research has, for the most part, relied on standard statistical techniques (e.g., regression analysis) with unduly restrictive assumptions presumed to hold in the underlying data-generating process. This paper reexamines the evidence regarding predictable variation in US stock returns using both artificial neural network (ANN) and regression, and compares simulated trading results obtained from ANN models with those obtained from regression. (C) 2000 Elsevier Science Ltd. All rights reserved.; A switching rule conditioned on out-of-sample one-step-ahead predictions of returns is used to establish investment positions in either stocks or Treasury bills. The economic significance of any discernible patterns of predictability is assessed by incorporating transaction costs in the simulated trading strategies. We find that ANN models produce switching signals that could have been exploited by investors in an out-of-sample context to achieve superior cumulative and risk-adjusted returns when compared to either regression or a simple buy-and-hold strategy in the market indices. The robustness of these results across a large number of stock market indices is encouraging. © 2004 Elsevier Science B.V., Amsterdam. All rights reserved.","Motiwalla, L.; Wahab, M.",2000,10.1016/s0305-0548(99)00148-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034046387&doi=10.1016%2FS0305-0548%2899%2900148-3&partnerID=40&md5=fc139aa19f3bbf2ee1db63ecc6efa633,scopus
8c52d0ea81ad2a78,Predicting Chinese bond risk premium with machine learning,This paper investigates whether bond yield curve and macroeconomic factors have nonlinear relationships with bond risk premia in the Chinese bond market. We apply machine learning approaches to forecast Chinese treasury bond one-year holding period excess returns. Our results show that the bond yield curve has significant nonlinear predictive relationships with bond risk premia. We find evidence that ‘monetary policy’ and ‘tax’ macroeconomic groups have stronger nonlinear relationships with risk premia while ‘invest’ macroeconomic factors matter more for bonds with longer maturities. This paper provides statistical evidence for a significant relationship between expected bond risk premia and several economic drivers including range of forecast of GDP and bond volatility variables. We further document the economic values of our forecasting results by showing they can generate statistically higher certain equivalent values than those from the benchmark forecast.,"Zhai, Jia; Xi, Jiahui; Wen, Conghua; Lu, Zong",2025,10.1080/1351847x.2024.2446719,None,proquest
1077743797ebe882,Predicting EU energy industry excess returns on EU market index via a constrained genetic algorithm,"This article introduces an automated procedure to simultaneously select variables and detect outliers in a dynamic linear model using information criteria as objective functions and diagnostic tests as constraints for the distributional properties of errors. A robust scaling method is considered to take into account the sensitiveness of estimates to abnormal data. A genetic algorithm is developed to these purposes. Two examples are presented where models are designed to produce short-term forecasts for the excess returns of the MSCI Europe Energy sector on the MSCI Europe index and a recursive estimation-window is used to shed light on their predictability performances. In the first application the data-set is obtained by a reduction procedure from a very large number of leading macro indicators and financial variables stacked at various lags, while in the second the complete set of 1-month lagged variables is considered. Results show a promising capability to predict excess sector returns through the selection, using the proposed methodology, of most valuable predictors. Reprinted by permission of Springer","Kaucic, Massimiliano",2009,10.1007/s10614-009-9176-4,None,proquest
85aad9d7cb4653db,Predicting Equity Premium: A New Momentum Indicator Selection Strategy With Machine Learning,"We propose a new momentum-determined indicator-switching (N-MDIS) strategy, harnessing the power of machine learning to enhance the accuracy of equity premium prediction. Specifically, we re-examine the regime-dependent feature of univariate predictive regression relative to the benchmark. Furthermore, we investigate the prediction mechanism of the momentum-determined indicator-switching (MDIS) strategy and validate the significance of market regime information for the MDIS. Our findings demonstrate an overwhelmingly superior ex-post forecasting performance compared with the MDIS. More notably, our empirical results substantiate that machine learning greatly aids in momentum indicator selection. The results show that the N-MDIS with machine learning generates more accurate ex-ante equity premium forecasts than both MDIS strategy and N-MDIS strategy with logistic regression, yielding statistically and economically significant results. Moreover, our new approach exhibits robust forecasting performance across a series of robustness tests.","Qu, Yong; Yuan, Ying",2025,10.1002/for.3200,None,wos
d8d9babf588c6b0c,Predicting Future Earnings Changes Using Machine Learning and Detailed Financial Data,"We use machine learning methods and high‐dimensional detailed financial data to predict the direction of one‐year‐ahead earnings changes. Our models show significant out‐of‐sample predictive power: the area under the receiver operating characteristics curve ranges from 67.52% to 68.66%, significantly higher than the 50% of a random guess. The annual size‐adjusted returns to hedge portfolios formed based on the prediction of our models range from 5.02% to 9.74%. Our models outperform two conventional models that use logistic regressions and small sets of accounting variables, and professional analysts’ forecasts. Analyses suggest that the outperformance relative to the conventional models stems from both nonlinear predictor interactions missed by regressions and the use of more detailed financial data by machine learning.","Chen, Xi; YANG HA (TONY) CHO; Dou, Yiwei; Lev, Baruch",2022,10.1111/1475-679x.12429,None,proquest
a8ce067fd156e398,Predicting Interest Rate Volatility Using Information on the Yield Curve,"This study examines whether information on the yield curve is useful for predicting volatility of the yield curve. The information is used within dynamic models by specifying the covariance matrix of changes in yield factors as nonlinear functions of the factors. Using such models, it is found that the information (i) is useful for predicting volatility of the slope factor, achieving the accuracy comparable with the GARCH model; (ii) has incremental value for predicting volatility of the curvature factor when combined with a volatility-specific factor; and (iii) does not much improve prediction of volatility of the level factor once the volatility-specific factor is introduced. © 2021 Elsevier B.V., All rights reserved.","Takamizawa, H.",2015,10.1111/irfi.12053,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940795801&doi=10.1111%2Firfi.12053&partnerID=40&md5=401dea9b3f3e7e9a0708eba14f080be1,scopus
dc45f56e400e0bc4,Predicting Recessions with Leading Indicators: Model Averaging and Selection over the Business Cycle,"Four methods of model selectionequally weighted forecasts, Bayesian model-averaged forecasts, and two models produced by the machine-learning algorithm boostingare applied to the problem of predicting business cycle turning points with a set of common macroeconomic variables. The methods address a fundamental problem faced by forecasters: the most useful model is simple but makes use of all relevant indicators. The results indicate that successful models of recession condition on different economic indicators at different forecast horizons. Predictors that describe real economic activity provide the clearest signal of recession at very short horizons. In contrast, signals from housing and financial markets produce the best forecasts at longer forecast horizons. A real-time forecast experiment explores the predictability of the 2001 and 2007 recessions. Copyright (c) 2015 John Wiley & Sons, Ltd.","Berge, Travis J.",2015,10.1002/for.2345,None,wos
d40c4143dfb51f9e,Predicting Stock Jumps and Crashes Using Options,"This paper investigates the informativeness of option-implied volatility and Greeks in forecasting extreme stock returns. Using a large data set of U.S. stocks and options from 1996 to 2022 and employing Light Gradient-Boosting Machine as a machine learning algorithm, we show that option characteristics, particularly implied volatility and delta, are strong predictors of extreme returns. The long-short portfolio utilizing option variables significantly outperforms a benchmark using only stock characteristics, suggesting that options provide information beyond what can be inferred from stock characteristics. Put options are revealed to be more informative than call options, and crashes are easier to predict than jumps.","Andreou, Panayiotis C.; Han, Chulwoo; Li, Nan",2025,10.1002/fut.22609,None,wos
a924be2f5f701f16,Predicting Wheat Futures Prices in India,"Futures markets perform their economic roles of price discovery and hedging only when they are efficient. One of the important features of efficient market is that one cannot make abnormal profits from the futures markets by trading in it. This paper addresses the question of whether Indian wheat futures prices can be forecast. This would add to our knowledge whether wheat futures market is efficient, and would enable brokers, traders and speculators to develop profitable trading strategy. We employ the economic variable model to predict the wheat futures prices, and employ out of sample point forecasts. We also evaluate the robustness of our results by employing several alternative specifications, viz. ARMA process and artificial neural network technique. We then test the statistical significance of point forecast using the Diebold and Mariano test. We consider random walk orecast as the bench mark. In order to predict the evolution of wheat futures prices, we use traders' expectations about the futures prices, a number of economic variables and futures prices (lagged) of wheat. The study finds that the futures price of wheat cannot be forecast, and the wheat futures market is efficient.","Kumar, Raushan",2021,10.1007/s10690-020-09320-6,None,wos
c0c7a7ba258e0e2a,Predicting bank inactivity: A comparative analysis of machine learning techniques for imbalanced data,"This study compares the predictive accuracy of a set of machine learning models coupled with three resampling techniques (Random Undersampling, Random Oversampling, and Synthetic Minority Oversampling Technique) in predicting bank inactivity. Our sample includes listed banks in EU-28 member states between 2011 and 2019. We employed 23 financial ratios comprising capital adequacy, asset quality, management capability, earnings, liquidity, and sensitivity indicators. The empirical findings established that XGBoost performs exceptionally well as a classifier in predicting bank inactivity, particularly when considering a one-year time frame before the event. Furthermore, our findings indicate that random forest with Synthetic Minority Oversampling Technique demonstrates the highest predictive accuracy two years prior to inactivity, while XGBoost with Random Oversampling outperforms other methods three years in advance. Furthermore, the empirical results emphasize the significance of management capability and loan quality ratios as key factors in predicting bank inactivity. Our findings present important policy implications.HighlightsBank inactivity predictive accuracy of machine learning techniques with resampling techniques is analyzed.Data on banks in the EU-28 member states between 2011 and 2019 are used.XGBoost performs exceptionally well one year before inactivity.Random Forest with Synthetic Minority Oversampling is the best classifier two years before inactivity.XGBoost with Random Oversampling outperforms other methods three years before inactivity.","Mrad, Ali Ben; Lahiani, Amine; Mefteh-Wali, Salma; Mselmi, Nada",2025,10.1007/s10479-024-06018-0,None,proquest
88b65f3a8cabb4d8,Predicting bond risk premiums with machine learning: Evidence from China,"This study evaluates the ability of machine-learning algorithms to forecast bond risk premiums in the Chinese market. Using a comprehensive set of macro-, firm- and bond-level predictors, we find that machine learning, especially neural network, delivers markedly higher out-of-sample performance than traditional linear benchmarks. The local per-capita fiscal expenditure (EXPEND), bond credit ratings (CREDIT), and profitability- and intangible-related firm characteristics emerge as the most informative variables. Predictive gains are especially pronounced for low-rated issues, non-state-owned enterprises, and periods of heightened economic policy uncertainty. Incorporating machine-learning-based forecasts also helps to enhance credit rating accuracy. Collectively, our findings highlight the value of non-linear machine learning modeling techniques for bond pricing in emerging markets. © 2025 Elsevier B.V., All rights reserved.","Chai, B.; Jiang, F.; Lin, Y.; You, T.",2025,10.1016/j.pacfin.2025.102882,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011378841&doi=10.1016%2Fj.pacfin.2025.102882&partnerID=40&md5=e8cc6284881f9db8972654ad641eaf0d,scopus
992e33dba092f9dd,Predicting corporate bankruptcy using the framework of Leland-Toft: evidence from U.S.,"In this paper, we evaluate an alternative approach for bankruptcy prediction that measures the financial healthiness of firms that have coupon-paying debts. The approach is based on the framework of Leland, H. and Toft, K.B. [Optimal capital structure, endogenous bankruptcy and the term structure of credit spreads. J. Financ., 1996, 51, 987–1019], which is an extension of a widely-used model; the Black–Scholes–Merton model. Using U.S. public firms between 1995 and 2014, we show that the Leland-Toft approach is more powerful than Black–Scholes–Merton in a variety of tests. Moreover, extending popular but also contemporary corporate bankruptcy models with the probability of bankruptcy derived from the Leland-Toft model, such as Altman, E. [Financial ratios, discriminant analysis and the prediction of corporate bankruptcy. J. Financ., 1968, 23, 589–609], Ohlson, J.A. [Financial ratios and the probabilistic prediction of bankruptcy. J. Account. Res., 1980, 18, 109–131] and Campbell, J. Y., Hilscher, J. and Szilagyi, J. [In search of distress risk. J. Financ., 2008, 63, 2899–2939], yields models with improved performance. One of our tests, for example, shows that banks using these extended models, achieve superior economic performance relative to other banks. Our results are consistent under a comprehensive out-of-sample framework. © 2020 Elsevier B.V., All rights reserved.","Charalambous, C.; Martzoukos, S.H.; Taoushianis, Z.",2020,10.1080/14697688.2019.1667519,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074765488&doi=10.1080%2F14697688.2019.1667519&partnerID=40&md5=b15d939b006661b2bf31cd24674df7cd,scopus
fd7272563aec0c21,Predicting daily oil prices: Linear and non-linear models,"In this paper, we assess the accuracy of linear and nonlinear models in predicting daily crude oil prices. Competing forecasts of crude oil prices are generated from parsimonious linear models which require no parameter estimation, as well as linear and nonlinear models. Two of the linear models that we employ exploit the informational content of oil demand and the increasing correlation between oil and equity prices and are novel to the literature. The nonlinear model that we consider is an artificial neural network. More specifically, we consider a bagged neural network, a neural network trained using the genetic algorithm as well as a neural network with fuzzy logic. We find that some of the linear models outperform the random walk in terms of out-of-sample statistical forecast accuracy. Our findings also suggest that while the buy-and-hold strategy dominates some of the models in terms of dollar payoffs and risk-adjusted returns under a long-only strategy, all the models that we consider generate higher dollar payoffs than the buy-and-hold strategy under the short-only strategy. An investor obtains the largest profits by trading based on the moving average convergence divergence which is a technical indicator.","Dbouk, Wassim; Jamali, Ibrahim",2018,10.1016/j.ribaf.2018.01.003,None,wos
b789cc7bea10aacd,Predicting equity premium using news-based economic policy uncertainty: Not all uncertainty changes are equally important,"This study contributes to the growing research that uses the news-based measure of U.S. economic policy uncertainty (EPU) suggested in Baker et al. (2016) to predict economic variables out-of-sample. Using simple predictive regressions à la Goyal and Welch (2008), we evaluate the predictive power afforded by various nonlinear transformations of the U.S. EPU measure suggested in Baker et al. (2016) to predict excess returns on the S&P 500 index one-month ahead. Using data from 1985m1 through 2020m12, we find that not all EPU movements are equally important for obtaining point prediction improvements relative to the historical average benchmark at the population level. Particularly, we document that the one-year net EPU increase, defined as EPU increases beyond the peak over the last year, otherwise zero delivers the most consistent pattern of prediction improvements relative to the benchmark. Conversely, other nonlinear specifications as well as the linear models using log-EPU and the first difference of log-EPU do not deliver the same performance. Overall, this study documents that the predictive impact of the U.S. EPU index suggested in Baker et al. (2016) on equity premium is nonlinear in that EPU increases matter only to the extent that they exceed the maximum value over the last twelve months. In other words, there is evidence of threshold nonlinearity. The statistical predictive power afforded by the one-year net EPU increase also translates into economic gains. © 2021 Elsevier B.V., All rights reserved.","Nonejad, N.",2021,10.1016/j.irfa.2021.101818,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108704036&doi=10.1016%2Fj.irfa.2021.101818&partnerID=40&md5=de440df2664db41659ed758b9ca17144,scopus
101def3e12ba19c0,Predicting failure risk using financial ratios: Quantile hazard model approach,"This study examines the role of financial ratios in predicting companies’ default risk using the quantile hazard model (QHM) approach and compares its results to the discrete hazard model (DHM). We adopt the LASSO method to select essential predictors among the variables mentioned in the literature. We show the preeminence of our proposed QHM through the fact that it presents a different degree of financial ratios’ effect over various quantile levels. While DHM only confirms the aftermaths of “stock return volatilities” and “total liabilities” and the positive effects of “stock price” “stock excess return” and “profitability” on businesses, under high quantile levels QHM is able to supplement “cash and short-term investment to total assets” “market capitalization” and “current liabilities ratio” into the list of factors that influence a default. More interestingly, “cash and short-term investment to total assets” and “market capitalization” switch signs in high quantile levels, showing their different influence on companies with different risk levels. We also discover evidence for the distinction of default probability among different industrial sectors. Lastly, our proposed QHM empirically demonstrates improved out-of-sample forecasting performance. © 2018 Elsevier B.V., All rights reserved.","Dong, M.C.; Tian, S.; Chen, C.W.S.",2018,10.1016/j.najef.2018.01.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042146925&doi=10.1016%2Fj.najef.2018.01.005&partnerID=40&md5=b61603138dc1c51707d88463ab14c1a7,scopus
dd758172438d1aca,"Predicting interest rates using shrinkage methods, real‐time diffusion indexes, and model combinations","In the context of predicting the term structure of interest rates, we explore the marginal predictive content of real‐time macroeconomic diffusion indexes extracted from a “data rich” real‐time data set, when used in dynamic Nelson–Siegel (NS) models of the variety discussed in Svensson (NBER technical report, 1994; NSS) and Diebold and Li (Journal of Econometrics, 2006, 130, 337–364; DNS). Our diffusion indexes are constructed using principal component analysis with both targeted and untargeted predictors, with targeting done using the lasso and elastic net. Our findings can be summarized as follows. First, the marginal predictive content of real‐time diffusion indexes is significant for the preponderance of the individual models that we examine. The exception to this finding is the post “Great Recession” period. Second, forecast combinations that include only yield variables result in our most accurate predictions, for most sample periods and maturities. In this case, diffusion indexes do not have marginal predictive content for yields and do not seem to reflect unspanned risks. This points to the continuing usefulness of DNS and NSS models that are purely yield driven. Finally, we find that the use of fully revised macroeconomic data may have an important confounding effect upon results obtained when forecasting yields, as prior research has indicated that diffusion indexes are often useful for predicting yields when constructed using fully revised data, regardless of whether forecast combination is used, or not. Nevertheless, our findings also underscore the potential importance of using machine learning, data reduction, and shrinkage methods in contexts such as term structure modeling.","Swanson, Norman R; Xiong, Weiqi; Yang, Xiye",2020,10.1002/jae.2768,None,proquest
2589459f5fd7391f,Predicting real growth and the probability of recession in the Euro area using the yield spread,"Although the spread has been established as a leading indicator of economic activity, recent studies in US and European Union (EU) countries have documented, theoretically and empirically, that the term spread-output growth relationship may not be stable over time and it may be subjected to nonlinearities. Using aggregate data for the Euro area over the period 1970:1-2000:4, we applied linear regression as well as nonlinear models to examine the predictive accuracy of the term spread-output growth relationship. Our results confirm the ability of the yield curve as a leading indicator. Moreover, significant nonlinearity with respect to time and past annual growth is detected, outperforming the linear model in out-of-sample forecasts of 1-year-ahead annual growth. Furthermore, probit models that use the EMU and US yield spreads are successful in predicting EMU recessions. © 2004 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved. © 2005 Elsevier B.V., All rights reserved.","Duarte, A.; Venetis, I.A.; Paya, I.",2005,10.1016/j.ijforecast.2004.09.008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-14844296381&doi=10.1016%2Fj.ijforecast.2004.09.008&partnerID=40&md5=1b54c1e1fff7743dddb40cdaf2e3bfbb,scopus
c77ed07cec4b8ecf,Predicting recessions using trends in the yield spread,"The yield spread, measured as the difference between long- and short-term interest rates, is widely regarded as one of the strongest predictors of economic recessions. In this paper, we propose an enhanced recession prediction model that incorporates trends in the value of the yield spread. We expect our model to generate stronger recession signals because a steadily declining value of the yield spread typically indicates growing pessimism associated with the reduced future business activity. We capture trends in the yield spread by considering both the level of the yield spread at a lag of 12 months as well as its value at each of the previous two quarters leading up to the forecast origin, and we evaluate its predictive abilities using both logit and artificial neural network models. Our results indicate that models incorporating information from the time series of the yield spread correctly predict future recession periods much better than models only considering the spread value as of the forecast origin. Furthermore, the results are strongest for our artificial neural network model and logistic regression model that includes interaction terms, which we confirm using both a blocked cross-validation technique as well as an expanding estimation window approach.","Kozlowski, Steven E.; Sim, Thaddeus",2019,10.1080/02664763.2018.1537364,None,wos
3bb815ed509032e9,Predicting risk premium under changes in the conditional distribution of stock returns,"The goal of this paper is to assess time-variation in asset returns while considering the whole conditional distribution. We use a quantile regression framework and quarterly data for the U.S., and show that the probabilistic distribution of expectations about future stock returns changes in response to variation in commonly used explanatory variables. Moreover, our results support the idea that lower quantiles are less stable than upper quantiles, thus, suggesting that asset pricing models are particularly accurate in capturing the expectations that less risk-averse agents have about future returns. © 2017 Elsevier B.V., All rights reserved.","Sousa, J.; Sousa, R.M.",2017,10.1016/j.intfin.2017.09.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030168894&doi=10.1016%2Fj.intfin.2017.09.002&partnerID=40&md5=302310729f73705e6b4efcc18f0ecccc,scopus
cc4a38ac36cf4d52,Predicting tanker freight rates using parsimonious variables and a hybrid artificial neural network with an adaptive genetic algorithm,"Short-term prediction of tanker freight rates (TFRs) is strategically important to stakeholders in the oil shipping industry. This study develops a hybrid TFR prediction model based on an artificial neural network (ANN) and an adaptive genetic algorithm (AGA). The AGA adaptively searches satisficing network parameters such as input delay size. The ANN iteratively optimizes a prediction network considering parsimonious variables and time-lag effects as predictors. Three parsimonious variables (crude oil price, fleet productivity and bunker price) are selected by a stepwise regression of TFR variables. The article compares the performance of its hybrid model with two traditional approaches (regression and moving average), as well as with the findings of existing ANN studies. The results of our model (root mean squared error (RMSE)= 11.2 WS) are not only significantly superior to the regression approach (RMSE = 21.6 WS) and the moving average approach (RMSE = 17.5 WS), but are even slightly superior to the results of existing ANN studies (RMSE = 14.6 WS-15.8 WS).","Eslami, Payman; Jung, Kihyo; Lee, Daewon; Tjolleng, Amir",2017,10.1057/mel.2016.1,None,wos
bf457be8f25995d5,Predicting the Canadian Yield Curve Using Machine Learning Techniques,"This study applies machine learning methods to predict the Canadian yield curve using a comprehensive set of macroeconomic variables. Lagged values of the yield curve and a wide array of Canadian and international macroeconomic variables are utilized across various machine learning models. Hyperparameters are estimated to minimize mispricing across government bonds with different maturities. The Group Lasso algorithm outperforms the other models studied, followed by Lasso. In addition, the majority of the models outperform the Random Walk benchmark. The feature importance analysis reveals that oil prices, bond-related factors, labor market conditions, banks’ balance sheets, and manufacturing-related factors significantly drive yield curve predictions. This study is one of the few that uses such a broad array of macroeconomic variables to examine Canadian macro-level outcomes. It provides valuable insights for policymakers and market participants, with its feature importance analysis highlighting key drivers of the yield curve.",Rayeni Ali; Naderi Hosein,2025,10.3390/ijfs13030170,None,proquest
0f8cf13e7b3aab14,Predicting the milk yield curve of dairy cows in the subsequent lactation period using deep learning,"Existing lactation models predict milk yields based on a fixed amount of observed milk production in early lactation. In contrast, this study proposes a model to predict the entire lactation curve of dairy cows by leveraging historical milk yield information observed in the preceding cycle. More specifically, we present a deep learning framework to encode the model inputs, predict the latent representation of the milk yield sequences and generate the corresponding lactation curves. Results show that the proposed framework outperforms the baseline models and that during the first 26 days of lactation, the model's predictions are more accurate than those of a state-of-the-art lactation model which is able to leverage the observed milk yields. As a result, the framework presented in this study allows farmers to increase their forecast horizon with respect to predicting its herd's total production and hence facilitates optimal herd management. Additionally, the model can be used to compare a cow's actual and expected milk yield over the entire course of the lactation cycle. This in turn can help to accelerate disease detection and enhance current animal monitoring systems. Finally, as the model incorporates the impact of health and reproduction events as well as herd management on the cow's productivity, future earnings and costs can be estimated more accurately.","Liseune, Arno; Salamone, Matthieu; Van den Poel, Dirk; van Ranst, Bonifacius; Hostens, Miel",2021,10.1016/j.compag.2020.105904,None,wos
3f472e4b03d6627f,"Prediction and Allocation of Stocks, Bonds, and REITs in the US Market","This study employs dynamic model averaging and selection of Vector Autoregressive and Time-Varying Parameters Vector Autoregressive models to forecast out-of-sample monthly returns of US stocks, bonds, and Real Estate Investment Trusts (REITs) indexes from October 2006 to December 2021. The models were recursively estimated using 17 additional predictors chosen by a genetic algorithm applied to an initial list of 155 predictors. These forecasts were then used to dynamically choose portfolios formed by these assets and the riskless asset proxied by the 3-month US treasury bills. Although we did not find any predictability in the stock market, positive results were obtained for REITs and especially for bonds. The Bayesian-based approaches applied to just the returns of the three risky assets resulted in portfolios that remarkably outperform the portfolios based on the historical means and covariances and the equally weighted portfolio in terms of certainty equivalent return, Sharpe ratio, Sortino ratio and even Conditional Value-at-Risk at 5%. This study points out that Constant Relative Risk Averse investors should use Bayesian-based approaches to forecast and choose the investment portfolios, focusing their attention on different types of assets.",None,2025,10.1007/s10614-024-10589-2,None,proquest
8f46c32be1e0bc51,Prediction of US 30‐years‐treasury‐bonds movement and trading entry point using the robust 1DCNN‐BiLSTM‐XGBoost algorithm,"This article presents a novel algorithm that accurately predicts market trends and identifies trading entry points for US 30‐year Treasury bonds. The proposed method employs a hybrid approach, integrating a 1‐dimensional convolutional neural network (1DCNN), long‐short term memory (LSTM), and XGBoost algorithms. The 1DCNN is used to learn local and short‐term patterns, while LSTM is employed to capture both short and long‐term dependencies. Furthermore, we have implemented an algorithm that utilizes hull moving average (HMA) and simple moving average (SMA) crossover data to detect trading entry points and major trends in the market. The combination of the SMA–HMA crossover algorithm and predictions provided by the 1DCNN‐BiLSTM‐XGBoost algorithm yields exceptional results in terms of prediction accuracy and profitability. Additionally, these integrated techniques effectively filter out noise and mitigate false breakouts, which are often observed with US 30‐year Treasury bonds. In the field of financial time series prediction, the effectiveness of 1DCNN and LSTM in identifying trading entry points and market perturbations has not been comprehensively studied. Therefore, our work fills this gap by demonstrating through experiments that the proposed 1DCNN‐BiLSTM‐XGBoost algorithm, in combination with moving average crossovers, effectively reduces noise and market perturbations. This leads to the precise identification of trading entry points and accurate recognition of trend signals for US 30‐year Treasury bonds. We demonstrate through experiments that our proposed approach achieves an average root mean squared error of 0.0001 and an R‐square value of 0.9999, highlighting its promise as a method for predicting market trends and trading entry points for US 30‐year Treasury bonds.","El Zaar, Abdellah; Benaya, Nabil; Bakir, Toufik; Mansouri, Amine; El Allati, Abderrahim",2024,10.1111/exsy.13459,None,proquest
60d9172998b8c2be,Prediction of long-term government bond yields using statistical and artificial intelligence methods,"This chapter investigates the use of different artificial intelligence and classical techniques for forecasting the monthly yield of the US 10-year Treasury bonds from a set of four economic indicators. The task is particularly challenging due to the sparseness of the data samples and the complex interactions amongst the variables. At the same time, it is of high significance because of the important and paradigmatic role played by the US market in the world economy. Four data-driven artificial intelligence approaches are considered: a manually built fuzzy logic model, a machine learned fuzzy logic model, a self-organising map model, and a multi-layer perceptron model. Their prediction accuracy is compared with that of two classical approaches: a statistical ARIMA model and an econometric error correction model. The algorithms are evaluated on a complete series of end-month US 10-year Treasury bonds yields and economic indicators from 1986:1 to 2004:12. In terms of prediction accuracy and reliability, the best results are obtained by the three parametric regression algorithms, namely the econometric, the statistical, and the multi-layer perceptron model. Due to the sparseness of the learning data samples, the manual and the automatic fuzzy logic approaches fail to follow with adequate precision the range of variations of the US 10-year Treasury bonds. For similar reasons, the self-organising map model performs unsatisfactorily. Analysis of the results indicates that the econometric model has a slight edge over the statistical and the multi-layer perceptron models. This suggests that pure data-driven induction may not fully capture the complicated mechanisms ruling the changes in interest rates. Overall, the prediction accuracy of the best models is only marginally better than the prediction accuracy of a basic one-step lag predictor. This result highlights the difficulty of the modelling task and, in general, the difficulty of building reliable predictors for financial markets. © 2014 Springer International Publishing Switzerland. © 2016 Elsevier B.V., All rights reserved.","Castellani, M.; Dos Santos, E.A.",2014,10.1007/978-3-319-01866-9_11,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958526206&doi=10.1007%2F978-3-319-01866-9_11&partnerID=40&md5=5bd2589979558156e7b4404cf22ec603,scopus
6c48d26410f11006,Prediction of the implied volatility surface–An empirical analysis of the SSE 50ETF option based on CNNs,"With advancements in artificial intelligence, deep learning techniques have been widely used in predicting financial market volatility. This study forecasts the implied volatility of stock options of the top 50 companies listed on the Shanghai Stock Exchange(SSE) using a convolutional neural network (CNN) with a scaled exponential linear unit activation function and no pooling layer. The CNN model is compared to a back-propagation (BP) neural network to evaluate predictive performance. Results show that the CNN model shows superior performance in predicting implied volatility compared to the BP neural network, accurately fitting data patterns as well as smile and term structures. © 2025 Elsevier B.V., All rights reserved.","Shao, H.; Zhou, B.; Gong, S.",2025,10.1016/j.frl.2025.107119,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219544528&doi=10.1016%2Fj.frl.2025.107119&partnerID=40&md5=55f23bdf3a42f4f7eba6a6d771cac644,scopus
e9d4cb3cc9f23a8f,Prediction-Based Portfolio Optimization Models Using Deep Neural Networks,"Portfolio optimization is a hot research topic, which has attracted many researchers in recent decades. Better portfolio optimization model can help investors earn more stable profits. This paper uses three deep neural networks (DNNs), i.e., deep multilayer perceptron (DMLP), long short memory (LSTM) neural network and convolutional neural network (CNN) to build prediction-based portfolio optimization models which own the advantages of both deep learning technology and modern portfolio theory. These models first use DNNs to predict each stock's future return. Then, predictive errors of DNNs are applied to measure the risk of each stock. Next, the portfolio optimization models are built by integrating the predictive returns and semi-absolute deviation of predictive errors. These models are compared with three equal weighted portfolios, where their stocks are selected by DMLP, LSTM neural network and CNN respectively. Also, two prediction-based portfolio models built with support vector regression are used as benchmarks. This paper applies component stocks of China securities 100 index in Chinese stock market as experimental data. Experimental results present that the prediction-based portfolio model based on DMLP performs the best among these models under different desired portfolio returns, and high desired portfolio return can further improve the performance of this model. This paper presents the promising performance of DNNs in building prediction-based portfolio models.",Y. Ma; R. Han; W. Wang,2020,10.1109/access.2020.3003819,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121212,ieeexplore
70093db6f3573ba2,Predictive power of Markovian models: Evidence from US recession forecasting,"This paper provides extensions to the application of Markovian models in predicting US recessions. The proposed Markovian models, including the hidden Markov and Markov models, incorporate the temporal autocorrelation of binary recession indicators in a traditional but natural way. Considering interest rates and spreads, stock prices, monetary aggregates, and output as the candidate predictors, we examine the out-of-sample performance of the Markovian models in predicting the recessions 1-12 months ahead, through rolling window experiments as well as experiments based on the fixed full training set. Our study shows that the Markovian models are superior to the probit models in detecting a recession and capturing the recession duration. But sometimes the rolling window method may affect the models' prediction reliability as it could incorporate the economy's unsystematic adjustments and erratic shocks into the forecast. In addition, the interest rate spreads and output are the most efficient predictor variables in explaining business cycles.","Tian, Ruilin; Shen, Gang",2019,10.1002/for.2579,None,wos
7b8a48fc4285407a,Predictive power of investor sentiment for Bitcoin returns: Evidence from COVID-19 pandemic,"In this paper, we examine the impact of investor sentiment on Bitcoin returns. Using a large dataset of messages discussed on social media and several financial indicators, we create a sentiment indicator based on computational text analysis and driven by the principal component analysis (PCA) method. We utilize a vector autoregressive analysis and other analytical methods to examine the sentiment index-bitcoin return nexus. Our findings reveal that the sentiment index is a strong predictor of cryptocurrency market returns in the short term. Furthermore, we confirm that during the COVID-19 pandemic, investors' sentiments significantly impacted Bitcoin returns. Our results show that the proposed sentiment index can generate excess returns for investors who utilize it as a return predictor. Our empirical findings suggest important policy implications.","Bouteska, Ahmed; Mefteh-Wali, Salma; Dang, Trung",2022,10.1016/j.techfore.2022.121999,None,wos
5957d41f05f017e9,Predictive trading strategy for physical electricity futures,"This article presents an original predictive strategy, based on a new mid-term forecasting model, to be used for trading physical electricity futures. The forecasting model is used to predict the average spot price, which is used to estimate the Risk Premium corresponding to electricity futures trade operations with a physical delivery. A feed-forward neural network trained with the extreme learning machine algorithm is used as the initial implementation of the forecasting model. The predictive strategy and the forecasting model only need information available from electricity derivatives and spot markets at the time of negotiation. In this paper, the predictive trading strategy has been applied successfully to the Iberian Electricity Market (MIBEL). The forecasting model was applied for the six types of maturities available for monthly futures in the MIBEL, from 1 to 6 months ahead. The forecasting model was trained with MIBEL price data corresponding to 44 months and the performances of the forecasting model and of the predictive strategy were tested with data corresponding to a further 12 months. Furthermore, a simpler forecasting model and three benchmark trading strategies are also presented and evaluated using the Risk Premium in the testing period, for comparative purposes. The results prove the advantages of the predictive strategy, even using the simpler forecasting model, which showed improvements over the conventional benchmark trading strategy, evincing an interesting hedging potential for electricity futures trading. © 2020 Elsevier B.V., All rights reserved.","Monteiro, C.; Fernandez-Jimenez, L.A.; Ramírez-Rosado, I.J.",2020,10.3390/en13143555,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090803020&doi=10.3390%2Fen13143555&partnerID=40&md5=d51d140d7458a000e4c17bee11df1825,scopus
9e5453d40cead624,Price Forecast of Treasury Bond Market Yield: Optimize Method Based on Deep Learning Model,"Accurate forecasting of the treasury bond market is beneficial for financial institutions to formulate investment research strategies and for national managers to build a modern financial system. This paper integrates the ideas of improved multivariate time series sampling and deep learning prediction model structure optimization, and proposes an optimized deep learning model framework under the LASSO-SMLR-PCA machine learning method. Through the LASSO and SMLR methods, the multicollinearity of the multivariate time series is reduced and the variables with insignificant correlation coefficients are eliminated. Then, the PCA method is used for dimensionality reduction and reconstruction, and finally, the LSTM deep learning model with Bayesian optimized hyperparameters is used to achieve rolling time prediction of the treasury bond market yield price. The empirical results show that the optimized deep learning model performs excellently in terms of evaluation indicators for treasury bond yield price forecasting, with accurate curve fitting, efficient model structure, and stable and effective practical application.",W. Ping; Y. Hu; L. Luo,2024,10.1109/access.2024.3519438,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10806713,ieeexplore
fba39a36693c57bd,Pricing Asian and Barrier Options Using a Combined Heston Model and Monte Carlo Simulation Approach with Artificial Intelligence,"The computation of fair values for exotic options often necessitates complex pricing techniques, which remain sparsely addressed in academic literature. Predominantly, the assessment of fair value for vanilla options relies on methodologies such as the Black-Scholes model or Monte Carlo simulations. This study proposes an innovative, dynamic approach to pricing, leveraging artificial intelligence in conjunction with the Heston model and a Monte Carlo simulation engine. This approach aims to furnish estimates of the prices for Barrier and Asian options. To enhance the accuracy of the model, calibration was performed employing a supervised machine learning algorithm, a continuous risk-free curve, and a dynamic implied volatility surface, derived from the current market data of vanilla options on S&P 500 futures. The amalgamation of these models yields instantaneous pricing for exotic option derivatives, contingent on the investor's determination of time to maturity and barrier levels. The efficacy of the model was evaluated by comparing the output prices to theoretical model predictions and a selection of over-the-counter traded options. Our findings indicate that the proposed dynamic, integrated approach substantially reduces the disparity between the theoretical models and current market prices. The prices calculated by our model demonstrate a marginal error of merely 0.33% in comparison to market prices, a significant improvement over the considerably larger error of 3.12% exhibited by traditional models. © 2023 Elsevier B.V., All rights reserved.","Khalife, D.; Yammine, J.; Rahal, S.; Freiha, S.",2023,10.18280/mmep.100519,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175234385&doi=10.18280%2Fmmep.100519&partnerID=40&md5=dd008174b8ed9190c2398219abc45cbb,scopus
dcdafcb93551583e,Pricing Climate Change Exposure,"We estimate the risk premium for firm-level climate change exposure among S&P 500 stocks and its time-series evolution between 2005 to 2020. Exposure reflects the attention paid by market participants in earnings calls to a firm's climate-related risks and opportunities. When extracted from realized returns, the unconditional risk premium is insignificant but exhibits a period with a positive risk premium before the financial crisis and a steady increase thereafter. Forward-looking expected return proxies deliver an unconditionally positive risk premium with maximum values of 0.5%–1% p.a., depending on the proxy, between 2011 and 2014. The risk premium has been lower since 2015, especially when the expected return proxy explicitly accounts for the higher opportunities and lower crash risks that characterize high-exposure stocks. This finding arises as the priced part of the risk premium primarily originates from uncertainty about climate-related upside opportunities. In the time series, the risk premium is negatively associated with green innovation; Big Three holdings; and environmental, social, and governance fund flows and positively associated with climate change adaptation programs.","Sautner, Zacharias; van Lent, Laurence; Vilkov, Grigory; Zhang, Ruishen",2023,10.1287/mnsc.2023.4686,None,proquest
6414f68f51ea9ec4,Pricing Deflation Risk with US Treasury Yields,"We use an arbitrage-free term structure model with spanned stochastic volatility to determine the value of the deflation protection option embedded in Treasury inflation-protected securities. The model accurately prices the deflation protection option prior to the financial crisis when its value was near zero; at the peak of the crisis in late 2008 when deflationary concerns spiked sharply; and in the post-crisis period. During 2009, the average value of this option at the 5-year maturity was 41 basis points on a par-yield basis. The option value is shown to be closely linked to overall market uncertainty as measured by the VIX, especially during and after the 2008 financial crisis.","Christensen, Jens H. E.; Lopez, Jose A.; Rudebusch, Glenn D.",2016,10.1093/rof/rfv029,None,wos
488001700e2f9649,Pricing currency options with support vector regression and stochastic volatility model with jumps,"This paper presents an efficient currency option pricing model based on support vector regression (SVR). This model focuses on selection of input variables of SVR. We apply stochastic volatility model with jumps to SVR in order to account for sudden big changes in exchange rate volatility. We use forward exchange rate as the input variable of SVR, since forward exchange rate takes interest rates of a basket of currencies into account. Therefore, the inputs of SVR will include moneyness (spot rate/strike price), forward exchange rate, volatility of the spot rate, domestic risk-free simple interest rate, and the time to maturity. Extensive experimental studies demonstrate the ability of new model to improve forecast accuracy. © 2010 Elsevier Ltd. All rights reserved. © 2011 Elsevier B.V., All rights reserved.","Wang, P.",2011,10.1016/j.eswa.2010.05.037,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956613198&doi=10.1016%2Fj.eswa.2010.05.037&partnerID=40&md5=c18e5dcbda6e97cf6ca8e0968802b1d1,scopus
99d3511092b99d04,Pricing participating longevity-linked life annuities: a Bayesian Model Ensemble approach,"Participating longevity-linked life annuities (PLLA) in which benefits are updated periodically based on the observed survival experience of a given underlying population and the performance of the investment portfolio are an alternative insurance product offering consumers individual longevity risk protection and the chance to profit from the upside potential of financial market developments. This paper builds on previous research on the design and pricing of PLLAs by considering a Bayesian Model Ensemble of single population generalised age-period-cohort stochastic mortality models in which individual forecasts are weighted by their posterior model probabilities. For the valuation, we adopt a longevity option decomposition approach with risk-neutral simulation and investigate the sensitivity of results to changes in the asset allocation by considering a more aggressive lifecycle strategy. We calibrate models using Taiwanese (mortality, yield curve and stock market) data from 1980 to 2019. The empirical results provide significant valuation and policy insights for the provision of a cost effective and efficient risk pooling mechanism that addresses the individual uncertainty of death, while providing appropriate retirement income and longevity protection.Participating longevity-linked life annuities (PLLA) in which benefits are updated periodically based on the observed survival experience of a given underlying population and the performance of the investment portfolio are an alternative insurance product offering consumers individual longevity risk protection and the chance to profit from the upside potential of financial market developments. This paper builds on previous research on the design and pricing of PLLAs by considering a Bayesian Model Ensemble of single population generalised age-period-cohort stochastic mortality models in which individual forecasts are weighted by their posterior model probabilities. For the valuation, we adopt a longevity option decomposition approach with risk-neutral simulation and investigate the sensitivity of results to changes in the asset allocation by considering a more aggressive lifecycle strategy. We calibrate models using Taiwanese (mortality, yield curve and stock market) data from 1980 to 2019. The empirical results provide significant valuation and policy insights for the provision of a cost effective and efficient risk pooling mechanism that addresses the individual uncertainty of death, while providing appropriate retirement income and longevity protection.","Bravo, Jorge Miguel",2022,10.1007/s13385-021-00279-w,None,proquest
72f324761d5c5db3,Pricing real options based on linear loss functions and conditional value at risk,"The main purpose of this paper is to expand real option analysis out of the realm of pure financial option pricing techniques. To overcome many of the well-known concerns by adopting the financial option pricing techniques for modeling real options problems such as replicating portfolio concept, geometric Brownian motion as underlying stochastic process, and estimating project volatility, we propose an alternative real option valuation based on the loss function approach. The option value determined by the loss function approach is equivalent to the expected value of perfect information (EVPI) in decision analysis. It basically sets the upper bound of risk premium to pay in retaining the options. In practice, many firms utilize the concept of Value at Risk to manage their portfolio risk. If a firm sets a target VAR, then we may be able to link this VAR in refining the actual risk premium to pay in hedging the risk embedded in the investment. With this practice in mind, we present a logic to figure out an appropriate amount of real option premium to pay for a given level of risk tolerance. A comprehensive example is presented to demonstrate the computational procedures as well as economic interpretations on the outcomes.","Kim, Kyongsun; Park, Chan S.",2020,10.1080/0013791x.2020.1867273,None,wos
eb633e8b54bef901,Pricing the volatility risk premium with a discrete stochastic volatility model,"Investors’ decisions on capital markets depend on their anticipation and preferences about risk, and volatility is one of the most common measures of risk. This paper proposes a method of estimating the market price of volatility risk by incorporating both conditional heteroscedasticity and nonlinear effects in market returns, while accounting for asymmetric shocks. We develop a model that allows dynamic risk premiums for the underlying asset and for the volatility of the asset under the physical measure. Specifically, a nonlinear in mean time series model combining the asymmetric autoregressive conditional heteroscedastic model with leverage (NGARCH) is adapted for modeling return dynamics. The local risk-neutral valuation relationship is used to model investors’ preferences of volatility risk. The transition probabilities governing the evolution of the price of the underlying asset are adjusted for investors’ attitude towards risk, presenting the asset returns as a function of the risk premium. Numerical studies on asset return data show the significance of market shocks and levels of asymmetry in pricing the volatility risk. Estimated premiums could be used in option pricing models, turning options markets into volatility trading markets, and in measuring reactions to market shocks. © 2021 Elsevier B.V., All rights reserved.","Šimović, P.; Tafro, A.",2021,10.3390/math9172038,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114048678&doi=10.3390%2Fmath9172038&partnerID=40&md5=b61140065f8e83e82fbeffb2d275f40c,scopus
540bc036a5d2025b,Pricing with finite dimensional dependence,"We consider derivative pricing in factor models, where the factor is Markov with Finite Dimensional Dependence (FDD). The FDD condition allows for explicit formulas for derivative prices and their term structure and in this respect is a serious competitor of models with affine dynamic factors. The approach is illustrated by a comparison of the prices of realized and integrated volatility swaps. We show that the usual practice of replacing a payoff written on the realized volatility by the payoff written on the integrated volatility can imply pricing errors which are not negligible when the volatility of the volatility is large.","Gourieroux, C; Monfort, A",2015,10.1016/j.jeconom.2015.02.027,None,proquest
e8ba8666d5c2c61f,Probabilistic assessment of earthquake insurance rates for Turkey,"A probabilistic model is presented to obtain a realistic estimate of earthquake insurance rates for reinforced concrete buildings in Turkey. The model integrates information on seismic hazard and information on expected earthquake damage on engineering facilities in a systematic way, yielding to estimates of earthquake insurance premiums. In order to demonstrate the application of the proposed probabilistic method, earthquake insurance rates are computed for reinforced concrete buildings constructed in five cities located in different seismic zones of Turkey. The resulting rates are compared with the rates currently charged by the insurance companies. The earthquake insurance rates are observed to be sensitive to the assumptions on seismic hazard and damage probability matrices and to increase significantly with increasing violation of the code requirements. © Springer 2005. © 2008 Elsevier B.V., All rights reserved.","Yücemen, M.S.",2005,10.1007/s11069-004-6485-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-23844495206&doi=10.1007%2Fs11069-004-6485-8&partnerID=40&md5=bc0c07df0ae19c758040a226d34e044e,scopus
4f6e1d762f4cecb7,Probabilistic forecasts of volatility and its risk premia,"The object of this paper is to produce distributional forecasts of asset price volatility and its associated risk premia using a non-linear state space approach. Option and spot market information on the latent variance process is captured by using dual 'model-free' variance measures to define a bivariate observation equation in the state space model. The premium for variance diffusive risk is defined as linear in the latent variance (in the usual fashion) whilst the premium for variance jump risk is specified as a conditionally deterministic dynamic process, driven by a function of past measurements. The inferential approach adopted is Bayesian, implemented via a Markov chain Monte Carlo algorithm that caters for the multiple sources of non-linearity in the model and for the bivariate measure. The method is applied to spot and option price data on the S&P500 index from 1999 to 2008, with conclusions drawn about investors' required compensation for variance risk during the recent financial turmoil. The accuracy of the probabilistic forecasts of the observable variance measures is demonstrated, and compared with that of forecasts yielded by alternative methods. To illustrate the benefits of the approach, it is used to produce forecasts of prices of derivatives on volatility itself. In addition, the posterior distribution is augmented by information on daily returns to produce value at risk predictions. Linking the variance risk premia to the risk aversion parameter in a representative agent model, probabilistic forecasts of (approximate) relative risk aversion are also produced. All rights reserved, Elsevier","Maneesoonthorn, W; Martin, G M; Forbes, C S; Grose, S D",2012,10.1016/j.jeconom.2012.06.006,None,proquest
873e33706d751e55,Projected polynomial autoregression for prediction of stationary time series,"Polynomial autoregressions are usually considered to be unrealistic models for time series. However, this paper shows that they can successfully be used when the purpose of the time series study is to provide forecasts. A projection scheme inspired from projection pursuit regression and feedforward artificial neural networks is used in order to avoid an explosion of the number of parameters when considering a large number of lags. The estimation of the parameters of the projected polynomial autoregressions is a non-linear least-squares problem. A consistency result is proved. A simulation study shows that the naive use of the common final prediction error criterion is inappropriate to identify the best projected polynomial autoregression. An explanation of this phenomenon is given and a correction to the criterion is proposed. An important feature of the polynomial predictors introduced in this paper is their simple implementation, which allows for automatic use. This is illustrated with real data for the three-month US Treasury Bill. © 2017 Elsevier B.V., All rights reserved.","de Luna, X.",1998,10.1080/02664769822756,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032459211&doi=10.1080%2F02664769822756&partnerID=40&md5=134c8744849f235aaae3661b345458cd,scopus
2278b01d1d5eb032,Pseudo-True SDFs in Conditional Asset Pricing Models,"This article is motivated by the need to bridge some gap between modern asset pric-ing theory and recent developments in econometric methodology. While asset pric-ing theory enhances the use of conditional pricing models, econometric inference of conditional models can be challenging due to misspecification or weak identifica-tion. To tackle the case of misspecification, we utilize the conditional Hansen and Jagannathan (1997) (HJ) distance as studied by Gagliardini and Ronchetti (2016), but we set the focus on interpretation and estimation of the pseudo-true value defined as the argument of the minimum of this distance. While efficient Generalized Method of Moments (GMM) has no meaning for estimation of a pseudo-true value, the HJ-distance not only delivers a meaningful loss function, but also features an additional advantage for the interpretation and estimation of man-aged portfolios whose exact pricing characterizes the pseudo-true pricing kernel (stochastic discount factor (SDF)). For conditionally affine pricing kernels, we can display some managed portfolios which are well-defined independently of the pseudo-true value of the parameters, although their exact pricing is achieved by the pseudo-true SDF. For the general case of nonlinear SDFs, we propose a smooth minimum distance (SMD) estimator (Lavergne and Patilea, 2013) that avoids a focus on specific directions as in the case of managed portfolios. Albeit based on kernel smoothing, the SMD approach avoids instabilities and the resulting need of trim-ming strategies displayed by classical local GMM estimators when the density func-tion of the conditioning variables may take arbitrarily small values. In addition, the fact that SMD may allow fixed bandwidth asymptotics is helpful regarding the curse of dimensionality. In contrast with the true unknown value for a well-specified model, the estimated pseudo-true value, albeit defined in a time-invariant (uncondi-tional) way, may actually depend on the choice of the state variables that define fun-damental factors and their scaling weights. Therefore, we may not want to be overly parsimonious about the set of explanatory variables. Finally, following Antoine and Lavergne (2014), we show how SMD can be further robustified to deal with weaker identification contexts. Since SMD can be seen as a local extension of the method of jackknife GMM (Newey and Windmeijer, 2009), we characterize the Gaussian asymptotic distribution of the estimator of the pseudo-true value using classical U-statistic theorems.","Antoine, Bertille; Proulx, Kevin; Renault, Eric",2020,10.1093/jjfinec/nby017,None,wos
f036e158a35eaa38,Psychological Pathways to Fraud: Understanding and Preventing Fraud in Organizations,"In response to calls for more research on how to prevent or detect fraud (ACAP, Final Report of the Advisory Committee on the Auditing Profession, United States Department of the Treasury, Washington, DC, 2008; AICPA, SAS No. 99: Consideration of Fraud in a Financial Statement Audit, New York, NY, 2002; Carcello et al., Working Paper, University of Tennessee, Bentley University and Kennesaw State University, 2008; Wells, Journal of Accountancy, 2004), we develop a framework that identifies three psychological pathways to fraud, supported by multiple theories relating to moral intuition and disengagement, rationalization, and the role played by negative affect. The purpose of developing the framework is twofold: (1) to draw attention to important yet under-researched aspects of ethical decision-making, and (2) to increase our understanding of the psychology of committing fraud. Our framework builds on the existing fraud triangle (PCAOB, Consideration of fraud in a financial statement audit. AU Section 316, www.pcaobus.org, 2005) which is used by auditors to assess fraud risk. The fraud triangle is composed of three factors that, together, predict the likelihood of fraud within an organization: opportunity, incentive/pressure, and attitude/rationalization. We find that, when faced with the opportunity and incentive/pressure, there are three psychological pathways to fraud nestled within attitude/rationalization: (1) lack of awareness, (2) intuition coupled with rationalization, and (3) reasoning. These distinctions are important for fraud prevention because each of these paths is driven by a different psychological mechanism. This framework is useful in a number of ways. First, it identifies certain insidious situational factors in which individuals commit fraud without recognizing it. Second, it extends our knowledge of rationalization by theorizing that individuals use rationalization to avoid or reduce the negative affect that accompanies performing an unethical behavior. Negative affect is important because individuals wish to avoid it. Third, it identifies several other methods fraudsters use to reduce negative affect, each of which could serve as potential ""psychological red flags"" and helps predict future fraudulent behavior. Finally, our framework can be used as a theoretical foundation to explore several interventions designed to prevent fraud.[PUBLICATION ABSTRACT]","Murphy, Pamela R; Dacin, M Tina",2011,10.1007/s10551-011-0741-0,None,proquest
7eace64f85144252,"Public attention, sentiment and the default of Silicon Valley Bank","We assess the interplay between public attention and trading of the Silicon Valley Bank (SVB) stock before its default on March 10, 2023. Based on intra-day data in 15-min intervals, we estimate SVB market excess returns and match these with intra-day measures of investor attention based on the relative number of tweets and Google searches. Wavelet analysis reveals bilateral lead–lag patterns between both series and demonstrates that a higher level of attention led to a significant decrease in SVB returns. Thereby, the results provide evidence that Twitter sentiment and media attention ultimately fueled and accelerated the crash dynamics of Silicon Valley Bank. Economically, Twitter provides information at lower costs and higher effectiveness than newspapers and allows direct communication without potential distortions from media bias or timing lags in reporting. Hence, individuals can coordinate and communicate their run beliefs at a much faster pace, emphasizing the importance for financial stability. © 2023 Elsevier B.V., All rights reserved.","Bales, S.; Burghof, H.-P.",2024,10.1016/j.najef.2023.102026,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174724134&doi=10.1016%2Fj.najef.2023.102026&partnerID=40&md5=bbf65da12d42f5e1e21b99d3d0426f1b,scopus
f61f9aaf4b3a4dc3,Public debt stabilization: the relevance of policymakers' time horizons,"Policymakers are stuck in time. Political short-termism, policy myopia, policy short-sightedness, and similar words have been coined to emphasize the present-centric policy thinking. Politics tends to produce short time horizons, and as a result, policymakers often fail to use present opportunities to mitigate future harms. Focusing on fiscal and monetary strategic interactions, given different separate decision makers, our paper aims to explore the effects of policymakers' time horizons on debt stabilization. To formalize our ideas, we use the novel concept of Nonlinear-model-predictive-control Feedback Nash Equilibrium (NFNE) and find that present-centric policy thinking and decision horizons matters under several dimensions.","Di Bartolomeo, Giovanni; Di Pietro, Marco; Saltari, Enrico; Semmler, Willi",2018,10.1007/s11127-018-0584-7,None,wos
3dc61fee5d9bbaf9,Purebred or hybrid?: Reproducing the volatility in term structure dynamics,"This paper investigates the ability of mixtures of affine, quadratic, and non-linear models to track the volatility in the term structure of interest rates. Term structure dynamics appear to exhibit pronounced time varying or stochastic volatility. Ahn et al. (Rev. Financial Stud. xx (2001) xxx) provide evidence suggesting that term structure models incorporating a set of quadratic factors are better able to reproduce term structure dynamics than affine models, although neither class of models is able to fully capture term structure volatility. In this study, we combine affine, quadratic and non-linear factors in order to maximize the ability of a term structure model to generate heteroskedastic volatility. We show that this combination entails a tradeoff between specification of heteroskedastic volatility and correlations among the factors. By combining factors, we are able to gauge the cost of this tradeoff. Using efficient method of moments (Gallant and Tauchen, Econometric Theory 12 (1996) 657), we find that augmenting a quadratic model with a non-linear factor results in improvement in fit over a model comprised solely of quadratic factors when the model only has to confront first and second moment dynamics. When the full dynamics are confronted, this result reverses. Since the non-linear factor is characterized by stronger dependence of volatility on the level of the factor, we conclude that flexibility in the specification of both level dependence and correlation structure of the factors are important for describing term structure dynamics. © 2003 Elsevier B.V. All rights reserved. © 2008 Elsevier B.V., All rights reserved.","Ahn, D.-H.; Dittmar, R.F.; Gallant, A.R.; Gao, B.",2003,10.1016/s0304-4076(03)00106-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0346937479&doi=10.1016%2FS0304-4076%2803%2900106-4&partnerID=40&md5=ea1e59d19022c6cce6ceb6b3b72bdb0e,scopus
1f915ca874b0d1e8,Quadratic stochastic intensity and prospective mortality tables,"We consider a quadratic stochastic intensity model with a Gaussian autoregressive factor, derive explicit formulas for predictive mortality tables and recursive updating formulas are also provided. We also explain how to use appropriately the Kalman filter to estimate the parameters of the model and to approximate the values of the underlying factor. This methodology is applied to French human mortality tables. (C) 2008 Elsevier B.V. Ail rights reserved.","Gourieroux, C.; Monfort, A.",2008,10.1016/j.insmatheco.2008.05.010,None,wos
e80e3012da1e8609,QuantFactor REINFORCE: Mining Steady Formulaic Alpha Factors With Variance-Bounded REINFORCE,"Alpha factor mining aims to discover investment signals from the historical financial market data, which can be used to predict asset returns and gain excess profits. Powerful deep learning methods for alpha factor mining lack interpretability, making them unacceptable in the risk-sensitive real markets. Formulaic alpha factors are preferred for their interpretability, while the search space is complex and powerful explorative methods are urged. Recently, a promising framework is proposed for generating formulaic alpha factors using deep reinforcement learning, and quickly gained research focuses from both academia and industries. This paper first argues that the originally employed policy training method, i.e., Proximal Policy Optimization (PPO), faces several important issues in the context of alpha factors mining. Herein, a novel reinforcement learning algorithm based on the well-known REINFORCE algorithm is proposed. REINFORCE employs Monte Carlo sampling to estimate the policy gradient—yielding unbiased but high variance estimates. The minimal environmental variability inherent in the underlying state transition function, which adheres to the Dirac distribution, can help alleviate this high variance issue, making REINFORCE algorithm more appropriate than PPO. A new dedicated baseline is designed to theoretically reduce the commonly suffered high variance of REINFORCE. Moreover, the information ratio is introduced as a reward shaping mechanism to encourage the generation of steady alpha factors that can better adapt to changes in market volatility. Evaluations on real assets data indicate the proposed algorithm boosts correlation with returns by 3.83%, and a stronger ability to obtain excess returns compared to the latest alpha factors mining methods, which meets the theoretical results well.",J. Zhao; C. Zhang; M. Qin; P. Yang,2025,10.1109/tsp.2025.3576781,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11024173,ieeexplore
c2f42ac2b768296a,Quantitative assessment of common practice procedures in the fair evaluation of embedded options in insurance contracts,"This work analyses the common industry practice used to evaluate financial options written on with profit policies issued by European insurance companies. In the last years regulators introduced, with the Solvency II directive, a market consistent valuation framework for determining the fair value of asset and liabilities of insurance funds. A relevant aspect is how to deal with the estimation of sovereign credit and liquidity risk, that are important components in the valuation of the majority of insurance funds, which are usually heavily invested in treasury bonds. The common practice is the adoption of the certainty equivalent approach (CEQ) for the risk neutral evaluation of insurance liabilities, which results in a deterministic risk adjustment of the securities cash flows. In this paper, we propose an arbitrage free stochastic model for interest rate, credit and liquidity risks, that takes into account the dependences between different government bond issuers. We test the impact of the common practice against our proposed model, via Monte Carlo simulations. We conclude that in the estimation of options whose pay-off is determined by statutory accounting rules, which is often the case for European traditional with-profit insurance products, the deterministic adjustment for risk of the securities cash flows is not appropriate, and that a more complete model such as the one described in this article is a viable and sensible alternative in the context of market consistent evaluations. (C) 2017 Elsevier B.V. All rights reserved.","Gambaro, Anna Maria; Casalini, Riccardo; Fusai, Gianluca; Ghilarducci, Alessandro",2018,10.1016/j.insmatheco.2017.10.005,None,wos
457adc903852506e,Quantitative law describing market dynamics before and after interest-rate change,"We study the behavior of U.S. markets both before and after U.S. Federal Open Market Commission meetings and show that the announcement of a U.S. Federal Reserve rate change causes a financial shock, where the dynamics after the announcement is described by an analog of the Omori earthquake law. We quantify the rate n(t) of aftershocks following an interest-rate change at time T and find power-law decay which scales as n(t-T) similar to (t-T)(-Omega), with Omega positive. Surprisingly, we find that the same law describes the rate n'(vertical bar t-T vertical bar) of preshocks before the interest-rate change at time T. This study quantitatively relates the size of the market response to the news which caused the shock and uncovers the presence of quantifiable preshocks. We demonstrate that the news associated with interest-rate change is responsible for causing both the anticipation before the announcement and the surprise after the announcement. We estimate the magnitude of financial news using the relative difference between the U.S. Treasury Bill and the Federal Funds effective rate. Our results are consistent with the sign effect, in which bad news has a larger impact than good news. Furthermore, we observe significant volatility aftershocks, confirming a market under-reaction that lasts at least one trading day.","Petersen, Alexander M.; Wang, Fengzhong; Havlin, Shlomo; Stanley, H. Eugene",2010,10.1103/physreve.81.066121,None,wos
dda1dd80242b5cb3,Quasi-likelihood estimation of a threshold diffusion process,"The threshold diffusion process, first introduced by Tong (1990), is a continuous-time process satisfying a stochastic differential equation with a piecewise linear drift term and a piecewise smooth diffusion term, e.g., a piecewise constant function or a piecewise power function. We consider the problem of estimating the (drift) parameters indexing the drift term of a threshold diffusion process with continuous-time observations. Maximum likelihood estimation of the drift parameters requires prior knowledge of the functional form of the diffusion term, which is, however, often unavailable. We propose a quasi-likelihood approach for estimating the drift parameters of a two-regime threshold diffusion process that does not require prior knowledge about the functional form of the diffusion term. We show that, under mild regularity conditions, the quasi-likelihood estimators of the drift parameters are consistent. Moreover, the estimator of the threshold parameter is super consistent and weakly converges to some non-Gaussian continuous distribution. Also, the estimators of the autoregressive parameters in the drift term are jointly asymptotically normal with distribution the same as that when the threshold parameter is known. The empirical properties of the quasi-likelihood estimator are studied by simulation. We apply the threshold model to estimate the term structure of a long time series of US interest rates. The proposed approach and asymptotic results can be readily lifted to the case of a multi-regime threshold diffusion process.","Su, Fei; Chan, Kung-sik",2015,10.1016/j.jeconom.2015.03.038,None,proquest
d59e983e8c52c31d,RETRACTED: Wheat Futures Prices Prediction in China: A Hybrid Approach (Retracted Article),"Stocks markets play their financial roles of price shocks and hedging just when they are proficient. The imperative highlights of productive market are that one cannot make extraordinary profit from the stocks markets. This research investigates whether China wheat futures price can be predicted by employing artificial intelligence neural network. This would add to our knowledge whether wheat futures market is resourceful and would enable traders, sellers, and investors to improve cost-effective trading strategy. We utilize the traditional financial model to forecast the wheat futures price and acquire out of sample point estimates. We additionally assess the robustness of our outcomes by applying several alternative forecasting techniques such as artificial intelligence with one hidden layer and autoregressive integrated moving average (ARIMA) model. Furthermore, the statistical significance of our point estimation was further tested through the Mariano and Diebold test. Considering random walk forecast as the bench mark, we used a number of economic indicators, trader's expectation towards futures prices, and lagged value of futures price of wheat in order to forecast the evaluation of wheat futures price. The computable significance of out of sample estimations recommends that our ANN with one hidden layer has the best anticipating presentation among all the models considered in this exploration and has the estimating power in foreseeing wheat futures returns. Furthermore, this investigation discovers that the futures price of wheat can be predicted, and the wheat futures market of China is not productive.","Sun, Yunpeng; Guo, Jin; Shan, Shan; Khan, Yousaf Ali",2021,10.1155/2021/5545802,None,wos
002bc07ecf503c9e,Radial Basis Functions With Adaptive Input and Composite Trend Representation for Portfolio Selection,"We propose a set of novel radial basis functions with adaptive input and composite trend representation (AICTR) for portfolio selection (PS). Trend representation of asset price is one of the main information to be exploited in PS. However, most state-of-the-art trend representation-based systems exploit only one kind of trend information and lack effective mechanisms to construct a composite trend representation. The proposed system exploits a set of RBFs with multiple trend representations, which improves the effectiveness and robustness in price prediction. Moreover, the input of the RBFs automatically switches to the best trend representation according to the recent investing performance of different price predictions. We also propose a novel objective to combine these RBFs and select the portfolio. Extensive experiments on six benchmark data sets (including a new challenging data set that we propose) from different real-world stock markets indicate that the proposed RBFs effectively combine different trend representations and AICTR achieves state-of-the-art investing performance and risk control. Besides, AICTR withstands the reasonable transaction costs and runs fast; hence, it is applicable to real-world financial environments.",Z. -R. Lai; D. -Q. Dai; C. -X. Ren; K. -K. Huang,2018,10.1109/tnnls.2018.2827952,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356708,ieeexplore
8b07c85a311ecc17,Rare Disasters and Risk Attitudes: International Differences and Implications for Integrated Assessment Modeling,"Evaluation of public policies with uncertain economic outcomes should consider society's preferences regarding risk. However, the preference models used in most integrated assessment models, including those commonly used to inform climate policy, do not adequately characterize the risk attitudes revealed by typical investment decisions. Here, we adopt an empirical approach to risk preference description using international historical data on investment returns and the occurrence of rare economic disasters. We improve on earlier analyses by employing a hierarchical Bayesian inference procedure that allows for nation-specific estimates of both disaster probabilities and preference parameters. This provides a stronger test of the underlying investment model than provided by previous calibrations and generates some compelling hypotheses for further study. Specifically, results suggest that society is substantially more averse to risk than typically assumed in integrated assessment models. In addition, there appear to be systematic differences in risk preferences among nations. These results are likely to have important implications for policy recommendations: higher aversion to risk increases the precautionary value of taking action to avoid low-probability, high-impact outcomes. However, geographically variable attitudes toward risk indicate that this precautionary value could vary widely across nations, thereby potentially complicating the negotiation of transboundary agreements focused on risk reduction. © 2012 Society for Risk Analysis. © 2013 Elsevier B.V., All rights reserved.; MEDLINE® is the source for the MeSH terms of this document.","Ding, P.; Gerst, M.D.; Bernstein, A.; Howarth, R.B.; Borsuk, M.E.",2012,10.1111/j.1539-6924.2012.01872.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869495004&doi=10.1111%2Fj.1539-6924.2012.01872.x&partnerID=40&md5=3d9232bba36bfd98b20035479434effc,scopus
ed37a20f156d7385,Rating Crop Insurance Contracts with Nonparametric Bayesian Model Averaging,Crop insurance is plagued by relatively little historical information but significant spatial information. We investigate the efficacy of using nonparametric Bayesian model averaging (BMA) to incorporate extraneous information into the estimated premium rates. Nonparametric BMA is particularly suited to this application because it does not make any assumptions about parametric form or the extent to which yields are similar. We evaluate the proposed estimator under small-to-medium sample sizes and various geographical restrictions on the distance of spatial smoothing for policy relevance. The nonparametric BMA consistently decreases error and enables statistically significant and economically important rents to be captured.,"Liu, Yong; Ker, Alan P",2020,10.22004/ag.econ.302453,None,proquest
4ca5e1c5b38940ea,Rational overoptimism and limited liability,"Is excessive risk-taking in credit cycles driven by incentives or biased beliefs? I propose a framework suggesting that the two are actually related and, specifically, that procyclical overoptimism can arise rationally from risk-taking incentives. I show that when firms and banks have a limited liability payoff structure, they have lower incentives to pay attention to the aggregate conditions that generate risk. This leads to systematic underestimation of the accumulation of risk during economic booms and overoptimistic beliefs. As a result, agents lend and borrow excessively, further increasing downside risk. Credit cycles driven by this new “uninformed” risk-taking are consistent with existing evidence such as high credit and low-risk premia predicting a higher probability of crises and negative returns for banks. My model suggests that regulating incentives can decrease overoptimistic beliefs and thus mitigate boom-and-bust cycles. © 2024 Elsevier B.V., All rights reserved.","Gemmi, L.",2024,10.1016/j.jmoneco.2023.11.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176101825&doi=10.1016%2Fj.jmoneco.2023.11.002&partnerID=40&md5=7c53bdf5beda43dd6dbaec5930afffaf,scopus
b042472b0d9b86fb,Re-examination of the predictability of economic activity using the yield spread: A nonlinear approach,"This paper examines the feasibility of using the term structure of nominal interest rates in empirical predictive relationships with future real activity growth serving as the dependent variable. In particular, we will focus on the strength and stability of the spread-output relationship. We employ smooth transition nonlinear models that can accommodate (a) regime switching type nonlinear behaviour and (b) time-varying parameters. We verify that the link exhibits strong threshold effects with respect to near past spread values implying that the relation is sufficiently strong in economic terms if past spread values did not exceed a positive threshold value. Furthermore, we are able to explicitly model time-variation in the preceding effects reaching the conclusion that the importance of the spread as an output predictor has been significantly diminished if not eradicated during recent years. The timing of the change in the information content of the spread appears to be related to a turn in certain monetary policy practices, in particular, the turn towards stronger inflation targeting practices. © 2002 Elsevier Science Inc. All rights reserved. © 2004 Elsevier Science B.V., Amsterdam. All rights reserved.","Venetis, I.A.; Paya, I.; Peel, D.A.",2003,10.1016/s1059-0560(02)00147-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037278128&doi=10.1016%2FS1059-0560%2802%2900147-8&partnerID=40&md5=4669263ed695d853f5f4317c4773535b,scopus
eae365d7b19c2a45,Real economic activity leading indicators: should we have paid more attention?,"The ability to predict business cycle activity is an invaluable skill for governments and policy makers alike, especially before an economy enters a downturn. We analyse causality relationships between key leading economic indicators and economic growth for three countries from 1970 to 2010. We find that while many indicators do not help explain current movements in GDP growth, lags of these indicators do. In addition, the direction of the change and the size of the change in the lagged economic indicators are very important in many cases. This is particularly true for housing indicators.","Ryan, Geraldine; Shinnick, Edward",2011,10.1080/17487870.2011.577645,None,wos
7098321857875dd1,Real estate climate index and aggregate stock returns: Evidence from China,"We show that China's real estate climate index (RECI) can be used to forecast the aggregate stock market return. It outperforms popular return predictors both in- and out-of-sample, especially at the monthly horizon. Additionally, RECI's predictive ability is stronger among stocks of small market capitalization and low momentum. For a typical mean-variance investor, RECI's predictive power may provide an additional utility gain of 3.41%. We discuss three potential sources of RECI's predictive ability and present the corresponding evidence, including the cash flow channel, the firm fundamental channel, and the investment substitution channel.","Jiang, Yuexiang; Fu, Tao; Long, Huaigang; Zaremba, Adam; Zhou, Wenyu",2022,10.1016/j.pacfin.2022.101841,None,wos
9f0348c54278ded0,Real-time Bayesian learning and bond return predictability,"The paper examines statistical and economic evidence of out-of-sample bond return predictability for a real-time Bayesian investor who learns about parameters, hidden states, and predictive models over time. We find some statistical evidence using information contained in forward rates. However, such statistical predictability can hardly generate any economic value for investors. Furthermore, we find that strong statistical and economic evidence of bond return predictability from fully-revised macroeconomic data vanishes when real-time macroeconomic information is used. We also show that highly levered investments in bonds can improve short-run bond return predictability. (C) 2021 Elsevier B.V. All rights reserved.","Wan, Runqing; Fulop, Andras; Li, Junye",2022,10.1016/j.jeconom.2020.04.052,None,wos
0b400ac015e33b86,Recent empirical evidence on the impact of the primary budget deficit on nominal longer term treasury note interest rate yields,"This study empirically investigates the impact of the federal budget deficit on the nominal interest rate yields on seven and ten year treasury notes over the 1992-2003 period. To measure the budget deficit, the primary budget deficit, which excludes net interest payments by the treasury, is adopted. In a loanable funds model that includes the monetary base, expected inflation, an ex ante real short term interest rate yield and an ex ante real intermediate term interest rate yield, the percentage growth rate of real GDP, and the percentage growth rate of the S&P 500 stock index, instrumental variables estimations using quarterly data reveal that the primary deficit has raised the nominal interest rate yields on both seven year and ten year treasury notes over the study period, raising serious concerns about the currently surging national debt.","Cebula, Richard J",2005,10.1504/gber.2005.006919,None,proquest
d709c1992299932e,Reconciling interest rates evidence with theory: Rejecting unit roots when the HD(1) is a competing alternative,"The paper introduces the HD(1), a Markovian process of order one with reversion rates that are faster the farther the process is from equilibrium. The aHD(1) approximation is introduced to allow for an estimation -calibration procedure based on available ARMA routines. Critical values of unit root tests with aHD(1) alternative are tabulated for the signed likelihood -ratio statistic. Revisiting the non-stationarity of interest rates stylized fact, the aHD(1) is found to be preferred to ARMA, SETAR and RCA and the resulting tests to reject the unit root hypothesis for all rates and yields considered.","Palandri, Alessandro",2024,10.1016/j.jbankfin.2024.107113,None,wos
4ab5048307f07e1c,Recovering Yield Curves from Dynamic Term Structure Models with Time-Varying Factors,"A dynamic version of the Nelson-Siegel-Svensson term structure model with time-varying factors is considered for predicting out-of-sample maturity yields. Simple linear interpolation cannot be applied to recover yields at the very short- and long- end of the term structure where data are often missing. This motivates the use of dynamic parametric term structure models that exploit both time series and cross-sectional variation in yield data to predict missing data at the extreme ends of the term structure. Although the dynamic Nelson–Siegel–Svensson model is weakly identified when the two decay factors become close to each other, their predictions may be more accurate than those from more restricted models depending on data and maturity. © 2024 Elsevier B.V., All rights reserved.","Kawakatsu, H.",2020,10.3390/stats3030020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138041887&doi=10.3390%2Fstats3030020&partnerID=40&md5=745ede452bb52fd755252d659d8e40c8,scopus
0a7b16e8ef5ab3d7,Recovering default risk from CDS spreads with a nonlinear filter,"We propose a nonlinear filter to estimate the time-varying default risk from the term structure of credit default swap (CDS) spreads. Based on the numerical solution of the Fokker-Planck equation (FPE) using a meshfree interpolation method, the filter performs a joint estimation of the risk-neutral default intensity and CIR model parameters. As the FPE can account for nonlinear functions and non-Gaussian errors, the proposed framework provides outstanding flexibility and accuracy. We test the nonlinear filter on simulated spreads and apply it to daily CDS data of the Dow Jones Industrial Average component companies from 2005 to 2010 with supportive results. © 2013 Elsevier B.V. © 2013 Elsevier B.V., All rights reserved.","Guarín, A.; Liu, X.; Ng, W.L.",2014,10.1016/j.jedc.2013.09.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890117707&doi=10.1016%2Fj.jedc.2013.09.006&partnerID=40&md5=abd3e9e9a830f35514ed25356804906c,scopus
187d1db1c854c026,Recovering the probability density function of asset prices using garch as diffusion approximations,"This paper uses Garch models to estimate the objective and risk-neutral density functions of financial asset prices and by comparing their shapes, recover detailed information on economic agents' attitudes toward risk. It differs from recent papers investigating analogous issues because it uses Nelson's result that Garch schemes are approximations of the kind of differential equations typically employed in finance to describe the evolution of asset prices. This feature of Garch schemes usually has been overshadowed by their well-known role as simple econometric tools providing reliable estimates of unobserved conditional variances. We show instead that the diffusion approximation property of Garch gives good results and can be extended to situations with (i) non-standard distributions for the innovations of a conditional mean equation of asset price changes and (ii) volatility concepts different from the variance. The objective PDF of the asset price is recovered from the estimation of a nonlinear Garch fitted to the historical path of the asset price. The risk-neutral PDF is extracted from cross-sections of bond option prices, after introducing a volatility risk premium function. The direct comparison of the shapes of the two PDF<inf>s</inf> reveals the price attached by economic agents to the different states of nature. Applications are carried out with regard to the futures written on the Italian 10-year bond. © 2001 Elsevier Science B.V. © 2005 Elsevier Science B.V., Amsterdam. All rights reserved.","Fornari, F.; Mele, A.",2001,10.1016/s0927-5398(01)00021-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041830388&doi=10.1016%2FS0927-5398%2801%2900021-4&partnerID=40&md5=19f6c9e38044f3279ef58d4ab148d647,scopus
0eff708fe81a1f18,Recursive bayesian estimation in forward price models implied by fair pricing,"In this paper we describe a recursive Bayesian algorithm for the estimation of forward price models. The forward price is modeled within the benchmark framework for a forward price volatility function which includes a stochastic variable; a forward price with a liquidly traded maturity. A relationship between the bond price, the spot price and certain forward prices is stated. We set up the stochastic real world dynamics for these discretely compounded market observed forward prices. We propose a dynamic Bayesian estimation algorithm for a Monte Carlo time-discretized version of the resulting forward prices dynamics. The parameter to be estimated is a vector consisting of the forward price volatility parameters and the benchmarked bond price volatility parameters. © 2010 World Scientific Publishing Company. © 2010 Elsevier B.V., All rights reserved.","El Qalli, Y.",2010,10.1142/s0219024910005784,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952516296&doi=10.1142%2FS0219024910005784&partnerID=40&md5=5245caaa7c31ebe7cd25a2cde564d272,scopus
32ae7d077ced29f9,Reducing Waiting Times to Improve Patient Satisfaction: A Hybrid Strategy for Decision Support Management,"Patient satisfaction and operational efficiency are critical in healthcare. Long waiting times negatively affect patient experience and hospital performance. Addressing these issues requires accurate system time predictions and actionable strategies. This paper presents a hybrid framework combining predictive modeling and optimization to reduce system times and enhance satisfaction, focusing on registration, vitals, and doctor consultation. We evaluated three predictive models: multiple linear regression (MLR), log-transformed regression (LTMLR), and artificial neural networks (ANN). The MLR model had the best performance, with an (Formula presented.) of 0.93, an MAE of 7.29 min, and an RMSE of 9.57 min. MLR was chosen for optimization due to its accuracy and efficiency, making it ideal for implementation. The hybrid framework combines the MLR model with a simulation-based optimization system to reduce waiting and processing times, considering resource constraints like staff and patient load. Simulating various scenarios, the framework identifies key bottlenecks and allocates resources effectively. Reducing registration and doctor consultation wait times were identified as primary areas for improvement. Efficiency factors were applied to optimize waiting and processing times. These factors include increasing staff during peak hours, improving workflows, and automating tasks. As a result, registration wait time decreased by 15%, vitals by 20%, and doctor consultation by 25%. Processing times improved by 10–15%, leading to an average reduction of 22.5 min in total system time. This paper introduces a hybrid decision support system that integrates predictive analytics with operational improvements. By combining the MLR model with simulation, healthcare managers can predict patient times and test strategies in a risk-free, simulated environment. This approach allows real-time decision-making and scenario exploration without disrupting operations. This methodology highlights how reducing waiting times has a direct impact on patient satisfaction and hospital operational efficiency, offering an applicable solution that does not require significant structural changes. The results are practical and implementable in resource-constrained healthcare environments, allowing for optimized staff management and patient flow. © 2024 Elsevier B.V., All rights reserved.","Morales, J.; Silva-Aravena, F.; Sáez, P.",2024,10.3390/math12233743,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211951995&doi=10.3390%2Fmath12233743&partnerID=40&md5=e8a747b3971e274a71c35b49e1f544cf,scopus
807af38ea69ef2a4,Reducing the cost of capital to finance the energy transition in developing countries,"Climate stabilization requires the mobilization of substantial investments in low- and zero-carbon technologies, especially in emerging and developing economies. However, access to stable and affordable finance varies dramatically across countries. Models used to evaluate the energy transition do not differentiate regional financing costs and therefore cannot study risk-sharing mechanisms for renewable electricity generation. In this study, we incorporated the empirically estimated cost of capital differentiated by country and technology into an ensemble of five climate–energy–economy models. We quantified the additional financing cost of decarbonization borne by developing regions and explored policies of risk premium convergence across countries. We found that alleviating financial constraints benefits both climate and equity as a result of more renewable and affordable energy in the developing world. This highlights the importance of fair finance for energy availability, affordability and sustainability, as well as the need to include financial considerations in model-based assessments.Fair finance in the energy sector is modelled in five climate–energy–economy models. The results show that convergence costs of capital could improve energy availability, affordability and sustainability in developing countries, thereby increasing the international equity of the energy transition.","Calcaterra, M.; Aleluia Reis, L.; Fragkos, P.; Briera, T.; de Boer, H. S.; Egli, F.; Emmerling, J.; Iyer, G.; Mittal, S.; Polzin, F. H. J.; Sanders, M. W. J. L.; Schmidt, T. S.; Serebriakova, A.; Steffen, B.; van de Ven, D. J.; van Vuuren, D. P.; Waidelich, P.; Tavoni, M.",2024,10.1038/s41560-024-01606-7,None,proquest
4e8eda2d3ff61821,Regime Changes and Financial Markets,"Regime-switching models can match the tendency of financial markets to often change their behavior abruptly and the phenomenon that the new behavior of financial variables often persists for several periods after such a change. Although the regimes captured by regime-switching models are identified by an econometric procedure, they often correspond to different periods in regulation, policy, and other secular changes. In empirical estimates, the means, volatilities, autocorrelations, and cross-covariances of asset returns often differ across regimes in a manner that allows regime-switching models to capture the stylized behavior of many financial series including fat tails, heteroskedasticity, skewness, and time-varying correlations. In equilibrium models, regimes in fundamental processes, such as consumption or dividend growth, strongly affect the dynamic properties of equilibrium asset prices and can induce non-linear risk-return trade-offs. Regime switches also lead to potentially large consequences for investors' optimal portfolio choice.","Ang, Andrew; Timmermann, Allan",2012,10.1146/annurev-financial-110311-101808,None,wos
c47d7837392e4b40,Regime-specific exchange rate predictability,"We study temporary phases of exchange rate predictability in a two-regime threshold predictive regression framework allowing for persistent predictors. Regime switches are triggered by an observable transition variable which relates to media news, expectations, uncertainty and global financial conditions. As predictors for G7 currencies and effective US-Dollar exchange rates, we study various interest rate spreads, yield curve factors, uncertainty measures and deviations from fundamental exchange rate parities. Besides established uncertainty measures, we use a wide range of measures for media coverage and construct uncertainty measures from survey data as transition variables for the activation of the predictability regime. Our results emphasize that short recurring phases of significant predictability are characterized by nonlinear patterns. Phases of predictability are triggered by increased media coverage and high uncertainty with interest rate dynamics emerging as the most important predictor. We find broadly similar results for a contemporaneous threshold analysis where our regressors are allowed to affect the exchange rate in the same period. From a theoretical point of view, we argue that our empirical results are useful for the empirical identification of scapegoat effects and that media coverage and uncertainty affect the exchange rate via the heterogeneity of private signals and the precision of public signals. © 2025 Elsevier B.V., All rights reserved.","Beckmann, J.; Kerkemeier, M.; Kruse, R.",2025,10.1016/j.jedc.2025.105095,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003202194&doi=10.1016%2Fj.jedc.2025.105095&partnerID=40&md5=1f794f64bc449a52a369b9e0c25980fb,scopus
3aba891800eef614,Relationship between expected treasury bill and Eurodollar interest rates: A fractional cointegration analysis,"In this paper, we extend Booth and Tse's (BT) 1995 analysis of fractional cointegration between the expected Eurodollar and Treasury bill interest rates implied by their respective futures contracts. The definition of fractional cointegration suggested by Cheung and Lai (1993) and used by BT is refined so that it requires the cointegrating relationship to be stationary as well as mean-reverting. In addition to the Geweke and Porter-Hudak method used by BT, a more efficient Maximum Likelihood (ML) method is used to estimate the cointegrating relationship. The LM (Engle (1982)) test indicates the possible existence of a heteroscedastic cointegrating relationship. Therefore, we use heteroscedastic models (GARCH and Exponential GARCH) to represent the cointegrating regression instead of the simple homoscedastic model used by BT. The empirical evidence cannot reject the null hypothesis of a stationary fractional cointegration relationship between the Eurodollar and Treasury bill interest rates. © 2001 Kluwer Academic Publishers. © 2018 Elsevier B.V., All rights reserved.","Shrestha, K.; Welch, R.L.",2001,10.1023/a:1008340408261,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846540251&doi=10.1023%2FA%3A1008340408261&partnerID=40&md5=899be94c4ad1bef4c2b113c4e3aaee7f,scopus
b6b4724b4c40c57d,Removing Bias in Estimating Financial Contagion: An Empirical Analysis Based on European Economies,"The degree of contagion is frequently measured by the size and significance of linear correlation coefficients. In this paper, we show that such linear measures are inappropriate for three reasons: contagion is likely to be nonlinear, the structural contagion model is unknown, and the contagion itself will be time-varying. Instead, we use a time-varying coefficient method to give a time-varying, unbiased measure of bilateral contagion between two countries, which shows that simple correlation measures over-estimate the average contagion from the source country and how the degree of contagion varies over the sample period. To illustrate, we use Greece as an exemplar source country and Belgium, France, Italy, Ireland, Netherlands, Portugal, and Spain as recipient countries over the period 2009 to 2022.","Du, Wenti; Pentecost, Eric; Bird, Graham",2025,10.1007/s11079-024-09788-z,None,proquest
fcef337c3b0fa757,Renewable integration and energy storage management and conversion in grid systems: A comprehensive review,"The dynamic behaviours of battery energy storage systems (BESSs) make their cutting-edge technology for power grid applications. A BESS must have a Battery Management System (BMS) for dependable, efficient, and risk-free operation. With an emphasis on BESSs and the control strategies for their state-of-charge (SoC) balancing, this article thoroughly reviews energy storage systems (ESSs) on a grid scale. It delves into the future of grid-scale BESSs and the function of ESS, focusing on Li-ion battery systems and drawing attention to the essential features and integration hurdles of Li-ion cells. This review examines the many sides, specifically the cost-benefit analysis, operational efficiencies, and financial incentives that push people to use ESSs. To further improve energy storage and utilization, the article delves into managing hybrid storage systems, which combine photovoltaics (PV), batteries, and supercapacitors. Innovative solutions and technological advancements are the main focus of this examination of current trends in power conversion systems (PCS) associated with BESSs. Finally, future developments in energy storage technology are discussed and how they could solve current problems while making the grid more stable and reliable.","Ahmad, Ashraf Bani; Ooi, Chia Ai; Ali, Omer; Charin, Chanuri; Maharum, Siti Marwangi Mohamad; Swadi, Mahmood; Salem, Mohamed",2025,10.1016/j.egyr.2025.02.008,None,wos
8239e0ec15a172c7,Research on Early Warning of Banking Crises from the Perspective of Credit Structures,"The relationship between credit expansion and banking crises is complex and cannot be fully explained by total credit alone. A systematic analysis of the relationship between the amount and structure of total credit and banking crises is important for an objective prediction of the influence of potential financial risks. This paper, drawing on data from 15 selected countries, delves into the power of credit indicators in the early warning of banking crises from the perspectives of industrial structure, sector structure, and term structure of credit. Various machine learning methods were used, including Logistic Regression, Random Forest, Decision Tree, Support Vector Machine (SVM), Bagging, and Boosting models. The empirical findings indicate that credit expansion plays a crucial role in triggering banking crises. However, total credit is better suited for the early warning of short-term banking crises, whereas credit structure is more useful for the early warning of long-term banking crises. Moreover, in an early warning system, identifying key early warning indicators is more meaningful than merely increasing the number of indicators. Machine learning can somewhat enhance the early warning power, but it may not always be robust. Therefore, more attention should be paid to potential systemic banking crises resulting from an imbalance in credit structure while regulating the total credit threshold. © 2024 Elsevier B.V., All rights reserved.","Yuqin, Z.; Zixuan, L.; Wu, W.",2024,10.19873/j.cnki.2096-0212.2024.03.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210133695&doi=10.19873%2Fj.cnki.2096-0212.2024.03.003&partnerID=40&md5=0337e2a748df7f5e03df0a89befbb474,scopus
3d3ecb8e3712fdf1,Research on Financial Stock Market Prediction Based on the Hidden Quantum Markov Model,"Quantum finance, as a key application scenario of quantum computing, showcases multiple significant advantages of quantum machine learning over traditional machine learning methods. This paper first aims to overcome the limitations of the hidden quantum Markov model (HQMM) in handling continuous data and proposes an innovative method to convert continuous data into discrete-time sequence data. Second, a hybrid quantum computing model is developed to forecast stock market trends. The model was used to predict 15 stock indices from the Shanghai and Shenzhen Stock Exchanges between June 2018 and June 2021. Experimental results demonstrate that the proposed quantum model outperforms classical algorithmic models in handling higher complexity, achieving improved efficiency, reduced computation time, and superior predictive performance. This validation of quantum advantage in financial forecasting enables the practical deployment of quantum-inspired prediction models by investors and institutions in trading environments. This quantum-enhanced model empowers investors to predict market regimes (bullish/bearish/range-bound) using real-time data, enabling dynamic portfolio adjustments, optimized risk controls, and data-driven allocation shifts.","Song Xingyao; Chen, Wenyu; Lu, Junyi",2025,10.3390/math13152505,None,proquest
dc4e0aa73eaa51f7,Research on RMB exchange rate forecast based on the neural network model and the Nelson–Siegel model,"This paper expands the neural network model to predict exchange rate based on the factors extracted from the Nelson–Siegel model. Based on the theory about exchange rate forecasting, interest could be used to predict the movement of exchange rate. Therefore, this paper analyzes the interest rate term structure factors based on the US and China yield curves data, then uses the Nelson–Siegel model to extract the factors of the interest rate term structure. Finally, the factors of yield curves are used as input data to of the neural network model. And the mean forecasting squared errors, mean absolute errors, mean absolute percentage errors of neural network model, Nelson–Siegel regression model, and ARIMA model are compared. The results show that the neural network model has a superior ability to explain the exchange rate fluctuations of the CNY and USD, and the prediction ability is better than the exchange rate prediction ability of the Nelson–Siegel regression model and ARIMA model.",Hua Rui; Hu Wenzhe; Zhao Xiuju,2020,10.1057/s41283-020-00062-3,None,proquest
b46293a022ea475b,Research on characterization and prediction of bond risk factors based on machine learning: evidence from the China,"Introduction: The scale of default on credit bonds in China has been expanding. Credit bond defaults not only increase the financing costs of enterprises but also affect the efficiency of debt issuance and even lead to the spread of risks in the financial market. Accurately identifying bond default risks, clarifying the characteristics of bond defaults, and understanding the default risk mechanism are of crucial importance. Methods: This paper takes corporate credit bonds as the research object and analyzes bond defaults from both macro and micro perspectives. From a macro perspective, it confirms the logical transmission between macro factors and bond defaults through causal relationships and grasps the overall characteristics of bond defaults by combining association rule mining and descriptive statistical research methods. Bonds are divided into a risk-free bond group and a risky bond group, and association rules are mined in four dimensions: the bond issuance region of the enterprise, whether the issuer is listed, the attributes of the issuing enterprise, and whether the enterprise bond is guaranteed. Based on these rules, a cross-analysis of bond risk factors is conducted. From a micro perspective, taking each bond as the research object, a bond default identification system is established, and default predictions are made based on the ensemble learning algorithm. The important characteristics of default bonds are analyzed from the perspective of whether the issuer is a state-owned enterprise, and further cause difference analysis is conducted. Results: The results show that M1 and M2 have an impact on bond defaults, and the ensemble machine learning algorithm can accurately predict bond default risks and obtain key factors for bond risk identification. It is reasonable to choose macro indicators to predict bond defaults. Discussion: Based on the experimental conclusions, this paper discusses and analyzes the bond risk evolution process and the reasons for risk concentration in certain industries, which is helpful for a comprehensive understanding of bond default risks. Our research can provide tool references and guidance for risk management in the actual bond market. © 2025 Elsevier B.V., All rights reserved.","Zhang, Y.; Cui, W.",2025,10.3389/fphy.2025.1559283,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002254323&doi=10.3389%2Ffphy.2025.1559283&partnerID=40&md5=0a0beaee8fb234ad9a3519e69b26697d,scopus
2d91d5fdaf6e3910,Research on e-commerce platform credit supervision resilience based on stochastic catastrophe theory; 基于随机突变的电商平台信用监管弹性研究,"With the development of the Internet economy, e-commerce platforms such as Taobao, DiDi, and Uber have received widespread attention. These enterprises have changed people′s lifestyles and have played an important role in promoting consumption and employment. However, the strong growth of the platform market comes with issues and scandals, including false or misleading information, poor quality, fake products, and counterfeits. The increasing number of such disputes has harmed the interests of consumers and has had a significant adverse social impact. Thus, how to achieve effective e-commerce platform supervision has become the focus of the government, practitioners, and researchers. E-commerce platform credit supervision requires collaboration and coordination between the government and e-commerce platforms. However, the collaborative regulation system is vulnerable and subject to various internal and external factors, such as interaction attributes, utility perception, and incentives. Resilience research explores whether changes in these factors lead to sudden changes in participants′ strategy selection, where resilience refers to the ability of the regulation system to maintain the current equilibrium state. Probing the mechanism of credit supervision resilience evolution can help capture the nonlinearity and randomness in the platform-government relationship from a quantitative perspective and provide decision support for developing credit supervision strategies. However, existing research on e-commerce platform credit supervision focuses on finding equilibrium strategies and their existence conditions, and “resilience” is rarely mentioned. In addition, existing resilience research is rarely based on a catastrophe perspective, and sudden changes in credit supervision are difficult to describe. Therefore, this study integrates resilience theory and stochastic catastrophe theory to propose a catastrophe-based resilience measure for the collaborative regulation system, investigate how system resilience is affected by how the system is regulated, and recommend preventive measures to effectively avoid unexpected radical changes. In the first part, the general framework and research context of the study are presented. In the second part, the catastrophe of supervision behavior is described using an evolutionary game and stochastic catastrophe theory. First, an evolutionary game model between the government and e-commerce platforms is proposed, and a payoff matrix is established. On this foundation, the Gaussian White noise is used to show the random disturbance in the game, and Itô stochastic differential equations are introduced to develop a stochastic dynamic system. Subsequently, a probability density function is introduced to build the stochastic cusp catastrophe model, and the catastrophe set is found to explain the catastrophe of the regulation system. In the third section, with the areas of catastrophes identified, the concept of credit regulation resilience is presented based on Holling′s definition of resilience, and a catastrophe-based resilience measure for the collaborative regulation system is proposed. In the fourth part, simulation experiments are conducted to explore the influence of excess return, punishment, the degree of collaboration between the government and e-commerce platforms, and the degree of public and media participation, and the effectiveness of the model is verified with practical cases. Finally, the advice on e-commerce platform credit supervision is presented in terms of results. Some important conclusions and managerial insights are derived. First, catastrophe occurs suddenly whenthe parameters cross the borderline of the catastrophe set. Therefore, controlling the relevant parameters away from the catastrophe set can maintain the effectiveness of the regulation system. Second, the resilience evolution process is consistent with the catastrophe process: the occurrence of catastrophe leads to rapid changes in resilience. Therefore, it is possible to predict the state of the regulation system based on resilience and intervene in time to control the occurrence of catastrophes when the value of resilience is found to change rapidly or be close to zero. Third, different parameters have different effects on resilience. Punishment has a significant impact on resilience, and the two share a “U”-shaped relationship. In addition, under the constraint of catastrophe threshold, resilience decreases with increasing excess returns and increases with increasing collaboration degree and public and media participation. Therefore, it would be more effective to combine resilience and catastrophe conditions to optimize the regulatory strategy. In general, this research integrates resilience theory and stochastic catastrophe theory to study e-commerce platform credit supervision issues, which provides new ideas for e-commerce platform credit supervision research. The study analyzes the impact of system parameter changes on catastrophe degree from a quantitative perspective through resilience measurement, and the conclusion can provide a basis for e-commerce platform supervision warnings and policy optimization. © 2024 Elsevier B.V., All rights reserved.","Xiaochao, W.; She, S.; Guihua, N.",2024,10.13587/j.cnki.jieem.2024.01.020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185965736&doi=10.13587%2Fj.cnki.jieem.2024.01.020&partnerID=40&md5=a3635447abe5d98ab6aa9b0b3e59b0d9,scopus
b8d5dbfcb1824da4,Research on quantitative investment strategies based on deep learning,"This paper takes 50 ETF options in the options market with high transaction complexity as the research goal. The Random Forest (RF) model, the Long Short-Term Memory network (LSTM) model, and the Support Vector Regression (SVR) model are used to predict 50 ETF price. Firstly, the original quantitative investment strategy is taken as the research object, and the 15 min trading frequency, which is more in line with the actual trading situation, is used, and then the Delta hedging concept of the options is introduced to control the risk of the quantitative investment strategy, to achieve the 15 min hedging strategy. Secondly, the final transaction price, buy price, highest price, lowest price, volume, historical volatility, and the implied volatility of the time segment marked with 50 ETF are the seven key factors affecting the price of 50 ETF. Then, two different types of LSTM-SVR models, LSTM-SVR I and LSTM-SVR II, are used to predict the final transaction price of the 50 ETF in the next time segment. In LSTM-SVR I model, the output of LSTM and seven key factors are combined as the input of SVR model. In LSTM-SVR II model, the hidden state vectors of LSTM and seven key factors are combined as the inputs of the SVR model. The results of the two LSTM-SVR models are compared with each other, and the better one is applied to the trading strategy. Finally, the benefit of the deep learning-based quantitative investment strategy, the resilience, and the maximum drawdown are used as indicators to judge the pros and cons of the research results. The accuracy and deviations of the LSTM-SVR prediction models are compared with those of the LSTM model and those of the RF model. The experimental results show that the quantitative investment strategy based on deep learning has higher returns than the traditional quantitative investment strategy, the yield curve is more stable, and the anti-fall performance is better. © 2019 Elsevier B.V., All rights reserved.","Fang, Y.; Chen, J.; Xue, Z.",2019,10.3390/a12020035,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061984447&doi=10.3390%2Fa12020035&partnerID=40&md5=72e2e75bf78b20e8f6b2ebc3a1549289,scopus
2726dff9c5e3c724,"Research on the Risks of Financial Informatization Construction in Colleges and Universities, Its Prevention and Control and Path Optimization","With the rapid growth of the demand for college and university funding, the financial management of colleges and universities from the traditional meaning of the risk-free state to the risky mode of change, for the college and university financial risk of accurate and reasonable prevention and control has become an important issue that needs to be resolved at this stage. This paper selects a university finance as the research object, designs 12 financial indicators as sample data, processes the financial risk indicator system through principal component analysis, and obtains 8 principal factor components as the input data of the risk prediction model. Then the particle swarm algorithm is combined with BP neural network to overcome the defects of BP neural network as a way to strengthen its prediction accuracy of financial risk. Through simulation experiments, comparative analysis of prediction rates of different models, it is found that the PSO-BP prediction model achieves an identification accuracy of 91.7% for 60 test samples, which improves the identification correctness by 23.7% and 8.4% compared with the traditional BP model and GA-BP model, respectively. It confirms that the PSO-BP neural network model has a higher prediction rate and is effective in introducing university finance for risk prediction. Finally, the article proposes an optimization strategy for the path of university finance information technology construction, in order to improve the effectiveness of university finance information technology construction.","Lv, Xin",2025,10.2478/amns-2025-1039,None,proquest
4ee8fbad2db12a73,Research on the Volatility of the Cotton Market under Different Term Structures: Perspective from Investor Attention,"This study performed comprehensive investigations of the complex interconnections between investor attention and cotton futures price volatility under different term structures. In this paper, in-sample analysis, out-of-sample forecast, influencing mechanisms, as well as nonlinear connections are fully explored using several linear model specifications. The results can be summarized as follows: first, investor attention is the Granger causality of the cotton futures volatility and shows significant linear impacts on cotton volatility; second, models incorporated with investor attention significantly improve the prediction accuracy of cotton volatility in the long term compared with the commonly used AR benchmark model; third, the influence of investor attention on cotton volatility may occur through open interest; and fourth, investor attention presents nonlinear impacts on cotton volatility as well. Overall, the results of this article can provide strong supporting evidence for the important roles of investor attention in asset pricing applications. © 2023 Elsevier B.V., All rights reserved.","Zhou, Q.; Zhu, P.; Wu, Y.; Zhang, Y.",2022,10.3390/su142114389,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146714935&doi=10.3390%2Fsu142114389&partnerID=40&md5=44ec11308eaba61a09e9858a300f5c37,scopus
bdf7a90ab5ce3943,Restrictions on Risk Prices in Dynamic Term Structure Models,"Restrictions on the risk-pricing in dynamic term structure models (DTSMs) tighten the link between cross-sectional and time-series variation of interest rates, and make absence of arbitrage useful for inference about expectations. This article presents a new econometric framework for estimation of affine Gaussian DTSMs under restrictions on risk prices, which addresses the issues of a large model space and of model uncertainty using a Bayesian approach. A simulation study demonstrates the good performance of the proposed method. Data for U.S.Treasury yields calls for tight restrictions on risk pricing: only level risk is priced, and only changes in the slope affect term premia. Incorporating the restrictions changes the model-implied short-rate expectations and term premia. Interest rate persistence is higher than in a maximally flexible model, hence expectations of future short rates are more variablerestrictions on risk prices help resolve the puzzle of implausibly stable short-rate expectations in this literature. Consistent with survey evidence and conventional macro wisdom, restricted models attribute a large share of the secular decline in long-term interest rates to expectations of future nominal short rates. Supplementary materials for this article are available online.","Bauer, Michael D.",2018,10.1080/07350015.2016.1164707,None,wos
ceb068473580003b,Retail Demand Forecasting Using Spatial-Temporal Gradient Boosting Methods,"With the significant growth of the e-commerce business, the retail industry is experiencing rapid developments, leading to the explosion of the number of stock-keeping units (SKUs). Therefore, it calls for forecasting algorithms to forecast a large number of product-level demands over a short forecasting horizon. We developed a novel machine learning algorithm—the spatial-temporal gradient boosting tree (ST-GBT)—for demand forecasting for the retail industry. By incorporating the cross-section and time-series information in the existing gradient-boosting decision tree algorithm, our new algorithm can accurately forecast tremendous SKUs in one process. Furthermore, we show potential factors related to the retail industry, while new factors, such as higher-order statistics and risk-free interest, are also proposed for demand forecasting tasks. The numerical experiment results based on a large e-commerce company’s historical transaction records support the comparative merits of the new algorithm with superior accuracy and automation ability. © 2024 Elsevier B.V., All rights reserved.","Wang, J.; Chong, W.K.; Lin, J.; Hedenstierna, C.P.T.",2024,10.1080/08874417.2023.2240753,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166741941&doi=10.1080%2F08874417.2023.2240753&partnerID=40&md5=23943f325a6dac965bd1f19dd163e2b1,scopus
7dd667d475419652,Retrospectives: Irving fisher's Appreciation and Interest (1896) and the fisher relation,"Irving Fisher's monograph Appreciation and Interest (1896) proposed his famous equation showing expected inflation as the difference between nominal interest and real interest rates. In addition, he drew attention to insightful remarks and numerical examples scattered through the earlier literature, and he derived results ranging from the uncovered interest arbitrage parity condition between currencies to the expectations theory of the term structure of interest rates. As J. Bradford DeLong wrote in this journal (Winter 2000), ""The story of 20th century macroeconomics begins with Irving Fisher"" and specifically with Appreciation and Interest because ""the transformation of the quantity theory of money into a tool for making quantitative analyses and predictions of the price level, inflation, and interest rates was the creation of Irving Fisher."" I discuss the message of Appreciation and Interest, and assess how original he was. © 2013 Elsevier B.V., All rights reserved.","Dimand, R.W.; Gomez Betancourt, R.G.",2012,10.1257/jep.26.4.185,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873335341&doi=10.1257%2Fjep.26.4.185&partnerID=40&md5=d258eb0252514708325ae1e7caafec1c,scopus
a70a5d5938d86e6e,Revealing the correlation between economic indicators and gold prices for forecasting: Medium term forecast framework with data patch,"Predicting gold prices through the analysis of key economic indicators such as inflation rates, Government Bond Yields, and the U.S. Dollar Index, alongside historical Gold Prices, is crucial for enabling investors to better understand market dynamics and make vital decisions to maximize returns. However, previous studies have faced challenges in extracting hidden factors related to gold price prediction from diverse economic indicators, and the comprehensive exploration of gold price data is yet to be fully achieved. To address this, the present study introduces a mid to long-term gold price prediction model named DPformer. This model utilizes a patching strategy to investigate the relationships between different economic indicators and Gold Prices. It also employs a decomposition approach to discover the mid to long-term trend characteristics and yearly seasonal patterns of Gold Prices. The core of the model integrates a Transformer module, which is solely based on an Encoder structure, and enhances it with multiple attention mechanisms and convolutions. This enhancement allows the improved Transformer model to more effectively capture the long-term dependencies of Gold Prices. The empirical results demonstrate that DPformer consistently outperforms a suite of advanced models widely adopted in terms of mid to long-term forecasting accuracy, including LSTM, GRU, Transformer, DLinear, and PatchTST. Notably, for the 30-step gold price prediction task, DPformer achieves a 21.78 % reduction in Mean Squared Error compared to PatchTST. Moreover, by quantitatively analyzing how various economic indicators influence gold price forecasts, this study provides substantial support for investors in making informed decisions at critical moments. © 2025 Elsevier B.V., All rights reserved.","Bao, G.; Niu, Y.; Cui, B.; Ji, W.",2026,10.1016/j.eswa.2025.129594,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105015297138&doi=10.1016%2Fj.eswa.2025.129594&partnerID=40&md5=b39221e28ac6635c40a32273e8371cef,scopus
da3315d9fa0074d1,Revisiting asset co-movement: Does network topology really matter?,"Asset co-movement has garnered increasing attention from researchers in both traditional finance and emerging interdisciplinary disciplines. However, there is limited knowledge regarding the consistency of market-wide co-movement proxies constructed based on these two perspectives. Employing Fama–French industry portfolios as samples, we construct market-wide co-movement proxies in terms of R2-based and network-based approaches. We further examine if and how market-wide co-movement is priced using supervised principal analysis (SPCA) proposed by Giglio et al. (2021). Our findings include: First, most topological properties are highly correlated with the R2-based proxies. Second, the risk-premium estimates by the SPCA range from 90 bps to 130 bps per month, depending on the size of the latent factors considered. Furthermore, most co-movement proxies are linked to the characteristics regarding asset fundamentals. However, the associated R2 values remain around only 15%, highlighting the challenges in hedging the risks associated with market-wide co-movement in equity markets. © 2023 Elsevier B.V., All rights reserved.","Shi, H.-L.; Chen, H.",2023,10.1016/j.ribaf.2023.102064,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169609130&doi=10.1016%2Fj.ribaf.2023.102064&partnerID=40&md5=552d46f0a087e1821531a343302ab073,scopus
91b7a341ab735f04,Revisiting the Dynamic Linkages of Treasury Bond Yields for the BRICS: A Forecasting Analysis,"We examined the dynamic linkages among money market interest rates in the so-called “BRICS” countries (Brazil, Russia, India, China, and South Africa) by using weekly data of the overnight, one-, three-, and six- months, as well as of one year, Treasury bills rates covering the period from January 2005 to August 2019. A long-run relationship among interest rates was established by employing the Vector Error Correction modeling (VECM), which revealed the validation of the Expectation Hypothesis Theory (EH) of the term structure of interest rates, taking into account long-run deviations from equilibrium and inherent nonlinearities. We unveiled short-run dynamic adjustments for the term structure of the BRICS, subject to regime switches. We then used Markov Switching Vector Error Correction models (MS-VECM) to forecast them dynamically during an out-of-sample period of May 2016 through August 2019. The MSIH-VECM forecasts were found to be superior to the VECM approaches. The novelty of our paper is mainly due to the exploration of the possibility of parameter instability as a crucial factor, which might explain the rejection of the restricted version of the cointegration space, and on the dynamic out-of-sample forecasts of the term structure over a more recent time span in order to assess further the usefulness of our nonlinear MS-VECM characterization of the term structure, capturing the effects of the global and domestic financial crisis. © 2022 Elsevier B.V., All rights reserved.","Bekiros, S.; Avdoulas, C.",2020,10.3390/forecast2020006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124554003&doi=10.3390%2Fforecast2020006&partnerID=40&md5=143c1143e1b1541385f42e9f6876da88,scopus
a83ca3456d3a610f,Reweighted Price Relative Tracking System for Automatic Portfolio Optimization,"In this paper, we propose a novel reweighted price relative tracking (RPRT) system for automatic portfolio optimization (APO). In the price prediction stage, it automatically assigns separate weights to the price relative predictions according to each asset's performance, and these weights will also be automatically updated. In the portfolio optimizing stage, a novel tracking system with a generalized increasing factor is proposed to maximize the future wealth of next period. Besides, an efficient algorithm is designed to solve the portfolio optimization objective, which is applicable to large-scale and time-limited situations. Extensive experiments on six benchmark datasets from real financial markets with diverse assets and different time spans are conducted. RPRT outperforms other state-of-the-art systems in cumulative wealth, mean excess return, annual percentage yield, and some typical risk metrics. Moreover, it can withstand considerable transaction costs and runs fast. It indicates that RPRT is an effective and efficient APO system.",Z. -R. Lai; P. -Y. Yang; L. Fang; X. Wu,2020,10.1109/tsmc.2018.2852651,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8411138,ieeexplore
c77233a418692ab3,Re‐Investigating the UIP Hypothesis: Recent Evidence From BRICS Economies,"The study re‐investigates the existence of the Uncovered interest parity (UIP) hypothesis and substantially adds to the literature by offering the most recent evidence during the period from 2000 to 2022 from developing and emerging economies. The study further augments the literature by extending the standard UIP hypothesis to account for the monetary policy stance and risk premium. The estimates of nonlinear autoregressive distributed lag (NARDL) and component generalised autoregressive conditional heteroscedasticity (C‐GARCH) show that the UIP hypothesis does not exist in any of the BRICS economies. Nevertheless, after accounting for the risk premium and monetary policy stance using inflation levels, the interest rate differential significantly and positively influences the expected changes in the spot exchange rates. This indicates three important aspects: first, the necessity of risk premium to make up for the higher risk that comes with holding the foreign bond for the benefit of domestic investors. Second that the UIP puzzle does not hold, such that higher interest differential depreciates the domestic currency. Third, the analysis underscores the substantial and direct impact of US inflation level, particularly for Brazil, Russia and India, in determining the changes in the spot exchange rate. These insights hold crucial implications for policymakers and regulators.","Bhatia, Madhur",2025,10.1111/ecno.70002,None,proquest
dbc2e7513ee4537a,Risk Assessments and Risk Premiums in the Eurodollar Market,"Increasing awareness of the potential risks involved in lending to heavily indebted governments focuses attention on credit pricing in the Eurodollar market. This paper utilizes a recent survey of country-by-country risk assessments as perceived by lenders to show that a systematic relationship exists between these assessments and interest rates in the Euromarket. The relationship is derived from an underlying model described in the paper. The estimated parameters verify a number of hypotheses, providing insights on the loss rates lenders expect to incur in case of default.","Feder, Gershon; Ross, Knud",1982,10.1111/j.1540-6261.1982.tb02217.x,None,proquest
950e074ff9401528,Risk aversion and the yield of corporate debt,"This paper develops a model to estimate the implied default probability of corporate bonds. The model explicitly considers the risk averse behavior of investors to provide a more precise framework for estimating the implied default probability. A Kalman filter method is used to estimate time-varying risk premium associated with the investor's risk aversion. The results of nonlinear regressions indicate that previous risk-neutrality models consistently overestimate the implied default rates of corporate bonds. The results also suggest that investors may have been adequately compensated for investment in risky bonds. © 2017 Elsevier B.V., All rights reserved.","Wu, C.; Yu, C.-H.",1996,10.1016/0378-4266(94)00099-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030100137&doi=10.1016%2F0378-4266%2894%2900099-9&partnerID=40&md5=d3ffd14c6e4c6ebb72f65d65b6f2180e,scopus
ff66a5008bdfba32,Risk factors selection with data mining methods for insurance premium ratemaking·,"Osiguravajuća društva koja su prva usvojila primjenu metoda rudarenja podataka u svom poslovanju postali su konkurentniji na tržištu osiguranja. Metode rudarenja podataka osiguravajućoj industriji pružaju brojne prednosti: kraće vrijeme obrade podataka, sofisticiranije metode za precizniju analizu podataka, bolje donošenje odluka itd. Osiguravajuća društva koriste metode rudarenja podataka u razne svrhe, od marketinških kampanja do sprečavanja prijevara, a med strok signu prvima je ta metoda bila u postupku odred strok signivanja premija osiguranja. Primjena metode rudarenja podataka u ovom radu ima za cilj poboljšati rezultate u procesu izračuna stope premije neživotnih osiguranja. Poboljšanje se ogleda u odabiru varijabli predvid strok signanja ili faktora rizika koji utječu na stope premija osiguranja. Istražene su sljedeće metode rudarenja podataka za odabir varijabli predvid strok signanja: Postepena regresija, Stabla odlučivanja i Neuronske mreže. Za izračun premijskih stopa korišteni su Generalizirani linearni modeli (GLM), koji su danas glavni statistički model odred strok signivanja premija neživotnih osiguranja u većini razvijenih tržišta osiguranja u svijetu.","Omerašević, Amela; Selimović, Jasmina",2020,10.18045/zbefri.2020.2.667,None,proquest
5fc9efc146bee8ef,Risk premia and seasonality in commodity futures,We develop and estimate a multifactor affine model of commodity futures that allows for stochastic seasonality. We document the existence of stochastic seasonal fluctuations in commodity futures and that properly accounting for the cost‐of‐carry curve requires at least three factors. We estimate the model using data on heating oil futures and analyze the contribution of the factors to risk premia. Correctly specifying seasonality as stochastic is important to avoid erroneously assigning those fluctuations to other risk factors. We also estimate a nonlinear version of the model that imposes the zero lower bound on interest rates and find similar results.,"Hevia, Constantino; Petrella, Ivan; Sola, Martin",2018,10.1002/jae.2631,None,proquest
721d894f60c0d83b,"Risk, Return and Volatility Feedback: A Bayesian Nonparametric Analysis","In this paper, we let the data speak for itself about the existence of volatility feedback and the often debated risk–return relationship. We do this by modeling the contemporaneous relationship between market excess returns and log-realized variances with a nonparametric, infinitely-ordered, mixture representation of the observables’ joint distribution. Our nonparametric estimator allows for deviation from conditional Gaussianity through non-zero, higher ordered, moments, like asymmetric, fat-tailed behavior, along with smooth, nonlinear, risk–return relationships. We use the parsimonious and relatively uninformative Bayesian Dirichlet process prior to overcoming the problem of having too many unknowns and not enough observations. Applying our Bayesian nonparametric model to more than a century’s worth of monthly US stock market returns and realized variances, we find strong, robust evidence of volatility feedback. Once volatility feedback is accounted for, we find an unambiguous positive, nonlinear, relationship between expected excess returns and expected log-realized variance. In addition to the conditional mean, volatility feedback impacts the entire joint distribution.","Jensen, Mark J; Maheu, John M",2018,10.3390/jrfm11030052,None,proquest
c717e8521a127885,Risk-based optimal bidding patterns in the deregulated power market using extended Markowitz model,"Deregulation of power industry has entailed important changes in the energy market. With the power industry being restructured, a generation company (GenCo) sells energy through auctions in a daily market, and submission of the appropriate amount of electricity with the right bidding price is important for a GenCo to maximize their profits and minimize the acceptance risk. The objective of this paper is to propose a novel approach for determination of the optimal biding patterns among GenCos in the deregulated power market using a hybrid of Markowitz Model and Genetic Algorithm (GA). While Markowitz Model as an optimization model considers the risk premium for biding patterns and GA as a search engine, considering the acceptance risk in deregulated market. A case study is used to examine the findings of the proposed approach. Also, to compare the proposed model, neural network by back propagation learning algorithm and real proposed pattern were considered. The numerical results indicate that the proposed model is statistically efficient and offers effective curves and biding patterns by lesser risk and equal profitability in day-ahead market as it is able to achieve better results compared to the neural network. © 2020 Elsevier B.V., All rights reserved.","Ostadi, B.; Motamedi Sedeh, O.; Husseinzadeh Kashan, A.",2020,10.1016/j.energy.2019.116516,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075892372&doi=10.1016%2Fj.energy.2019.116516&partnerID=40&md5=38a0c00b1e470d79a0ad16e40e62044f,scopus
98742387c3e762c5,Risk-neutral valuation of participating life insurance contracts in a stochastic interest rate environment,"Over the last years, the valuation of life insurance contracts using concepts from financial mathematics has become a popular research area for actuaries as well as financial economists. In particular, several methods have been proposed of how to model and price participating policies, which are characterized by an annual interest rate guarantee and some bonus distribution rules. However, despite the long terms of life insurance products, most valuation models allowing for sophisticated bonus distribution rules and the inclusion of frequently offered options assume a simple Black-Scholes setup and, more specifically, deterministic or even constant interest rates.We present a framework in which participating life insurance contracts including predominant kinds of guarantees and options can be valuated and analyzed in a stochastic interest rate environment. In particular, the different option elements can be priced and analyzed separately. We use Monte Carlo and discretization methods to derive the respective values.The sensitivity of the contract and guarantee values with respect to multiple parameters is studied using the bonus distribution schemes as introduced in [Bauer, D., Kiesel, R., Kling, A., Russ, J., 2006. Risk-neutral valuation of participating life insurance contracts. Insurance: Math. Econom. 39, 171-183]. Surprisingly, even though the value of the contract as a whole is only moderately affected by the stochasticity of the short rate of interest, the value of the different embedded options is altered considerably in comparison to the value under constant interest rates. Furthermore, using a simplified asset portfolio and empirical parameter estimations, we show that the proportion of stock within the insurer's asset portfolio substantially affects the value of the contract. Published by Elsevier B. V.","Zaglauer, Katharina; Bauer, Daniel",2008,10.1016/j.insmatheco.2007.09.003,None,wos
e0a69d7554298af5,Risk-return relationship in equity markets: Using a robust GMM estimator for GARCH-M models,"While most asset pricing models postulate a positive relationship between excess returns and risk, there is no consensus on the nature of the relationship due to conflicting empirical evidence. The relationship is particularly ambiguous within a GARCH-M framework. This paper demonstrates that such a conflict can be attributed primarily to the downward bias of standard estimators that neglect additive outliers (AO) commonly observed in financial returns, and proposes a feasible estimation method (RGMME) for the GARCH-M model based upon a robust variant of the GMM. Monte Carlo experiments demonstrate that AOs cause more serious bias in the ML and GMM estimates of the relationship coefficient than previously expected. Therefore, in the presence of AOs, the RGMME appears superior to other standard estimators in terms of the root mean square error criterion. There is strong evidence favouring the RGMME over standard estimators based on its empirical application. In particular, it is substantially evident from the results of the RGMME that there is support for a positive relationship between excess returns and conditional volatility for all three major equity markets. © 2009 Elsevier B.V., All rights reserved.","Park, B.-J.",2009,10.1080/14697680801898584,https://www.scopus.com/inward/record.uri?eid=2-s2.0-61449224631&doi=10.1080%2F14697680801898584&partnerID=40&md5=299f690c41cd8d9b3024ed2a38d344d4,scopus
adc9220e7da7566a,Risks and risk premiums of GE corn: A macromarketing framework,"It has been more than two decades since genetic engineered (GE) corn has been introduced in the United States and Spain. Despite the wide scale adoption of GE corn, (92% of planted acreage in the US in 2017), biodiversity conservation, environmental protection goals, and food safety continue to surface as potential risk factors. We developed a macromarketing framework to provide a linkage between the consumers, producers, and societal impacts of GE corn. An empirical Arbitrage Pricing Model (APT) was used to quantify risks and risk premiums associated with GE corn production. The risk premium deduced from the APT model provides a measure of intrinsic compensation for taking on higher or lower risks by participants in the marketing system. An Auto-Regressive Distributed Lag (ARDL) regression estimation of the APT model reveals that GE causes corn prices to go down due to increase supply, but significantly reduced the risk premium for producing corn in the United States. GE corn also provided environmental beneficial outcomes by reducing the use of fertilizers.","Nganje, William; Fosu",2022,10.1016/j.ecolecon.2022.107560,None,proquest
016ee04e5aa868c2,Robust analysis of default intensity,"The problem of robust estimation and multivariate outlier detection of the term structure of default intensity is considered. Both the multivariate Vasicek and CIR models, embedding the Kalman filter algorithm in a forward search context, are used to estimate default intensity. The focus is not on the estimation of credit models including jumps, but on the automatic detection of masked multiple outliers in multivariate time series. Both simulated and real market credit spread time series are analyzed. In order to make inference on outliers, confidence envelopes which are virtually independent of the estimated parameters are introduced. The output is not only a unique default intensity term structure curve, as often used in the financial literature, but a robust confidence interval within which default intensity is likely to stay. © 2010 Elsevier B.V. All rights reserved. © 2012 Elsevier B.V., All rights reserved.","Bellini, T.; Riani, M.",2012,10.1016/j.csda.2011.03.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052729228&doi=10.1016%2Fj.csda.2011.03.007&partnerID=40&md5=c461a0037e44f8f1bb762976a3665485,scopus
11277b48778899ce,Robust out-of-sample inference,"This paper presents analytical, empirical and simulation results concerning inference about the moments of nondifferentiable functions of out-of-sample forecasts and forecast errors. Special attention is given to the measurement of a model's predictive ability using the test of equal mean absolute error. Tests for equal mean absolute error and mean square error are used to evaluate predictions of excess returns to the S & P 500 composite. Simulations indicate that appropriately constructed tests for equal mean absolute error can provide more accurately sized and more powerful tests than inappropriately constructed tests for equal mean absolute error and mean square error. © 2000 Elsevier Science S.A. All rights reserved. © 2017 Elsevier B.V., All rights reserved.","McCracken, M.W.",2000,10.1016/s0304-4076(00)00022-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0001909961&doi=10.1016%2FS0304-4076%2800%2900022-1&partnerID=40&md5=92f2aa5d4aad4c137b65fa13fd612370,scopus
1a226116b97cd3c2,Robust portfolio choice with limited attention,"This paper investigates a robust portfolio selection problem with the agent’s limited attention. The agent has access to a risk-free asset and a stock in a financial market. But she does not observe perfectly the expected return rate of the stock so she has to estimate this key parameter before making decisions. Besides the general observable financial information, the agent can also acquire a news signal process whose accuracy depends on the agent’s attention. We assume that the agent pays limited attention on the signal and she does not trust her estimation model. So it is necessary to consider model ambiguity in this paper as well. The agent maximizes the expected utility of her terminal wealth under the worst-case scenario. Under this setting, we derive the robust optimal strategy explicitly. In the presence of the attention and ambiguity aversion, the myopic term of the strategy, the hedging term of the strategy and the worst-case scenario are all changed. We find that more attention makes the variance of the estimated return smaller. The numerical examples also show that a more attentive agent has a better estimation of the unobservable parameter and is more confident on her estimation. Consequently, the worst-case scenario deviates less from the reference model, which implies a higher expected return rate under the worst-case scenario, thus invests more in the stock © 2023 Elsevier B.V., All rights reserved.","Ma, Y.; Li, Z.",2023,10.3934/era.2023186,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159911737&doi=10.3934%2FERA.2023186&partnerID=40&md5=f806efd2b7aacacd69a68d507fee36c1,scopus
2e134d879ec17033,Robust term structure estimation in developed and emerging markets,"Despite powerful advances in interest rate curve modeling for data-rich countries in the last 30 years, comparatively little attention has been paid to the key practical problem of estimation of the term structure of interest rates for emerging markets. This may be partly due to limited data availability. However, emerging bond markets are becoming increasingly important and liquid. It is, therefore, important to be understand whether conclusions drawn from developed countries carry over to emerging markets. We estimate model parameters of fully flexible Nelson–Siegel–Svensson term structures model which has become one of the most popular term structure model among academics, practitioners, and central bankers. We investigate four sets of bond data: U.S. Treasuries, and three major emerging market government bond data-sets (Brazil, Mexico and Turkey). By including both the very dense U.S. data and the comparatively sparse emerging market data, we ensure that are results are not specific to a particular data-set. We find that gradient and direct search methods perform poorly in estimating term structures of interest rates, while global optimization methods, particularly the hybrid particle swarm optimization introduced in this paper, do well. Our results are consistent across four countries, both in- and out-of-sample, and for perturbations in prices and starting values. For academics and practitioners interested in optimization methods, this study provides clear evidence of the practical importance of choice of optimization method and validates a method that works well for the NSS model.","Ahi, Emrah; Akgiray, Vedat; Sener, Emrah",2018,10.1007/s10479-016-2282-5,None,proquest
9cc573c83e0fa832,SCORING: FAILURE RISK MANAGEMENT TOOL FOR SMES IN ALGERIA,"Algerian public banks need to implement credit risk management techniques tailored to the specific characteristics of SMEs to prevent the deterioration of the banks' solvency due to the degradation of the quality of their SME portfolios. In this regard, our main objective is to highlight the interest that credit risk management will have within the People's Credit of Algeria by developing a Credit Scoring model based on the logistic regression technique, using a sample of 226 SMEs. The study results demonstrate the importance of the logistic regression model in classifying companies and its predictive ability for default, with a good classification rate of 91.2%.","Tarhlissia, Lamine",2024,10.2478/bsaft-2024-0018,None,proquest
9cdfe4c8e3175d9e,SF-Transformer: A Mutual Information-Enhanced Transformer Model with Spot-Forward Parity for Forecasting Long-Term Chinese Stock Index Futures Prices,"The complexity in stock index futures markets, influenced by the intricate interplay of human behavior, is characterized as nonlinearity and dynamism, contributing to significant uncertainty in long-term price forecasting. While machine learning models have demonstrated their efficacy in stock price forecasting, they rely solely on historical price data, which, given the inherent volatility and dynamic nature of financial markets, are insufficient to address the complexity and uncertainty in long-term forecasting due to the limited connection between historical and forecasting prices. This paper introduces a pioneering approach that integrates financial theory with advanced deep learning methods to enhance predictive accuracy and risk management in China’s stock index futures market. The SF-Transformer model, combining spot-forward parity and the Transformer model, is proposed to improve forecasting accuracy across short and long-term horizons. Formulated upon the arbitrage-free futures pricing model, the spot-forward parity model offers variables such as stock index price, risk-free rate, and stock index dividend yield for forecasting. Our insight is that the mutual information generated by these variables has the potential to significantly reduce uncertainty in long-term forecasting. A case study on predicting major stock index futures prices in China demonstrates the superiority of the SF-Transformer model over models based on LSTM, MLP, and the stock index futures arbitrage-free pricing model, covering both short and long-term forecasting up to 28 days. Unlike existing machine learning models, the Transformer processes entire time series concurrently, leveraging its attention mechanism to discern intricate dependencies and capture long-range relationships, thereby offering a holistic understanding of time series data. An enhancement of mutual information is observed after introducing spot-forward parity in the forecasting. The variation of mutual information and ablation study results highlights the significant contributions of spot-forward parity, particularly to the long-term forecasting. Overall, these findings highlight the SF-Transformer model’s efficacy in leveraging spot-forward parity for reducing uncertainty and advancing robust and comprehensive approaches in long-term stock index futures price forecasting.","Mao, Weifang; Liu, Pin; Huang, Jixian; Huang, Jixian",2024,10.3390/e26060478,None,proquest
32f440cd8991d935,SIMULTANEOUS SPECIFICATION TESTING OF MEAN AND VARIANCE STRUCTURES IN NONLINEAR TIME SERIES REGRESSION,"This paper proposes a nonparametric simultaneous test for parametric specification of the conditional mean and variance functions in a time series regression model. The test is based on an empirical likelihood (EL) statistic that measures the goodness of fit between the parametric estimates and the nonparametric kernel estimates of the mean and variance functions. A unique feature of the test is its ability to distribute natural weights automatically between the mean and the variance components of the goodness-of-fit measure. To reduce the dependence of the test on a single pair of smoothing bandwidths, we construct an adaptive test by maximizing a standardized version of the empirical likelihood test statistic over a set of smoothing bandwidths. The test procedure is based on a bootstrap calibration to the distribution of the empirical likelihood test statistic. We demonstrate that the empirical likelihood test is able to distinguish local alternatives that are different from the null hypothesis at an optimal rate.","Chen, Song Xi; Gao, Jiti",2011,10.1017/s0266466610000502,None,wos
a1733dd5c20d41d0,SPCM: A Machine Learning Approach for Sentiment-Based Stock Recommendation System,"Recommendation systems play a pivotal role in delivering user preference information. However, they often face the challenge of information cocoons due to repeated content delivery, particularly prevalent in stock recommendations that are susceptible to investor sentiment. In response to the information cocoons, we propose the Sentiment and Price Combined Model (SPCM), which leverages sentiment features and price factors to predict stock price movements. This novel framework combines collective sentiment analysis with state-of-the-art BERT transformer models and advanced machine learning techniques. Over a three-year period, we collected 40 million stock comments from the Guba platform, extracting investor sentiment conveyed in text information and investigating the impact of metrics such as homophily on stock recommendations. Experimental results indicate that both the volume of posts and the agreement index affect the effectiveness of investor sentiment, while homophily reduces the accuracy of participants’ stock price judgments. The recognition accuracy of the BERT-based sentiment analysis model reaches an impressive 84.12%, and the portfolio constructed by SPCM yields a cumulative return four times that of the industry benchmark. Furthermore, homogeneous quantitative metrics also enhance diversification in stock selection.",J. Wang; Z. Chen,2024,10.1109/access.2024.3357114,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10411881,ieeexplore
9d05ef274491439a,SVM-Based Techniques for Predicting Cross-Functional Team Performance: Using Team Trust as a Predictor,"Due to the characteristics of cross-functional teams, trust is crucial for cross-functional teams to enhance performance. However, as a significant factor, trust had been neglected in previous team performance models. In this paper, we investigate whether trust can be used as a predictor of cross-functional team performance by proposing a prediction model. The inputs of the model are both team structural and contextual (SC) factors, and project process (PP) factors, which are two major sources that form team trust. The output of the model is different levels of team performance, which consists of internal performance and external performance. The support vector machine techniques are used to establish the model. Results show that prediction accuracy is high (84.95%) when using both SC and PP factors as inputs, while PP factors have better prediction accuracy than SC factors on team performance and internal performance. It is suggested that team trust can be used as a good predictor of cross-functional team performance. In practice, this paper presents a better understanding of the relationship between trust and performance in cross-functional teams, and thus, enhances practitioners' managerial skills. It also gives reference for managers to dynamically control and predict team performance during project period.",L. Zhang; X. Zhang,2015,10.1109/tem.2014.2380177,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004820,ieeexplore
031c94725788365c,Satellite-detected gain in built-up area as a leading economic indicator,"Leading indicators of future economic activity include measures such as new housing starts, managers purchasing index, money supply, and bond yields. Such macroeconomic and financial indicators hold predictive power in signaling recessionary periods. However, many indicators are constrained by the fact that data are often published with some delay and are subject to constant revision (Bandholz and Funke 2003, Huanget al 2018, Orphanides 2003). In this research, we propose a leading indicator derived from satellite imagery, the expansion of anthropogenic bare ground. Satellite-detected gain in built-up area, a major land cover and land use (LCLU) outcome of anthropogenic bare ground gain (ABGG), provides an inexpensive, consistent, and near-real-time indicator of global and regional macroeconomic change. Our panel data analysis across four major regions of the world from 2001 to 2012 shows that the logarithm of total ABGG, mostly owing to its major LCLU outcome, the expansion of built-up land in either year t, t - 1 or t - 2, significantly correlated with the year t logarithm of gross domestic product (GDP, de-trended by Hodrick-Prescott filter). Global ABGG between 2001 and 2012 averaged 7875 km(2) yr(-1), with a peak gain of 11 875 (+/- 2014 km(2) at the 95% confidence interval) in 2006, prior to the 2007-2008 global financial crisis. The curve of global ABGG or its major LCLU outcome of built-up area in year t - 1 accords well with that of the de-trended logarithm of the global GDP in year t. Given the 40 year archive of free satellite data, a growing satellite constellation, advances in machine learning, and scalable methods, this study suggests that analyses of ABGG as a whole or its LCLU outcomes can provide valuable information in near-real time for socioeconomic research, development planning, and economic forecasting.","Ying, Qing; Hansen, Matthew C.; Sun, Laixiang; Wang, Lei; Steininger, Marc",2019,10.1088/1748-9326/ab443e,None,wos
8338ecaf338c20d8,Semiparametric Estimates of Monetary Policy Effects: String Theory Revisited,"We develop flexible semiparametric time series methods for the estimation of the causal effect of monetary policy on macroeconomic aggregates. Our estimator captures the average causal response to discrete policy interventions in a macrodynamic setting, without the need for assumptions about the process generating macroeconomic outcomes. The proposed estimation strategy, based on propensity score weighting, easily accommodates asymmetric and nonlinear responses. Using this estimator, we show that monetary tightening has clear effects on the yield curve and on economic activity. Monetary accommodation, however, appears to generate less pronounced responses from both. Estimates for recent financial crisis years display a similarly dampened response to monetary accommodation. © 2018 Elsevier B.V., All rights reserved.","Angrist, J.D.; Jordà, Ò.; Kuersteiner, G.M.",2018,10.1080/07350015.2016.1204919,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019125628&doi=10.1080%2F07350015.2016.1204919&partnerID=40&md5=c8ba3071db31226cdbb135e277f4b0e5,scopus
58ae8ef2afebef3f,Semiparametric inference in a GARCH-in-mean model,"A new semiparametric estimator for an empirical asset pricing model with general nonparametric risk-return tradeoff and GARCH-type underlying volatility is introduced. Based on the profile likelihood approach, it does not rely on any initial parametric estimator of the conditional mean function, and it is under stated conditions consistent, asymptotically normal, and efficient, i.e., it achieves the semiparametric lower bound. A sampling experiment provides finite sample comparisons with the parametric approach and the iterative semiparametric approach with parametric initial estimate of Conrad and Mammen (2008). An application to daily stock market returns suggests that the risk-return relation is indeed nonlinear. (C) 2011 Elsevier B.V. All rights reserved.","Christensen, Bent Jesper; Dahl, Christian M.; Iglesias, Emma M.",2012,10.1016/j.jeconom.2011.09.028,None,wos
33528ceaf46b6df9,"Sensitivity, moment conditions, and the risk-free rate in Yogo (2006)","In this paper, we show that results presented in the seminal paper by Yogo, A Consumption Based Explanation of Expected Stock Returns, cannot be replicated. We find different estimates for the parameters and we obtain values of over-identified statistics that being much larger than those in the original paper indicate rejection of the durable consumption asset pricing model. By careful inspection of Yogo's replication files, we were able to track down the inconsistency to a coding bug. The rejection of the durable model is exemplified by its inability to simultaneously explain the risk-free rate and excess stock returns. © 2018 Elsevier B.V., All rights reserved.","Borri, N.; Ragusa, G.",2017,10.1561/104.00000050,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047126663&doi=10.1561%2F104.00000050&partnerID=40&md5=2e80cdf8a809220a2a0c9a68c39d3f9e,scopus
e1717bb531c0dcd0,Sentiment lost: the effect of projecting the pricing kernel onto a smaller filtration set,"This paper provides a theoretical analysis on the impacts of using a suboptimal information set for the estimation of the pricing kernel and, more in general, for the validity of the fundamental theorems of asset pricing. While inferring the risk-neutral measure from options data provides a naturally forward-looking estimate, extracting the real world measure from historical returns is only partially informative, thus suboptimal with respect to investors’ future beliefs. As a consequence of this disalignment, the two measures no longer share the same nullset, thus distorting the investors’ risk premium and the validity of the pricing measure. From a probabilistic viewpoint, the missing beliefs are totally unaccessible stopping times on the coarser filtration set, so that an absolutely continuous strict local martingale, once projected on it, becomes continuous with jumps. Some empirical examples complete the paper.","Sala, Carlo; Barone-Adesi, Giovanni",2020,10.1080/07362994.2019.1711119,None,proquest
8952329c631edb64,Sentiment spillover effects for US and European companies,"The fast-growing literature on news analytics provides evidence that financial markets are partially driven by sentiments. In contrast with previous studies that have almost exclusively focused on the direct effects of the news related to single companies or sectors, we investigate the time-varying dynamics of news’ cross-industry influences for a set of US and European stocks over a period of 10 years. The graphical Granger causality of the news sentiments-excess return networks is estimated by applying the adaptive lasso. We find significant spillover effects and show the importance of sentiments related to certain sectors for the whole cross-section of stocks. © 2019 Elsevier B.V., All rights reserved.","Audrino, F.; Tetereva, A.",2019,10.1016/j.jbankfin.2019.07.022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070492911&doi=10.1016%2Fj.jbankfin.2019.07.022&partnerID=40&md5=a82745431816b9d30c291b182aa0c89b,scopus
996f7b5a24667f4b,"Sentiment, Attention, and Earnings Pricing","We find that investor sentiment restrains the predictability of earnings news on announcement returns but the constraining effect of sentiment on the predictive power of earnings news diminishes as sentiment falls. We document that investor attention works as an important channel in the relation between investor sentiment and announcement returns. Investor attention enhances the immediate price reaction to earnings news by curbing the impact of sentiment on the predictive power of earnings news. Our findings reflect the joint effect of attention and sentiment on the source of excess returns documented in the prior earnings-based market anomaly literature. © 2024 Elsevier B.V., All rights reserved.","Cai, Q.; Yung, K.",2024,10.1080/15427560.2022.2100381,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134382035&doi=10.1080%2F15427560.2022.2100381&partnerID=40&md5=380f51696ca6525d0a7916caf01ca30e,scopus
17b1f4e7dc5f6e24,Sequential Monte Carlo Methods to Train Neural Network Models,"We discuss a novel strategy for training neural networks using sequential Monte Carlo algorithms and propose a new hybrid gradient descent/sampling importance resampling algorithm (HySIR). In terms of computational time and accuracy, the hybrid SIR is a clear improvement over conventional sequential Monte Carlo techniques. The new algorithm may be viewed as a global optimization strategy that allows us to learn the probability distributions of the network weights and outputs in a sequential framework. It is well suited to applications involving on-line, nonlinear, and nongaussian signal processing. We show how the new algorithm outperforms extended Kalman filter training on several problems. In particular, we address the problem of pricing option contracts, traded in financial markets. In this context, we are able to estimate the one-step-ahead probability density functions of the options prices.",J. F. G. d. Freitas; M. Niranjan; A. H. Gee; A. Doucet,2000,10.1162/089976600300015664,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6790037,ieeexplore
b426a797302dce5e,Short rate nonlinearities and regime switches,"Using non-parametric estimation methods, various authors have shown distinct non-linearities in the drift and volatility function of the US short rate, which are inconsistent with standard affine term structure models. We document how a regime-switching model with state-dependent transition probabilities between regimes can replicate the patterns found by the non-parametric studies. To do so, we use data from the UK and Germany in addition to US data and include term spreads in some of our models. We also examine the drift and volatility function of the term spread. (C) 2002 Elsevier Science B.V. All rights reserved.","Ang, A; Bekaert, G",2002,10.1016/s0165-1889(01)00042-2,None,wos
86bd40f3a759ac70,Short term forecasting with support vector machines and application to stock price prediction,"Forecasting a stock price movement is one of the most difficult problems in finance. The reason is that financial time series are complex, non stationary. Furthermore, it is also very difficult to predict this movement with parametric models. Instead of parametric models, we propose two techniques, which are data driven and non parametric. Based on the idea that excess returns would be possible with publicly available information, we developed two models in order to forecast the short term price movements by using technical indicators. Our assumption is that the future value of a stock price depends on the financial indicators although there is no parametric model to explain this relationship. This relationship comes from the technical analysis. Comparison shows that support vector regression (SVR) out performs the multi layer perceptron (MLP) networks for a short term prediction in terms of the mean square error. If the risk premium is used as a comparison criterion, then the SVR technique is as good as the MLP method or better.","Ince, Huseyin; Trafalis, Theodore B",2008,10.1080/03081070601068595,None,proquest
967c7f9c55b36c26,Shrinkage drift parameter estimation for multi-factor ornstein-uhlenbeck processes,"We consider some inference problems concerning the drift parameters of multi-factors Vasicek model (or multivariate Ornstein-Uhlebeck process). For example, in modeling for interest rates, the Vasicek model asserts that the term structure of interest rate is not just a single process, but rather a superposition of several analogous processes. This motivates us to develop an improved estimation theory for the drift parameters when homogeneity of several parameters may hold. However, the information regarding the equality of these parameters may be imprecise. In this context, we consider Stein-rule (or shrinkage) estimators that allow us to improve on the performance of the classical maximum likelihood estimator (MLE). Under an asymptotic distributional quadratic risk criterion, their relative dominance is explored and assessed. We illustrate the suggested methods by analyzing interbank interest rates of three European countries. Further, a simulation study illustrates the behavior of the suggested method for observation periods of small and moderate lengths of time. Our analytical and simulation results demonstrate that shrinkage estimators (SEs) provide excellent estimation accuracy and outperform the MLE uniformly. An over-ridding theme of this paper is that the SEs provide powerful extensions of their classical counterparts. Copyright © 2009 John Wiley & Sons, Ltd. © 2010 Elsevier B.V., All rights reserved.","Nkurunziza, S.; Ahmed, S.E.",2010,10.1002/asmb.775,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950822342&doi=10.1002%2Fasmb.775&partnerID=40&md5=87b9e60a35435f4613bac68331ed6461,scopus
f566ead501f33867,Shrinking return forecasts,"We develop a new approach that shrinks a given model forecast to the benchmark model forecast in order to improve forecasting performance. Simulation results show the superior performance of our approach, relative to popular methods such as forecast combination and the robustness to model misspecification. We apply our method to forecasting the returns on the S&P 500 index and find significant predictability when shrinking the principal component (PC) regression forecasts based on statistical and economic evaluation criteria. The forecast improvement from our shrinkage approach can be explained by the ability of its hyperparameters to be better predict real economic changes.","Liu, Li; Pan, Zhiyuan; Wang, Yudong",2022,10.1111/fire.12297,None,wos
d2764adfcc2c78a8,Sign realized jump risk and the cross-section of stock returns: Evidence from China's stock market,"Using 5-minute high frequency data from the Chinese stock market, we employ a non-parametric method to estimate Fama-French portfolio realized jumps and investigate whether the estimated positive, negative and sign realized jumps could forecast or explain the cross-sectional stock returns. The Fama-MacBeth regression results show that not only have the realized jump components and the continuous volatility been compensated with risk premium, but also that the negative jump risk, the positive jump risk and the sign jump risk, to some extent, could explain the return of the stock portfolios. Therefore, we should pay high attention to the downside tail risk and the upside tail risk.Using 5-minute high frequency data from the Chinese stock market, we employ a non-parametric method to estimate Fama-French portfolio realized jumps and investigate whether the estimated positive, negative and sign realized jumps could forecast or explain the cross-sectional stock returns. The Fama-MacBeth regression results show that not only have the realized jump components and the continuous volatility been compensated with risk premium, but also that the negative jump risk, the positive jump risk and the sign jump risk, to some extent, could explain the return of the stock portfolios. Therefore, we should pay high attention to the downside tail risk and the upside tail risk.","Chao, Youcong; Liu, Xiaoqun; Guo, Shijun",2017,10.1371/journal.pone.0181990,None,proquest
b337b8c39825dae7,Simplicity and Risk,"I introduce and test for preference for simplicity in choice under risk. I characterize the theory axiomatically, and derive its properties and unique predictions relative to canonical models. By designing and running theoretically motivated experiments, I document that people value simplicity in ways not fully captured by existing models that study risk premia in financial markets. Participants' risk premia increase as complexity increases, holding moments fixed; their dominance violations increase in complexity; their behavior is predicted by simplicity's characterizing axiom; and their complexity aversion is heterogeneous in cognitive ability. None of expected utility theory, cumulative prospect theory, prospect theory, rational inattention, sparsity, salience, or probability weighting that differs by number of outcomes fully capture the experimental findings. I generalize the underlying theory to additionally capture broader measures of complexity, including obfuscation, computation, and language effects.","Puri, Indira",2025,10.1111/jofi.13417,None,proquest
ca7dacc8f8e60862,Simulation-based estimation of contingent-claims prices,"A new methodology is proposed to estimate theoretical prices of financial contingent claims whose values are dependent on some other underlying financial assets. In the literature, the preferred choice of estimator is usually maximum likelihood (ML). ML has strong asymptotic justification but is not necessarily the best method in finite samples. This paper proposes a simulation-based method. When it is used in connection with ML, it can improve the finite-sample performance of the ML estimator while maintaining its good asymptotic properties. The method is implemented and evaluated here in the Black-Scholes option pricing model and in the Vasicek bond and bond option pricing model. It is especially favored when the bias in ML is large due to strong persistence in the data or strong nonlinearity in pricing functions. Monte Carlo studies show that the proposed procedures achieve bias reductions over ML estimation in pricing contingent claims when ML is biased. The bias reductions are sometimes accompanied by reductions in variance. Empirical applications to U.S. Treasury bills highlight the differences between the bond prices implied by the simulation-based approach and those delivered by ML. Some consequences for the statistical testing of contingent-claim pricing models are discussed. Reprinted by permission of Oxford University Press","Phillips, Peter C.B.; Yu, Jun",2009,10.1093/rfs/hhp009,None,proquest
2bf6170d727cf04b,Simultaneous nonparametric inference of time series,"We consider kernel estimation of marginal densities and regression functions of stationary processes. It is shown that for a wide class of time series, with proper centering and scaling, the maximum deviations of kernel density and regression estimates are asymptotically Gumbel. Our results substantially generalize earlier ones which were obtained under independence or beta mixing assumptions. The asymptotic results can be applied to assess patterns of marginal densities or regression functions via the construction of simultaneous confidence bands for which one can perform goodness-of-fit tests. As an application, we construct simultaneous confidence bands for drift and volatility functions in a dynamic short-term rate model for the U.S. Treasury yield curve rates data. © Institute of Mathematical Statistics, 2010. © 2010 Elsevier B.V., All rights reserved.","Liu, W.; Wu, W.B.",2010,10.1214/09-aos789,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955161966&doi=10.1214%2F09-AOS789&partnerID=40&md5=ab2390352cc6b054754f9e082002cee6,scopus
fcf25faf491d1950,Smoothing spline nonlinear nonparametric regression models,"Almost all of the current nonparametric regression methods, such as smoothing splines, generalized additive models, and varying-coefficients models, assume a linear relationship when nonparametric functions are regarded as parameters. In this article we propose a general class of smoothing spline nonlinear nonparametric models that allow nonparametric functions to act nonlinearly. They arise in many fields as either theoretical or empirical models. Our new estimation methods are based on an extension of the Gauss-Newton method to infinite-dimensional spaces and the backfilling procedure. We extend the generalized cross-validation and generalized maximum likeli-hood methods to estimate smoothing parameters. We establish connections between some nonlinear nonparametric models and nonlinear mixed-effects models. We derive approximate Bayesian confidence intervals for inference. We illustrate the methods with an application to term structure of interest rates and conduct simulations to evaluate the finite-sample performance of our methods. © 2012 Elsevier B.V., All rights reserved.","Ke, C.; Wang, Y.",2004,10.1198/016214504000000755,https://www.scopus.com/inward/record.uri?eid=2-s2.0-10844220603&doi=10.1198%2F016214504000000755&partnerID=40&md5=279118ed9878d6bf94922de6cfe6fa44,scopus
1045c81233fea906,Some benefits and costs of genetic improvement in new zealand’s sheep and beef cattle industry:ii discounted costs and returns on a farm basis following selection,"Estimated physical returns and their calculated value net of food costs have been used as the basis for an analysis of discounted costs and returns from a selection programme for a 200-ewe flock and a 100-cow beef herd. Recording costs (computing, labour, tags, and scales) of $1–2 per ewe and $2–3 per cow are assumed, with a discount rate of 10% as used by the New Zealand Treasury. It is also assumed that no stock for breeding were purchased or sold. Results are expressed in 1979 dollars, for 1 year or round of selection applied. The net present value of 10 years of selection is $4950 or $3600 in sheep ($1 or $2 per ewe in costs) and $3670–4870 in beef cattle, depending on recording costs and the assumed level of food costs incurred by the herd in achieving higher weight-for-age. With sheep, net production is much more important than fleece weight in its contribution to higher profits. A very important contribution in the beef herd under consideration is the return from a higher net calf crop; even small percentage biological gains are of great economic importance. Net returns for a breeder also selling stock for breeding would probably be much higher. © 1980 Taylor & Fracis Group, LLC. © 2016 Elsevier B.V., All rights reserved.","Morris, C.A.",1980,10.1080/03015521.1980.10426284,https://www.scopus.com/inward/record.uri?eid=2-s2.0-34447574295&doi=10.1080%2F03015521.1980.10426284&partnerID=40&md5=52a22c886f9f1a8745ae7df917205a97,scopus
0e58fa6aadafd7b6,Sovereign CDS Spread and Term Structure Forecasting Based on Neural Network,"The article aims to forecast credit risk for BRICS countries using daily credit default swaps (CDS) spreads obtained from Datastream data base from 2018 to 2023. Our approach consists, first, of forecasting the CDS spread in order to estimate the forecasted CDS term structure. The general regression neural network (GRNN) is used to predict the CDS spread. By checking the accuracy of the prediction, the results show that the GRNN model can be recommended as an effective forecasting tool for CDS spread. Second, the predicted spreads are used to estimate the forecasted CDS term structure using the Nelson–Siegel model. The results show that for Russia, overall, the CDS spreads in the long term are less than those in the short term, which implies that the future outlook is more optimistic, given the events that occurred during the study period, but it still retains the highest level of credit risk compared to other countries. Unlike Brazil, India and South Africa, the future outlook is more pessimistic. For China, the term structure is unstable; in the short term, there is a tendency to reduce the risk, but for longer horizons, the risk will increase. Thus, BRICS countries have different risk profiles depending on investment horizons. The study’s findings help policymakers in developing tailored risk management strategies for BRICS countries and guide investors in making informed credit investment decisions. The use of advanced forecasting tools like GRNN and Nelson–Siegel models emphasizes the importance of sophisticated techniques in enhancing financial market resilience. © 2024 Elsevier B.V., All rights reserved.","Abid, A.; Souissi, N.",2024,10.1177/09721509241276952,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206434819&doi=10.1177%2F09721509241276952&partnerID=40&md5=e2af5a9387b092f3129034c1c1b3e1d7,scopus
b10f6a1cfc7ff655,Sovereign Default Forecasting in the Era of the COVID-19 Crisis,"The COVID-19 crisis has revealed the economic vulnerability of various countries and, thus, has instigated the systematic exploration and forecasting of sovereign default risks. Multivariate statistical and stochastic process-based sovereign default risk forecasting has a 50-year developmental history. This article describes a continuous, non-homogeneous Markov chain method as the basis for a COVID-19-related sovereign default risk forecast model. It demonstrates the estimation of sovereign probabilities of default (PDs) over a five-year horizon period with the developed model reflecting the impact of the COVID-19 crisis. The COVID-19-adopted Markov model estimates PDs for most countries, including those that are advanced with AAA and AA ratings, to suggest that no sovereign nation's economy is secure from the financial impact of the COVID-19 pandemic. The dynamics of the estimated PDs are indicative of contemporary evidence as experienced in the recent financial crisis. The empirical results of this article have policy implications for foreign investors, sovereign lenders, export finance institutions, foreign trade experts, risk management professionals, and policymakers in the field of finance. The developed model can be used to timely recognize potential problems with sovereign entities in the current COVID-19 crisis and to take appropriate mitigating actions.","Kristof, Tamas",2021,10.3390/jrfm14100494,None,wos
77a29933a035a55b,Sovereign bond yield spreads and market sentiment and expectations: Empirical evidence from Euro area countries,"The paper investigates the determinants of sovereign bond yield spreads in the Euro area and extends the models commonly used in empirical analyses by focusing on the impact of market expectations and behavioral factors.Using monthly panel data for ten European countries over the period 2000-2012, the analysis adopts a pooled mean-group approach to estimate non-stationary dynamic models of spreads determinants, allowing for country heterogeneities in short-run dynamics.Results show that the behavioral indicators considered, proxies of consumer and market sentiment and expectations, strongly affect spreads behavior, especially during the crisis. Specific attention is also paid to check the robustness of the estimated effects of behavioral indicators and to assess the impact of global financial crisis on the determinants of government bond rate differentials. © 2024 Elsevier B.V., All rights reserved.","Aristei, D.; Duccio Martelli, D.",2014,10.1016/j.jeconbus.2014.08.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927125445&doi=10.1016%2Fj.jeconbus.2014.08.001&partnerID=40&md5=2e2df8bfd63ae330adfe189e467f28ee,scopus
40b1a6f001f4f67c,Sovereign bond yield spreads: A time-varying coefficient approach,"We study the determinants of sovereign bond yield spreads across 10 EMU countries between Q1/1999 and Q1/2010. We apply a semiparametric time-varying coefficient model to identify, to what extent an observed change in the yield spread is due to a shift in macroeconomic fundamentals or due to altering risk pricing. We find that at the beginning of EMU, the government debt level and the general investors' risk aversion had a significant impact on interest differentials. In the subsequent years, however, financial markets paid less attention to the fiscal position of a country and the safe haven status of Germany diminished in importance. By the end of 2006, two years before the fall of Lehman Brothers, financial markets began to grant Germany safe haven status again. One year later, when financial turmoil began, the market reaction to fiscal loosening increased considerably. The altering in risk pricing over time period confirms the need of time-varying coefficient models in this context. © 2011 Elsevier Ltd. © 2012 Elsevier B.V., All rights reserved.","Bernoth, K.; Erdogan, B.",2012,10.1016/j.jimonfin.2011.10.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857451801&doi=10.1016%2Fj.jimonfin.2011.10.006&partnerID=40&md5=b27a4c46ffb5293d5ad3fdea6037a760,scopus
f727ea2b065264c6,Sovereign debt spreads in EMU: The time-varying role of fundamentals and market distrust,"This paper provides further analysis on the determinants of sovereign debt spreads for peripheral Eurozone countries since the start of EMU, paying special attention to episodes that characterized the global financial crisis aftermath starting in 2007. More specifically, the purpose of our research is to disentangle the role of fundamental variables and market perception about variations on risk in order to explain the evolution of sovereign spreads in EMU during the recent crisis. Our results, in line with previous literature, show the importance of three groups of observable variables, namely, changes in risk-aversion of creditors, fiscal indebtedness and liquidity variables. In addition, our model includes unobserved components that are estimated through the Kalman filter as time-varying deviation from fixed-mean parameters of spread determinants. This shows the importance of expectations (market sentiments), amplifying (or reducing) the relative importance of the spread determinants over time through the time-varying behavior of the parameters around their steady-state estimates. © 2017 Elsevier B.V., All rights reserved.","Paniagua, J.; Sapena, J.; Tamarit, C.",2017,10.1016/j.jfs.2016.06.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85003968366&doi=10.1016%2Fj.jfs.2016.06.004&partnerID=40&md5=30cea9ab8a37d258da1d42b867fa74c8,scopus
6d7c5e9a1bb1743e,Sovereign default risk premia: Evidence from the default swap market,"This study explores the risk premia embedded in sovereign default swaps using a term structure model. The risk premia remunerate investors for unexpected changes in the default intensity. A number of interesting results emerge from the analysis. First, the risk premia contribution to spreads decreases over the sample, 2003-07, and rebounds at the start of the 'credit crunch.' Second, daily risk premia co-move with US macro variables and corporate default risk. Third, global factors explain most of Latin American countries' premia, and local factors best explain European and Asian premia. The importance of global factors grows over time. Finally, conditioning on lagged local and global variables at a weekly frequency, sovereign risk premia are highly predictable. (c) 2012 Elsevier B.V. All rights reserved.","Zinna, Gabriele",2013,10.1016/j.jempfin.2012.12.006,None,wos
5b09e441b05c7dfd,Spatio-Temporal Momentum: Jointly Learning Time-Series and Cross-Sectional Strategies,"The authors introduce spatio-temporal momentum strategies, a class of models that unify both time-series and cross-sectional momentum strategies by trading assets based on their cross-sectional momentum features over time. Although both time-series and cross-sectional momentum strategies are designed to systematically capture momentum risk premiums, these strategies are regarded as distinct implementations and do not consider the concurrent relationship and predictability between temporal and cross-sectional momentum features of different assets. They model spatio-temporal momentum with neural networks of varying complexities and demonstrate that a simple neural network with only a single fully connected layer learns to simultaneously generate trading signals for all assets in a portfolio by incorporating both their time-series and cross-sectional momentum features. Back testing on portfolios of 46 actively traded US equities and 12 equity index futures contracts, they demonstrate that the model is able to retain its performance over benchmarks in the presence of high transaction costs of up to 5–10 basis points. In particular, they find that the model when coupled with least absolute shrinkage and turnover regularization results in the best performance over various transaction cost scenarios. © 2023 Elsevier B.V., All rights reserved.","Tan, W.L.; Roberts, S.; Zohren, S.",2023,10.3905/jfds.2023.1.130,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179918020&doi=10.3905%2Fjfds.2023.1.130&partnerID=40&md5=f0dcc0bfe7da5374392a0b389a7636f9,scopus
cba55a63862ae3c0,Spatiotemporal adaptive neural network for long-term forecasting of financial time series,"Optimal decision-making in social settings is often based on forecasts from time series (TS) data. Recently, several approaches using deep neural networks (DNNs) such as recurrent neural networks (RNNs) have been introduced for TS forecasting and have shown promising results. However, the applicability of these approaches is being questioned for TS settings where there is a lack of quality training data and where the TS to forecast exhibit complex behaviors. Examples of such settings include financial TS forecasting, where producing accurate and consistent long-term forecasts is notoriously difficult. In this work, we investigate whether DNN-based models can be used to forecast these TS conjointly by learning a joint representation of the series instead of computing the forecast from the raw time-series representations. To this end, we make use of the dynamic factor graph (DFG) to build a multivariate autoregressive model. We investigate a common limitation of RNNs that rely on the DFG framework and propose a novel variable-length attention-based mechanism (ACTM) to address it. With ACTM, it is possible to vary the autoregressive order of a TS model over time and model a larger set of probability distributions than with previous approaches. Using this mechanism, we propose a self-supervised DNN architecture for multivariate TS forecasting that learns and takes advantage of the relationships between them. We test our model on two datasets covering 19 years of investment fund activities. Our experimental results show that the proposed approach significantly outperforms typical DNN-based and statistical models at forecasting the 21-day price trajectory. We point out how improving forecasting accuracy and knowing which forecaster to use can improve the excess return of autonomous trading strategies. © 2021 Elsevier B.V., All rights reserved.","Chatigny, P.; Patenaude, J.-M.; Wang, S.",2021,10.1016/j.ijar.2020.12.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101315001&doi=10.1016%2Fj.ijar.2020.12.002&partnerID=40&md5=eed6e32a846204aecf5b2e3a39ad4c48,scopus
ee3869d724e9f558,Specification tests for nonlinear dynamic models,"We propose a new adequacy test and a graphical evaluation tool for nonlinear dynamic models. The proposed techniques can be applied in any set-up where parametric conditional distribution of the data is specified and, in particular, to models involving conditional volatility, conditional higher moments, conditional quantiles, asymmetry, Value at Risk models, duration models, diffusion models, etc. Compared to other tests, the new test properly controls the nonlinear dynamic behaviour in conditional distribution and does not rely on smoothing techniques that require a choice of several tuning parameters. The test is based on a new kind of multivariate empirical process of contemporaneous and lagged probability integral transforms. We establish weak convergence of the process under parameter uncertainty and local alternatives. We justify a parametric bootstrap approximation that accounts for parameter estimation effects often ignored in practice. Monte Carlo experiments show that the test has good finite-sample size and power properties. Using the new test and graphical tools, we check the adequacy of various popular heteroscedastic models for stock exchange index data.","Kheifets, Igor L.",2015,10.1111/ectj.12040,None,wos
e1687aa7566d8268,Spot price forecasting for best trading strategy decision support in the Iberian electricity market,"The increasing volatility in electricity markets has reinforced the need for better trading strategies by both sellers and buyers to limit the exposure to losses. Accordingly, this paper proposes an electricity trading strategy based on a mid-term forecast of the average spot price and a risk premium analysis based on this forecast. This strategy can help traders (buyers and sellers) decide whether to trade in the futures market (of varying monthly maturity) or to wait and trade in the spot market. The forecast model consists of an Artificial Neural Network trained with the Long Short Term Memory architecture to predict the average monthly spot prices, using only market price-related data as input variables. Statistical analysis verified the correlation and dependency between variables. The forecast model was trained, validated and tested with price data from the Iberian Electricity Market (MIBEL), in particular the Spanish zone, between January 2015 and August 2019. The last year of this period was reserved for testing the performance of the proposed forecast model and trading strategy. For comparison purposes, the results of a forecasting model trained with the Extreme Learning Machine over the same period are also presented. In addition, the forecasted value of the average monthly spot price was used to perform a risk premium analysis. The results were promising, as they indicated benefits for traders adopting the proposed trading strategy, proving the potential of the forecast model and the risk premium analysis based on this forecast. © 2023 Elsevier B.V., All rights reserved.","Magalhães, B.G.; Bento, P.M.R.; Pombo, J.A.N.; Calado, M.R.A.; Mariano, S.J.P.S.",2023,10.1016/j.eswa.2023.120059,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152124621&doi=10.1016%2Fj.eswa.2023.120059&partnerID=40&md5=2fc811ab19d0dccddc007edf8afeaadc,scopus
a76de222c4ec67a3,"Statistical actuarial estimation of the Capitation Payment Unit from copula functions and deep learning: historical comparability analysis for the Colombian health system, 2015–2021","The Capitation Payment Unit (CPU) financing mechanism constitutes more than 70% of health spending in Colombia, with a budget allocation of close to 60 trillion Colombian pesos for the year 2022 (approximately 15.7 billion US dollars). This article estimates actuarially, using modern techniques, the CPU for the contributory regime of the General System of Social Security in Health in Colombia, and compares it with what is estimated by the Ministry of Health and Social Protection. Using freely available information systems, by means of statistical copulas functions and artificial neural networks, pure risk premiums are calculated between 2015 and 2021. The study concludes that the weights by risk category are systematically different, showing historical pure premiums surpluses in the group of 0–1 years and deficits (for the regions normal and cities) in the groups over 54 years of age.","Espinosa, Oscar; Bejarano, Valeria; Ramos, Jeferson; Martínez, Boris",2023,10.1186/s13561-022-00416-5,None,proquest
e89622193853160a,Statistical-mechanical aids to calculating term-structure models,"Recent work in statistical mechanics has developed new analytical and numerical techniques to solve coupled stochastic equations. This paper describes application of the very fast simulated reannealing and path-integral methodologies to the estimation of the Brennan and Schwartz two-factor term-structure (time-dependent) model of bond prices. It is shown that these methodologies can be utilized to estimate more complicated n-factor nonlinear models. Applications to other systems are stressed. © 1990 The American Physical Society. © 2015 Elsevier B.V., All rights reserved.","Ingber, L.",1990,10.1103/physreva.42.7057,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0000885755&doi=10.1103%2FPhysRevA.42.7057&partnerID=40&md5=7a538a086e652ffbed77c37d63eb9224,scopus
ff04be79fa6dba3b,Stochastic Gradient Descent in Continuous Time,"Stochastic gradient descent in continuous time (SGDCT) provides a computationally efficient method for the statistical learning of continuous-time models, which are widely used in science, engineering, and finance. The SGDCT algorithm follows a (noisy) descent direction along a continuous stream of data. SGDCT performs an online parameter update in continuous time with the parameter updates theta(t) satisfying a stochastic differential equation. We prove that lim(t ->infinity) del(g) over bar(theta(t)) = 0, where (g) over bar is is a natural objective function for the estimation of the continuous-time dynamics. The convergence proof leverages ergodicity by using an appropriate Poisson equation to help describe the evolution of the parameters for large times. For certain continuous-time problems, SGDCT has some promising advantages compared to a traditional stochastic gradient descent algorithm. This paper mainly focuses on applications in finance, such as model estimation for stocks, bonds, interest rates, and financial derivatives. SGDCT can also be used for the optimization of high-dimensional continuous time models, such as American options. As an example application, SGDCT is combined with a deep neural network to price high-dimensional American options (up to 100 dimensions).","Sirignano, Justin; Spiliopoulos, Konstantinos",2017,10.1137/17m1126825,None,wos
5f581f84b018d30d,Stochastic interest rates in the analysis of energy investments: Implications on economic performance and sustainability,"A systematic impact assessment of stochastic interest and inflation rates on the analysis of energy investments is presented. A real-options algorithm has been created for this task. Constant interest rates incorporating high risk premium have been extensively used for economic calculations, within the framework of traditional direct cash flow methods, thus favouring immediate, irreversible investments in the expense of, sometimes, insubstantially low anticipated yields. In this article, not only incomes and expenses but also interest and inflation rates are considered stochastically evolving according to specific probabilistic models. The numerical experiments indicated that the stochastic interest rate forecasts fluctuate in such low levels that may signal delayed investment entry in favour of higher expected yields. The implementation of stochastically evolving interest rates in energy investment analysis may have a controversial effect on sustainability. Displacements of inefficient plants may be significantly delayed, thus prolonging high CO sub(2) emission rates. Under the current CO sub(2) allowance prices or their medium-term forecasts, this situation may not be improved and flexible policy interventions may be necessitated.","Tolis, Athanasios; Doukelis, Aggelos; Tatsiopoulos, Ilias",2010,10.1016/j.apenergy.2009.11.033,None,proquest
f2cb1b203a86e3d4,Stochastic period and cohort effect state-space mortality models incorporating demographic factors via probabilistic robust principal components,"In this study we develop a multi-factor extension of the family of Lee-Carter stochastic mortality models. We build upon the time, period and cohort stochastic model structure to extend it to include exogenous observable demographic features that can be used as additional factors to improve model fit and forecasting accuracy. We develop a dimension reduction feature extraction framework which (a) employs projection based techniques of dimensionality reduction; in doing this we also develop (b) a robust feature extraction framework that is amenable to different structures of demographic data; (c) we analyse demographic data sets from the patterns of missingness and the impact of such missingness on the feature extraction, and (d) introduce a class of multi-factor stochastic mortality models incorporating time, period, cohort and demographic features, which we develop within a Bayesian state-space estimation framework; finally (e) we develop an efficient combined Markov chain and filtering framework for sampling the posterior and forecasting. We undertake a detailed case study on the Human Mortality Database demographic data from European countries and we use the extracted features to better explain the term structure of mortality in the UK over time for male and female populations when compared to a pure Lee-Carter stochastic mortality model, demonstrating our feature extraction framework and consequent multi-factor mortality model improves both in sample fit and importantly out-off sample mortality forecasts by a non-trivial gain in performance. © 2021 Elsevier B.V., All rights reserved.","Toczydłowska, D.; Peters, G.; Fung, M.C.; Shevchenko, P.V.",2017,10.3390/risks5030042,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055749896&doi=10.3390%2Frisks5030042&partnerID=40&md5=8e1387341d859cffdee037ca8e59109b,scopus
9efd0961480d44fa,Stock Market Over-reaction: The South African Evidence,"It has been suggested that stock markets over-react and that investors pay too much attention to recent “dramatic” news. If over-reaction does occur and prices overshoot then there should be a subsequent revision in the opposite direction. This paper outlines empirical research into the over-reaction hypothesis on the Johannesburg Stock Exchange using data over the period July 1974 to June 1989 for two hundred and four relatively well traded securities. The results are consistent with the over-reaction hypothesis and indicate substantial weak form inefficiencies in the South African stock market in the long-term. The performance of portfolios of shares formed on the basis of prior return data can be predicted and, on average, portfolios of prior ‘losers’ outperformed prior ‘winners’ by about twenty percent over the three years after portfolio formation. Finally, comparison between the empirical results and a similar study for the New York Stock Exchange calls into some question the hypothesis that exceptionally large returns in January in the USA are due to investor tax loss selling. There is evidence of both a January effect and an asymmetric excess returns effect for the South African market but it is less pronounced than for the American market. © 1992, Taylor & Francis Group, LLC. All rights reserved. © 2015 Elsevier B.V., All rights reserved.","Page, M.J.; Way, C.V.",1992,10.1080/10293523.1992.11082314,https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649803751&doi=10.1080%2F10293523.1992.11082314&partnerID=40&md5=9cd756ed9454bc64c6b0446e9333f57b,scopus
f529c768b7421166,Stock Ranking with Multi-Task Learning,"Stock prediction, aiming at predicting the future trends of stocks, plays a key role in stock investment. Towards the investment target, the primary task is selecting the stocks with potentials to obtain the highest excess returns, always regarded as stock ranking. List-wise stock ranking is able to consider the relative comparisons of multiple stocks, approaching the essence of stock ranking most. However, most existing methods fail in list-wise stock ranking, because the information complexity and small number of samples bring in training difficulties. To address these limitations, a novel Deep Multi-Task Learning (DMTL) solution is proposed, called Multi-Task Stock Ranking (MTSR). It utilizes the joint learning framework of DMTL to learn the list-wise stock ranking with the enhancements of auxiliary tasks. With DMTL, the easily-trained tasks act as learning guider, providing extra gradient backpropagation, to help learn the hardly-trained list-wise ranking task. Additionally, Task Relation Attention is utilized to capture the dynamic task relations to achieve better knowledge transfer between tasks. The experiments conducted on real-world stock datasets demonstrate the superiority of MTSR over several state-of-the-art methods. © 2022 Elsevier B.V., All rights reserved.","Ma, T.; Tan, Y.",2022,10.1016/j.eswa.2022.116886,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127127011&doi=10.1016%2Fj.eswa.2022.116886&partnerID=40&md5=8ec2a8a3cf191d9de530898998c026d3,scopus
3b6660617e1be27a,Stock Selection Using Machine Learning Based on Financial Ratios,"Stock prediction has garnered considerable attention among investors, with a recent focus on the application of machine learning techniques to enhance predictive accuracy. Prior research has established the effectiveness of machine learning in forecasting stock market trends, irrespective of the analytical approach employed, be it technical, fundamental, or sentiment analysis. In the context of fiscal year-end selection, the decision may initially seem straightforward, with December 31 being the apparent choice, as discussed by B. Kamp in 2002. The primary argument for a uniform fiscal year-end centers around comparability. When assessing the financial performance of two firms with differing fiscal year-ends, substantial shifts in the business environment during non-overlapping periods can impede meaningful comparisons. Moreover, when two firms merge, the need to synchronize their annual reporting often results in shorter or longer fiscal years, complicating time series analysis. In the US S&P stock market, misaligned fiscal years lead to variations in report publication dates across different industries and market segments. Since the financial reporting dates of US S&P companies are determined independently by each listed entity, relying solely on these dates for investment decisions may prove less than entirely reliable and impact the accuracy of return prediction models. Hence, our interest lies in the synchronized fiscal year of the TW stock market, leveraging machine learning models for fundamental analysis to forecast returns. We employed four machine learning models: Random Forest (RF), Feedforward Neural Network (FNN), Gated Recurrent Unit (GRU), and Financial Graph Attention Network (FinGAT). We crafted portfolios by selecting stocks with higher predicted returns using these machine learning models. These portfolios outperformed the TW50 index benchmarks in the Taiwan stock market, demonstrating superior returns and portfolio scores. Our study’s findings underscore the advantages of using aligned financial ratios for predicting the top 20 high-return stocks in a mid-to-long-term investment context, delivering over 50% excess returns across the four models while maintaining lower risk profiles. Using the top 10 high-return stocks produced over 100% relative returns with an acceptable level of risk, highlighting the effectiveness of employing machine learning techniques based on financial ratios for stock prediction.","Tsai, Pei-Fen; Cheng-Han, Gao; Yuan, Shyan-Ming",2023,10.3390/math11234758,None,proquest
0c6ee7d2bea7d19d,Stock Trading Strategy Based on Multi-Scale Deep Reinforcement Learning and Price Movement Prediction,"Owing to the dynamic and complex properties of the stock market, generating a stable and highly profitable trading strategy is a challenge. Therefore, in this paper, a novel trading strategy is proposed, grounded in multi-scale deep reinforcement learning and stock price trend prediction, with supervised learning and reinforcement learning unified within a unified framework. Our proposed method is separated into three stages. First, a novel network was designed to predict stock price movement (upward, stationary, or downward) with 67.34% accuracy by combining the strengths of Convolutional Neural Network and Long-Short Term Memory. Second, leveraging the trained trend prediction network, states were enhanced with daily and weekly stock information, and multi-scale and backbone network modules were employed for effective feature extraction. Finally, a Double Deep Q-Network algorithm based on the augmented state was adopted to learn robust trading strategies. This study also contributes to the theoretical advancement of stock price prediction models by introducing a hybrid CNN-LSTM architecture for trend prediction and a multi-scale feature extraction framework for improved decision-making. Experimental results across six U.S. financial assets demonstrate that a notable accuracy of 67.34% for price trend prediction is achieved by our Convolutional Neural Network-Long-Short Term Memory network. Furthermore, the proposed trading strategy outperforms other deep reinforcement learning algorithms, yielding an average annualized return of 44.47%. By comparison, the PPO model achieves 37.60%, the TDQN model achieves 13.38%, the DQN-vanilla model achieves 28.71%, and the DQN-pattern model achieves 22.21%. These results validate the efficacy of the approach, showcasing substantial excess returns. © 2025 Elsevier B.V., All rights reserved.","Huang, Y.; Cui, K.; Lu, X.",2025,10.1142/s0219622025500737,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012223869&doi=10.1142%2FS0219622025500737&partnerID=40&md5=d6dec46fc1f5507e9743879f2357481f,scopus
b637484b643b9a37,Stock investment strategy combining earnings power index and machine learning,"We propose an intermediate-term stock investment strategy based on fundamental analysis and machine learning. The approach uses predictors from the Earnings Power Index (EPI) as input variables derived from cross-sectional and time-series data from a company's financial statements. The analytical methods of machine learning allow us to validate the link between financial factors and excess returns directly. We then select stocks for which returns are likely to increase at the time of the next disclosed financial statement. To verify the proposed approach's usefulness, we use company data listed publicly on the Korean stock market from 2013 to 2019. We examine the profitability of trading strategy based on ten machine-learning techniques by forming long, short, and hedge portfolios with three different measures. As a result, most portfolios, including EPI-related variables, present positive returns regardless of the period. Especially, the neural network of the two layers with sigmoid function presents the best performance for the period of 3 months and 6 months, respectively. Our results show that incorporating machine learning is useful for mid-term stock investment. Further research into the possible convergence of financial statement analysis and machine-learning techniques is warranted. © 2022 Elsevier B.V., All rights reserved.","Jun, S.Y.; Kim, D.S.; Jung, S.Y.; Jun, S.G.; Kim, J.W.",2022,10.1016/j.accinf.2022.100576,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138051303&doi=10.1016%2Fj.accinf.2022.100576&partnerID=40&md5=c12843ef5be8986f6a9785fb0232e51f,scopus
ab47e4e16b2d8b40,Stock market risk and return: An equilibrium approach,"Empirical evidence that expected stock returns are weakly related to volatility at the market level appears to contradict the intuition that risk and return are positively related. We investigate this issue in a general equilibrium exchange economy characterized by a regime-switching consumption process with time-varying transition probabilities between regimes. When estimated using consumption data, the model generates a complex, nonlinear and time-varying relation between expected returns and volatility, duplicating the salient features of the risk/return trade-off in the data. The results emphasize the importance of time-varying investment opportunities and highlight the perils of relying on intuition from static models.","Whitelaw, RF",2000,10.1093/rfs/13.3.521,None,wos
4d2e4e1efd54f90f,Stock market volatility predictability in a data-rich world: A new insight,"This study develops a shrinkage method, LASSO with a Markov regime-switching model (MRS-LASSO), to predict US stock market volatility. A set of 17 well-known macroeconomic and financial factors are used. The out-of-sample results reveal that the MRS-LASSO model yields statistically and economically significant volatility predictions. We further investigate the predictability of MRS-LASSO with respect to different market conditions, business cycles, and variable selection. Three factors (equity market returns, a short-term reversal factor, and a consumer sentiment index) are the most frequent predictors. To investigate the practical implications, we construct the expected variance risk premium (VRP) by using volatility forecasts generated from the LASSO and MRS-LASSO models to forecast future stock returns and find that those models are also powerful. © 2023 Elsevier B.V., All rights reserved.","Ma, F.; Wang, J.; Wahab, M.I.M.; Ma, Y.",2023,10.1016/j.ijforecast.2022.08.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140291431&doi=10.1016%2Fj.ijforecast.2022.08.010&partnerID=40&md5=2f88412fe379d55e2ce23fed80d4a33d,scopus
6444a892b0e70ae6,Stock return predictability in emerging markets: Does the choice of predictors and models matter across countries?,"This study aims to examine return predictability in 24 emerging markets disaggregated in different regions. We propose four specifications, including a benchmark model. Then, an augmented model appropriate for each country, including a large set of potential factors, is evaluated. Furthermore, a dynamic multifactor model is investigated for all countries. Finally, we relax the symmetric hypothesis in asset return predictability based on a non-parametric non-linear approach: the projection pursuit regression model. Our study reveals three main findings. First, we reject all previous findings supporting a standard model of asset return predictability that is valuable for all countries, as we show that each country has specific domestic factors (both macroeconomic and financial) useful to predict future returns. Second, our empirical framework shows that asset return predictability might be robustly modelled based on non-linear specification based on the projection pursuit regression model. Our findings' explanatory power of out-of-sample estimations is economically relevant. Our results are useful for investors and policy-makers for portfolio diversification and regulation policies.","Hadhri, Sinda; Ftiti, Zied",2017,10.1016/j.ribaf.2017.04.057,None,wos
1ec1888cb4dcdea5,Stock return prediction with multiple measures using neural network models,"In the field of empirical asset pricing, the challenges of high dimensionality, non-linear relationships, and interaction effects have led to the increasing popularity of machine learning (ML) methods. This study investigates the performance of ML methods when predicting different measures of stock returns from various factor models and investigates the feature importance and interaction effects among firm-specific variables and macroeconomic factors in this context. Our findings reveal that neural network models exhibit consistent performance across different stock return measures when they rely solely on firm-specific characteristic variables. However, the inclusion of macroeconomic factors from the financial market, real economic activities, and investor sentiment leads to substantial improvements in the model performance. Notably, the degree of improvement varies with the specific measures of stock returns under consideration. Furthermore, our analysis indicates that, after the inclusion of macroeconomic factors, there is a dissimilarity in model performance, variable importance, and interaction effects among macroeconomic and firm-specific variables, particularly concerning abnormal returns derived from the Fama–French three- and five-factor models compared with excess returns. This divergence is primarily attributed to the extent to which these factor models remove the variance associated with the macroeconomic variables. These findings collectively offer valuable insights into the efficacy of neural network models for stock return predictions and contribute to a deeper understanding of the intricate relationship between factor models, stock returns, and macroeconomic conditions in the domain of empirical asset pricing.","Wang, Cong",2024,10.1186/s40854-023-00608-w,None,proquest
47139e88004ecf9f,Stock return prediction: Stacking a variety of models,"We employ an ensemble learning approach, “stacking”, to refine and combine a variety of linear and nonlinear individual stock return prediction models. In an application of forecasting U.S. market excess return, stacking with a simple structure can outperform the traditional historical mean benchmark, Mallows model averaging, simple combination forecast, complete subset regression, combination elastic net forecast, and several other models in terms of both in- and out-of-sample performance measures on a consistent basis. More importantly, we find that the out-of-sample gains of stacking are especially evident during extreme downside market movements. Overall, stacking can generate substantive improvements in market excess return predictability. © 2022 Elsevier B.V., All rights reserved.","Zhao, A.B.; Cheng, T.",2022,10.1016/j.jempfin.2022.04.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129550064&doi=10.1016%2Fj.jempfin.2022.04.001&partnerID=40&md5=d484a59706ba72cf605ca0e12ac292de,scopus
9cf54d76c497fd00,Stock selection with random forest: An exploitation of excess return in the Chinese stock market,"In recent years, a variety of research fields, including finance, have begun to place great emphasis on machine learning techniques because they exhibit broad abilities to simulate more complicated problems. In contrast to the traditional linear regression scheme that is usually used to describe the relationship between the stock forward return and company characteristics, the field of finance has experienced the rapid development of tree-based algorithms and neural network paradigms when illustrating complex stock dynamics. These nonlinear methods have proved to be effective in predicting stock prices and selecting stocks that can outperform the general market. This article implements and evaluates the robustness of the random forest (RF) model in the context of the stock selection strategy. The model is trained for stocks in the Chinese stock market, and two types of feature spaces, fundamental/technical feature space and pure momentum feature space, are adopted to forecast the price trend in the long run and the short run, respectively. It is evidenced that both feature paradigms have led to remarkable excess returns during the past five out-of-sample period years, with the Sharpe ratios calculated to be 2.75 and 5 for the portfolio net value of the multi-factor space strategy and momentum space strategy, respectively. Although the excess return has weakened in recent years with respect to the multi-factor strategy, our findings point to a less efficient market that is far from equilibrium.In recent years, a variety of research fields, including finance, have begun to place great emphasis on machine learning techniques because they exhibit broad abilities to simulate more complicated problems. In contrast to the traditional linear regression scheme that is usually used to describe the relationship between the stock forward return and company characteristics, the field of finance has experienced the rapid development of tree-based algorithms and neural network paradigms when illustrating complex stock dynamics. These nonlinear methods have proved to be effective in predicting stock prices and selecting stocks that can outperform the general market. This article implements and evaluates the robustness of the random forest (RF) model in the context of the stock selection strategy. The model is trained for stocks in the Chinese stock market, and two types of feature spaces, fundamental/technical feature space and pure momentum feature space, are adopted to forecast the price trend in the long run and the short run, respectively. It is evidenced that both feature paradigms have led to remarkable excess returns during the past five out-of-sample period years, with the Sharpe ratios calculated to be 2.75 and 5 for the portfolio net value of the multi-factor space strategy and momentum space strategy, respectively. Although the excess return has weakened in recent years with respect to the multi-factor strategy, our findings point to a less efficient market that is far from equilibrium.","Tan, Zheng; Yan, Ziqin; Zhu, Guangwei",2019,10.1016/j.heliyon.2019.e02310,None,proquest
86f133ebdc5eaa79,Strategy and tactics in public debt management,"We examine the public debt management problem with respect to the maturity mix of new issues in a mean-variance framework. After identifying the main determinants of the long-run target (strategy), we focus on which interest rate conditions allow for a temporary deviation (tactics). The study is partly motivated by the apparent window of opportunity to issue more heavily at longer maturities given the recent historically low yields. We show that the room for long tactical positions on the long-term bond is actually narrower than predicted by rules of thumb based on Sharpe-like ratios. Once the model is augmented to embed real world features such as no price-taking and transaction costs, the scope for tactical position shrinks further. We discuss the model results and its implications in terms of the principal agent dilemma (government vs. debt manager); the paper also explores the financial stability implications arising from public debt issuance choices. All in all, our findings provide a rationale for the degree of caution often shown by many public debt managers in fulfilling their mandate. (C) 2015 Society for Policy Modeling. Published by Elsevier Inc. All rights reserved.","Dottori, Davide; Manna, Michele",2016,10.1016/j.jpolmod.2015.12.003,None,wos
9968a1106eb5e0f0,Stripping the Swiss discount curve using kernel ridge regression,"We analyze and implement the kernel ridge regression (KR) method developed in Filipovic et al. (Stripping the discount curve—a robust machine learning approach. Swiss Finance Institute Research Paper No. 22–24. SSRN. https://ssrn.com/abstract=4058150, 2022) to estimate the risk-free discount curve for the Swiss government bond market. We show that the insurance industry standard Smith–Wilson method is a special case of the KR framework. We recapitulate the curve estimation methods of the Swiss Solvency Test (SST) and the Swiss National Bank (SNB). In an extensive empirical study covering the years 2010–2022 we compare the KR curves with the SST and SNB curves. The KR method proves to be robust, flexible, transparent, reproducible and easy to implement, and outperforms the benchmarks in- and out-of-sample. We show the limitations of all methods for extrapolating the yield curve and propose possible solutions for the extrapolation problem. We conclude that the KR method is the preferred method for estimating the discount curve. © 2024 Elsevier B.V., All rights reserved.","Camenzind, N.; Filipovic, D.",2024,10.1007/s13385-024-00386-4,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195370618&doi=10.1007%2Fs13385-024-00386-4&partnerID=40&md5=f8b724d5222c2422b156f081fb57b69f,scopus
c38e480a7ebbb97e,Strongly-typed genetic programming and fuzzy inference system: An embedded approach to model and generate trading rules,"Generating trading signals is an interesting topic and a hard problem to solve. This work uses fuzzy inference system (FIS) and strongly typed genetic programming (STGP) to generate trading rules for the US stock market, a framework that we call FISTGP. The two embedded models have not been widely evaluated in financial applications, and according to the literature, their combination could improve forecasting performance. The fitness function used to train the STGP model is based on accuracy, optimizing the buy and sell signals, taking a different approach to the classic optimization of return–risk ratio. The rules are generated in a FIS framework, and the final signal depends on the amount of information that the investor relies on. The model is suited to each investor as a recommendation of when to change portfolio composition according to his or her particular criteria. Ternary rules are generated based on an economic interpretation, considering the risk-free rate as a part of more demanding rules. The model is applied to 90 of the most traded and active stocks in the US stock market. This approach generates important recommendations and delivers useful information to investors. The results show that the proposed model outperforms the Buy and Hold (B&H) strategy by 28.62% in the test period, considering excesses of return, with almost the same risk (1.28% higher). The other base models underperform in comparison to the B&H, with the proposed model also outperforming them. © 2020 Elsevier B.V., All rights reserved.","Michell, K.; Kristjanpoller R., W.",2020,10.1016/j.asoc.2020.106169,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079842746&doi=10.1016%2Fj.asoc.2020.106169&partnerID=40&md5=7d044e5fcb41907b98487380158cfe03,scopus
50e1df452d50cc94,Structural Laplace Transform and Compound Autoregressive Models,"This paper presents a new general class of compound autoregressive (Car) models for non-Gaussian time series. The distinctive feature of the class is that Car models are specified by means of the conditional Laplace transforms. This approach allows for simple derivation of the ergodicity conditions and ensures the existence of forecasting distributions in closed form, at any horizon. The last property is of particular interest for applications to finance and economics that investigate the term structure of variables and/or of their nonlinear transforms. The Car class includes a number of time-series models that already exist in the literature, as well as new models introduced in this paper. Their applications are illustrated by examples of portfolio management, term structure and extreme risk analysis.","Darolles, Serge; Gourieroux, Christian; Jasiak, Joann",2006,10.1111/j.1467-9892.2006.00479.x,None,proquest
fdcb4bf37f076de6,Structural break threshold VARs for predicting us recessions using the spread,"This paper proposes a model to predict recessions that accounts for non-linearity and a structural break when the spread between long- and short-term interest rates is the leading indicator. Estimation and model selection procedures allow us to estimate and identify time-varying non-linearity in a VAR. The structural break threshold VAR (SBTVAR) predicts better the timing of recessions than models with constant threshold or with only a break. Using real-time data, the SBTVAR with spread as leading indicator is able to anticipate correctly the timing of the 2001 recession. Copyright (c) 2006 John Wiley & Sons, Ltd.","Galvao, Ana Beatriz C.",2006,10.1002/jae.840,None,wos
6d40d863e6ce5316,Structural models of corporate bond pricing with maximum likelihood estimation,"This paper empirically examines the proxy, volatility-restriction (VR) and maximum likelihood (ML) approaches to implementing structural corporate bond pricing models, and documents that ML estimation is the best among the three implementation methods. Empirical studies using either the proxy approach or the VR method conclude that barrier-independent models significantly underestimate corporate bond yields. Although barrier-dependent models tend to overestimate the yield on average, they generate a sizable degree of underestimation. The present paper shows that the proxy approach is an upwardly biased estimator of the corporate assets and makes the empirical framework work systematically against structural models of corporate bond pricing. The VR approach may generate inconsistent corporate bond prices or may fail to give a positive corporate bond price for some structural models. When the Merton, LS, BD and LT models are implemented with ML estimation, we find substantial improvement in their performances. Our empirical analysis shows that the LT model is very accurate for predicting short-term bond yields, whereas the LS and BD models are good predictors for medium-term and long-term bonds. The Merton model however significantly overestimates short-term bond yields and underestimates long-term bond yields. Unlike empirical studies in the past, the Merton model implemented with ML estimation does not consistently underestimate corporate bond yields. All rights reserved, Elsevier","Li, K L; Wong, Hoi Ying",2008,10.1016/j.jempfin.2008.01.001,None,proquest
60815d5382594062,Structure of the intact ppar-γ-rxr-α nuclear receptor complex on dna,"This article develops critical values to test the null hypothesis of a unit root against the alternative of stationarity with asymmetric adjustment. Specific attention is paid to threshold and momentum threshold autoregressive processes. The standard Dickey–Fuller tests emerge as a special case. Within a reasonable range of adjustment parameters, the power of the new tests is shown to be greater than that of the corresponding Dickey–Fuller test. The use of the tests is illustrated using the term structure of interest rates. It is shown that the movements toward the long-run equilibrium relationship are best estimated as an asymmetric process. © 1998 Taylor & Francis Group, LLC. © 2017 Elsevier B.V., All rights reserved.","Enders, W.; Granger, C.W.J.",1998,10.1080/07350015.1998.10524769,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032345729&doi=10.1080%2F07350015.1998.10524769&partnerID=40&md5=22eda4c7422cb3f9079f6babe2f18cb9,scopus
cd2aff9d49f38305,"Supply, demand, and risk premiums in electricity markets","We model the impact of supply and demand on risk premiums in electricity futures, using daily data for 2003-2014. The model provides a satisfactory fit and allows for unspanned economic risk not embedded in futures prices. Model-implied spot risk premiums and forward biases are large, negative, highly time-varying, and exhibit plausible seasonal patterns. They differ from existing models, especially in periods of market turmoil, have not decreased in size over time, and help predict future returns. Both demand and supply have an economically significant impact on risk premiums. The risk premium associated with supply is characterized by large positive outliers. (c) 2021 Elsevier B.V. All rights reserved.","Jacobs, Kris; Li, Yu; Pirrong, Craig",2022,10.1016/j.jbankfin.2021.106390,None,wos
b583a5af78b01dc0,Surrogate-assisted optimal re-dispatch control for risk-aware regulation of dynamic total transfer capability,"To enable reliable power delivery through transmission tie-lines, total transfer capability (TTC) must be calculated and regulated to accommodate the transferred amount. However, the traditional optimal power flow (OPF)-based total transfer capability calculation is computationally expensive for efficient total transfer capability control due to the inclusion of a large set of differential-algebraic equations (DAEs) to verify transient stability constraints. In order to enable practicable total transfer capability regulation, a novel risk-aware deep learning-assisted paradigm is proposed here. First, a deep belief network (DBN) is employed to establish the total transfer capability predictor and surrogate the computation-intensive differential-algebraic equations in original optimal power flow formulas, simplifying the high-dimensional and intractable constraints deep belief networks without loss of nonlinearity. Particularly, in order to be aware of control risk from the predictive error of the deep belief networks, prediction intervals (PIs) are produced improved by using ensemble learning and used to disclose the probability of insufficient actions, further guaranteeing the sufficient and cost-effective control by compromising the tradeoff between cost and risk. Symbiotic organisms search (SOS) is then applied to solve the proposed risk-aware deep belief network-assisted total transfer capability control problem globally. The numerical studies testify that the proposed method enables economical, reliable, and full nonlinearity-retained dynamic total transfer capability regulation control within a risk-free surrogate-assisted and tractable physical model-driven hybrid framework. © 2021 Elsevier B.V., All rights reserved.","Qiu, G.; Liu, Y.; Liu, J.; Wang, L.; Liu, T.; Gao, H.; Jawad, S.",2021,10.1049/gtd2.12147,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101158129&doi=10.1049%2Fgtd2.12147&partnerID=40&md5=73bcf2eadd06cf306adf48ea591817a5,scopus
a252363c576b1816,Systematic Pricing and Trading of Municipal Bonds,"In this article, the authors propose a systematic approach for pricing and trading municipal bonds that leverages the feature-rich information available at the individual bond level. Based on the proposed pricing framework, they estimate several models using ridge regression and Kalman filtering. In their empirical work, they show that the models compare favorably in pricing accuracy to those available in the literature. In addition, the models can quickly adapt to changing market conditions. Incorporating the pricing models into relative value trading strategies, the authors demonstrate that the resulting portfolios generate significant excess returns and positive alpha relative to the Vanguard Long-Term Tax-Exempt Fund, one of the largest mutual funds in the municipal space. © 2022 Elsevier B.V., All rights reserved.","Kolm, P.N.; Purushothaman, S.",2022,10.3905/jfds.2021.1.079,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127392362&doi=10.3905%2Fjfds.2021.1.079&partnerID=40&md5=0d3f3669aec2fa0af60630b8e7f93f28,scopus
6c0ac1888b8f742d,TEND: A Target-Dependent Representation Learning Framework for News Document,"Real-time news documents published on the Internet have global financial and political impacts. Pioneering statistical approaches investigate manually defined features to capture lexical, sentiment, and event information, which suffer from feature sparsity. As a remedy, recent work has considered learning dense vector representations for documents. Such representations are general, which can not model target-dependent scenarios, such as stance detection towards a specific claim. There has been work on target-specific word and sentence representations, but little was done on target-dependent document representation. Moreover, documents contain more potentially helpful information, but also noise compared to events and sentences. To address the above issues, we focus on models that are: 1. task-driven, which optimize the neural network representations for the end task; 2. target-specific, learning news representations by considering the influence of specific targets. In particular, we propose a novel document-level target-dependent learning framework TEND. The framework employs the information of the target and the news abstract as clues, obtaining relatively informative sentences from the entire document for our objectives. The framework assembles a document representation by integrating the news abstract representation and a weighted sum of sentence representations in the document. To the best of our knowledge, we are among the first to investigate target-dependent document representation. Existing text representation models can be easily integrated into our TEND framework, and it is general enough to be applied to different target-dependent document representation tasks. We empirically evaluate our framework on two target-dependent document-level tasks, including a cumulative abnormal return prediction task and a news stance detection task. Results show that our models give the best performances compared to state-of-the-art document embedding methods, yielding robust and consistent performances across datasets.",J. Duan; X. Ding; Y. Zhang; T. Liu,2019,10.1109/taslp.2019.2947364,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8868172,ieeexplore
5b3f2c4540a8a7c5,THE REGIME-DEPENDENT EVOLUTION of CREDIBILITY: A FRESH LOOK at Hong Kong'S LINKED EXCHANGE RATE SYSTEM,"An estimated Markov-switching DSGE modeling framework that allows for parameter shifts across regimes is employed to test the hypothesis of regime-dependent credibility of Hong Kong's linked exchange rate system. The baseline model distinguishes two regimes with respect to the time-series properties of the risk premium. Regime-dependent impulse responses to macroeconomic shocks reveal substantial differences in spreads. To test the sensitivity of the results, a number of robustness checks are performed. The findings contribute to efforts at modeling exchange rate regime credibility as a nonlinear process with two distinct regimes. © 2019 Elsevier B.V., All rights reserved.","Blagov, B.; Funke, M.",2019,10.1017/s136510051700075x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045762185&doi=10.1017%2FS136510051700075X&partnerID=40&md5=e7efb5e1e34ec2ce7ac00bf000c579d0,scopus
fe46b71e2ee515f3,THE SEARCH FOR TIME-SERIES PREDICTABILITY-BASED ANOMALIES,". This paper introduces a new algorithm for exploiting time-series predictability-based patterns to obtain an abnormal return, or alpha, with respect to a given benchmark asset pricing model. The algorithm proposes a deterministic daily market timing strategy that decides between being fully invested in a risky asset or in a risk-free asset, with the trading rule represented by a parametric perceptron. The optimal parameters are sought in-sample via differential evolution to directly maximize the alpha. Successively using two modern asset pricing models and two different portfolio weighting schemes, the algorithm was able to discover an undocumented anomaly in the United States stock market cross-section, both out-of-sample and using small transaction costs. The new algorithm represents a simple and flexible alternative to technical analysis and forecast-based trading rules, neither of which necessarily maximizes the alpha. This new algorithm was inspired by recent insights into representing reinforcement learning as evolutionary computation. © 2022 Elsevier B.V., All rights reserved.","Ospina-Holguin, J.H.; Padilla-Ospina, A.M.",2021,10.3846/jbem.2021.15650,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123798331&doi=10.3846%2Fjbem.2021.15650&partnerID=40&md5=24f80df9c903c2537c0327df647bf65c,scopus
8922354095aaf07f,THE SPECULATIVE DEMAND FOR MONEY - AN ALTERNATIVE APPROACH,"THE SPECULATIVE DEMAND FOR MONEY HAS OCCUPIED AN IMPORTANT ROLE IN KEYNES' GENERAL THEORY.  SINCE THEN IT HAS RECEIVED ONLY SPORADIC ATTENTION, DUE LARGELY TO THE FACT THAT THE THEORY IN ITS ORIGINAL FORM HAS USUALLY FAILED TO SURVIVE THE EMPIRICAL TESTS.  THE SPECULATIVE DEMAND FOR MONEY IS ESTIMATED USING THE GENERAL FRAMEWORK OF THE 'EFFICIENT MARKETS THEORY'.  THE PERIOD COVERED IS OF A RELATIVELY STABLE INSTITUTIONAL SETTING FOLLOWING THE 1951 U.S.  TREASURY-FEDERAL RESERVE ACCORD.  THE RESULTS FOR THIS PERIOD STRONGLY INDICATE THE EXISTENCE OF THE SPECULATIVE DEMAND FOR MONEY.  TABLE.  NOTES.","Laumas, G S",1976,10.1111/j.1536-7150.1976.tb01210.x,None,proquest
45482d9d94cd349f,THE STRUCTURE OF SKEWNESS PREFERENCES IN ASSET PRICING MODELS WITH HIGHER MOMENTS: AN EMPIRICAL TEST,"In this paper, the authors employ a nonlinear formulation to examine empirically the structural content of the three moment capital asset pricing model (CAPM). Whereas previous research focused on the coefficients of beta and co‐skewness, this paper presents empirical results on the market risk premium and elasticity coefficient components of these two coefficients. The results indicate that although the estimated coefficient of coskewness gives important information on the marginal rate of substitution between skewness and expected return, the elasticity coefficient can provide additional (albeit different) information on skewness preference that is independent of the effects of the market risk premium. This research also shows how the non‐linear formulation provides a direct linkage between the twomoment and three‐moment CAPM versions and thus provides an empirical test of the theoretical conditions under which skewness preference is consistent with the two‐moment CAPM empiricial results. Copyright © 1988, Wiley Blackwell. All rights reserved © 2016 Elsevier B.V., All rights reserved.","Sears, R.S.; Wei, K.C.J.",1988,10.1111/j.1540-6288.1988.tb00772.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0013178861&doi=10.1111%2Fj.1540-6288.1988.tb00772.x&partnerID=40&md5=4187f72b11f820ea8b517dd3bcad4551,scopus
b1aa1d6583414fbd,THE VALUE OF MORTGAGE PREPAYMENT AND DEFAULT OPTIONS,"We use an implicit alternating direction numerical procedure to estimate the value of a fixed-rate mortgage (FRM) with embedded default and prepayment options. The value of FRMs depends on interest rates, the house value, and mortgage maturity. Our numerical results suggest that the joint option value of prepayment and default is considerably high, even at loan origination. We extend the model to include prepayment penalties in FRM valuation. (C) 2009 Wiley Periodicals, Inc. Jrl Fut Mark 29:840-861, 2009","Chen, Yong; Connolly, Michael; Tang, Wenjin; Su, Tie",2009,10.1002/fut.20388,None,wos
c3de53dd92c70087,Targeting Long Rates in a Model with Segmented Markets,"This paper develops a model of segmented financial markets in which the net worth of financial institutions limits the degree of arbitrage across the term structure. The model is embedded into the canonical Dynamic New Keynesian (DNK) framework. We estimate the model using data on the term premium. Our principal results include the following. First, the estimated segmentation coefficient implies a nontrivial effect of central bank asset purchases on yields and real activity. Second, there are welfare gains to having the central bank respond to the term. premium, e.g., including the term premium in the Taylor Rule. Third, a policy that directly targets the term premium sterilizes the real economy from shocks originating in the financial sector. A term-premium peg can have sigmficant welfare effects. (ILL E12, E23, E31, E43, E52, E58)","Carlstrom, Charles T.; Fuerst, Timothy S.; Paustian, Matthias",2017,10.1257/mac.20150179,None,wos
bf72d6fc89554dd0,Technical indicators and aggregate stock returns: An updated look,"We provide updated analyses of technical indicators and aggregate stock return forecasting. We construct 105 new technical indicators as big data predictors and adopt eight advanced shrinkage methods in our forecasting analyses. Our evidence suggests that the refinements of 105 technical factors successfully overcome those of Neely et al.’s (2014) 14 technical variables to a large extent and challenge the forecasting role of Welch and Goyal's (2008) 14 popular macroeconomic variables when ENet and Lasso are used. The excellent performance of the forecasting information based on 105 technical indicators generates sufficiently high in-sample and out-of-sample R-squared values and economically sizable gains in forecasting the excess returns of the composite Standard & Poor 500 market. The corresponding evidence remains robust to changes in the business cycle, forecasting horizons, and alternative evaluation periods. © 2025 Elsevier B.V., All rights reserved.","Shi, Q.",2025,10.1016/j.mulfin.2025.100898,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216555986&doi=10.1016%2Fj.mulfin.2025.100898&partnerID=40&md5=d990bba991d2907cab343d027f7fee3d,scopus
80e3352b0bafafdc,Technical trading rules and the size of the risk premium in security returns,"Among analysts, technical trading rules are widely used for forecasting security returns. Recent literature provides evidence that these rules may provide positive profits after accounting for transaction costs. This would be contrary to the theory of the efficient market hypothesis which states that security prices cannot be forecasted from their past values or other past variables. This paper uses the daily Dow Jones Industrial Average Index from 1963 to 1988 to examine the linear and nonlinear predictability of stock market returns with simple technical trading rules, by using the nearest neighbors and the feedforward network regressions. Evidence of nonlinear predictability is found in the stock market returns by using the past returns and the buy and sell signals of the moving average rules.","Gencay, R; Stengos, T",1997,10.2202/1558-3708.1026,None,wos
8b3b7d7aa07bfbd6,Techno-Economic Investment Risk Modeling of Battery Energy Storage System Participating in Day-Ahead Frequency Regulation Market,"Owing to its high capital cost, Battery Energy Storage System (BESS) investment risk has received considerable attention in recent years. Currently, day-ahead frequency regulation service is one major revenue source for BESS, and the revenue is exposed to a compound of stochastic market risk and technical risk. On the market risk side, due to a lack of long-term contracts, investors are exposed to “price risk” and “volume (revenue hours) risk” over the entire investment horizon of 5–10 years. On the technical side, performance issues such as equipment degradation and inherent defects can result in reduced or even negative revenue for BESS under the pay-for-performance remuneration structure. Quantifying these risks is important for investors and banks to assess a project’s investability and bankability. However, existing BESS techno-economic literature has mostly focused on developing optimal control strategies to maximize revenue or optimal battery sizing to reduce capital expenditure. To our knowledge, none of the literature to date has addressed the long-term risk perspective of BESS investment. This study aims to fill this gap by developing a long-term probabilistic revenue estimate that considers these risk factors using Monte Carlo simulations. A case study using Taiwan’s newly launched day-ahead market, which has similar grid dynamics and revenue risk factors as in most markets, is also presented in this paper. Simulation result shows that, for the conservative P90 (90% exceedance probability) scenario, expected return of a hypothetical 10MW (half-hour battery) BESS investment is 8.65% and its debt service coverage ratio is 1.189.",P. -H. Hsi; J. C. P. Shieh,2024,10.1109/access.2024.3390439,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10504254,ieeexplore
c778d20e72c5f015,Technological bias at the exchange rate market,"Prediction of exchange rates has been a topic for debate in economic literature since the late 1980s. The recent development of machine learning techniques has spurred a plethora of studies that further improves the prediction models for currency markets. This high‐tech progress may create challenges for market efficiency along with information asymmetry and irrationality of decision‐making. This technological bias emerges from the fact that recent innovative approaches have been used to solve trading tasks and to find the best trading strategies. This paper demonstrates that traders can leverage technological bias for financial market forecasting. Those traders who adapt faster to the changes in market innovations will get excess returns. To support this hypothesis we compare the performance of deep learning methods, shallow neural networks with baseline prediction methods and a random walk model using daily closing rate between three currency pairs: Euro and US Dollar (EUR/USD), British Pound and US Dollar (GBP/USD), and US Dollar and Japanese Yen (USD/JPY). The results demonstrate that deep learning achieves higher accuracy than alternate methods. The shallow neural network outperforms the random walk model, but cannot surpass ARIMA accuracy significantly. The paper discusses possible outcomes of the technological shift for financial market development and accounting conforming also to adaptive market hypothesis.","Galeshchuk, Svitlana",2017,10.1002/isaf.1408,None,proquest
f0b7502b7b81fe47,Temperature effects on crop yields in heat index insurance,"Heat can cause substantial yield losses in crop production and climate change is increasing the risk of this kind of damage. Weather index insurance can help to reduce the financial losses resulting from heat exposure. This paper introduces crop-specific payout functions based on restricted cubic splines in heat index insurance. The use of restricted cubic splines is a cutting-edge method to reflect empirically estimated temperature effects on crop yields and to estimate temperature-related yield losses. The integration of these temperature effects in payout functions facilitates insurance design and allows hourly temperatures to be used as the underlying index. An empirical analysis is used to assess heat stress effects for a panel of East German winter wheat and winter rapeseed producers, to calibrate insurance contracts accordingly and simulate the resulting risk reducing capacities. We find that the insurance scheme introduced here leads to statistically and economically significant out-of-sample risk reducing capacities for farmers, i.e. risk premiums are reduced by up to approximately 20% at the median, in comparison to the uninsured status and at the actuarially fair premium. Moreover, we highlight that policy-makers can support the cost-efficient provision of market-based weather index insurance by fostering data collection and data","Bucheli, Janic; Dalhaus, Tobias; Finger, Robert",2022,10.1016/j.foodpol.2021.102214,None,wos
91b97eea44bd9561,Term Structure Modeling and Forecasting of Government Bond Yields,"Accurate modelling and precise estimation of the term structure of interest rate are of crucial importance in many areas of finance and macroeconomics as it is the most important factor in the capital market and probably the economy. This study compares the in-sample fit and out-of-sample forecast accuracy of the Cox-Ingersoll-Ross (CIR) and Nelson-Siegel models. For the in-sample fit, there is a significant lack of information on the short-term CIR model. The CIR model should also be considered too poor to describe the term structure in a simulation-based context. It generates a downward slope average yield curve. Contrary to CIR model, Nelson-Siegel model is not only compatible to fit attractively the yield curve but also accurately forecast the future yield for various maturities. Furthermore, the non-linear version of the Nelson-Siegel model outperforms the linearised one. In a simulation-based context, the Nelson-Siegel model is capable to replicate most of the stylised facts of the Japanese market yield curve. Therefore, it turns out that the Nelson-Siegel model (non-linear version) could be a good candidate among various alternatives to study the evolution of the yield curve in Japanese market. Adapted from source document.","Ullah, Wali; Matsuda, Yasumasa; Tsukuda, Yoshihiko",2013,10.1111/1759-3441.12046,None,proquest
a2af68494b9d3555,Term structure estimation with liquidity-adjusted Affine Nelson Siegel model: A nonlinear state space approach applied to the Indian bond market,"Efficient term structure estimation in emerging markets is difficult not only because of overall lack of liquidity, but also because of the concentration of liquidity in a few securities. Using the arbitrage-free Affine Nelson-Siegel model, we explicitly incorporate this phenomenon using a proxy for liquidity based on observable data in the bond pricing function and estimate the term structure for Indian Government bond markets in a nonlinear state space setting using the Unscented Kalman Filter. We find strong empirical evidence in support of the extended model with both i) a better in-sample fit to bond prices, and ii) the likelihood ratio test rejecting the restrictions assumed in the standard AFNS specification. In an alternative specification, we also model liquidity as a latent risk factor within the AFNS framework. The estimated latent liquidity factor is found to be strongly correlated with the standard market benchmarks of overall liquidity and the India VIX index.","Kumar, Sudarshan; Virmani, Vineet",2022,10.1080/00036846.2021.1967866,None,proquest
187c6ade28f04d09,Term structure of risk under alternative econometric specifications,"This paper characterizes the term structure of risk measures such as value at risk (VaR) and expected shortfall under different econometric approaches including multivariate regime switching, GARCH-in-mean models with Student-t errors, two-component GARCH models and a nonparametric bootstrap. We show how to derive the risk measures for each of these models and document large variations in term structures across econometric specifications. An out-of-sample forecasting experiment applied to stock, bond and cash portfolios suggests that the best model is asset- and horizon specific but that the bootstrap and regime switching model are best overall for VaR levels of 5% and 1%, respectively. (c) 2005 Elsevier B.V. All rights reserved.","Guidolin, M; Timmermann, A",2006,10.1016/j.jeconom.2005.01.033,None,wos
e642c871e85d54cb,Testing different forms of efficiency for Dhaka Stock Exchange,"The Efficient-Market Hypothesis (EMH) asserts that efficient markets are informationally efficient or all information (market, public or private) should reflect on stock prices. No one could earn excess profit using any kind of information in efficient market. There are three forms of efficiency in markets: strong, semi-strong and weak. We tested EMH for Dhaka Stock Exchange (DSE) for the period 2003 2005. We used the excess return market model to test the semi-strong form efficiency of DSE. Two forecasting techniques, Autoregressive Integrated Moving Average (ARIMA) and neural network, are used to test the weak form efficiency of DSE. We get excess return for many stocks listed in DSE, demonstrating that DSE is not an efficient market in semi-strong form. Besides, the DSE market index is not random and the trend could be captured by ARIMA and neural network techniques. Therefore, the DSE is also not an efficient market in weak form.","Arefin, Jarka; Rahman, Rashedur M",2011,10.1504/ijfsm.2011.038325,None,proquest
5b36dfbcd718497b,"Testing for UIP-Type Relationships: Nonlinearities, Monetary Announcements and Interest Rate Expectations","This paper tests for UIP-type relationships by estimating first a benchmark linear Cointegrated VAR including the nominal exchange rate and the interest rate differential as well as central bank announcements, and then a Smooth Transition Cointegrated VAR (STCVAR) model incorporating nonlinearities and also taking into account the role of interest rate expectations. The analysis is conducted for five inflation targeting countries (the UK, Canada, Australia, New Zealand and Sweden) and three non-targeters (the US, the Euro-Area and Switzerland) using daily data from January 2000 to December 2020. While we cannot confirm the validity of UIP in its strictest theoretical sense, we find evidence for the existence of an equilibrium relationship between the exchange rate and the interest rate differential. Specifically, the nonlinear framework appears to be more appropriate to capture the adjustment towards the long-run equilibrium, since the estimated speed of adjustment is substantially faster and the short-run dynamic linkages more significant. Further, interest rate expectations play an important role: a fast adjustment only occurs when the market expects the interest rate to increase in the near future, namely central banks are perceived as more credible when sticking to their goal of keeping inflation at a low and stable rate. Also, central bank announcements have a more sizeable short-run effect in the nonlinear model. Finally, the equilibrium relationship between the exchange rate and the interest rate differential holds better in inflation targeting countries, where monetary authorities appear to achieve a higher degree of credibility.","Anderl, Christina; Caporale, Guglielmo Maria",2022,10.1007/s11079-021-09640-8,None,wos
3d256d8a11b4dd5d,Testing for two-regime threshold cointegration in vector error-correction models,"This paper examines a two-regime vector error-correction model with a single cointegrating vector and a threshold effect in the error-correction term. We propose a relatively simple algorithm to obtain maximum likelihood estimation of the complete threshold cointegration model for the bivariate case. We propose a SupLM test for the presence of a threshold. We derive the null asymptotic distribution, show how to simulate asymptotic critical values, and present a bootstrap approximation. We investigate the performance of the test using Monte Carlo simulation, and find that the test works quite well. Applying our methods to the term structure model of interest rates, we find strong evidence for a threshold effect. (C) 2002 Published by Elsevier Science B.V.","Hansen, BE; Seo, B",2002,10.1016/s0304-4076(02)00097-0,None,wos
00b59708a2208b21,Testing predictability and nonlinear dependence in the Indian stock market,"This paper suggests a systematic approach to studying predictability and nonlinear dependence in the context of the Indian stock market, one of the most important emerging stock markets in the world. The proposed approach considers nonlinear dependence in returns and envisages appropriate specification of both the conditional first- and second-order moments, so that final conclusions are free from any probable statistical consequences of misspecification. To this end, a number of rigorous tests are applied on the returns, based on four major daily indices of the Indian stock market. It is found that the Indian stock market is predictable, and this observed lack of efficiency is due to serial correlation, nonlinear dependence, day-of-the week effects, parameter instability, conditional heteroskedasticity (GARCH), daily-level seasonality in volatility, the short-term interest rate (in some subperiods of some indices), and some dynamics in the higher-order moments.","Sarkar, N; Mukhopadhyay, D",2005,10.1080/1540496x.2005.11052624,None,wos
045ccef9485f38e1,Testing the empirical performance of stochastic volatility models of the short-term interest rate,"I introduce two-factor discrete time stochastic volatility models of the short-term interest rate to compare the relative performance of existing and alternative empirical specifications. I develop a nonlinear asymmetric framework that allows for comparisons of non-nested models featuring conditional heteroskedasticity and sensitivity of the volatility process to interest rate levels. A new class of stochastic volatility models with asymmetric drift and nonlinear asymmetric diffusion process is introduced in discrete time and tested against the popular continuous time and symmetric and asymmetric GARCH models. The existing models are rejected in favor of the newly proposed models because of the asymmetric drift of the short rate, and the presence of nonlinearity, asymmetry, GARCH, and level effects in its volatility. I test the predictive power of nested and non-nested models in capturing the stochastic behavior of the risk-free rate. Empirical evidence on three-, six-, and 12-month U.S. Treasury bills indicates that two-factor stochastic volatility models are better than diffusion and GARCH models in forecasting the future level and volatility of interest rate changes. © 2018 Elsevier B.V., All rights reserved.","Bali, T.G.",2000,10.2307/2676190,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034386111&doi=10.2307%2F2676190&partnerID=40&md5=9adf8aee423204a0e105653f3f21f549,scopus
3eebe90718f24024,Testing the expectations theory of the term structure of interest rates in threshold models,"We test the expectations theory of the term structure of U.S. interest rates in nonlinear systems. These models allow the response of the change in short rates to past values of the spread to depend upon the level of the spread. The nonlinear system is tested against a linear system, and the results of testing the expectations theory in both models are contrasted. We find that the results of tests of the implications of the expectations theory depend on the size and sign of the spread. The long maturity spread predicts future changes of the short rate only when it is high. © 2008 Elsevier B.V., All rights reserved.","Clements, M.P.; Galvão, A.B.",2003,10.1017/s1365100502020163,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0141636266&doi=10.1017%2FS1365100502020163&partnerID=40&md5=1acc28231c51f29898d54323e04bb347,scopus
74695cb70436aa62,"Testing the uncovered interest parity using traded volatility, a time-varying risk premium and heterogeneous expectations","This paper carries out an empirical investigation of an extended version of Flood and Marion's (2000, Self-fulfilling risk predictions: an application to speculative attacks. Journal of International Economics 50, 245-268) UIP model, which incorporates a nonlinear time-varying risk premium that depends on both the expected variance of the future exchange rate and the relative worldwide private holdings of domestic and foreign government bonds. A novel contribution of our paper is the use of traded currency volatility, which is directly observable in the market place, to measure expectations about the future volatility of the exchange rate. Another contribution is the explicit modelling of heterogeneous exchange rate expectations formed by forward-looking fundamentalists and backward-looking chartists. Our overall empirical evidence provides strong support for the extended nonlinear UIP model. We also investigate for the first time the role of traded volatility in the dynamic behaviour of exchange rates, and find that high currency volatility is likely to produce oscillatory and unstable exchange rate paths. © 2006 Elsevier Ltd. All rights reserved. © 2006 Elsevier B.V., All rights reserved.","Sarantis, N.",2006,10.1016/j.jimonfin.2006.08.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750960093&doi=10.1016%2Fj.jimonfin.2006.08.002&partnerID=40&md5=5f02c4167892f6e8da7fd7b515be19f7,scopus
02493d3e75cc8c16,"The ""forward premium puzzle"" and the sovereign default risk","Carry-trade strategies which consist of buying forward high-yield currencies tend to yield positive excess returns when global financial markets are booming, whereas they generate losses during crises. Firstly, we show that the sovereign default risk, which is taken on by investing in high-yield currencies, may increase the magnitude of the gains during the boom periods and the losses during crises. We empirically test for this hypothesis on a sample of 18 emerging currencies over the period from June 2005 to September 2010, the default risk being proxied by the sovereign credit default swap spread. Relying on smooth transition regression (STR) models, we show that default risk contributes to the carry-trade gains during booms, and worsens the losses during busts. Secondly, we turn to the ""Fama regression"" linking the exchange-rate depreciation to the interest-rate differential. We propose a nonlinear estimation of this equation, explaining the puzzling evolution of its coefficient by the change in the market volatility along the financial cycle. Then, we introduce the default risk into this equation and show that the ""forward bias"", usually evidenced by a coefficient smaller than unity in this regression, is somewhat alleviated, as the default risk is significant to explain the exchange-rate change. © 2012 Elsevier Ltd. © 2017 Elsevier B.V., All rights reserved.","Coudert, V.; Mignon, V.",2013,10.1016/j.jimonfin.2012.05.025,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874775246&doi=10.1016%2Fj.jimonfin.2012.05.025&partnerID=40&md5=b7fab6ec75aa72f841ac0789d409a42e,scopus
5b51de8e2d09e5f3,The American foreign exchange option in time-dependent one-dimensional diffusion model for exchange rate,"The classical Garman-Kohlhagen model for the currency exchange assumes that the domestic and foreign currency risk-free interest rates are constant and the exchange rate follows a log-normal diffusion process. In this paper we consider the general case, when exchange rate evolves according to arbitrary one-dimensional diffusion process with local volatility that is the function of time and the current exchange rate and where the domestic and foreign currency risk-free interest rates may be arbitrary continuous functions of time. First non-trivial problem we encounter in time-dependent case is the continuity in time argument of the value function of the American put option and the regularity properties of the optimal exercise boundary. We establish these properties based on systematic use of the monotonicity in volatility for the value functions of the American as well as European options with convex payoffs together with the Dynamic Programming Principle and we obtain certain type of comparison result for the value functions and corresponding exercise boundaries for the American puts with different strikes, maturities and volatilities. Starting from the latter fact that the optimal exercise boundary curve is left continuous with right-hand limits we give a mathematically rigorous and transparent derivation of the significant early exercise premium representation for the value function of the American foreign exchange put option as the sum of the European put option value function and the early exercise premium. The proof essentially relies on the particular property of the stochastic integral with respect to arbitrary continuous semimartingale over the predictable subsets of its zeros. We derive from the latter the nonlinear integral equation for the optimal exercise boundary which can be studied by numerical methods. © 2008 Springer Science+Business Media, LLC. © 2012 Elsevier B.V., All rights reserved.","Rehman, N.; Shashiashvili, M.",2009,10.1007/s00245-008-9056-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-63049128694&doi=10.1007%2Fs00245-008-9056-7&partnerID=40&md5=5005bfa644091fda79c4d7e25bdfdd4e,scopus
086419ef1e815c6a,The COVID-19 pandemic and Bitcoin: Perspective from investor attention,"The response of the Bitcoin market to the novel coronavirus (COVID-19) pandemic is an example of how a global public health crisis can cause drastic market adjustments or even a market crash. Investor attention on the COVID-19 pandemic is likely to play an important role in this response. Focusing on the Bitcoin futures market, this paper aims to investigate whether pandemic attention can explain and forecast the returns and volatility of Bitcoin futures. Using the daily Google search volume index for the ""coronavirus"" keyword from January 2020 to February 2022 to represent pandemic attention, this paper implements the Granger causality test, Vector Autoregression (VAR) analysis, and several linear effects analyses. The findings suggest that pandemic attention is a granger cause of Bitcoin returns and volatility. It appears that an increase in pandemic attention results in lower returns and excessive volatility in the Bitcoin futures market, even after taking into account the interactive effects and the influence of controlling other financial markets. In addition, this paper carries out the out-of-sample forecasts and finds that the predictive models with pandemic attention do improve the out-of-sample forecast performance, which is enhanced in the prediction of Bitcoin returns while diminished in the prediction of Bitcoin volatility as the forecast horizon is extended. Finally, the predictive models including pandemic attention can generate significant economic benefits by constructing portfolios among Bitcoin futures and risk-free assets. All the results demonstrate that pandemic attention plays an important and non-negligible role in the Bitcoin futures market. This paper can provide enlightens for subsequent research on Bitcoin based on investor attention sparked by public emergencies.The response of the Bitcoin market to the novel coronavirus (COVID-19) pandemic is an example of how a global public health crisis can cause drastic market adjustments or even a market crash. Investor attention on the COVID-19 pandemic is likely to play an important role in this response. Focusing on the Bitcoin futures market, this paper aims to investigate whether pandemic attention can explain and forecast the returns and volatility of Bitcoin futures. Using the daily Google search volume index for the ""coronavirus"" keyword from January 2020 to February 2022 to represent pandemic attention, this paper implements the Granger causality test, Vector Autoregression (VAR) analysis, and several linear effects analyses. The findings suggest that pandemic attention is a granger cause of Bitcoin returns and volatility. It appears that an increase in pandemic attention results in lower returns and excessive volatility in the Bitcoin futures market, even after taking into account the interactive effects and the influence of controlling other financial markets. In addition, this paper carries out the out-of-sample forecasts and finds that the predictive models with pandemic attention do improve the out-of-sample forecast performance, which is enhanced in the prediction of Bitcoin returns while diminished in the prediction of Bitcoin volatility as the forecast horizon is extended. Finally, the predictive models including pandemic attention can generate significant economic benefits by constructing portfolios among Bitcoin futures and risk-free assets. All the results demonstrate that pandemic attention plays an important and non-negligible role in the Bitcoin futures market. This paper can provide enlightens for subsequent research on Bitcoin based on investor attention sparked by public emergencies.","Wan, Jieru; Wu, You; Zhu, Panpan",2023,10.3389/fpubh.2023.1147838,None,proquest
1144b886f92f558b,The Case for Causal Factor Investing,"Researchers use factor models to obtain unbiased estimates of the premia harvested by assets exposed to certain risk characteristics. These estimates are unbiased only if the factor models are correctly specified. Choosing the correct model specification requires knowledge of the causal graph that characterizes the underlying data-generating process. Following the current econometric canon, however, factor researchers choose their model specifications using associational (noncausal) arguments, such as the model's explanatory power, instead of applying causal inference procedures, such as do-calculus. As a result, factor investing models are likely misspecified, and the estimates of risk premia are biased. This article explains the dire consequences of factor investing's specification errors and calls for the need to rebuild the discipline under the more scientific foundations of causal factor investing. © 2024 Elsevier B.V., All rights reserved.","de Prado, M.; Lipton, A.; Zoonekynd, V.",2024,10.3905/jpm.2024.51.1.146,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209686202&doi=10.3905%2Fjpm.2024.51.1.146&partnerID=40&md5=b31ceb8daae39541bf7abf6b6d68e29d,scopus
32219b4eb50b7726,The Co-Integrated Vector Autoregression with Errors–in–Variables,"The co-integrated vector autoregression is extended to allow variables to be observed with classical measurement errors (ME). For estimation, the model is parametrized as a time invariant state-space form, and an accelerated expectation-maximization algorithm is derived. A simulation study shows that (i) the finite-sample properties of the maximum likelihood (ML) estimates and reduced rank test statistics are excellent (ii) neglected measurement errors will generally distort unit root inference due to a moving average component in the residuals, and (iii) the moving average component may–in principle–be approximated by a long autoregression, but a pure autoregression cannot identify the autoregressive structure of the latent process, and the adjustment coefficients are estimated with a substantial asymptotic bias. An application to the zero-coupon yield-curve is given. © 2021 Elsevier B.V., All rights reserved.","Nielsen, H.B.",2016,10.1080/07474938.2013.806853,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948710369&doi=10.1080%2F07474938.2013.806853&partnerID=40&md5=c5d9ff605a01be7d486ad7381bf29666,scopus
1aec91d9d8da5a64,The Dynamic Impact of Macro Factors on the Performance of Blended Real Estate Equity Strategies,"This article uses a small number of macro factors to model the performance of private US core real estate and associated blended strategies that incorporate listed and private non-core components. The macro factors selected are economic growth, real rate, expected inflation, the term structure, and credit spreads. Private real estate performance was de-smoothed using a nonlinear modeling approach that accounted for differing smoothing effects during identifiable regimes through market cycles. The estimated linear factor loadings are aligned with economic intuition and expectations, including real estate’s inflation hedging characteristics. Using threshold regression modeling to capture nonlinearities in the relationships, a smaller number of the factors were found to be of greater statistical significance. The impact of these factors is found to evolve over time, particularly during phases of market disruption. Although linear factor modeling remains the common approach to estimate risk–return exposures for asset allocation and portfolio risk management processes, the results suggest that these linear models should be adapted to consider these shifting relationships and resulting implications. © 2025 Elsevier B.V., All rights reserved.","Farrelly, K.; Moss, A.",2025,10.3905/jpm.2025.51.11.142,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105017711928&doi=10.3905%2Fjpm.2025.51.11.142&partnerID=40&md5=ef0473a31b5e01f9ac2af83908260360,scopus
94bc216fc3b42dd9,The Effect of Risk Factor Disclosures on the Pricing of Credit Default Swaps,"This study examines the relation between narrative risk disclosures in mandatory reports and the pricing of credit risk. In particular, we investigate whether and how the Securities and Exchange Commission (SEC) mandate of risk factor disclosures (RFDs) affects credit default swap (CDS) spreads. Based on the theory of Duffie and Lando (2001), we predict and find that CDS spreads decrease significantly after RFDs are made available in 10‐K/10‐Q filings. These results suggest that RFDs improve information transparency about the firm's underlying risk, thereby reducing the information risk premium in CDS spreads. The content analysis further reveals that disclosures pertinent to financial and idiosyncratic risk are especially relevant to credit investors. In cross‐sectional analyses, we document that RFDs are more useful for evaluating the business prospects and default risk of firms with greater information uncertainty/asymmetry. Overall, our findings imply that the SEC requirement for adding a risk factor section to periodic reports enhances the transparency of firm risk and facilitates credit investors in evaluating the credit quality of the firm.","Tzu‐Ting Chiu; Guan, Yuyan; Jeong‐Bon Kim",2018,10.1111/1911-3846.12362,None,proquest
3ed92f80d0db991c,The Informational Content of the Term Spread in Forecasting the US Inflation Rate: A Nonlinear Approach,"The difficulty in modelling inflation and the significance in discovering the underlying data-generating process of inflation is expressed in an extensive literature regarding inflation forecasting. In this paper we evaluate nonlinear machine learning and econometric methodologies in forecasting US inflation based on autoregressive and structural models of the term structure. We employ two nonlinear methodologies: the econometric least absolute shrinkage and selection operator (LASSO) and the machine-learning support vector regression (SVR) method. The SVR has never been used before in inflation forecasting considering the term spread as a regressor. In doing so, we use a long monthly dataset spanning the period 1871:1-2015:3 that covers the entire history of inflation in the US economy. For comparison purposes we also use ordinary least squares regression models as a benchmark. In order to evaluate the contribution of the term spread in inflation forecasting in different time periods, we measure the out-of-sample forecasting performance of all models using rolling window regressions. Considering various forecasting horizons, the empirical evidence suggests that the structural models do not outperform the autoregressive ones, regardless of the model's method. Thus we conclude that the term spread models are not more accurate than autoregressive models in inflation forecasting. Copyright © 2016 John Wiley & Sons, Ltd.","Plakandaras, Vasilios; Gogas, Periklis; Papadimitriou, Theophilos; Gupta, Rangan",2017,10.1002/for.2417,None,proquest
8df5c5a1183a28ea,The London Business School With Gower Publishing: FIGHTING YESTERDAY'S BATTLES,"With still no firm evidence at home of a recovery in non‐oil GDP, the government's main worries centre on the path of output ahead of the General Election. In a forecast, which relies heavily on exports to stimulate demand in 1992, the Treasury cannot regard the rising probability of renewed recession in the US or the very sharp slowdown currently taking place in Europe as the post‐unification German boom runs out of steam with equanimity. The fear mist remain in Conservative politicians' minds that there will be no meaningful recovery within an electorally significant timescale. We sketch out this background, but our focus here is not on the prospects for recovery; rather we ask whether the recession has achieved its objectives. The recession was, it should be remembered, the direct product of government policy ‐ interest rates were raised to 15per cent ahead of ERM membership ‐ aimed at reversing the excesses of the late 198Os'boom and in particular at bringing inflation quickly down to acceptable European levels and reducing the deficit on the current account, which at its peak in 1989 amounted to 4 per cent of GDP. Our answer is that, over the last year of recession, considerable progress has been made: the rate of inflation is now in line with that in Germany and the current account deficit has fallen to under 1 per cent of GDP. But, on the government's own forecasts contained in the Autumn Statement, there will be some slippage on both counts in 1992. It is this worrying feature that we consider here. Our overall conclusion is that the recession has not completely delivered its objectives and that, even as the politicians turn their attention to recovery, we still have to fight yesterday's battles. Copyright © 1991, Wiley Blackwell. All rights reserved © 2016 Elsevier B.V., All rights reserved.","Dicks, G.",1991,10.1111/j.1468-0319.1991.tb00158.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978558611&doi=10.1111%2Fj.1468-0319.1991.tb00158.x&partnerID=40&md5=b960fc38fda667cdd4f0e4365e15cf2e,scopus
cafdecb4b42b0a46,The London Business School with Gower Publishing,"Collapsing oil prices and a falling dollar set the background to a Budget in which the Chancellor, hamstrung by lower oil revenues, was seen as having little room for manoeuvre. In fact the sharp fall in the sterling price of oil has provided him with the perfect excuse for not making significant cuts in personal income tax that were largely irrelevant to the needs of the economy. Instead of a boost to household demand we have had, thanks to OPEC, a transfer to companies in the form of a reduction in costs. This should enable them to expand output against a background of falling inflation. Our post‐Budget assessment of macroeconomic prospects (Section I), made on the Treasury's assumption of a $15 oil price, shows output growing by 2 1/2 per cent this year and inflation falling below 3 per cent in 1987. We are thus less optimistic than the Treasury about output but more optimistic about inflation. How was the Chancellor able, within the confines of the Medium‐Term Financial Strategy, to give anything away having lost so much oil revenue? A detailed analysis of the PSBR forecast (Section II) reveals good reasons why non‐oil tax revenues should be some £3 1/2n higher than forecast this time last year. But, because we still expect public spending to be above the official figures, our PSBR forecast is £1bn higher than the Treasury's. Although the macroeconomic impact of the Budget was small (especially in relation to that of the fall in oil prices which preceded it), it continued the process of tax reform. We focus, in Section III, on the new proposals to deal with the problem of the pension fund surpluses to which we drew attention in the November issue of Financial Outlook. We conclude that the proposed measures could have a larger effect on tax revenues in the longer term than is indicated by the Treasury's Budget estimates. Copyright © 1986, Wiley Blackwell. All rights reserved © 2016 Elsevier B.V., All rights reserved.","Dicks, G.; Keating, G.; Robinson, B.",1986,10.1111/j.1468-0319.1986.tb00132.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978583037&doi=10.1111%2Fj.1468-0319.1986.tb00132.x&partnerID=40&md5=b54956c2c887c359c6614df6985def4e,scopus
0f494f7b776c3aa9,The Macroeconomics of Financial Speculation,"I review the literature on financial speculation driven by belief disagreements from a macroeconomics perspective. To highlight unifying themes, I develop a stylized macroeconomic model that embeds several mechanisms. With short-selling constraints, speculation can generate overvaluation and speculative bubbles. Leverage can substantially inflate speculative bubbles, and leverage limits depend on perceived downside risks. Shifts in beliefs about downside tail scenarios can explain the emergence and the collapse of leveraged speculative bubbles. Speculative bubbles are related to rational bubbles, but they match better the empirical evidence on the predictability of asset returns. Even without short-selling constraints, speculation induces procyclical asset valuation. When speculation affects the price of aggregate assets, it also influences macroeconomic outcomes such as aggregate consumption, investment, and output. Speculation in the boom years reduces asset prices, aggregate demand, and output in the subsequent recession. Macroprudential policies that restrict speculation in the boom can improve macroeconomic stability and social welfare.","Simsek, Alp",2021,10.1146/annurev-economics-092120-050543,None,wos
6e5ee856b4eecc9e,The Markov-switching jump diffusion LIBOR market model,"In this paper, we introduce an extension to the LIBOR Market Model (LMM) that is suitable to incorporate both sudden market shocks as well as changes in the overall economic climate into the interest rate dynamics. This is achieved by substituting the simple diffusion process of the original LMM by a regime-switching jump diffusion. We demonstrate that the new Markov-switching jump diffusion (MSJD) LMM can be embedded into a generalized regime-switching Heath-Jarrow-Morton model and prove that the considered market is arbitrage-free. We derive pricing formulas for caps, floors and swaptions using Fourier pricing techniques and show how the model can be calibrated to real market data.","Steinruecke, L.; Zagst, R.; Swishchuk, A.",2015,10.1080/14697688.2014.962594,None,wos
53693a3db3c1fcab,The Nonlinear Nature of Country Risk and its Implications for DSGE Models,"Country risk premia can substantially affect macroeconomic dynamics. We concentrate on one of their most important determinants- A country's net foreign asset (NFA) position and-in contrast to the existing research-investigate its nonlinear link to risk premia. The importance of this particular nonlinearity is two-fold. First, it allows to identify the NFA level above which the elasticity becomes much (possibly dangerously) higher. Second, such a nonlinear relationship is a standard ingredient of dynamic stochastic general equilibrium (DSGE) models, but its proper calibration/estimation is missing. Our estimation shows that indeed the link is highly nonlinear and helps to identify the NFA position where the nonlinearity kicks in at approximately-70% to-75% of GDP. We also provide a proper calibration of the risk premium-NFA relationship which can be used in DSGE models and demonstrate that its slope matters significantly for economic dynamics in such a model. © 2020 Elsevier B.V., All rights reserved.","Brzoza-Brzezina, M.; Kotłowski, J.",2020,10.1017/s136510051800038x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052611952&doi=10.1017%2FS136510051800038X&partnerID=40&md5=37354b76d72bae70019c8812aed9cfcb,scopus
e22be0f2824e7ad1,The October 2014 United States Treasury bond flash crash and the contributory effect of mini flash crashes,"We investigate the causal uncertainty surrounding the flash crash in the U.S. Treasury bond market on October 15, 2014, and the unresolved concern that no clear link has been identified between the start of the flash crash at 9:33 and the opening of the U.S. equity market at 9:30. We consider the contributory effect of mini flash crashes in equity markets, and find that the number of equity mini flash crashes in the three-minute window between market open and the Treasury Flash Crash was 2.6 times larger than the number experienced in any other three-minute window in the prior ten weekdays. We argue that (a) this statistically significant finding suggests that mini flash crashes in equity markets both predicted and contributed to the October 2014 U.S. Treasury Bond Flash Crash, and (b) mini-flash crashes are important phenomena with negative externalities that deserve much greater scholarly attention.","Levine, Zachary S; Hale, Scott A; Floridi, Luciano",2017,10.1371/journal.pone.0186688,None,proquest
bb9b735a815837e5,The Predictability of the Exchange Rate When Combining Machine Learning and Fundamental Models,"In 1983, Meese and Rogoff showed that traditional economic models developed since the 1970s do not perform better than the random walk in predicting out-of-sample exchange rates when using data obtained after the beginning of the floating rate system. Subsequently, whether traditional economical models can ever outperform the random walk in forecasting out-of-sample exchange rates has received scholarly attention. Recently, a combination of fundamental models with machine learning methodologies was found to outcompete the predictability of random walk (Amat et al. 2018). This paper focuses on combining modern machine learning methodologies with traditional economic models and examines whether such combinations can outperform the prediction performance of random walk without drift. More specifically, this paper applies the random forest, support vector machine, and neural network models to four fundamental theories (uncovered interest rate parity, purchase power parity, the monetary model, and the Taylor rule models). We performed a thorough robustness check using six government bonds with different maturities and four price indexes, which demonstrated the superior performance of fundamental models combined with modern machine learning in predicting future exchange rates in comparison with the results of random walk. These results were examined using a root mean squared error (RMSE) and a Diebold–Mariano (DM) test. The main findings are as follows. First, when comparing the performance of fundamental models combined with machine learning with the performance of random walk, the RMSE results show that the fundamental models with machine learning outperform the random walk. In the DM test, the results are mixed as most of the results show significantly different predictive accuracies compared with the random walk. Second, when comparing the performance of fundamental models combined with machine learning, the models using the producer price index (PPI) consistently show good predictability. Meanwhile, the consumer price index (CPI) appears to be comparatively poor in predicting exchange rate, based on its poor results in the RMSE test and the DM test. © 2023 Elsevier B.V., All rights reserved.","Zhang, Y.; Hamori, S.",2020,10.3390/jrfm13030048,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091877651&doi=10.3390%2Fjrfm13030048&partnerID=40&md5=352d6320ec6190df592c437a799b8a70,scopus
f4423359be40fb95,The Price of Predictability: Estimating Inconsistency Premiums in Social Interactions,"For financial decision-making, people trade off the expected value (return) and the variance (risk) of an option, preferring higher returns to lower ones and lower risks to higher ones. To make decision-makers indifferent between a risky and risk-free option, the expected value of the risky option must exceed the value of the risk-free option by a certain amount-the risk premium. Previous psychological research suggests that similar to risk aversion, people dislike inconsistency in an interaction partner's behavior. In eight experiments (total N = 2,412) we pitted this inconsistency aversion against the expected returns from interacting with an inconsistent partner. We identified the additional expected return of interacting with an inconsistent partner that must be granted to make decision-makers prefer a more profitable, but inconsistent partner to a consistent, but less profitable one. We locate this inconsistency premium at around 31% of the expected value of the risk-free option.","Gerten, Judith; Zuern, Michael K.; Topolinski, Sascha",2022,10.1177/0146167221998533,None,wos
dd8b9653412c131a,The Pricing of Time-Varying Exchange Rate Risk in the Stock Market: A Nonparametric Approach,"This paper reexamines the pricing of exchange rate risk in the U.S. stock market. We first construct stock portfolios based on the Foreign Exchange Income (FEI), a measure of currency exposure of firms, reported in their annual reports. We then develop two-factor and multi-factor nonparametric models that allow time variation in risk exposure and risk premium, and nonlinearity in the return generating process. When we assume that risk exposure can be time-varying but risk premium is constant, the estimated premium for exchange rate risk is significant only for the most positive FEI-ranked portfolio and marginally significant for the most negative FEI-ranked portfolio. When we further assume that both risk exposure and risk premium can be time-varying, results suggest that exchange rate risk is significantly priced for all the FEI-ranked portfolios except the one with little exposure.","Chung, Y. Peter; Zhou, Zhong-guo",2012,10.1515/1558-3708.1634,None,wos
e309d7d47495412e,The Pruned State-Space System for Non-Linear DSGE Models: Theory and Empirical Applications,"This article studies the pruned state-space system for higher-order perturbation approximations to dynamic stochastic general equilibrium (DSGE) models. We show the stability of the pruned approximation up to third order and provide closed-form expressions for first and second unconditional moments and impulse response functions. Our results introduce generalized method of moments (GMM) estimation and impulse-response matching for DSGE models approximated up to third order and provide a foundation for indirect inference and simulated method of moments (SMM). As an application,we consider a New Keynesian model with Epstein–Zin preferences and two novel feedback effects from long-term bonds to the real economy, allowing us to match the level and variability of the $10$-year term premium in the U.S. with a low relative risk aversion of $5$.","Andreasen, Martin M",2018,10.1093/restud/rdx037,None,proquest
6baa570f6471f39a,The Relationship Between Volatility and Sovereign Credit Risk in the Emerging Markets: A Nonlinear ARDL Approach,"This study investigates the short- and long-run nexus between the volatility index of VIX and sovereign credit risk represented by CDS spread in emerging markets, namely Turkey, China, Russia, Brazil, and Mexico. The emerging markets are at the center of investors' interest due to high return opportunities. The relationship between volatility and sovereign credit risk has been studied many times via linear models. However, financial series exhibit asymmetric dynamics, as volatility clustering, excess kurtosis, and others. Thus, we use nonlinear autoregressive distributed lags (NARDL) analysis to capture nonlinear relations between the volatility and the sovereign credit risks of these countries by using daily data from 04.01.2010 to 29.11.2019. The bounds test of the NARDL model confirms the cointegration between VIX and CDS spreads of the countries under study. The analysis of estimated NARDL parameters shows that negative shocks of the volatility index have a long-lasting impact on CDS spreads. Chinese CDS spread are more sensitive to VIX index changes in the short run. The effect of a decrease in volatility on Russian CDS spread is higher than the effect of an increase. Turkish and Brazilian CDS spreads are more reactive to increase in the VIX, whereas Mexican CDS is less sensitive. These findings show that investors, arbitrageurs and speculators should consider global indicators when taking a position on sovereign bonds of emerging markets.","Yigit, Fatih; Aliyev, Fuzuli",2022,10.21121/eab.1064521,None,wos
403a1d83ec233556,The Relationship between Default Risk and Asset Pricing: Empirical Evidence from Pakistan,"This paper examines the efficacy of the default risk factor in an emerging market context using the Fama-French five-factor model. Our aim is to test whether the Fama-French five-factor model augmented with a default risk factor improves the predictability of returns of portfolios sorted on the firm’s characteristics as well as on industry. The default risk factor is constructed by estimating the probability of default using a hybrid version of dynamic panel probit and artificial neural network (ANN) to proxy default risk. This study also provides evidence on the temporal stability of risk premiums obtained using the Fama-MacBeth approach. Using a sample of 3,806 firm-year observations on non-financial listed companies of Pakistan over 2006–2015 we found that the augmented model performed better when tested across size-investment-default sorted portfolios. The investment factor contains some default-related information, but default risk is independently priced and bears a significantly positive risk premium. The risk premiums are also found temporally stable over the full sample and more recent sample period 2010–2015 as evidence by the Fama-MacBeth regressions. The finding suggests that the default risk factor is not a useless factor and due to mispricing, default risk anomaly prevails in the Pakistani equity market. © 2021 Elsevier B.V., All rights reserved.","Khan, U.E.; Iqbal, J.",2021,10.13106/jafeb.2021.vol8.no3.0717,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102257576&doi=10.13106%2Fjafeb.2021.vol8.no3.0717&partnerID=40&md5=0a2f393054f1fd8ea20a186359d1a9cc,scopus
5f06ab538ee9699f,The Role of Regime Shifts in the Term Structure of Interest Rates: Further Evidence from an Emerging Market,"In this paper, we investigate the interrelationships among Turkish interest rates having different maturities by using a regime-switching vector error correction model. We find a relationship of long-run equilibrium among interest rates having various maturities. Furthermore, we conclude that term structure dynamics exhibit significant nonlinearity. A forecasting experiment also reveals that the nonlinear term structure models fare better in forecasting than other linear specifications. However, we cannot conclude that interest rate adjustments are made in an asymmetric way in the long run. Adapted from the source document.","Saltoglu, Burak; Yazgan, M Ege",2012,10.2753/ree1540-496x4806s504,None,proquest
ed8aac9bf33c2706,The SR approach: A new estimation procedure for non-linear and non-Gaussian dynamic term structure models,This paper suggests a new approach for estimating linear and non-linear dynamic term structure models with latent factors. We impose no distributional assumptions on the factors which therefore may be non-Gaussian. The novelty of our approach is to use many observables (yields or bond prices) in the cross-section dimension. This implies that the latent factors can be determined quite accurately by a sequence of cross-section regressions. We also show how output from these regressions can be used to obtain model parameters by a two- or three-step moment-based estimation procedure.,"Andreasen, Martin M; Christensen, Bent Jesper",2015,10.1016/j.jeconom.2014.10.002,None,proquest
ace765e9f57e674b,The Stern Review on the Economic Effects of Climate Change,"In a study of the economics of climate change commissioned by the British government, released on 30 October, the former World Bank chief economist Sir Nicholas Stern presents a vigorously argued case for early curtailment of greenhouse gas emissions and proposes mitigation strategies that appear to offer highly favorable benefit-cost ratios. An excerpt from the Executive Summary of the Stern Review, concerned with the nature and magnitude of the deleterious economic consequences of anticipated climate change, is printed below. The principal scientific reviews of knowledge of climate change, its consequences, and mitigation strategies are the (roughly) quinquennial reports of the Intergovernmental Panel on Climate Change (IPCC)-the work of hundreds of lead authors, subjected in turn to elaborate peer review and line-by-line scrutiny by interested governments. They represent a broad, though not total, expert consensus. The third IPCC assessment was issued in 2001; the fourth, already in draft, will be released next year. The Stern Review draws heavily on this scientific underpinning, but goes further than the IPCC exercise in computing economic values for the projected changes and costing out remedial policy responses. More forthright in style and emphatic in its conclusions, it reads as a resounding call to international action. The Review explores the implications of atmospheric concentrations of carbon dioxide and other greenhouse gases being capped at 550ppm (parts per million), double the preindustrial level, an objective it argues is feasible. That concentration would be reached by 2050 at current emission rates, or by 2035 if emissions rise as expected. The resulting warming, it believes, would be 2-5 degree C, roughly in accord with the IPCC's third-assessment estimates (see the Documents section of PDR 27, no. 1 for the IPCC projections). The positive feedbacks identified in some recent studies, generated by processes such as release of methane from permafrost, could lead to still higher temperatures. The forecast effects described are by now familiar, though no less grim for being so: species extinctions, expanding disease zones, reductions in surface water availability, coastal flooding, ocean acidification, and so on. The Review translates these effects into economic losses, adjusting for risk, using Monte Carlo simulation applied to an integrated assessment model (the so-called PAGE 2002 model). The exercise, requiring many heroic-and often contestable-assumptions, produces the most quoted figures in the report: that climate change 'will reduce welfare by an amount equivalent to a reduction in consumption per head of between 5 and 20%'-now and into the future. The absolute magnitude of those projected economic losses is made arbitrarily large by their permanence. Typical benefit-cost calculations applied to appraisal of development projects convert such long-term trajectories into a present value using a discount rate comparable to a market interest rate or some (lower) assumed rate of time preference. The Stern Review, however, argues that any discounting is ethically inappropriate for this global issue: 'if a future generation will be present, we suppose that it has the same claim on our ethical attention as the current one' (p. 31). The only exception is an allowance for the possibility that future generations are not present-through human extinction-which is held to justify a minuscule discount rate of 0.1 percent per annum (p. 161). The percentage economic losses from climate change appear less daunting if set against the recent pace of expansion in the world economy. Real per capita income growth since 1990 has averaged about 1.5 percent per year worldwide, and about 3 percent in developing countries. In such a regime, a 5 percent one-time drop to a lower expansion path is no more than a two- or three-year delay in attaining a given income level. For China and India, whose economies are doubling in size each decade, even a 20 percent reduction in income would be a mere hiccough on the path to affluence-hardly enough to motivate major shifts in lifestyle ambitions. The dire repercussions on global environments of a greenhouse warming at the upper end of the forecast range are poorly captured by those percentages. Demography has a marginal place in the Review. The underlying IPCC emission scenarios incorporate expected population growth, using the UN medium projections. Many of the climate-change effects incur costs that are similarly magnified by population growth. One-sixth of the world's population is 'threatened' by water scarcities; 1 in 20 people may be displaced by a rising sea level; mortality may increase from vector-borne diseases and from malnutrition linked to income losses. The later part of the Review is concerned with mitigation and adaptation strategies. It lays out an ambitious set of policies for transition to a low-carbon economy that could stabilize greenhouse gas concentrations over the next several decades. By 2050, emissions would have to be 25 percent below today's and emissions per unit of GDP 75 percent below. In perhaps the most problematic part of the exercise the Review asserts that such cuts could be achieved at a cost of only around 1 percent of annual global GDP-implying that investment in mitigation should be strongly favored on straightforward economic grounds. (This figure, like others in the Review, is acknowledged to lie within a substantial envelope of uncertainty-here a range of -1.0 percent to +3.5 percent of global GDP (p. 212), or, drawing on a wider range of models, -4 percent to +15 percent (p. 241).) In the decades before the investment pays off, adverse consequences of the warming trends already underway must be dealt with by adaptation, such as through better disaster preparedness, lessening the vulnerability of infrastructure, and risk-pooling measures. The excerpt is from pp. iii-iv and vi-xi. The full Stern Review (579 pages), the executive summary, and the commissioned background papers are available online at 'http://www.hm-treasury.gov.uk/independent_reviews/stern_review_ec o nomics_climate_change/sternreview_index.cfm'. A hard copy of the Review will be issued by Cambridge University Press.",None,2006,10.1111/j.1728-4457.2006.00153.x,None,proquest
91cc331ca08e8342,The Stochastic Stationary Root Model,"We propose and study the stochastic stationary root model. The model resembles the cointegrated VAR model but is novel in that: (i) the stationary relations follow a random coefficient autoregressive process, i.e., exhibhits heavy-tailed dynamics, and (ii) the system is observed with measurement error. Unlike the cointegrated VAR model, estimation and inference for the SSR model is complicated by a lack of closed-form expressions for the likelihood function and its derivatives. To overcome this, we introduce particle filter-based approximations of the log-likelihood function, sample score, and observed Information matrix. These enable us to approximate the ML estimator via stochastic approximation and to conduct inference via the approximated observed Information matrix. We conjecture the asymptotic properties of the ML estimator and conduct a simulation study to investigate the validity of the conjecture. Model diagnostics to assess model fit are considered. Finally, we present an empirical application to the 10-year government bond rates in Germany and Greece during the period from January 1999 to February 2018.","Hetland, Andreas",2018,10.3390/econometrics6030039,None,proquest
97060010610a3aec,The Term Structure of Machine Learning Alpha,"Machine learning (ML) models for predicting stock returns are typically trained on one-month forward returns. Although these models show impressive full-sample gross alphas, their performance net of transaction costs post-2004 is close to zero. By training on longer prediction horizons and using efficient portfolio construction rules, the authors demonstrate that ML-based investment strategies can still yield significant positive net returns. Longer-horizon strategies select slower signals and load more on traditional asset pricing factors but still unlock unique alpha. The authors conclude that design choices are critical for the success of ML models in real-life applications. © 2023 Elsevier B.V., All rights reserved.","Blitz, D.; Hanauer, M.X.; Hoogteijling, T.; Howard, C.",2023,10.3905/jfds.2023.1.135,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176099492&doi=10.3905%2Fjfds.2023.1.135&partnerID=40&md5=d9c1c7c51b12768f2f8c95b1d8c8e9bc,scopus
753b60459addde65,"The UK Companies Act of 2006, the Sarbanes-Oxley Act of 2002, and important reviews of 2009. Implications for the certainty equivalent coefficient net present value criterion","Purpose - The purpose of this paper is to draw attention to the fact that the certainty equivalent coefficient net present value criterion, CEC(NPV), in disregarding a fundamental requirement for the calculation of cash flows for purposes of discounted cash flow analysis, invalidates this capital budgeting criterion from the perspective of sound research methodology. The paper also investigates the impact of the UK Companies Act of 2006, the Sarbanes-Oxley Act of 2002, and important reviews such as the Turner Review of 2009, the Walker Review of 2009, and the Review of the Combined Code of 2009 on this operationally invalid capital budgeting criterion, as well as its impact on the process of financial managerial decision making. Design/methodology/approach - The CEC(NPV) as a discounted cash flow capital budgeting criterion was examined from the perspective of the axioms of cash flow estimation as well as from the definition of the cost of capital in order to ascertain the contribution of this criterion to financial management. The relevant sections of the UK Companies Act of 2006, the Sarbanes-Oxley Act of 2002, the Turner Review of 2009, the Walker Review of 2009, and the Review of the Combined Code of 2009 were studied in order to establish whether the CEC(NPV) was able to satisfy the requirements of this legislation and these important reviews. Findings - The CEC(NPV) is construct invalid and does not measure what it purports to measure: it over-states financial viability. As a consequence, it does not meet the requirements of sound research methodology and therefore is at odds with the UK Companies Act of 2006, the Sarbanes-Oxley Act of 2002, and falls foul of the Turner Review of 2009, the Walker Review of 2009, the 2009 Review of the Combined Code issued by the Financial Reporting Council. As such it cannot be endorsed by the Financial Services Authority. Originality/value - The paper usefully shows that the CEC(NPV) denies financial managers application of Fisherian analysis for resolving conflicts in the rankings of mutually exclusive projects, and, the comparison of project cost of capital with their respective internal rates of return. Comparisons of the internal rate of return, not with the risk-free rate (that is assumed to be a constant and which exhibits minimal variability in comparison with the cost of capital), but with the cost of capital cost of capital, are a sine qua non for managerial decision making, especially capital budgeting.","Paulo, S",2010,10.1108/17542431011093162,None,proquest
6b9cd4fca22e9660,The UK and the Eurozone,"The article reviews the case for the UK to join the Eurozone by way of presenting a review of HM Treasury's widely well-regarded ""Euro Report"" (2003). The review provides an opportunity to rehearse and update the elements of optimum currency area (OCA) theory. In particular, the study draws attention to fresh estimates of the trade effect of the UK's adhesion to the Eurozone, the small size of which sharply contrasts with earlier estimates. They substantially remove a challenge to the Report's negative conclusion. The study sets the review in the perspective of public opinion surveys and HM Government's decisions. © 2006 Oxford University Press. © 2008 Elsevier B.V., All rights reserved.","Artis, M.",2006,10.1093/cesifo/ifj002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750451943&doi=10.1093%2Fcesifo%2Fifj002&partnerID=40&md5=bd9251b7434142022294a2c53adc8d2b,scopus
ebb0790b8221da7a,The Use of Simulation in Vascular Surgery Education: Current State and Future Directions,"Simulation-based training (SBT) has become essential in vascular surgery education, providing a risk-free environment for skill development. This scoping review evaluates the current state of vascular surgery simulation, highlighting validated models, educational impact, and areas for improvement. A systematic literature search was conducted in PubMed, Embase, and Scopus, following PRISMA-ScR guidelines. Studies assessing validated simulation models for open and endovascular procedures, vascular anastomosis, carotid interventions, peripheral vascular interventions, and nontechnical skills training were included. Data extraction focused on fidelity, skill acquisition, procedural efficiency, and accessibility. Validated high-fidelity models, including 3D-printed, virtual reality (VR), and pulsatile cadaveric systems, significantly enhance technical proficiency and confidence. Bench and porcine models improve vascular anastomosis training, while VR-based simulators enhance catheter manipulation and decision-making. However, simulation remains limited by high costs, accessibility challenges, and lack of standardized nontechnical skills training. Simulation improves competency in vascular surgery but requires further integration into training curricula. AI-driven assessments, hybrid simulation models, and expanded cost-effective solutions are needed to bridge existing gaps. Standardization and broader adoption of simulation will enhance competency-based training and improve patient outcomes.Simulation-based training (SBT) has become essential in vascular surgery education, providing a risk-free environment for skill development. This scoping review evaluates the current state of vascular surgery simulation, highlighting validated models, educational impact, and areas for improvement. A systematic literature search was conducted in PubMed, Embase, and Scopus, following PRISMA-ScR guidelines. Studies assessing validated simulation models for open and endovascular procedures, vascular anastomosis, carotid interventions, peripheral vascular interventions, and nontechnical skills training were included. Data extraction focused on fidelity, skill acquisition, procedural efficiency, and accessibility. Validated high-fidelity models, including 3D-printed, virtual reality (VR), and pulsatile cadaveric systems, significantly enhance technical proficiency and confidence. Bench and porcine models improve vascular anastomosis training, while VR-based simulators enhance catheter manipulation and decision-making. However, simulation remains limited by high costs, accessibility challenges, and lack of standardized nontechnical skills training. Simulation improves competency in vascular surgery but requires further integration into training curricula. AI-driven assessments, hybrid simulation models, and expanded cost-effective solutions are needed to bridge existing gaps. Standardization and broader adoption of simulation will enhance competency-based training and improve patient outcomes.","Fereydooni, Arash; Sgroi, Michael David",2025,10.1053/j.semvascsurg.2025.03.001,None,proquest
2d7d94f5cc68cb41,The VIX Premium,"Ex ante estimates of the volatility premium embedded in VIX futures, known as the VIX premium, fall or stay flat when ex ante measures of risk rise. This is not an artifact of mismeasurement: (i) ex ante premiums reliably predict ex post returns to VIX futures with a coefficient near one, and (ii) falling ex ante premiums predict increasing ex post market and investment risk, creating profitable trading opportunities. Falling hedging demand helps explain this behavior, as premiums and trader exposures tend to fall together when risk rises. These facts provide a puzzle for theories of why investors hedge volatility. Received January 13, 2017; editorial decision April 26, 2018 by Editor Stijn Van Nieuwerburgh. Authors have furnished an Internet Appendix, which is available on the Oxford University Press Web site next to the link to the final published paper online.","Cheng, Ing-Haw",2019,10.1093/rfs/hhy062,None,wos
e6571fb417c7b72e,The Yield Curve as a Recession Leading Indicator. An Application for Gradient Boosting and Random Forest,"Most representative decision-tree ensemble methods have been used to examine the variable importance of Treasury term spreads to predict US economic recessions with a balance of generating rules for US economic recession detection. A strategy is proposed for training the classifiers with Treasury term spreads data and the results are compared in order to select the best model for interpretability. We also discuss the use of SHapley Additive exPlanations (SHAP) framework to understand US recession forecasts by analyzing feature importance. Consistently with the existing literature we find the most relevant Treasury term spreads for predicting US economic recession and a methodology for detecting relevant rules for economic recession detection. In this case, the most relevant term spread found is 3-month–6-month, which is proposed to be monitored by economic authorities. Finally, the methodology detected rules with high lift on predicting economic recession that can be used by these entities for this propose. This latter result stands in contrast to a growing body of literature demonstrating that machine learning methods are useful for interpretation comparing many alternative algorithms and we discuss the interpretation for our result and propose further research lines aligned with this work. © 2022 Elsevier B.V., All rights reserved.","Delgado, P.C.; Congregado, E.; Golpe, A.A.; Vides, J.C.",2022,10.9781/ijimai.2022.02.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127570531&doi=10.9781%2Fijimai.2022.02.006&partnerID=40&md5=9f07996466ae0db75c8618f7c33d0667,scopus
85e5ea3195695843,The advantages of CBOE credit VIXs for corporate bond investors in North America: A sectoral analysis,"This paper examines the safe-haven role of the recently introduced CBOE credit VIXs for investment-grade and high-yield corporate bonds, at both aggregate and sectoral levels. Using a time-varying quantile-based framework and daily data from June 5, 2014 to December 10, 2023, the safe-haven role of credit VIX is confirmed irrespective of bond sector. The safe-haven property of credit VIX is pronounced for high-yield bonds which embed a high credit risk-premium. This result stands when taking into account interest rate volatility, as measured by the MOVE index. A time-varying analysis shows the persistence of credit VIX as a safe-haven for all bond sectors after the COVID-19 pandemic and during a high US interest-rate regime. Corporate bond investors and traders can use these findings to refine their investment and trading decisions and offset credit risk during both normal and turbulent periods.","Iqbal, Najaf; Bouri, Elie; Ozkan, Oktay",2025,10.1016/j.ribaf.2024.102607,None,wos
9446610b432fae4b,The causality link between political risk and stock prices,"PurposePrior studies have paid close attention to the impact of political risk on financial markets. Following this strand of literature, this paper aims to focus on the causality link between political shocks and their impacts on emerging stock markets.Design/methodology/approachThis paper highlights an innovative counterfactual model for political risk assessment. Based on a natural experiment, i.e. the Taiwan Strait Crisis in 1995-1996, this study utilizes one data-driven approach, e.g. the synthetic control methods (SCMs), to estimate causal impact of this political shock on Taiwan’s stock market.FindingsMajor findings in this study are consistent with existing literature on the price of political risk, e.g. political uncertainty commands a risk premium. The SCM estimations suggest that Taiwan’s stock prices dramatically underperformed its newly industrialized peers and other developed markets during the crisis. The SCM results are statistically significant and robust to various cross-validation tests.Research limitations/implicationsFindings in this study indicate that political risks could generate enormous impacts on emerging financial markets. In particular, political uncertainty following new geopolitical dynamics requires proper identification and assessment.Originality/valueTo the author’s knowledge, this paper is the first rigorous counterfactual study to the causality relationship between political uncertainty and stock prices in emerging markets. This paper is distinct from previous studies in applying a data-driven approach to combine the features of learning from others (cross-sectional) and learning from the past (time series).","Wang, Huiqiang",2019,10.1108/jfep-07-2018-0106,None,proquest
0b2ab325246838cf,The commodity risk premium and neural networks,"The paper uses linear and nonlinear predictive models to study the linkage between a set of 128 macroeconomic and financial predictors and the risk premium of commodity futures contracts. The linear models use shrinkage methods based on either naive averaging or principal components. The nonlinear models use feedforward deep neural networks (DNN) either as stand-alone or in conjunction with a long short-term memory network (LSTM). Out of the four specifications considered, the LSTM-DNN architecture best captures the risk premium, which underscores the need to estimate models that are both nonlinear and recurrent. The superior performance of the LSTM-DNN portfolio persists after accounting for transaction costs or illiquidity and is unrelated to previously-documented commodity risk factors. © 2023 Elsevier B.V., All rights reserved.","Rad, H.; Low, R.K.Y.; Miffre, J.; Faff, R.",2023,10.1016/j.jempfin.2023.101433,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174155469&doi=10.1016%2Fj.jempfin.2023.101433&partnerID=40&md5=2b9b49f1dc40abe23ee81ebf9bd51eb2,scopus
e1060b1fe4f87af2,The composition of CMBS risk,"This paper identifies the put-option, liquidity availability proportion, and shadow liquidity risk premia embedded within commercial mortgage backed securities (CMBS) using reduced form and structural generalization models. These risk values are then interpreted as trading signals which are tested with automated trading strategies that buy undervalued and sell overvalued CMBS from November 2007 through June 2015. All three signals generate substantial positive trading profits in testing for the reduced form model but not for the structural generalization. The risk signals constructed independently of market pricing provide more profitable automated trading insights than those constructed from interactions between modeled risk measures and market spreads. In my tests of the information content of the risk signals with respect to future macroeconomic indicators, I find statistically significant evidence in keeping with recent studies. While I cannot reject CMBS efficiency, this paper's disclosure of new risk measures, the profitability of automated strategies based on those risk measures, and the statistical significance of their forward guidance capabilities, together contributes to our understanding of CMBS risk and the credit spread puzzle debate. (C) 2016 Elsevier B.V. All rights reserved.","Christopoulos, Andreas D.",2017,10.1016/j.jbankfin.2016.12.005,None,wos
a790fbd9f3a6e1cb,The contribution of wealth concentration to the subprime crisis: a quantitative estimation,"The crisis that broke out in mid-2007 was caused by the fact that the collateralised debt obligation (CDO) market had grown to a size sufficient to wreak general havoc when it suddenly collapsed. Several authors have argued that economic inequality was important to the growth of this market. This paper attempts to strengthen this argument by concentrating attention on global wealth concentration. After summarising recent evidence on the negative impact of investor demand on US bond yields in the pre-crisis period, new evidence regarding the specific contribution of high-net-worth individuals to this negative impact is presented. The paper then goes on to show how, after having helped to cause a yield problem in the major US debt markets, high-net-worth individuals (via hedge funds) continued to be a major source of the pressure on US banks to resolve this yield problem through the mass production of CDOs. Adapted from the source document.","Goda, Thomas; Lysandrou, Photis",2014,10.1093/cje/bet061,None,proquest
f5d2f8581abc1e8f,The conundrum of stock versus bond prices,"In a general way, stock and bond prices do not display any significant correlation. Yet, if we concentrate our attention on the specific episodes marked by a crash followed by a rebound, then we observe that stock prices have a strong connection with interest rates on one hand, and with bond yield spreads on the other hand. That second relationship is particularly stable in the course of time having been observed for over 140 years. Throughout the paper we use a quasi-experimental approach. By observing how markets respond to well-defined exogenous shocks (such as the shock of 11 September 2001) we are able to determine how investors organize their ""flight to safety"": which safe haven they select, how long their collective panic lasts, and so on. As rebounds come to an end the correlation of stock and bond prices fades away, a clear sign that the collective behavior of investors loses some of its coherence; this observation can be used as an objective criterion for assessing the end of a market rebound. Based on the behavior of investors, we introduce a distinction between ""genuine stock market rallies"", as opposed to spurious rallies such as those brought about by the buyback programs implemented by large companies. The paper ends with a discussion of testable predictions. © 2003 Elsevier B.V. All rights reserved. © 2008 Elsevier B.V., All rights reserved.","Maslov, S.; Roehner, B.M.",2004,10.1016/j.physa.2003.11.031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0742272492&doi=10.1016%2Fj.physa.2003.11.031&partnerID=40&md5=37ee85a0dd59a70b6cb37fc7c52bcf8c,scopus
6cf2e94f995ed821,The cost of carbon capture and storage for natural gas combined cycle power plants,"This paper examines the cost of CO(2) capture and storage (CCS) for natural gas combined cycle (NGCC) power plants. Existing studies employ a broad range of assumptions and lack a consistent costing method. This study takes a more systematic approach to analyze plants with an amine-based postcombustion CCS system with 90% CO(2) capture. We employ sensitivity analyses together with a probabilistic analysis to quantify costs for plants with and without CCS under uncertainty or variability in key parameters. Results for new baseload plants indicate a likely increase in levelized cost of electricity (LCOE) of $20-32/MWh (constant 2007$) or $22-40/MWh in current dollars. A risk premium for plants with CCS increases these ranges to $23-39/MWh and $25-46/MWh, respectively. Based on current cost estimates, our analysis further shows that a policy to encourage CCS at new NGCC plants via an emission tax or carbon price requires (at 95% confidence) a price of at least $125/t CO(2) to ensure NGCC-CCS is cheaper than a plant without CCS. Higher costs are found for nonbaseload plants and CCS retrofits.This paper examines the cost of CO(2) capture and storage (CCS) for natural gas combined cycle (NGCC) power plants. Existing studies employ a broad range of assumptions and lack a consistent costing method. This study takes a more systematic approach to analyze plants with an amine-based postcombustion CCS system with 90% CO(2) capture. We employ sensitivity analyses together with a probabilistic analysis to quantify costs for plants with and without CCS under uncertainty or variability in key parameters. Results for new baseload plants indicate a likely increase in levelized cost of electricity (LCOE) of $20-32/MWh (constant 2007$) or $22-40/MWh in current dollars. A risk premium for plants with CCS increases these ranges to $23-39/MWh and $25-46/MWh, respectively. Based on current cost estimates, our analysis further shows that a policy to encourage CCS at new NGCC plants via an emission tax or carbon price requires (at 95% confidence) a price of at least $125/t CO(2) to ensure NGCC-CCS is cheaper than a plant without CCS. Higher costs are found for nonbaseload plants and CCS retrofits.","Rubin, Edward S; Zhai, Haibo",2012,10.1021/es204514f,None,proquest
d85d0baae566aaa4,The cross-sectional stock return predictions via quantum neural network and tensor network,"In this paper, we investigate the application of quantum and quantum-inspired machine learning algorithms to stock return predictions. Specifically, we evaluate the performance of quantum neural network, an algorithm suited for noisy intermediate-scale quantum computers, and tensor network, a quantum-inspired machine learning algorithm, against classical models such as linear regression and neural networks. To evaluate their abilities, we construct portfolios based on their predictions and measure investment performances. The empirical study on the Japanese stock market shows the tensor network model achieves superior performance compared to classical benchmark models, including linear and neural network models. Though the quantum neural network model attains the lowered risk-adjusted excess return than the classical neural network models over the whole period, both the quantum neural network and tensor network models have superior performances in the latest market environment, which suggests capability of model’s capturing non-linearity between input features. © 2023 Elsevier B.V., All rights reserved.","Kobayashi, N.; Suimon, Y.; Miyamoto, K.; Mitarai, K.",2023,10.1007/s42484-023-00136-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178906367&doi=10.1007%2Fs42484-023-00136-x&partnerID=40&md5=5778bbe192db850d188778151b988196,scopus
55e0fae1741d6efd,The decoupling between public debt fundamentals and bond spreads after the European sovereign debt crisis,"We contribute to the literature that documents empirically that the relationship between public debt fundamentals and sovereign bond spreads in Spain, France, and Italy (versus Germany) weakened after the 2010–2012 episode of sovereign debt markets’ significant distress. To construct our measure of public debt fundamentals, we build on the literature that combines the Value at Risk approach with the estimation of the correlation pattern of public debt dynamics’ macroeconomic determinants via Vector Auto Regressions (VARs) to estimate the probability distribution of alternative debt trajectories. Since we incorporate in the VAR new information in a sequential manner, we are able to retrieve time-varying probabilities that characterize the expected behaviour of debt at a given point in time in the future. We then empirically confront such probabilistic indicators with market-derived sovereign bond spreads.","Guirola, Luis; Pérez, Javier J",2023,10.1080/00036846.2022.2120959,None,proquest
58601be935f1ee81,"The demand for M1 in the U.S.A., 1960-1988","Estimated U.S. M1 demand functions appear unstable, regularly “breaking down,” over 1960-1988 (e.g. missing money, great velocity decline, M1-explosion). We propose a money demand function whose arguments include inflation, real income, long-term bond yield and risk, T-bill interest rates, and learning curve weighted yields on newly introduced instruments in Ml and non-transactions M2. The model is estimated in dynamic error-correction form; it is constant and, with an equation standard error of 0.4%, variance-dominates most previous models. Estimating alternative specifications explains earlier “breakdowns,” showing the model’s distinctive features to be important in accounting for the data. © 1992 The Review of Economic Studies Limited. © 2016 Elsevier B.V., All rights reserved.","Baba, Y.; Hendry, D.F.; Starr, R.M.",1992,10.2307/2297924,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963027196&doi=10.2307%2F2297924&partnerID=40&md5=8fb6ec0e52860e6e8e381822049eedc4,scopus
f82cbd04c25cf4f6,The determinants of capitalization rates: evidence from the US real estate markets,"Purpose Establishing the strength of a novel variable-mortgage debt as a fraction of US gross domestic product (GDP)-on forecasting capitalization rates in both the US office and multifamily sectors. Design/methodology/approach The authors specifies a vector error correction model (VECM) to the data. VECM are used to address the nonstationarity issues of financial variables while maintaining the information embedded in the levels of the data, as opposed to their differences. The cap rate series used are from Green Street Advisors and represent transaction cap rates which avoids the problem of artificial smoothness found in appraisal-based cap rates. Findings Using a VECM specified with the novel variable, unemployment and past cap rates contains enough information to produce more robust forecasts than the traditional variables (return expectations and risk premiums). The method is robust both in and out of sample. Practical implications This has direct implications for governmental policy, offering a path to real estate price stability and growth through mortgage access-functions largely influenced by the Fed and the quasi-federal agencies Fannie Mae and Freddie Mac. It also offers a timely alternative to interest rate-based forecasting models, which are likely to be less useful as interest rates are to be held low for the foreseeable future. Originality/value This study offers a new and highly explanatory variable to the literature while being among the only to model either (1) transactional cap rates (versus appraisal) (2) out-of-sample data (versus in-sample) (3) without the use of the traditional variables thought to be integral to cap rate modelling (return expectations and risk premiums).","Larriva, Matt; Linneman, Peter",2022,10.1108/jpif-12-2020-0140,None,wos
3a2fe3ca49a5826d,The determinants of main stock exchange index changes in emerging countries: evidence from Turkey in COVID-19 pandemic age,"With the emergence and spreading of COVID-19 pandemic all over the world, the uncertainty has been increasing for countries. Depending on this condition, especially emerging countries have been affected negatively by foreign portfolio investment outflows from stock exchanges, and main stock exchange indices have been collapsed. The study examines the causes of the main stock exchange index changes in Turkey in the COVID-19 period. In this context, 14 variables (3 global, 6 country-level, 5 market-level) are analyzed by employing random forest and support vector machine algorithms and using daily data between 01.02.2020 and 05.15.2020, which includes the pre-pandemic and the pandemic periods. The findings prove that (i) the most important variables are the retention amount of foreign investors in the equity market, credit default swap spreads, government bonds interest rates, Morgan Stanley Capital International (MSCI) emerging markets index, and volatility index in the pre-pandemic period; (ii) the importance of variables changes as MSCI emerging markets index, the volatility index, retention amount of foreign investors in the equity market, amount of securities held by the Central Bank of Republic of Turkey (CBRT), equity market traded value in the pandemic period; (iii) support vector machine has superior estimation accuracy concerning random forest algorithms in both pre-pandemic and pandemic period.","Kartal, Mustafa Tevfik; Depren, Ozer; Depren, Serpil Kilic",2020,10.3934/qfe.2020025,None,wos
2be14e5dcfdbdd60,The disappearance of style in the US equity market,"This article investigates the modelling of style returns in the United States and the returns to style 'tilts' based on forecasts of enhanced future style returns. We use hidden Markov model to build our forecasts for data from 1975 to 1998. We do not include more recent observations as the subsequent trend and volatility sways the analysis. Our finding that style returns are less forecastible in the late 1990s is consistent with the hypothesis that style returns are the result of anomalies rather than risk premia. The erosion of anomalous returns as public awareness of their presence is translated into strategies that arbitrage away the excess returns seems to be a hypothesis consistent with our modelling results. Reprinted by permission of Routledge, Taylor and Francis Ltd.","Hwang, S; Satchell, S E",2007,10.1080/09603100701217978,None,proquest
056f1ead8d9317b9,The dynamic interaction of speculation and diversification,"A discrete time model of a financial market is developed, in which heterogeneous interacting groups of agents allocate their wealth between two risky assets and a riskless asset. In each period each group formulates its demand for the risky assets and the risk-free asset according to myopic mean-variance maximizazion. The market consists of two types of agents: fundamentalists, who hold an estimate of the fundamental values of the risky assets and whose demand for each asset is a function of the deviation of the current price from the fundamental, and chartists, a group basing their trading decisions on an analysis of past returns. The time evolution of the prices is modelled by assuming the existence of a market maker, who sets excess demand of each asset to zero at the end of each trading period by taking an offsetting long or short position, and who announces the next period prices as functions of the excess demand for each asset and with a view to long-run market stability. The model is reduced to a seven-dimensional nonlinear discrete-time dynamical system, that describes the time evolution of prices and agents' beliefs about expected returns, variances and correlation. The unique steady state of the model is determined and the local asymptotic stability of the equilibrium is analysed, as a function of the key parameters that characterize agents' behaviour. In particular it is shown that when chartists update their expectations sufficiently fast, then the stability of the equilibrium is lost through a supercritical Neimark-Hopf bifurcation, and self-sustained price fluctuations along an attracting limit cycle appear in one or both markets. Global analysis is also performed, by using numerical techniques, in order to understand the role played by the chartists' behaviour in the transition to a regime characterized by irregular oscillatory motion and coexistence of attractors. It is also shown how changes occurring in one market may affect the price dynamics of the alternative risky asset, as a consequence of the dynamic updating of agents' portfolios. © 2005 Taylor & Francis Group Ltd. © 2005 Elsevier B.V., All rights reserved.","Chiarella, C.; Dieci, R.; Gardini, L.",2005,10.1080/1350486042000260072,https://www.scopus.com/inward/record.uri?eid=2-s2.0-16644376238&doi=10.1080%2F1350486042000260072&partnerID=40&md5=eb95c9185d3b76bd89c850f8dda27d54,scopus
1254037e95e027a2,The dynamic relationship between the prices of ADRs and their underlying stocks: evidence from the threshold vector error correction model,"This paper sets out to estimate the dynamic relationship that exists between the prices of ADRs and their underlying stocks, in both the short run and the long run, using a number of recent developments of the threshold cointegration framework. The empirical results support the notion of nonlinear mean reversion of the prices of ADRs and their underlying stocks.","Chung, HM; Ho, TW; Wei, LJ",2005,10.1080/00036840500218729,None,wos
6fe2543d6bbabec5,The economic value of advanced time series methods for modelling and trading 10-year government bonds,"The motivation for this paper is to determine the potential economic value of advanced modelling methods for devising trading decision tools for 10-year Government bonds. Two advanced methods are used: time-varying parameter models with the implementation of state space modelling using a Kalman filter and nonparametric nonlinear models with Neural Network Regression (NNR). These are benchmarked against more traditional forecasting techniques to ascertain their potential as a forecasting tool and their economic value as a base for a trading decision tool. The models were developed using data from the UK Gilt market, US T-Bond market and German Bund market. Using in-sample data from April 2001 to January 2003 to develop the models, their results were assessed using the out-of-sample period of January 2003 to June 2003. Performance evaluation was based upon forecasting accuracy measures and financial criteria using a simulated trading strategy incorporating realistic trading costs. It is concluded that for the time series studied and for the period under investigation, the performance of the advanced models is mixed. While the NNR models have the ability to forecast the 10-year Government bond yield and add economic value as a trading decision tool, the Kalman filter models' performance is not as conclusive. The Kalman filter models outperformed the traditional techniques using forecasting accuracy measures, however they did not perform as well in the simulated trading strategy. Reprinted by permission of Routledge, Taylor and Francis Ltd.","Dunis, Christian L; Morrison, Vincent",2007,10.1080/13518470600880010,None,proquest
fcd1ed39b63802de,The effect of managerial ownership on the cost of debt: Evidence from Japan,"This article examines the effect of managerial ownership (MO) on the cost of debt as measured by the interest rate spread on corporate bonds for Japanese firms. First, the authors find that the MO is positively associated with interest rate spread after controlling for the other Japanese ownership structure, cross-shareholdings, and the stable shareholdings by financial institutions. Second, by employing factor analysis to measure the agency cost of debt (ACD) based on financial variables, the authors also find that MO has higher correlation with interest rate spread when the ACD at the time of bond issue is already larger. The results are robust to additional analyses, including the possibility of nonlinear relationship, bond rating, endogeneity problem, and Fama and MacBeth approach. The results suggest that prospective bondholders use MO information to anticipate a firm's future ACD and estimate it higher when the current ACD at issuing bond is already larger. The results also suggest that accounting information is useful to estimate the ACD and increase the efficiency of bond contracting. Finally, although previous studies are often prone to emphasizing the findings on the Japanese unique ownership structure, the results of this article reveal that traditional agency theory on MO apply to Japanese bond market, which is consistent with the findings of U.S. firms. © The Author(s) 2011. © 2011 Elsevier B.V., All rights reserved.","Shuto, A.; Kitagawa, N.",2011,10.1177/0148558x11401553,https://www.scopus.com/inward/record.uri?eid=2-s2.0-81255200514&doi=10.1177%2F0148558X11401553&partnerID=40&md5=27550a2d37ccf3c421fd165a5c3d8a92,scopus
3f2dc0f0809e9321,The efficacy of neural networks in predicting returns on stock and bond indices,"This paper uses two recently developed tests to identify neglected nonlinearity in the relationship between excess returns on four asset classes and several economic and financial variables. Having found some evidence of possible nonlinearity, it was then investigated whether the predictive power of these variables could be enhanced by using neural network models instead of linear regression or GARCH models. Some evidence of nonlinearity in the relationships between the explanatory variables and large stocks and corporate bonds was found. It was also found that the GARCH models are conditionally efficient with respect to neural network models, but the neural network models outperform GARCH models if financial performance measures are used. In resonance with the results reported for the tests for neglected nonlinearity, it was found that the neural network forecasts are conditionally efficient with respect to linear regression models for large stocks and corporate bonds, whereas the evidence is not statistically significant for small stocks and intermediate-term government bonds. This difference persists even when financial performance measures for individual asset classes are used for comparison. © 2018 Elsevier B.V., All rights reserved.","Desai, V.S.; Bharati, R.",1998,10.1111/j.1540-5915.1998.tb01582.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032392191&doi=10.1111%2Fj.1540-5915.1998.tb01582.x&partnerID=40&md5=a3740dd5ed940d8a119fb152e4c41aab,scopus
601095a482cc9b1e,The evolution of risk premium as a measure for intra-regional equity market integration,"We estimate and test the conditional version of an international capital asset pricing model using a parsimonious multivariate GARCH process and the multivariate nonlinear least squares method. Since our approaches are fully parametric, we can recover any quantity that is a function of the first two conditional moments. Our findings strongly support using a model that includes both regional market and foreign exchange risk. However, both sources of risk are detected only when their prices are allowed to change over time. Our empirical results show clear evidence of market integration to varying degrees, explained by the US term premium and the level of market openness. Though it reaches high values during turmoil periods and exhibits an upward trend toward the end of the estimation period, the Indonesian stock market remains partially integrated into the ASEAN-5 regional market. These results suggest that diversification into Indonesian market assets continues to produce substantial profits and that asset pricing rules should reflect a state of partial integration. © 2015 Elsevier B.V., All rights reserved.","Guesmi, K.; Teulon, F.; Muzaffar, A.T.",2014,10.1016/j.irfa.2014.07.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84909581587&doi=10.1016%2Fj.irfa.2014.07.003&partnerID=40&md5=6d13f0bc7cb045a3f4f9ab77d2cc3801,scopus
0357b90591cd9a40,The expectations hypothesis of the term structure when interest rates are close to zero,"In an economy where cash can be stored costlessly in nominal terms, the nominal interest rate is bounded below by zero. This paper derives the implications of this non-negativity constraint for the term structure and shows that it induces a nonlinear and convex relation between short- and long-term interest rates. The long-term rate responds asymmetrically to changes in the short-term rate, and by less than that is predicted by the benchmark linear model. In particular, a decrease in the short-term rate produces a smaller response in the long-term rate than an increase of the same magnitude. The empirical predictions of the model are examined using data from Japan. All rights reserved, Elsevier","Ruge-Murcia, Francisco J",2006,10.1016/j.jmoneco.2005.07.014,None,proquest
33d0e0f20fc3942d,The expected inflation channel of government spending in the postwar U.S.,"There exist sticky price models in which the output response to a government spending change can be large if the central bank is nonresponsive to inflation. According to this ""expected inflation channel,"" government spending drives up expected inflation, which in turn, reduces the real interest rate and leads to an increase in private consumption. This paper examines whether the channel was important in the post-WWII U.S., with particular attention to the 2009 Recovery Act period. First, we show that a model calibrated to have a large output multiplier requires a large response of expected inflation to a government spending shock. Next, we show that this large response is inconsistent with structural vector autoregression evidence from the Federal Reserve's passive policy period (1959-1979). Then, we study expected inflation measures during the Recovery Act period in conjunction with a panel of professional forecaster surveys, a cross-country comparison of bond yields and fiscal policy news announcements. We show that the expected inflation response was too small to engender a large output multiplier. © 2020 Elsevier B.V., All rights reserved.","Dupor, B.; Li, R.",2015,10.1016/j.euroecorev.2014.11.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920172590&doi=10.1016%2Fj.euroecorev.2014.11.004&partnerID=40&md5=6d2a17fcdbe357ec1335ae439f96aa03,scopus
09eb13bc70199528,The fundamentals of commodity futures returns,"Commodity futures risk premiums vary across commodities and over time depending on the level of physical inventories. The convenience yield is a decreasing, nonlinear function of inventories. Price measures, such as the futures basis, prior futures returns, prior spot returns, and spot price volatilities reflect the state of inventories and are informative about commodity futures risk premiums. We verify these theoretical predictions using a comprehensive data set on 31 commodity futures and physical inventories between 1971 and 2010. We find no evidence that the positions of participants in futures markets predict risk premiums on commodity futures. © 2012 The Authors. © 2012 Elsevier B.V., All rights reserved.","Gorton, G.B.; Hayashi, F.; Rouwenhorst, K.G.",2013,10.1093/rof/rfs019,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871192702&doi=10.1093%2Frof%2Frfs019&partnerID=40&md5=16b0c06ebb4692992c6f341dd79c6265,scopus
62cb6b8984b2f540,The hawk eye scan: Halyomorpha halys detection relying on aerial tele photos and neural networks,"This paper faces the challenge of monitoring the Brown Marmorated Stink Bug (H.halys) (Halyomorpha halys) within orchards, utilizing drones, and computer vision. H.halys is an invasive species originating from East Asia, that is extremely polyphagous and poses a significant threat to various crops. Our first contribution is a drone navigation protocol, which ensures risk-free drone flights in cluttered orchard environments, preserving image quality and avoiding obstacles. We then create a pioneering H.halys dataset consisting of aerial telephotos captured in the field autonomously by the drone. The dataset allows the development and evaluation for the first time of multiple ML models for H.halys detection in the field. We trained YOLOV5, YOLOV8, RETINANET, and FASTER-RCNN models using different learning methodologies, exploiting different percentages of images without the bug, and using different slicing procedures for the images. The Medium YOLOV5 model trained with all images containing a bug detects the largest number of H.halys on the testing set and overall performs the best, while RETINANET and FASTER-RCNN provide the best trade-off between precision and recall. Models vary in their ability to handle occluded H.halys and bug-free images, which are common since the presence of the bug cannot be predicted before capturing a photo. These results show promising potential for automating H.halys monitoring, despite the image complexity and the early dataset stage. Our work marks a significant step towards enhancing smart agriculture practices due to the simplicity of the data acquisition process and the off-the-shelf hardware selection. © 2025 Elsevier B.V., All rights reserved.","Palazzetti, L.; Rangarajan, A.K.; Dinca, A.; Boom, B.; Popescu, D.; Offermans, P.; Pinotti, C.M.",2024,10.1016/j.compag.2024.109365,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202194488&doi=10.1016%2Fj.compag.2024.109365&partnerID=40&md5=6343a88c6f0066b44a1045827b3a882c,scopus
19ee415ed7fb651b,"The impact of contagion effects of media reports, investors' sentiment and attention on the stock market based on HAR-RV model","In this paper, the Shanghai Securities Composite Index and 18 A-share listed companies are used to justify the impact of contagion effects of media reports, investors' sentiment and attention on stock market. Five indicators are built: The news media optimistic tendency, investors' attention, investors' sentiment, investors' sentiment disagreement and media sentiment disagreement. Furthermore, theoretical models are constructed based on HAR-RV model to analyze the contagion structure between media sentiment and investors' sentiment and its impact on the performance of stock market. Additionally, the reverse silence spiral theory is proposed to analyze the regulatory role of sentiment disagreement in the contagion effects according to the information communication theory. The empirical results demonstrate the following conclusions. (1) The optimism degree of media reports positively affects investors' subjective sentiment and increases their transaction volume. (2) Strengthening investors' attention to corporate-related information is the main path by which media sentiment interferes with investors' sentiment. (3) Media sentiment will indirectly affect the excess return and volatility of stocks through investors' sentiment and their transactions. (4) Media sentiment disagreement has weakened the influence of media sentiment on investors' attention and sentiment. Investors' sentiment disagreement has alleviated its impact on the excess returns and volatility of stocks.","Lei, Bolin; Song, Yuping",2023,10.1142/s242478632350010x,None,wos
029c751e000c5cf6,The impact of corporate social responsibility on financial distress: evidence from developing economy,"Purpose: This study aims to explore the role of corporate social responsibility (CSR) on the likelihood of financial distress for a sample of 139 Pakistan Stock Exchange (PSX) listed firms throughout 2008–2019. Design/methodology/approach: The dynamic generalized method of moments (GMM) estimator is used to examine the impact of CSR on financial distress. The investment in CSR is measured through a multidimensional financial approach which comprises the sum of the contribution made by the company in the form of charitable donation, employees’ welfare and research and development, while the Altman Z-score is used as an indicator of financial distress. The higher the Z-score, the lower will be the probability of financial distress. Findings: The authors find a significant positive impact of CSR on financial distress in GMM model. This finding is consistent with the shareholder view and over-investment hypothesis of CSR as management makes an investment in CSR to get personal benefits, which resultantly leads the firm toward financial distress state. Further, this positive relationship remains present for firms having strong involvement in foreign business through exports. Research limitations/implications: Like other studies, the present study is not free from limitations. First, financial firms are skipped from the sample, although literature witnesses a lot of studies highlight the financial firms’ commitment to achieving CSR goals. Second, financial distress occurs in different stages, and this study fails to establish a linkage between CSR engagement at different stages of financial distress. In the future, researchers can make valuable addition by covering these missing links in present studies. Practical implications: Findings suggest several practical implications. For policymakers, they should encourage firms to adopt more socially responsible behavior as it not only prevents them from distress but also comes with better investment behavior, minimize bankruptcies and make economies more strong and stable. Second, results suggest corporate managers emphasize socially responsible behavior as its benefits are beyond the “societal benefits” as it lessens financial distress through lower cost of debt, lesser financial constraints and reduced cost of information asymmetry, and it minimizes the cost of capital. Lastly, investors make risk premium assessments related to future earnings by determining the likelihood of financial distress in the future. Originality/value: The study extends the body of existing literature on CSR and the likelihood of financial distress in Pakistan, which is according to the best knowledge of the authors, not yet studied before. The results suggest that policymakers may pay special attention to the quality of CSR while predicting corporate financial distress. © 2021 Elsevier B.V., All rights reserved.","Farooq, M.; Noor, A.",2021,10.1108/par-10-2020-0196,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107835740&doi=10.1108%2FPAR-10-2020-0196&partnerID=40&md5=c3473de3b8ddfd1041890bffc2ae76da,scopus
f110f366b4d54e29,The impact of oil price shocks on Turkish sovereign yield curve,"Purpose>This paper aims to investigate the impact of oil price shocks on the Turkish sovereign yield curve factors.Design/methodology/approach>To extract the latent factors (level, slope and curvature) of the Turkish sovereign yield curve, we estimate conventional Nelson and Siegel (1987) model with nonlinear least squares. Then, we decompose oil price shocks into supply, demand and risk shocks using structural VAR (structural VAR) models. After this separation, we apply Engle (2002) dynamic conditional correlation GARCH (DCC-GARCH (1,1)) method to investigate time-varying co-movements between yield curve factors and oil price shocks. Finally, using the LP (local projections) proposed by Jorda (2005), we estimate the impulse-response functions to examine the impact of different oil price shocks on yield curve factors.Findings>Our results demonstrate that the various oil price shocks influence the yield curve factors quite differently. A supply shock leads to a statistically significant increase in the level factor. This result shows that elevated oil prices due to supply disruptions are interpreted as a signal of a surge in inflation expectations since the cost channel prevails. Besides, unanticipated demand shocks have a positive impact on the slope factor as a result of the central bank policy response for offsetting the elevated inflation expectations. Finally, a risk shock is associated with a decrease in the curvature factor indicating that risk shocks influence the medium-term bonds due to the deflationary pressure resulting from depressed economic conditions.Practical implications>Our results provide new insights to understand the driving forces of yield curve movements induced by various oil shocks to formulate appropriate policy responses.Originality/value>The study contributes to the literature by two main dimensions. First, the recent oil shock identification scheme of Ready (2018) is modified using the “geopolitical oil price risk index” to capture the changes in the risk perceptions of oil markets driven by geopolitical tensions such as terrorism and conflicts and sanctions. The modified identification scheme attributes more power to demand shocks in explaining the variation of the oil price compared to that of the baseline scheme. Second, it provides recent evidence that distinguishes the impact of oil demand and supply shocks on Turkey's yield curve.","Çepni, Oğuzhan; Gül, Selçuk; Yılmaz, Muhammed Hasan; Lucey, Brian",2022,10.1108/ijoem-06-2020-0681,None,proquest
ae0436eaafdd494a,The impact of serial correlation on testing for structural change in binary choice model: Monte Carlo evidence,"This paper examines the finite sample properties of structural change tests with an unknown breakpoint for the probit model in the presence of serial correlation. The combination of structural change and serial correlation renders model estimation challenging, affecting the consistency of coefficient estimates. Although there is vast literature concerning structural change tests for linear time series models, the literature for such tests in the context of binary choice models is somewhat sparse. More importantly, the empirical literature has applied the standard tests of structural change on the discrete choice model, despite the fact that most of these tests were developed specifically for the linear regression model. Subsequently, the theoretical properties of these tests in the context of non-linear models are unknown. This includes the class of discrete choice models, such as probit and logit. The issue becomes even more complicated in the presence of serial correlation, since typical tests for structural change often require the assumption of independence in the error terms. Even when the tests allow for a weakly dependent structure in the data, their finite sample performance remains unknown. This paper conducts simulation analysis on the size of 'supremum' Wald, LR and LM tests for structural change in the context of the probit model with varying levels of serial correlation. It is found that the shortcomings of the tests in linear models are magnified in probit models. In particular, the tests exhibit greater size distortion for the probit model than the linear model with the same level of serial correlation. Bootstrapping is also considered as an alternative approach to obtaining critical values, and though it reduces the size distortion in finite samples, it is unable to accommodate the distortion associated with a high level of serial correlation. (C) 2012 IMACS. Published by Elsevier B.V. All rights reserved.","Chan, Felix; Pauwels, Laurent L.; Wongsosaputro, Johnathan",2013,10.1016/j.matcom.2012.11.001,None,wos
3708ca7e2a4ab89a,The impact of sponsorship announcements on shareholder wealth in Australia,"Purpose – The purpose of this paper is to examine the impact of 51 sponsorship announcements upon the stock prices of firms sponsoring in Australia. The research examines the broader question of whether sponsorship has the potential to transcend cultural boundaries and contribute to financial performance in regional markets. Design/methodology/approach – The methodology is based on the event study technique which is applied to the estimation of excess returns that arise in response to announcements of corporate sponsorship made by leading industrial stocks trading on the Australian Stock Exchange. Regressions examine whether the cost and duration of sponsorship signal information of importance to investors regarding the financial prospects of sponsoring firms. Findings – A small, fleeting positive increase in wealth effects is observed indicating that economically, sponsorship expenditure in Australia is more or less value neutral. While investors appear indifferent to sponsorship cost, they value shortterm sponsorships of less than two years in particular. Research limitations/implications – Future research needs to examine the role of associated variables such as contract size and length, and the type and level of sponsorship investment. Originality/value – For firms, the study indicates that sponsorship in smaller regional markets should be valued by investors especially when firms keep the duration of the sponsorship as short. As stock prices tend to rise briefly following sponsorship announcements, marketers should leverage sponsorships immediately to gain the attention of investors. For a regional market, short and sharp sponsorships appear to be the optimal approach. © 2010, Emerald Group Publishing Limited © 2016 Elsevier B.V., All rights reserved.","Johnston, M.A.",2010,10.1108/13555851011026926,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77958474981&doi=10.1108%2F13555851011026926&partnerID=40&md5=d22fd09480a4e4c7d08d82235d6f52f7,scopus
34a2d6abf168cbd6,The impact of the Covid-19 related media coverage upon the five major developing markets,"This paper analyses the influence of the Covid-19 coverage by the social media upon the shape of the sovereign yield curves of the five major developing countries, namely Federative Republic of B razil, Russian Federation, Republic of India, People's Republic of China, and the Republic of South Africa (BRICS). The coherenc e between the level, slope, and the curvature of the sovereign yield term structures and the Covid-19 medi a coverage is found to vary between low and high ranges, depending on the phases of the pandemic. The empirical estimations of the yield-curve factors a re performed by means of the Diebold-Li modified version of the Nelson-Siegel model. The intervals of low coherence reveal the capacity of the two latent factors, level and slope, to be used for creating cross-factor diversification strategies, workable under crisis conditions, as evidenced on the example of the ongoing pandemic. Diverse coherence patterns are reported on a per-country basis, highlighting a promising potential of sovereign debt investments for designing cross-country and cross-factor fixed-income strategies, capable of hedging downside risks. © 2021 Elsevier B.V., All rights reserved.","Umar, Z.; Gubareva, M.; Sokolova, T.",2021,10.1371/journal.pone.0253791,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109009430&doi=10.1371%2Fjournal.pone.0253791&partnerID=40&md5=c2e168481e34ba89a700029c35741b67,scopus
e0d0deaef6ebe9c8,The impact of variability and correlation of selected geological parameters on the economic assessment of bituminous coal deposits with use of non parametric bootstrap and copula-based Monte Carlo simulation,"This paper presents an assessment of the impact of variability and interdependencies of selected deposit parameters on the net present value (NPV) and internal rate of return (IRR). The subjects of the analyses were three economically viable seams at one of the bituminous coal deposits in Poland. The source of information was the geological model and operational data of the mine X. The simulation was developed based on non-parametric bootstrapping, where the influence of coal quality parameters, seam thickness, spatial density of coal, and waste rock derived from coal partings, floor cutting and dinting, and roof falls, was tested.The interdependencies of geological and mining parameters were replicated in a simulation model using Gaussian and empirical copulas. In the model, the relationship between the amount of total waste rock and operating costs was associated with the use of elaborate mathematical formulas. Economic appraisal was based on an income approach, using the free cash flow for the firm (FCFF) analysis and discounting process.Based on the Gaussian copula, in the X-1 and X-2 seams, the average NPV differences achieved were a maximum of 39%. In the case of IRR, the mean difference did not exceed 3.6% points (pp). The quantified spread between the correlated and uncorrelated average values of NPV was at most 45% and 4.8 pp for IRR. Empirical copula limits the range of variation of input and output parameters, resulting in different values for the average NPV, at a maximum of 11.8%, and IRR, 2.4 pp.If the IRR reflects the level of expected return of investment, it can be stated that the additional risk premium resulting from the volatility and correlation of analysed deposits parameters of bituminous coal should be relatively low and less than 2.4 pp in similar cases. The analyses also revealed that the amount of available geological information is of secondary importance in the valuation process, as it does not negatively affect the regularity and symmetry of predicted outcomes.","Kopacz, Michal; Sobczyk, Eugeniusz J.; Galica, Dominik",2018,10.1016/j.resourpol.2017.11.015,None,wos
e257b7e9d88f79c0,The impact of word sense disambiguation on stock price prediction,"State-of-the-art decision support systems for stock price prediction incorporate pattern-based event detection in text into their predictions. These systems typically fail to account for word meaning, even though word sense disambiguation is crucial for text understanding. Therefore, we propose an advanced natural language processing pipeline for event-based stock price prediction, that allows for word sense disambiguation to be incorporated in the event detection process. We identify events in natural language news messages and subsequently weight these events for their historical impact on stock prices. We assess the merit of word sense disambiguation in event-based stock price prediction in two evaluation scenarios for NASDAQ-100 companies, based on historical stock prices and news articles retrieved from Dow Jones Newswires over a 2-year period. We evaluate the precision of generated buy and sell signals based on our predicted stock price movements, as well as the excess returns generated by a trading strategy that acts upon these signals. Event-based stock price predictions seem most reliable about 2 days into the future. The number of detected events tends to reduce with over 30% when graph-based word sense disambiguation using a degree centrality measure is applied in the event detection process, thus reducing the noise introduced into the stock price movement predictions by high-impact ambiguous events. As a result, modest improvements in the precision of buy and sell signals generated based on these predictions tend to lead to vast improvements of on average about 70% in the associated excess returns. © 2021 Elsevier B.V., All rights reserved.","Hogenboom, A.; Brojba-Micu, A.; Frasincar, F.",2021,10.1016/j.eswa.2021.115568,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109887638&doi=10.1016%2Fj.eswa.2021.115568&partnerID=40&md5=dfaeda381e54eef7aab7c102e3b6ad12,scopus
7fa232dd8733f7ab,The implied volatility smirk of commodity options,"This paper studies the implied volatility (IV) smirks in four commodity markets by adopting Zhang and Xiang's methodology. First, we document the term structure and dynamics of IV smirks. Overall, the commodity IV curves are negatively skewed with a positive curvature. Then we analyze the commodity and S&P 500 returns' predictability based on in-sample and out-of-sample tests and find that the information embedded in IV smirks can significantly predict monthly commodity and S&P 500 returns. For example, the risk-neutral fourth cumulant (FC) from the crude oil market outperforms all of the standard predictors in predicting the S&P 500 returns.","Jia, Xiaolan; Ruan, Xinfeng; Zhang, Jin E.",2021,10.1002/fut.22161,None,wos
38aa2888d66b462f,The information content of a nonlinear macro-finance model for commodity prices,"State-of-the-art term structure models of commodity prices have serious difficulties extrapolating the prices of long-maturity futures contracts from short-dated contracts. This situation is problematic for valuing real commodity-linked assets. We estimate a nonlinear four-factor continuous time model of commodity price dynamics. The model nests many previous specifications. To estimate the model, we use crude oil prices and inventories. The inventory data and nonlinear price dynamics have a large impact on oil price forecasts. The additional factor in our model compared with current three-factor models has a significant impact on model-implied long-maturity futures prices. © 2021 Elsevier B.V., All rights reserved.","Khan, S.; Khokher, Z.; Simin, T.",2017,10.1093/rfs/hhw087,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027014860&doi=10.1093%2Frfs%2Fhhw087&partnerID=40&md5=9dc58ffacd4b0157ed4a02671873fc2f,scopus
2c0b739e8ae2211a,The information content of option-implied volatility for credit default swap valuation,"Credit default swaps (CDS) are similar to out-of-the-money put options in that both offer a low cost and effective protection against downside risk. This study investigates whether put option-implied volatility is an important determinant of CDS spreads. Using a large sample of firms with both CDS and options data, we find that individual firms put option-implied volatility dominates historical volatility in explaining the time-series variation in CDS spreads. To understand this result, we show that implied volatility is a more efficient forecast for future realized volatility than historical volatility. More importantly, the volatility risk premium embedded in option prices covaries with the CDS spread. These findings complement existing empirical evidence based on market-level data. (C) 2010 Elsevier B.V. All rights reserved.","Cao, Charles; Yu, Fan; Zhong, Zhaodong",2010,10.1016/j.finmar.2010.01.002,None,wos
73a39603932c7788,The informational content of the embedded deflation option in TIPS,"We estimate the value of the embedded option in U.S. Treasury Inflation-Protected Securities (TIPS). The embedded option value exhibits time variation that is correlated with periods of deflationary expectations. We construct embedded option explanatory variables that are statistically and economically significant for explaining future inflation, even in the presence of traditional inflation variables such as lagged inflation, the gold return, the crude oil return, the VIX return, liquidity, surveys, and the yield spread between nominal Treasuries and TIPS. After conducting robustness tests, we conclude that the TIPS embedded option contains useful information for future inflation. (C) 2016 Elsevier B.V. All rights reserved.","Grishchenko, Olesya V.; Vanden, Joel M.; Zhang, Jianing",2016,10.1016/j.jbankfin.2015.12.004,None,wos
f87c91979270a5eb,The market for commonwealth government securities,"This study of the market for Commonwealth government securities in Australia pays particular attention to the influence of interest rate expectations on demand. Attempts to estimate expectations with current and past information, including the use of a Box-Jenkins time series model are unsuccessful. An assumption that interest rate expectations are based on perfect foresight proves valuable in explaining the demand for government securities. The picture of the market which emerges is one of a private sector which acts on new information more quickly than it is incorporated in the official yield curve. © 1980, SAGE Publications. All rights reserved. © 2016 Elsevier B.V., All rights reserved.","Evans, W.H.; Rozenstein, H.A.",1980,10.1177/031289628000500206,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965949166&doi=10.1177%2F031289628000500206&partnerID=40&md5=f511b472fcc843f2453db0ea9c6b3733,scopus
77c22962c65d3851,The maturity premium,"We show that firms with longer debt maturities earn risk premia not explained by unconditional factors. Embedding dynamic capital structure choices in an asset-pricing framework where the market price of risk evolves with the business cycle, we find that firms with long-term debt exhibit more countercyclical leverage. The induced covariance between betas and the market price of risk generates a maturity premium similar in size to our empirical estimate of 0.21% per month. We also provide direct evidence for the model mechanism and confirm that the maturity premium is consistent with observed leverage dynamics of long- and short-maturity firms.","Chaderina, Maria; Weiss, Patrick; Zechner, Josef",2022,10.1016/j.jfineco.2021.07.008,None,proquest
25fb4c8caf97c256,"The meaning of structural breaks for risk management: new evidence, mechanisms, and innovative views for the post-COVID-19 era","This paper quantitatively reveals the meaning of structural breaks for risk management by analyzing US and major European banking sector stocks. Applying newly extended Glosten-Jagannathan-Runkle generalized autoregressive conditional heteroscedasticity models, we supply the following new evidence. First, we find that incorporating structural breaks is always effective in estimating banking stock volatilities. Second, we clarify that structural breaks partially explain the tail fatness of banking stock returns. Third, we find that when incorporating structural breaks, the estimated volatilities more accurately capture their downside risk, proving that structural breaks matter for risk management. Fourth, our news impact curve and model parameter analyses also uncover that when incorporating structural breaks, the asymmetry in volatility responses to return shocks is more accurately captured. This proves why the estimated volatilities by incorporating structural breaks better explain downside risk. In addition, we further reveal that the estimated volatilities obtained through incorporating structural breaks increase sharply during momentous events such as the Lehman crisis, the European debt crisis, Brexit, and the recent COVID-19 crisis. Moreover, we also clarify that the volatility spreads between models with and without structural breaks rise during the Lehman and COVID-19 crises. Finally, based on our findings, we derive many significant and beneficial interpretations, implications, and innovative views for risk management using artificial intelligence in the post-COVID-19 era.","Tsuji, Chikashi",2022,10.3934/qfe.2022012,None,wos
7719bbf25e28541e,The multifactor nature of the volatility of futures markets,"This paper estimates a model of interest rate dynamics containing multi-factor Wiener and single-factor Poisson jump volatility components. Data from the highly liquid but short term futures markets are used. The difficult numerical problem of estimating such multi-factor models is resolved by using a genetic algorithm to carry out the optimization procedure. It is established that the multi-factor Wiener volatility components are adequate to model the interest rate dynamics without the need to incorporate Poisson jump components, the existence of which would create difficulties in the practical use of interest rate models. Reprinted by permission of Springer","Chiarella, Carl; Tô, Thuy-Duong",2006,10.1007/s10614-006-9023-9,None,proquest
af84a9d1919ec35b,The performance of variance ratio unit root tests under nonlinear stationary TAR and STAR processes: Evidence from Monte Carlo simulations and applications,"This paper investigates the performance of variance ratio unit root tests under nonlinear stationary three-regime threshold autoregressive (TAR) and smooth transition autoregressive (STAR) processes that are significant for some economic theories and variables. Variance ratio unit root tests are effective tools in empirical analysis because they can theoretically consider broad classes of nonlinear stationary processes under the null or alternative hypothesis. Nevertheless, our Monte Carlo simulations demonstrate that these tests perform poorly (with severe size distortions or low power) under stationary TAR and STAR processes. To verify our Monte Carlo results, we apply these tests to yield spreads such as the TAR and STAR processes.","Maki, Daiki",2008,10.1007/s10614-007-9107-1,None,wos
01e6238a15a50b30,The predictive distributions of thinning-based count processes,"This paper shows that the term structure of conditional (i.e. predictive) distributions allows for closed form expression in a large family of (possibly higher order or infinite order) thinning-based count processes such as INAR(p), INARCH(p), NBAR(p), and INGARCH(1,1). Such predictive distributions are currently often deemed intractable by the literature and existing approximation methods are usually time consuming and induce approximation errors. In this paper, we propose a Taylor's expansion algorithm for these predictive distributions, which is both exact and fast. Through extensive simulation exercises, we demonstrate its advantages with respect to existing methods in terms of the computational gain and/or precision. © 2021 Elsevier B.V., All rights reserved.","Lu, Y.",2021,10.1111/sjos.12438,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077400529&doi=10.1111%2Fsjos.12438&partnerID=40&md5=51d29189308bafffdf7533af066f2877,scopus
edcd8b865beeefe6,The price of power: The valuation of power and weather derivatives,"Pricing contingent claims on power presents numerous challenges due to (1) the unique behavior of power prices, and (2) time-dependent variations in prices. We propose and implement a model in which the spot price of power is a function of two state variables: demand (load) and fuel price. in this model, any power derivative price must satisfy a PDE with boundary conditions that reflect capacity limits and the non-linear relation between load and the spot price of power. Moreover, since power is non-storable and demand is not a traded asset, the power derivative price embeds a market price of risk. Using inverse problem techniques and power forward prices from the PJM market, we solve for this market price of risk function. During 1999-2001, the upward bias in the forward price was as large as $50/MWh for some days in July. By 2005, the largest estimated upward bias had fallen to $19/MWh. These large biases are plausibly due to the extreme right skewness of power prices: this induces left skewness in the payoff to short forward positions, and a large risk premium is required to induce traders to sell power forwards. This risk premium suggests that the power market is not fully integrated with the broader financial markets. (C) 2008 Published by Elsevier B.V.","Pirrong, Craig; Jermakyan, Martin",2008,10.1016/j.jbankfin.2008.04.007,None,wos
6b731db9ed4214e8,The relation between the equity risk premium and the bond maturity premium in the UK: 1900-2006,"Using a rich data set for the UK for over a century, we find that the relation between the equity risk premium and the government bond maturity premium is nonlinear and subject to stochastic regime switching. We identify a regime in which both premia are jointly characterized by low volatility and another regime in which both premia are characterized by high volatility. The occurrence of the high volatility regime chronologically coincides with major changes in the pound exchange rate. The low volatility regime has a higher probability of turning up over two consecutive years than the high volatility regime, but it is not perceived by investors to be an absorbing regime. The lagged maturity premium is a strong predictor of the equity risk premium only in the regime of low volatility. In addition, the lagged equity premium is a predictor of the maturity premium also in the low volatility regime. This result on regime-dependent bidirectional predictability is robust to alternative definitions of the equity premium, and to the inclusion of real interest rate and real growth effects. © 2008 Springer Science+Business Media, LLC. © 2009 Elsevier B.V., All rights reserved.","Kanas, A.",2009,10.1007/s12197-008-9038-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-65249147174&doi=10.1007%2Fs12197-008-9038-2&partnerID=40&md5=8f24282c2b2092e99ed1ca80871e306d,scopus
c7b17c47b92ccbbf,The relationship between risk-neutral and actual default probabilities: the credit risk premium,"The study investigates empirically the relationship between the risk-neutral measure Q and the real-world measure P. We study the ratio between the risk-neutral and actual default intensities, which we call the coverage ratio or the relative credit risk premium. Actual default intensities are derived from rating agencies annual transition matrices, while risk-neutral default intensities are bootstrapped from CDS quotes of European corporates. We quantify the average risk premium and its changes over time. Compared to related literature, special attention is given to the effects of the recent financial and European sovereign crises. We find that average credit risk premia rose substantially and that post-crisis levels are still higher than those observed before the financial crisis. This observation is especially true for high-quality debt and if it persists, it will have an impact on corporates funding costs. The quantification and revision of risk premia contributes to the discussion of the credit spread puzzle and could give extra insights in valuation models that start from real-world estimates. Our work is furthermore important in the context of state aid assessment. The real economic value (REV) methodology, applied by the European Commission to evaluate impaired portfolios, is based on a long-term average risk premium. © 2017 Elsevier B.V., All rights reserved.","Heynderickx, W.; Cariboni, J.; Schoutens, W.; Smits, B.",2016,10.1080/00036846.2016.1150953,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966698707&doi=10.1080%2F00036846.2016.1150953&partnerID=40&md5=b10de6b3c90e0f224539f72a8ec3ddf7,scopus
eac1579c9a56f66f,The risk premia embedded in index options,"We study the dynamic relation between market risks and risk premia using time series of index option surfaces. We find that priced left tail risk cannot be spanned by market volatility (and its components) and introduce a new tail factor. This tail factor has no incremental predictive power for future volatility and jump risks, beyond current and past volatility, but is critical in predicting future market equity and variance risk premia. Our findings suggest a wide wedge between the dynamics of market risks and their compensation, which typically displays a far more persistent reaction following market crises. (C) 2015 Elsevier B.V. All rights reserved.","Andersen, Torben G.; Fusari, Nicola; Todorov, Viktor",2015,10.1016/j.jfineco.2015.06.005,None,wos
e3949ad7076546c5,The role of an aligned investor sentiment index in predicting bond risk premia of the U.S,"In this paper, we develop a new investor sentiment index that is aligned to predict the excess returns on U.S. government bonds that have 2–5 years maturities. The new index is constructed by eliminating a common noise component in underlying sentiment proxies using the partial least squares (PLS) approach. The findings show that the new aligned sentiment index has much greater predictive power than the original principal component analysis (PCA)-based sentiment index both in- and out-of-sample. In addition, predictability is statistically significant, especially for bond premia with shorter maturities, even after controlling for a large number of financial and macro factors, as well as investor attention and manager sentiment indexes. Given the role of U.S. Treasury securities in forecasting of output and inflation, as well as in portfolio allocation decisions, our findings have significant implications for investors, policymakers, and researchers interested in accurately the forecasting return dynamics for these assets. © 2020 Elsevier B.V., All rights reserved.","Cepni, O.; Güney, I.E.; Gupta, R.; Wohar, M.E.",2020,10.1016/j.finmar.2020.100541,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079393274&doi=10.1016%2Fj.finmar.2020.100541&partnerID=40&md5=8f38616f6da46e99c620db8243d7aeb2,scopus
84f8c1f8bb04677d,The role of supervised learning in the decision process to fair trade US municipal debt,"Determining a fair price and an appropriate timescale to trade municipal debt is a complex decision. This research uses data informatics to explore transaction characteristics and trading activity of investment grade US municipal bonds. Using the relatively recent data stream distributed by the Municipal Securities Rulemaking Board, we provide an institutional summary of market participants and their trading behavior. Subsequently, we focus on a sample of AAA bonds to derive a new methodology to estimate a trade-weighted benchmark municipal yield curve. The methodology integrates the study of ridge regression, artificial neural networks, and support vector regression. We find an enhanced radial basis function artificial neural network outperforms alternate methods used to estimate municipal term structure. This result forms the foundation for establishing a decision theory on optimal municipal bond trading. Using multivariate modeling of a liquidity domain measured across three dependent variables, we investigate the proposed decision theory by estimating weekly production-theoretic bond liquidity returns to scale. Across the three liquidity measures and for almost all weeks investigated, bond trading liquidity is elastic with respect to the modeled factors. This finding leads us to conclude that an optimal trading policy for municipal debt can be implemented on a weekly timescale using the elasticity estimates of bond price, trade size, risk, days-to-maturity, and the macroeconomic influences of labor in the workforce and building activity.","Dash, Gordon H; Kajiji, Nina; Vonella, Domenic",2018,10.1007/s40070-018-0079-2,None,proquest
d28b32f410fc35cb,The role of term spread and pattern changes in predicting stock returns and volatility of the United Kingdom: Evidence from a nonparametric causality-in-quantiles test using over 250 years of data,"Given the existence of nonlinear relationship between equity premium and term spread, as well as pattern changes and the interaction of pattern changes with the term-spread and changes in the shape of the yield curve, we use a nonparametric k-th order causality-in-quantiles test to predict the movement in excess returns and volatility based on changes in the shape of the yield curve. With the test applied to over 250 years of monthly data for the UK covering the period 1753:08 to 2017:02, we find that pattern changes and the interaction of pattern changes with the term-spread, besides the term spread itself, tends to also play an important role in predicting volatility at the upper end of its conditional distribution. In addition, the effect on excess returns from term spread, pattern changes and the interaction is found to have improved markedly over time, barring at the conditional median of the equity premium. Finally, comparisons are made with historical data of the US and South Africa, and implications of our results are discussed. © 2019 Elsevier B.V., All rights reserved.","Gupta, R.; Risse, M.; Volkman, D.A.; Wohar, M.E.",2019,10.1016/j.najef.2018.05.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047273301&doi=10.1016%2Fj.najef.2018.05.006&partnerID=40&md5=0b1ce5fd52c3e2ea5edef836d785eb8c,scopus
4b19ed1da48dc4e8,The role of uncertainty and sentiment for intraday volatility connectedness between oil and financial markets,"We quantify intraday volatility connectedness between oil and key financial assets and assess how it is related to uncertainty and sentiment measures. For that purpose, we integrate the well-known spillover methodology with a TVP VAR model estimated on a unique, vast dataset of roughly 300 thousand 5 min quotations for most heavily traded financial assets: crude oil, the US dollar, S&P 500 index, gold and US treasury bonds. This distinguishes our investigation from previous studies, which usually employ relatively short samples of daily or weekly data and focus on connectedness between two asset classes. We contribute to the literature across three margins. First, we document that market connectedness at intraday frequency presents a different picture on markets co-movement compared to the estimates obtained using daily data. Second, we show that at 5 min frequency volatility is mostly transmitted from the stock market and absorbed by the bond and dollar markets, with oil and gold markets being occasionally important for volatility transmission. Third, we present evidence that daily averages of intraday connectedness measures respond to changes in sentiment and market- specific uncertainty. Interestingly, our results contrast with earlier findings, as they show that connectedness among markets decreases in periods of high volatility owing to market-specific factors. Our study points to the importance of using high-frequency data in order to better understand financial and commodity markets dynamics.","Szafranek, Karol; Rubaszek, Michal; Uddin, Gazi Salah",2024,10.1016/j.eneco.2024.107760,None,wos
f275f02d334fb4b6,The shape of the risk premium: Evidence from a semiparametric generalized autoregressive conditional heteroscedasticity model,"We examine the relationship between the risk premium on the Center for Research on Security Prices (CRSP) value-weighted index total return and its conditional variance. We propose a new serniparametric model in which the conditional variance process is parametric and the conditional mean is an arbitrary function of the conditional variance. For monthly CRSP value-weighted excess returns, the relationship between the two moments that we uncover is nonlinear and nonmonotonic.","Linton, O; Perron, B",2003,10.1198/073500103288619052,None,wos
e3dd71ea367283cb,The term structure of Eurozone peripheral bond yields: an asymmetric regime-switching equilibrium correction approach,"Several studies have established the predictive power of the yield curve i.e. the difference between long and short-term bond rates and the role of asymmetries in the term structure of bond yields with respect to real economic activity. Using an extensive dataset, comprising 3-month, 1-year, 5-year and 10-year constant maturity Treasury bonds for the Eurozone southern periphery countries - the so-called PIIGS - from January 1999 to April 2019, we investigate the links between bond yields of different maturities for the Eurozone southern peripheral countries and we find they co-evolve in line with the predictions of the Expectations Hypothesis theory. We demonstrate the presence of nonlinearities in the term structure, and utilize a multivariate asymmetric two-regime Markov-switching VAR methodology to model them properly. Moreover, we address the economic reasoning behind the introduction of an equilibrium-correction regime-switching approach, hence providing potentially important insights on the behaviour of the entire yield curve. We reveal that the regime shifts are related to the state of the business cycle, particularly in economies in which monetary policy decisions are implemented via changes in short-term rates as a response to deviations of output from equilibrium levels. Our results may have important statistical and economic implications on the behaviour of the term structure of bond yields.","Avdoulas, Christos; Bekiros, Stelios; Lucey, Brian",2020,10.1515/snde-2018-0105,None,wos
1c272d0569feb4e8,The term structure of Japanese interest rates: The equilibrium spread with asymmetric dynamics,"This paper examines the dynamic adjustment to long-run relationship between Japanese interest rates of different maturities. We employ a new estimation methodology that permits threshold and the momentum-threshold adjustment towards equilibrium. The results support the expectations hypothesis of the term structure of interest rate using Japanese interest rates. As in the case of the United States, it shown that the error-correction process is best estimated as asymmetric. © 2003 Elsevier Inc. All rights reserved. © 2017 Elsevier B.V., All rights reserved.","Kuo, S.-H.; Enders, W.",2004,10.1016/s0889-1583(03)00046-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-1442355381&doi=10.1016%2FS0889-1583%2803%2900046-7&partnerID=40&md5=c7948c0dbdc2c0c80ba7960123a64018,scopus
968c221aed751383,The term structure of policy rules,"A formula is derived that links the coefficients of the monetary policy rule for the short-term interest rate to the coefficients of the implied affine equations for long-term interest rates. The formula predicts that an increase in the coefficients in the monetary policy rule will lead to an increase in the coefficients in the affine equations. Empirical evidence for such a prediction is provided. The curve of the response coefficients by maturity is also predicted by the formula. The formula's predictive accuracy and its closed form make it a useful tool for studying the policy implications of embedding no-arbitrage affine theories into macro models. All rights reserved, Elsevier","Smith, J M; Taylor, John B",2009,10.1016/j.jmoneco.2009.09.004,None,proquest
693d8e2872e52e11,The value of options for time charterparty extension: an artificial neural networks (ANN) approach,"The most frequently associated options in the physical shipping market are options to extend the charter period on time charters and additional shipment options on contracts of affreightment. The value of freight options, in practice, is estimated mostly by referring to forward curves. An option on freight has different properties from its financial counterparts, and the straightforward adoption of theoretical models does not produce promising results. In this paper, extension options, which have the property of options on futures, were transformed into regular European options before the application of the Black-Scholes model (BSM). The efficient market hypothesis, which justifies the parity of the performance of a long-term charter to that of repetitive short-term charters, worked as the basis for the transformation. The option values determined by the BSM were compared with actual realized values. Additionally, the artificial neural networks (ANN) was employed to derive the option values. This study is meaningful as the first-time application of both the closed-form solution and the ANN to the valuation of physical freight options. The research results can contribute to the quality of chartering decisions. The results could also be used in quantifying credit risk, as extension options tend to be granted to charterers with more creditability.","Yun, Heesung; Lim, Sangseop; Lee, Kihwan",2018,10.1080/03088839.2017.1392630,None,wos
3f4988cc62025b37,The value premium and uncertainty: An approach by support vector regression algorithm,"Risk premium plays an important role in stock investing. Experiments have shown that value stocks typically have a higher average return than growth stocks; however, this effect persists indefinitely, even disappearing in some stages. Some studies suggested high volatility in the series of returns, broken structures, market volatility, or the impact of financial crises. This study aimed to build the uncertainty index and control it in the regression analysis model to solve the limitations above. The empirical analysis in Ho Chi Minh Stock Exchange (HOSE) showed that a value premium exists, and value stocks have a higher average return than growth stocks due to the higher overall risk. Furthermore, this study combined the Support Vector Regression (SVR) algorithm with the risk premium theoretical framework for the forecasting model; consequently, it is the most efficient model.","Bui Thanh Khoa; Huynh, Tran Trong",2023,10.1080/23322039.2023.2191459,None,proquest
d715fc9fe9bf9d9c,The volatility of the instantaneous spot interest rate implied by arbitrage pricing-A dynamic Bayesian approach,"This paper considers the estimation of the volatility of the instantaneous short interest rate from a new perspective. Rather than using discretely compounded market rates as a proxy for the instantaneous short rate of interest, we derive a relationship between observed LIBOR rates and certain unobserved instantaneous forward rates. We determine the stochastic dynamics for these rates under the risk-neutral measure and propose a filtering estimation algorithm for a time-discretised version of the resulting interest rate dynamics based on dynamic Bayesian updating in order to estimate the volatility function. Our time discretisation can be justified by the fact that data are observed discretely in time. The method is applied to US Treasury rates of various maturities to compute a (posterior) distribution for the parameters of the volatility specification. © 2006 Elsevier Ltd. All rights reserved. © 2011 Elsevier B.V., All rights reserved.","Bhar, R.; Chiarella, C.; Hung, H.; Runggaldier, W.J.",2006,10.1016/j.automatica.2005.12.027,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745492982&doi=10.1016%2Fj.automatica.2005.12.027&partnerID=40&md5=ec0449cd3c7a17d3e872a04c83968d09,scopus
75536a9b5e21dd96,The volatility structure of the fixed income market under the HJM framework: A nonlinear filtering approach,"The dynamics for interest rate processes within the well-known multi-factor Heath, Jarrow and Morton (HJM) specification are considered. Despite the flexibility of and the notable advances in theoretical research about the HJM model, the number of empirical studies of it is still very sparse. This paucity is principally due to the difficulties in estimating models in this class, which are not only high-dimensional, but also nonlinear and involve latent state variables. The estimation of a fairly broad class of HJM models as a nonlinear filtering problem is undertaken by adopting the local linearization filter, which is known to have some desirable statistical and numerical features, so enabling the estimation of the model via the maximum likelihood method. The estimator is then applied to the US, the UK and the Australian markets. Different two- and three-factor models are found to be the best for each market, with the factors being the level, the slope and the twist effect. The contribution of each factor towards overall variability of the interest rates and the financial reward each factor claims are found to differ considerably from one market to another. (C) 2008 Elsevier B.V. All rights reserved.","Chiarella, Carl; Hung, Hing; To, Thuy-Duong",2009,10.1016/j.csda.2008.07.036,None,wos
a213a5d346735bc3,The “probability of recession”: Evaluating probabilistic and non-probabilistic forecasts from probit models of U.S. recessions,"This letter evaluates forecasts from probit models that use the slope of the yield curve to forecast recessions. These models give reliable non-probabilistic warnings of recessions, but the estimated probabilities do not match the conditional frequency of recession months.","Ratcliff, Ryan",2013,10.1016/j.econlet.2013.09.002,None,proquest
38b1d9a67bf5a236,Third-party Logistics in Bio-medical Waste System: a Path Towards a Risk-free Sector,"After the sudden advent of COVID-19, the amount of medical waste has escalated to a great extent. The incremented medical waste amidst the pandemic exposes the improper waste management system of various developing countries. India, being one of the prominent developing countries, produces the largest waste in the world. Nonetheless, the Indian waste management system is not able to manage the massive amount of waste generated. Henceforth, this research study approaches to reveal the prominent factors which are causing failure in the system of medical waste management in India. This manuscript mainly focuses on two aspects. Firstly, this paper illuminates the factors which are hindering medical waste management by third-party logistics (3PL). Secondly, this study discusses a unique interval-value intuitionistic fuzzy set (IVIFS) based on Decision Making Trial and Evaluation Laboratory (DEMATEL) to depict graphical causal interrelationships among the factors. In addition, the analytic network process (ANP) is utilized to estimate the influence ranking of each factor. The results of this research anticipate that the transportation and disposal-related constraining factors require more attention from 3PL managers. The current study is unique as it enriches the various hindering factors on 3PL BMW management by discussing the ranking and relationship among factors. © 2022 Elsevier B.V., All rights reserved.","Dwivedi, N.; Sharma, H.; Shanker, S.; Barve, A.",2022,10.1007/s41660-022-00259-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131091442&doi=10.1007%2Fs41660-022-00259-x&partnerID=40&md5=a5ee5ac604d47fbacde57222e113ccfe,scopus
e612eb3d499c8d9c,Threshold Dynamics of Short-term Interest Rates: Empirical Evidence and Implications for the Term Structure,"This paper studies a nonlinear one-factor term structure model in discrete time. The short-term interest rate follows a self-exciting threshold autoregressive (SETAR) process that allows for shifts in the intercept and the variance. In comparison with a linear model, we find empirical evidence in favour of the threshold model for Germany and the US. Based on the estimated short-rate dynamics we derive the implied arbitrage-free term structure of interest rates. Since analytical solutions are not feasible, bond prices are computed by means of Monte Carlo integration. The resulting term structure captures stylized facts of the data. In particular, it implies a nonlinear relation between long rates and the short rate.","Archontakis, Theofanis; Lemke, Wolfgang",2008,10.1111/j.1468-0300.2008.00189.x,None,proquest
2eb3060f2d35d3d1,"Tightly Coupled, Graph-Based DVL/IMU Fusion and Decoupled Mapping for SLAM-Centric Maritime Infrastructure Inspection","In this article, we address the problem of simultaneous localization and mapping (SLAM)-centric maritime infrastructure inspection [using unmanned surface vehicles (USVs)] via novel approaches in tightly-coupled, graph-based DVL/IMU fusion and decoupled mapping. As our first contribution, we formalize the preintegration of linear velocity measurements, obtained by a Doppler velocity log (DVL), in combination with angular velocity measurements, obtained by an inertial measurement unit (IMU), as binary factors encoding relative position. To evaluate state estimation improvements imparted by DVL/IMU fusion, we implement our proposed factor within a state-of-the-art, graph-based lidar-visual-inertial (LVI) SLAM system as our second contribution. Accuracy and robustness improvements are demonstrated in simulation by comparing maximum a posteriori pose estimates with and without DVL/IMU fusion against ground truth poses. As our third contribution, we propose a map generation framework for downstream inspection applications decoupled from SLAM. In our framework, volumetric data (captured by sonar, lidar, etc.) is transformed into a common world coordinate frame using extrinsic calibrations and SLAM pose estimates as input. Our framework operates over the complete set of raw volumetric data, whereas SLAM systems (both online and offline) typically operate over a subset of down-sampled volumetric data. To address the processing of additional volumetric data, we present innovations in refined pose correction and staged filtering for user-controlled denoising. We experimentally evaluate our map generation framework against the LVI SLAM system adopted for this study using real-world data and demonstrate improvements to map quality metrics important to inspection.",A. Thoms; G. Earle; N. Charron; S. Narasimhan,2023,10.1109/joe.2023.3265742,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10149804,ieeexplore
c0e7db18be904853,"Time-varying market, interest rate, and exchange rate risk premia in the US commercial bank stock returns","This paper examines the role of market, interest rate, and exchange rate risks in pricing a sample of the US Commercial Bank stocks by developing and estimating a multi-factor model under both unconditional and conditional frameworks. Three different econometric methodologies are used to conduct the estimations and testing. Estimations based on nonlinear seemingly unrelated regression (NLSUR) via GMM approach indicate that interest rate risk is the only priced factor in the unconditional three-factor model. However, based on 'pricing kernel' approach by Dumas and Solnik [(1995). J. Finance 50, 445-479], strong evidence of exchange rate risk is found in both large bank and regional bank stocks in the conditional three-factor model with time-varying risk prices. Finally, estimations based on the multivariate GARCH in mean (MGARCH-M) approach where both conditional first and second moments of bank portfolio returns and risk factors are estimated simultaneously show strong evidence of time-varying interest rate and exchange rate risk premia and weak evidence of time-varying world market risk premium for all three bank portfolios, namely those of Money Center bank, Large bank, and Regional bank. © 2000 Elsevier Science B.V. All rights reserved. JEL classification: C32; G12; G21. © 2020 Elsevier B.V., All rights reserved.","Tai, C.S.",2000,10.1016/s1042-444x(00)00031-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034416407&doi=10.1016%2Fs1042-444x%2800%2900031-1&partnerID=40&md5=5c47f8f299b31f1053bf00598a4e8e5c,scopus
1ad66b307696646b,Time-varying nonlinear regression models: Nonparametric estimation and model selection,"This paper considers a general class of nonparametric time series regression models where the regression function can be time-dependent. We establish an asymptotic theory for estimates of the time-varying regression functions. For this general class of models, an important issue in practice is to address the necessity of modeling the regression function as nonlinear and time-varying. To tackle this, we propose an information criterion and prove its selection consistency property. The results are applied to the U.S. Treasury interest rate data. © 2021 Elsevier B.V., All rights reserved.","Zhang, T.; Wu, W.B.",2015,10.1214/14-aos1299,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924955365&doi=10.1214%2F14-AOS1299&partnerID=40&md5=53a8865b43b98d298f604f1e25a5a74a,scopus
430a63506326c22c,Time-varying risk of nominal bonds: How important are macroeconomic shocks?,"I study the sufficiency of macroeconomic information to explain the time-variation in second moments of stock and bond returns, with a particular attention to stock-bond correlations. I propose an external habit model supplemented with realistic non-Gaussian fundamentals estimated solely from macroeconomic data. Intertemporal smoothing and precautionary savings effects – driven by consumption shocks – combine with a time-varying covariance between consumption and inflation to generate large positive and negative stock-bond return correlations. Macroeconomic shocks are most important in explaining second moments of stock and bond returns from the late 1970’s to mid-1990’s and during the Great Recession. © 2022 Elsevier B.V., All rights reserved.","Ermolov, A.",2022,10.1016/j.jfineco.2022.04.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129401050&doi=10.1016%2Fj.jfineco.2022.04.003&partnerID=40&md5=1d94bf5d3b46c594a19799c91da57432,scopus
dba4d319451eec06,Tools for non-linear time series forecasting in economics - An empirical comparison of regime switching vector autoregressive models and recurrent neural networks,"The purpose of this study is to contrast the forecasting performance of two non-linear models, a regime-switching vector autoregressive model (RS-VAR) and a recurrent neural network (RNN), to that of a linear benchmark VAR model. Our specific forecasting experiment is U.K. inflation and we utilize monthly data from 1969 to 2003. The RS-VAR and the RNN perform approximately on par over both monthly and annual forecast horizons. Both non-linear models perform significantly better than the VAR model.","Binner, JM; Elger, T; Nilsson, B; Tepper, JA",2004,10.1016/s0731-9053(04)19003-8,None,wos
3f9abe9daf6dd16e,Towards ubiquitous information supply for individual investors: A decision support system design,"This paper introduces an IT artifact called MoFiN DSS that comprises hard- and software components that provide the basis for a prototype of a financial decision support system (DSS) to support individual investors reacting to unforeseen market events. We have derived our motivation for building such a system design from behavioral finance research. Analyses of the behavior of individual investors provide evidence that this segment does react more significantly to any public news published compared to institutional investors. On the other hand, the analyses show that they react significantly slower than their institutional counterparts. Since empirical intraday event study analyses show that capital markets react promptly to new information and that excess returns decrease over a specific period of time, individual investors miss significant trading opportunities due to their current strategies of information research. We address the problem that this market segment is not able to continuously observe diverse information channels and to assess all the new information available. Our prototype decision support system continuously observes company announcements and forecasts their potential impact on the corresponding stock price. After identifying those events for which significant market reactions can be expected, wireless push-based message services provide the technical basis for prompt and location-independent information supply. Based on a novel simulation-based evaluation methodology we have developed, we demonstrate and quantify the advantages that the developed system provides to the individual investors. © 2009 Elsevier B.V. All rights reserved. © 2009 Elsevier B.V., All rights reserved.","Muntermann, J.",2009,10.1016/j.dss.2009.01.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-64949122389&doi=10.1016%2Fj.dss.2009.01.003&partnerID=40&md5=63342a2f3bab4265f4a2068b33fff64b,scopus
d54605fff352145d,Tracking market and non-traditional sources of risks in procyclical and countercyclical hedge fund strategies under extreme scenarios: a nonlinear VAR approach,"The subprime crisis was quite damaging for hedge funds. Using the local projection method (Jordà 2004, 2005, 2009), we forecast the dynamic responses of the betas of hedge fund strategies to macroeconomic and financial shocks-especially volatility and illiquidity shocks-over the subprime crisis in order to investigate their market timing activities. In a robustness check, using TVAR (Balke 2000), we simulate the reaction of hedge fund strategies' betas in extreme scenarios allowing moderate and strong adverse shocks. Our results show that the behavior of hedge fund strategies regarding the monitoring of systematic risk is highly nonlinear in extreme scenarios-especially during the subprime crisis. We find that countercyclical strategies have an investment technology which differs from procyclical ones. During crises, the former seek to capture non-traditional risk premia by deliberately increasing their systematic risk while the later focus more on minimizing risk. Our results suggest that the hedge fund strategies' betas respond more to illiquidity uncertainty than to illiquidity risk during crises. We find that illiquidity and VIX shocks are the major drivers of systemic risk in the hedge fund industry.The subprime crisis was quite damaging for hedge funds. Using the local projection method (Jordà 2004, 2005, 2009), we forecast the dynamic responses of the betas of hedge fund strategies to macroeconomic and financial shocks-especially volatility and illiquidity shocks-over the subprime crisis in order to investigate their market timing activities. In a robustness check, using TVAR (Balke 2000), we simulate the reaction of hedge fund strategies' betas in extreme scenarios allowing moderate and strong adverse shocks. Our results show that the behavior of hedge fund strategies regarding the monitoring of systematic risk is highly nonlinear in extreme scenarios-especially during the subprime crisis. We find that countercyclical strategies have an investment technology which differs from procyclical ones. During crises, the former seek to capture non-traditional risk premia by deliberately increasing their systematic risk while the later focus more on minimizing risk. Our results suggest that the hedge fund strategies' betas respond more to illiquidity uncertainty than to illiquidity risk during crises. We find that illiquidity and VIX shocks are the major drivers of systemic risk in the hedge fund industry.","Racicot, François-Éric; Théoret, Raymond",2022,10.1186/s40854-021-00316-3,None,proquest
82d9f4b0a102aaea,Tractable nonlinear production planning models for semiconductor wafer fabrication facilities,"We describe a simulation study of a production planning model for multistage production inventory systems that reflects the nonlinear relationship between resource utilization and lead time. The model is based on the use of clearing functions that capture the nonlinear relationship between workload and throughput. We show how these clearing functions can be estimated from empirical data using a simulation model as a surrogate for observation of the production system under study. We then examine the sensitivity of the estimated clearing function to different dispatching algorithms, different demand patterns, and production planning techniques. Computational experiments based on a scaled-down model of a semiconductor wafer fabrication facility illustrate the potential benefits of the clearing function model relative to conventional linear programming models.",J. Asmundsson; R. L. Rardin; R. Uzsoy,2006,10.1109/tsm.2005.863214,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1588867,ieeexplore
2e9d948cb12c0935,Trading Macro-Cycles of Foreign Exchange Markets Using Hybrid Models,"Most existing studies on forecasting exchange rates focus on predicting next-period returns. In contrast, this study takes the novel approach of forecasting and trading the longer-term trends (macro-cycles) of exchange rates. It proposes a unique hybrid forecast model consisting of linear regression, multilayer neural network, and combination models embedded with technical trading rules and economic fundamentals to predict the macro-cycles of the selected currencies and investigate the predicative power and market timing ability of the model. The results confirm that the combination model has a significant predictive power and market timing ability, and outperforms the benchmark models in terms of returns. The finding that the government bond yield differentials and CPI differentials are the important factors in exchange rate forecasts further implies that interest rate parity and PPP have strong influence on foreign exchange market participants.","Bin Ling, Joseph Zhi; Tsui, Albert K; Zhang, Zhaoyong",2021,10.3390/su13179820,None,proquest
e33e0490e032325b,Trading the FX volatility risk premium with machine learning and alternative data,"In this study, we show how both machine learning and alternative data can be successfully leveraged to improve and develop trading strategies. Starting from a trading strategy that harvests the EUR/USD volatility risk premium by selling one-week straddles every weekday, we present a machine learning approach to more skillfully time new trades and thus prevent unfavorable ones. To this end, we build probability-calibrated Random Forests on various predictors, extracted from both traditional market data and financial news, to predict the closing Sharpe ratio of short one-week delta-hedged straddles. We then demonstrate how the output of these calibrated machine learning models can be used to engineer intuitive new trading strategies. Ultimately, we show that our proposed strategies outperform the original strategy on risk-based performance measures. Moreover, the features that we derived from financial news articles significantly improve the performance of the approach. © 2022 Elsevier B.V., All rights reserved.","Dierckx, T.; Davis, J.; Schoutens, W.",2022,10.1016/j.jfds.2022.07.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135525638&doi=10.1016%2Fj.jfds.2022.07.001&partnerID=40&md5=7121ebeb12981bacae46150f14854560,scopus
edae0558b51d4ae1,Transaction costs and nonlinear adjustment towards equilibrium in the US treasury bill market,"This paper uses nonlinear error correction models to study yield movements in the US Treasury Bill Market. Nonlinear error correction arises because portfolio adjustment is an 'on-off' process, which occurs only when disequilibrium in the bill market is large enough to induce investors to incur the transaction costs associated with buying/selling bills. This, together with heterogeneity of transaction costs, implies that the strength of aggregate error correction depends on both the distribution of costs and the extent of disequilibrium in the market. Smooth transition models are used to describe an aggregate adjustment process which is strong when the market is distant from equilibrium, but becomes weaker as the market approaches equilibrium. Linearity tests indicate that the types of nonlinearities that would be induced by transactions costs are statistically significant, and estimated models which incororate these nonlinearities outperform their linear counterparts, both in sample and out of sample. © Blackwell Publishers 1997. © 2018 Elsevier B.V., All rights reserved.","Anderson, H.M.",1997,10.1111/1468-0084.00078,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031523523&doi=10.1111%2F1468-0084.00078&partnerID=40&md5=97619a45ee86a6fafd0456ff928a5b07,scopus
361f9221ee0d7559,Transition densities for interest rate and other nonlinear diffusions,"This paper applies to interest rate models the theoretical method developed in Ait-Sahalia (1998) to generate accurate closed-form approximations to the transition function of an arbitrary diffusion. While the main focus of this paper is on the maximum-likelihood estimation of interest rate models with otherwise unknown transition functions, applications to the valuation of derivative securities are also briefly discussed.","Aït-Sahalia, Y",1999,10.1111/0022-1082.00149,None,wos
7bf6f432caa24633,Turning point vs trend,"At the beginning of the paper some shortcomings of the existing forecasting systems are demonstrated on examples of products of the EU forecasting service and of the Macroeconomic Prospect Team of the Treasury of the UK. And apart of it the smoothed lines of Nobel Prize winner of 2010 Professor Pissarides are considered in comparison with clear forecasts of turning points received by the author on the same time series. Then a description of forecasting of the recession of the early 1990s in the UK is given, as a part of forecasting of innovative growth. It is underlined that statistics must show explicitly ‘the height of technological leap’ and provide separate parameters of old and new technologies. And that the current focusing of attention on the most advanced technologies only should be broadened to all technologies which actually are being implementing in the economy. Comparison with the Cambridge Multisectoral Dynamic Model of the British Economy shows how peculiarities of reflection of new technologies could affect ability of seeing turning points. At the end some remarks are contributed to the current discussion between the competing schools. Positive aspects of the “Great Recession” of 2008 – 2010 are highlighted along with their similarity with previous crises. At that an attempt to restore the “shattered intellectual structure” of Alan Greenspan is made. © 2021 Elsevier B.V., All rights reserved.","Ryaboshlyk, V.",2011,10.14254/2071-8330.2011/4-1/6,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969842369&doi=10.14254%2F2071-8330.2011%2F4-1%2F6&partnerID=40&md5=9e9f89c66430456f736ae5a0762ab880,scopus
ed3aad09e82d6a77,Twin Picks: Disentangling the Determinants of Risk- Taking in Household Portfolios,"This paper investigates risk-taking in the liquid portfolios held by a large panel of Swedish twins. We document that the portfolio share invested in risky assets is an increasing and concave function of financial wealth, leading to different risk sensitivities across investors. Human capital, which we estimate directly from individual labor income, also affects risk-taking positively, while internal habit and expenditure commitments tend to reduce it. Our microfindings lend strong support to decreasing relative risk aversion and habit formation preferences. Furthermore, heterogeneous risk sensitivities across investors help reconcile individual preferences with representative-agent models.","Calvet, Laurent E.; Sodini, Paolo",2014,10.1111/jofi.12125,None,wos
95ecc7b2a3f725c5,Two Derivative Algorithms of Gradient Boosting Decision Tree for Silicon Content in Blast Furnace System Prediction,"The background of the present study complies with silicon content prediction in hot metal in the blast furnace system. The blast furnace system is a highly complex industrial reactor in the conventional process. The system is subject to several problems (e.g., system automation, the thermal state of the blast furnace, and the life prediction of blast furnace) that should be addressed by professionals. To determine the prediction state of the heat in the blast furnace, the silicon content in the blast furnace molten iron commonly acts as a key indicator. Based on the assumption that the blast furnace system exhibits a stable state, the accuracy of hot metal silicon is analyzed by using a range of machine learning algorithms. In the present study, two derivative algorithms of gradient boosting decision tree are adopted to develop a strong boosting predictor based on the extreme gradient boosting (XGBoost) algorithm and the light gradient boosting machine (LightGBM) algorithm for prediction. Compared with the conventional algorithms (e.g., lasso, random forest, support vector machine and gradient boosting decision tree), the prediction by using the two boosting algorithms is capable of more effectively guiding and determining the state of the blast furnace. As revealed from experimentally simulated results, the mentioned two boosting algorithms exhibit better comprehensive prediction performance than the conventional algorithms on the datasets of two practical blast furnace systems, demonstrating that the R-square of the two blast furnaces in the training set is over 0.7. The mentioned two algorithms are of certain guiding significance for exploring blast furnace problems.",S. Luo; T. Chen,2020,10.1109/access.2020.3034566,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9243945,ieeexplore
ef197579e7c25b65,Two-Stage Classification Method for Individual Workout Status Prediction with Machine Learning Approach,"The default risk, one of the main risk factors for bonds, should be measured and reflected in the bond yield. Particularly, in the case of financial companies that treat bonds as a major product, failure to properly identify and filter customers' workout status adversely affects returns. This study proposes a two-stage classification algorithm for workout prediction based on the history data of individual customers such as transaction details of financial companies secured after loans, which is collected over 10 years. The first stage is to rank variables that are closely related to the workout application based on feature selection. In the second step, the first to nth cumulative variables input to each machine learning method generate n candidate classifiers, respectively. Among the total candidates, the model with the highest classification accuracy was selected as the optimal one, which is the Gradient Boost combined with F-score-based feature selection.","Noh, Yoonjae; Yoon, YoonIl; Kim, Sangjin",2024,10.1080/15366367.2023.2246109,None,proquest
deab06de18be4232,U.S. leveraged loan and debt markets: Implications for optimal portfolio and hedging,"This paper offers fresh empirical evidence on the relationship between leverage loans and US debt markets by investigating the distributional predictability and directional predictability between leveraged loans and treasury bonds, fixed income securities and corporate bonds in the U.S economy. We use daily price data from January 2013 to April 2021. First, we analyze the causal relationship between variables by applying non-parametric causality-in-quantiles test and find that quantile causality in variance shows the stronger impact of leverage loan market returns on US debt market returns over the entire quantile range. Second, quantile dependence and directional predictability between leverage loan market and US debt markets are analyzed by applying cross-quantilogram approach and estimated results show the heterogeneous quantile relations from leverage loan market to US debt market. Moreover, the cross-quantile correlation results demonstrate the evidence of negative predictability from leverage loan market to US debt market in low, medium and high quantile range. These evidences are important for US investors and portfolio managers. © 2023 Elsevier B.V., All rights reserved.","Abakah, E.J.A.; Nasreen, S.; Tiwari, A.K.; Lee, C.-C.",2023,10.1016/j.irfa.2023.102514,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148346724&doi=10.1016%2Fj.irfa.2023.102514&partnerID=40&md5=c81900d99e18ad5d1fd4f21f01d0a1fd,scopus
8931a636ddc04803,U.S. vertically integrated electric utility greenhouse gas emissions and carbon risk premiums around the Paris Accord,"We study the pricing of greenhouse gas emissions of vertically integrated producers of electricity around the Paris Accord (PA). We study whether emissions are priced by financial markets, providing a market-based incentive for firms to reduce their carbon footprints and if the heightened attention on climate change post-Paris Accord (PA) impacts the size of the “carbon risk premium.” We focus on electricity generators, because they are responsible for the largest share of emissions and emissions reductions in the U.S. and are highly exposed to regulatory, physical, and stranded asset risks. We find the cost of carbon risk is reflected in the returns of vertically integrated electric utilities. The post-PA period provides the strongest evidence that carbon risk is priced. We find that equity markets provide incentives for power producers to reduce emissions, as reductions in emissions are associated with reductions in required returns on equity (increases in equity market values). The challenge for regulators is how to respond in rate cases. Lowering a utility's regulated return to reflect lower market estimates of the return on equity would dilute the market-based incentive for emissions reductions. Adding a longer-term return incentive for continued investment in emissions reductions would reinforce the market incentive.","Michelfelder, Richard A; Pilotte, Eugene A. https://orcid.org/0000-0001-6111-1853",2024,10.1016/j.enpol.2024.114346,None,proquest
60fc52bc2a9b4fc3,US Funds’ returns-based ESG extraction and implementation: a multifaceted quantile regression approach,"This study introduces a novel ESG intrinsic-based return factor and its application in asset pricing. This factor is extracted using a parallelized rolling window estimation and extreme value-weighted quantile portfolios. It carries a positive risk premium, indicating that investors are willing to assess its risk exposure. We further show that higher returns can be obtained in the top 30% quantiles using a long-only trading strategy. We apply a Monotone Composite Quantile Regression Neural Network (MCQRNN) model to explain US fund returns and address the needs of investors seeking to optimize their investment strategies. This model surpasses traditional benchmark models by performing deep quantile estimation and considering the nonlinear relationships between fund returns and six firm-based characteristics. This approach empowers investors by explaining the core principles of impact investing and highlighting how our constructed ESG risk factor can generate competitive returns even in volatile markets when its risk is well assessed. © 2025 Elsevier B.V., All rights reserved.","Nasri, F.; Ben Sassi, S.B.",2025,10.1080/20430795.2024.2420916,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209061239&doi=10.1080%2F20430795.2024.2420916&partnerID=40&md5=e6baeb1542709665fb74b6cb180af04d,scopus
23e3c100156433a3,US-Swiss term structures and exchange rate dynamics,"In this study, a multi-country nonlinear model is constructed to simultaneously estimate the exchange rate dynamics and the term structure of interest rates in the US and in Switzerland. The model has better empirical performance compared to the earlier well-known affine international models. Risk premiums of bond yields vary between the two countries. The estimated state variables exhibit local characteristics. These conclusions imply the potential advantages of international diversification and demonstrate the Home Bias puzzle. Exchange rate dynamics estimated by the models account for the Forward Premium Anomaly. © 2007 Elsevier Inc. All rights reserved. © 2007 Elsevier B.V., All rights reserved.","Inci, A.C.",2007,10.1016/j.gfj.2006.08.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-35448929801&doi=10.1016%2Fj.gfj.2006.08.003&partnerID=40&md5=723f81983d7870a8b99c8ff115b76d95,scopus
ae8fca5c4958de8d,USING NON-PARAMETRIC SEARCH ALGORITHMS TO FORECAST DAILY EXCESS STOCK RETURNS,"Are the learning procedures of genetic algorithms (GAs) able to generate optimal architectures for artificial neural networks (ANNs) in high frequency data? In this experimental study, GAs are used to identify the best architecture for ANNs. Additional learning is undertaken by the ANNs to forecast daily excess stock returns. No ANN architectures were able to outperform a random walk, despite the finding of non-linearity in the excess returns. This failure is attributed to the absence of suitable ANN structures and further implies that researchers need to be cautious when making inferences from ANN results that use high frequency data. © 2004 Elsevier Ltd. All rights reserved. © 2008 Elsevier B.V., All rights reserved.","Joseph, N.L.; Brée, D.S.; Kalyvas, E.",2004,10.1016/s0731-9053(04)19004-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748517846&doi=10.1016%2FS0731-9053%2804%2919004-X&partnerID=40&md5=5097515a501d6e10702723cf743f9dfd,scopus
bac2a47404767287,USING NONLINEAR METHODS TO SEARCH FOR RISK PREMIA IN CURRENCY FUTURES,"This paper uses currency futures prices to test the joint null hypotheses of rational expectations and absence of a time-varying risk premium in the foreign exchange market. We find no linear predictability in the logarithm of futures price changes, either using its own past or past interest differentials. Also we establish that there is no non-linear predictability in log price changes, conditioning on its own past, or past interest rate differentials. Thus, if a time-varying risk premium exists in currency futures market, it is not related to its own past or past interest rate differentials.","HSIEH, DA",1993,10.1016/0022-1996(93)90007-k,None,wos
0a0c2a619cb3d88f,Uncertainty and Forecasts of US Recessions,"We estimate Boosted Regression Trees (BRT) on a sample of monthly data that extends back to 1889 to recover the predictive value of disaggregated news-based uncertainty indexes for U.S recessions. We control for widely-studied standard predictors and use out-of-sample metrics to assess forecast performance. We find that war-related uncertainty is among the top five predictors of recessions at three different forecast horizons (3, 6, and 12 months). The predictive value of war-related uncertainty has fallen in the second half of the 20th century. Uncertainty regarding the state of securities markets has gained in relative importance. The probability of a recession is a nonlinear function of war-related and securities-markets uncertainty. Receiver-operating-characteristic curves show that uncertainty improves out-of-sample forecast performance at the longer forecast horizons. A dynamic version of the BRT approach sheds light on the importance of various lags of government-related uncertainty for recession forecasting at the long forecast horizon.","Pierdzioch, Christian; Gupta, Rangan",2020,10.1515/snde-2018-0083,None,wos
134ec5431d15e9ae,Uncertainty-Aware Portfolio Management With Risk-Sensitive Multiagent Network,"As deep neural networks (DNNs) have gained considerable attention in recent years, there have been several cases applying DNNs to portfolio management (PM). Although some researchers have experimentally demonstrated its ability to make a profit, it is still insufficient to use in real situations because existing studies have failed to answer how risky investment decisions are. Furthermore, even though the objective of PM is to maximize returns within a risk tolerance, they overlook the predictive uncertainty of DNNs in the process of risk management. To overcome these limitations, we propose a novel framework called risk-sensitive multiagent network (RSMAN), which includes risk-sensitive agents (RSAs) and a risk adaptive portfolio generator (RAPG). Standard DNNs do not understand the risks of their decision, whereas RSA can take risk-sensitive decisions by estimating market uncertainty and parameter uncertainty. Acting as a trader, this agent is trained via reinforcement learning from dynamic trading simulations to estimate the distribution of reward and via unsupervised learning to assess parameter uncertainty without labeled data. We also present an RAPG that can generate a portfolio fitting the user’s risk appetite without retraining by exploiting the estimated information from the RSAs. We tested our framework on the U.S. and Korean real financial markets to demonstrate the practicality of the RSMAN.",K. Park; H. -G. Jung; T. -S. Eom; S. -W. Lee,2024,10.1109/tnnls.2022.3174642,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9779871,ieeexplore
282122e9935c6034,Unconventional Monetary Policy in the Euro Zone,"The European Central Bank adopted a policy of quantitative easing early in 2015, long after the US and UK, and after implementing a succession of measures to increase liquidity in the Euro zone financial markets, none of which proved sufficient eventually. The paper draws out lessons for the Euro zone from US and UK experience. Numerous event studies have been undertaken to uncover the effects of QE on yields on and prices of financial assets. Estimated effects on long-term government bond yields are then converted into the size of the cut in the policy rate that would normally have been needed to produce them. From these implicit cuts in policy rates, estimates of the effect on GDP and inflation are generated. Euro zone QE appears to have had a much smaller effect on bond yields for the core members states than did QE in the US or UK. Therefore its effects on output and inflation are likely to be proportionately smaller. Its effects on long-term government bond yields in periphery members are greater. QE is compressing interest differential among Euro zone member states. The dangers of QE to which various commentators draw attention, that it creates a danger of inflation in the future, that it creates asset price bubbles, that it allows zombie firms and banks to survive, slowing down the process of adjustment, seem remote. Meanwhile it makes a useful contribution to cutting the costs of debt service and allowing member states more fiscal room for maneouvre.","Driffill, John",2016,10.1007/s11079-016-9393-0,None,proquest
87335a002c6d32e3,Unconventional monetary policy in a nonlinear quadratic model,"After the financial market meltdown and the Great Recession of the years 2007–9, the financial market-macro link has become an important issue in monetary policy modeling. We develop a dynamic model that contains a nonlinear Phillips curve, a dynamic output equation, and a nonlinear credit flow equation – capturing the importance of credit cycles, risk premia, and credit spreads. Our Nonlinear Quadratic Model (NLQ) model has three dynamic state equations and a quadratic objective function. It can be used to evaluate the response of central banks to the Great Recession in moving from conventional to unconventional monetary policy. We solve the model with a new numerical procedure using estimated parameters for the euro area. We conduct simulations to explore the (de)stabilizing effects of the nonlinearities in the model. We demonstrate that credit flows, risk premia, and credit spreads play an important role as an amplification mechanism and in affecting the transmission of monetary policy. We thereby highlight the importance of the natural rate of interest as an anchor for a central bank target and the weight it places on the credit flows for the effectiveness of unconventional monetary policy. Our model is similar in structure compared to larger scale macro-econometric models which many central banks employ.","Faulwasser, Timm; Gross, Marco; Semmler, Willi; Loungani, Prakash",2020,10.1515/snde-2019-0099,None,proquest
1a56df038c2e8350,Uncovering nonlinear dependencies in the Treasury-funds rate spread: Quantile-based explanation,"This study examines the structural dynamics of the spread between the 10-year Treasury yield and the federal funds rate, a key indicator of U.S. financial conditions. Cross-quantilogram analysis reveals a nonlinear dependency across adjacent periods, with stronger connectedness observed in the tail distribution than in the middle. Additionally, the functional quantile autoregression model confirms the spread's nonlinear and asymmetric nature from a distributional perspective. Specifically, higher quantiles of the previous spread exert a stronger influence on the current spread, indicating a positive persistence mechanism. Conversely, lower quantiles of the previous spread negatively affect the higher quantiles of the current spread. These findings suggest that bullish market conditions tend to sustain themselves, whereas bearish conditions hinder upward momentum, underscoring the need for quantile-specific policy interventions.","Meng, Fanyu",2025,10.1016/j.frl.2025.107216,None,wos
39f83bbe481f5679,Understanding Two Remarkable Findings about Stock Yields and Growth,"Two regularities regarding stock prices and expected inflation have received less attention than they deserve. First, earnings and dividend yields move with long-term expected inflation and risk-free rates. Second, analysts' forecasts of nominal growth, not real growth, vary little with expected inflation. These patterns are remarkable because financial economists predict exactly the opposite. One explanation for these contrary findings is that stock prices are too high (low) when inflation is low (high), because investors confuse nominal and real growth rates. The authors assert that investors are unlikely to be so systematically naive about expected inflation and argue that the contrary evidence is, in fact, consistent with a rational market. The key insight offered by the authors is that reported earnings include inflationary holding gains, which causes higher earnings yields when inflation is high (the first regularity) and, in turn, explains why forecasts of nominal growth need not vary with inflation (the second regularity).","Thomas, Jacob; Zhang, Frank",2009,10.3905/jpm.2009.35.4.158,None,wos
a88f01f8d0739b30,Understanding index option returns,"Previous research concludes that options are mispriced based on the high average returns, CAPM alphas, and Sharpe ratios of various put selling strategies. One criticism of these conclusions is that these benchmarks are ill suited to handle the extreme statistical nature of option returns generated by nonlinear payoffs. We propose an alternative way to evaluate the statistical significance of option returns by comparing historical statistics to those generated by option pricing models. The most puzzling finding in the existing literature, the large returns to writing out-of-the-money puts, is not inconsistent (i.e., is statistically insignificant) relative to the Black-Scholes model or the Heston stochastic volatility model due to the extreme sampling uncertainty associated with put returns. This sampling problem can largely be alleviated by analyzing market-neutral portfolios such as straddles or delta-hedged returns. The returns on these portfolios can be explained by jump risk premiums and estimation risk. © 2012 Elsevier B.V., All rights reserved.","Broadie, M.; Chernov, M.; Johannes, M.",2009,10.1093/rfs/hhp032,https://www.scopus.com/inward/record.uri?eid=2-s2.0-64149102384&doi=10.1093%2Frfs%2Fhhp032&partnerID=40&md5=0ede27dbc5c9649e2874de880e44de26,scopus
51c6a633d70ff311,Understanding the determinants of bond excess returns using explainable AI,"Recent empirical evidence indicates that bond excess returns can be predicted using machine learning models. However, although the predictive power of machine learning models is intriguing, they typically lack transparency. This paper introduces the state-of-the-art explainable artificial intelligence technique SHapley Additive exPlanations (SHAP) to open the black box of these models. Our analysis identifies the key determinants that drive the predictions of bond excess returns produced by machine learning models and recognizes how these determinants relate to bond excess returns. This approach facilitates an economic interpretation of the predictions of bond excess returns made by machine learning models and contributes to a thorough understanding of the determinants of bond excess returns, which is critical for the decisions of market participants and the evaluation of economic theories. © 2023 Elsevier B.V., All rights reserved.","Beckmann, L.; Debener, J.; Kriebel, J.",2023,10.1007/s11573-023-01149-5,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160660732&doi=10.1007%2Fs11573-023-01149-5&partnerID=40&md5=e58f5c87140bb001abb38c4aebeb2e78,scopus
398476d4b3717e7e,Unemployment insurance and mortgages,"We consider mortgages including the possibility of an unemployment insurance. The insurance company pays the cash flows of the credit as soon as the borrower becomes unemployed, for a maximal number of payments fixed in the contract. We develop a probabilistic model for describing the cash flows paid by the insurance company. We jointly take into account unemployment, job search and prepayment phenomena. With such a model it is possible to study the probabilistic properties of the cash flow pattern as a function of the age of the credit. Finally, we discuss the estimation of the parameters of such a model and its use for pricing the insurance contract. (C) 1997 Elsevier Science B.V.","Gourieroux, C; Scaillet, O",1997,10.1016/s0167-6687(97)00003-6,None,wos
2648f39614791bbd,Unit-root tests and asymmetric adjustment with an example using the term structure of interest rates,"This article develops critical values to test the null hypothesis of a unit root against the alternative of stationarity with asymmetric adjustment. Specific attention is paid to threshold and momentum threshold autoregressive processes. The standard Dickey-Fuller tests emerge as a special case. Within a reasonable range of adjustment parameters, the power of the new tests is shown to be greater than that of the corresponding Dickey-Fuller test. The use of the tests is illustrated using the term structure of interest rates. It is shown that the movements toward the long-run equilibrium relationship are best estimated as an asymmetric process.","Enders, W; Granger, CWJ",1998,10.2307/1392506,None,wos
7b15a54aad66cc21,United States banking stability: An explanation through machine learning,"In this paper, an analysis of the prediction of bank stability in the United States from 1990 to 2017 is carried out, using bank solvency, delinquency and an ad hoc bank stability indicator as variables to measure said stability. Different machine learning assembly models have been used in the study, a random forest is developed because it is the most accurate of all those tested. Another novel element of the work is the use of partial dependency graphs (PDP) and individual conditional expectation curves (ICES) to interpret the results that allow observing for specific values how the banking variables vary, when the macro-financial variables vary.It is concluded that the most determining variables to predict bank solvency in the United States are interest rates, specifically the mortgage rate and the 5 and 10-year interest rates of treasury bonds, reducing solvency as these rates increase. For delinquency, the most important variable is the unemployment rate in the forecast. The financial stability index is made up of the normalized difference between the two factors obtained, one for solvency and the other for delinquency. The index prediction concludes that stability worsens as BBB corporate yield increases.","Fernández Fernández, José Alejandro",2020,10.21511/bbs.15(4).2020.12,None,proquest
3c76378dff70bc76,Univariate and multivariate forecasting of the electricity futures curve using Dynamic Recurrent Neural Networks,"In recent years international power markets have witnessed high uncertainty and extraordinary volatility which, given the inherent complexity of the market, has made the Electricity Price Forecasting (EPF) process increasingly difficult. Therefore the development of a proper forecasting framework suitable for both stable and volatile periods has assumed an increasing importance for market players and policymakers in both strategic planning and risk management. At present, the majority of the studies on electricity price forecasting focused on the analysis of spot markets, neglecting the importance of derivative price modeling to mitigate the risks induced by market downturns and turmoil. Our study nests within this research stream and analyzes the potential of a set of state-of-the-art Machine Learning (ML) models for the prediction of the term structure of electricity futures prices. The objective is to define an ML-based framework capable of ensuring high predictive performance of the term structure during both stable and extremely turbulent conditions. In this regard we examined the predictive capabilities of a variety of Dynamic Recurrent Neural Networks (DRNNs) including: Nonlinear Autoregressive Neural Networks (NAR-NNs), NAR with Exogenous Inputs (NARX-NNs), Long Short-Term Memory (LSTM-NNs), Stacked Long Short-Term Memory (ST-LSTM-NNs), Bidirectional Long Short-Term Memory (BI-LSTM-NNs) and Encoder–Decoder Long Short-Term Memory Neural Networks (ED-LSTM-NNs). The models were applied to both low fluctuating and volatile sets of daily futures prices of the European Energy Exchange (EEX) for univariate as well as multivariate forecasting. Additionally, we compared this set of networks to baseline models commonly used in the EPF literature, including classical statistical and ML methods. Empirical results highlighted that DRNN models predictions are consistent with futures prices trends observed under different market regimes and outperform the competitors’ performance. Overall, main outcomes of the study may be summarized as follows: LSTM-based models seem to have the highest predictive power, with robust performance under various conditions. In detail the Multivariate BI-LSTM-NN performs better under quiet market conditions ensuring an accuracy level of 98.11 %, while the Univariate ED-LSTM-NN ensures superior predictive performance in presence of turmoil, achieving a 95.33 % accuracy. © 2025 Elsevier B.V., All rights reserved.","Castello, O.; Resta, M.",2025,10.1016/j.apenergy.2025.126082,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006717802&doi=10.1016%2Fj.apenergy.2025.126082&partnerID=40&md5=e71b13e9cb03bed028f944d93dbc5d7e,scopus
164d3e1462675b58,Unstable volatility: the break-preserving local linear estimator,"The objective of this paper is to introduce the break-preserving local linear (BPLL) estimator for the estimation of unstable volatility functions for independent and asymptotically independent processes. Breaks in the structure of the conditional mean and/or the volatility functions are common in Finance. Nonparametric estimators are well suited for these events due to the flexibility of their functional form and their good asymptotic properties. However, the local polynomial kernel estimators are not consistent at points where the volatility function has a break. The estimator presented in this paper generalises the classical local linear (LL). The BPLL estimator maintains the desirable properties of the LL estimator with regard to the bias and the boundary estimation while it estimates the breaks consistently. An extensive Monte Carlo study is shown as well as detailed proofs of the estimator asymptotic behaviour.","Casas, Isabel; Gijbels, Irene",2012,10.1080/10485252.2012.720981,None,wos
09d07317676ce634,Using Markov-switching models with Markov chain Monte Carlo inference methods in agricultural commodities trading,"In this work, the use of Markov-switching GARCH (MS-GARCH) models is tested in an active trading algorithm for corn and soybean future markets. By assuming that a given investor lives in a two-regime world (with low- and high-volatility time periods), a trading algorithm was simulated (from January 2000 to March 2019), which helped the investor to forecast the probability of being in the high-volatility regime att + 1. Once this probability was known, the investor could decide to invest either in commodities, during low-volatility periods or in the 3-month US Treasury bills, during high-volatility periods. Our results suggest that the Gaussian MS-GARCH model is the most appropriate to generate alpha or extra returns (from a passive investment strategy) in the corn market and thet-Student MS-GARCH is the best one for soybean trading.","De la Torre-Torres, Oscar, V; Aguilasocho-Montoya, Dora; Alvarez-Garcia, Jose; Simonetti, Biagio",2020,10.1007/s00500-019-04629-5,None,wos
061c3ab3803363ee,Using Neural Networks to Forecast Volatility for an Asset Allocation Strategy Based on the Target Volatility,"The objective of this study is to use artificial neural networks for volatility forecasting to enhance the ability of an asset allocation strategy based on the target volatility. The target volatility level is achieved by dynamically allocating between a risky asset and a risk-free cash position. However, a challenge to data-driven approaches is the limited availability of data since periods of high volatility, such as during financial crises, are relatively rare. To resolve this issue, we apply a stability-oriented approach to compare data for the current period to a past set of data for a period of low volatility, providing a much more abundant source of data for comparison. In order to explore the impact of the proposed model, the results of this approach will be compared to different volatility forecast methodologies, such as the volatility index, the historical volatility, the exponentially weighted moving average (EWMA), and the generalized autoregressive conditional heteroskedasticity (GARCH) model. Trading measures are used to evaluate the performance of the models for forecasting volatility. An empirical study of the proposed model is conducted using the Korea Composite Stock Price Index 200 (KOSPI 200) and certificate of deposit interest rates from January, 2006 to February, 2016. (C) 2016 The Authors. Published by Elsevier B.V.","Kim, Youngmin; Enke, David",2016,10.1016/j.procs.2016.09.335,None,wos
acd7831e2b54af56,Using Particle Swarm Optimization Algorithm to Calibrate the Term Structure Model,"One of the advantages of stochastic differential equations (SDE) is that they can follow a variety of different trends so that they can establish complex dynamic systems in the economic and financial fields. Although some estimation methods have been proposed to identify the unknown parameters in virtue of the results in the SDE model to speed up the process, these solutions only focus on using explicit approach to solve SDEs, and therefore they are not reliable to deal with data source merged being large and varied. Thus, this study makes progress in creating a new implicit way to fill in the gaps of accurately calibrating the unknown parameters in the SDE model. Essentially, the primary goal of the article is to generate rigid SDE simulation. Meanwhile, the particle swarm optimization method serves a purpose to search and simultaneously obtain the optimal estimation of the model unknown parameters in the complicated experiment of parameter space in an effective way. Finally, in an interest rate term structure model, it is verified that the method effectively deals with parameter estimation in the SDE model.","Zhou, Yanli; Liu, Shican; Tian, Tianhai; He, Qi; Ge, Xiangyu",2021,10.1155/2021/8893940,None,proquest
c77bf0ed0e86b54c,Using proxies for the short rate: When are three months like an instant?,"The dynamics of the unobservable short rate are frequently estimated directly using a proxy. We examine the biases resulting From this practice (the proxy problem). Analytic results show that the proxy problem is not economically significant for single-factor affine models. In the two-factor affine model of Longstaff and Schwartz (1992), the proxy problem is only economically significant for pricing discount bonds with maturities of more than five years. We also describe two different numerical procedures for assessing the magnitude of the proxy problem in a general interest rate model. When applied to a nonlinear single-factor model, they suggest that the proxy problem can be economically significant.","Chapman, DA; Long, JB; Pearson, ND",1999,10.1093/rfs/12.4.763,None,wos
4e973d99311508de,Using the yield curve to forecast economic growth,"This paper finds the yield curve to have a well-performing ability to forecast the real gross domestic product growth in the USA, compared to professional forecasters and time series models. Past studies have different arguments concerning growth lags, structural breaks, and ultimately the ability of the yield curve to forecast economic growth. This paper finds such results to be dependent on the estimation and forecasting techniques employed. By allowing various interest rates to act as explanatory variables and various window sizes for the out-of-sample forecasts, significant forecasts from many window sizes can be found. These seemingly good forecasts may face issues, including persistent forecasting errors. However, by using statistical learning algorithms, such issues can be cured to some extent. The overall result suggests, by scientifically deciding the window sizes, interest rate data, and learning algorithms, many outperforming forecasts be produced for all lags from one quarter to 3 years, although some may be worse than the others due to the irreducible noise of the data.","Yang, Parley Ruogu",2020,10.1002/for.2676,None,wos
b369ae93e8a8645c,VALUATION OF EMBEDDED OPTIONS IN NON-MARKETABLE CALLABLE BONDS: A NEW NUMERICAL APPROACH,"The issue of how to price options embedded in callable bonds has attracted a lot of interest over the years. The usual bond valuation methods rely on yield curves, risk premium, and other parameters to estimate interest rates used in discounted cash flow calculations. The option to retire the bond is, however, neglected in the standard pricing models, causing a systematic overvaluation of callable bonds. In the event of a decline in interest rates, investors are exposed to the risk of a lower return on investment than indicated by the yield to maturity. We propose a novel approach to valuing the risk that the issuer will use the right to buy back the bond at a specific call price. While prior models are focused on valuing marketable callable bonds, we deliver a unique approach to valuing bonds with an embedded European option (or a multiple option) that are traded solely through private transactions. These can typically be characterized by the lack of historical records on transaction prices. The modular character of calculation we propose allows us to take into account additional information, such as probable behaviour of the issuer, available opportunities for achieving alternative earnings or different estimates in terms of interest rate development.","Skalicky, Roman; Zinecker, Marek; Balcerzak, Adam P.; Pietrzak, Michal Bernard; Rogalska, Elzbieta",2022,10.3846/tede.2022.17060,None,wos
eaf9d6fda873b291,Value-at-Risk via mixture distributions reconsidered,"Value-at-Risk (VaR) has evolved as one of the most prominent measures of downside risk in financial markets. Zhang and Cheng [M.-H. Zhang, Q.-S. Cheng, An Approach to VaR for capital markets with Gaussian mixture, Applied Mathematics and Computation 168 (2005) 1079-1085] proposed an approach to VaR for daily returns based on Gaussian mixtures, which have become rather popular in empirical economics and finance since the seminal paper of Hamilton [J.D. Hamilton, A new approach to the economic analysis of nonstationary time series and the business cycle, Econometrica 57 (2) (1989) 357-384]. However, they do not conduct tests to assess the accuracy of the mixture-implied VaR measures. Recently, Guidolin and Timmermann [M. Guidolin, A. Timmermann, Term structure of risk under alternative econometric specifications, Journal of Econometrics, 131 (2006) 285-308] showed that Markov mixture models do well in measuring VaR at a monthly frequency, but the results may not hold for daily returns due to their more pronounced non-Gaussian features. This paper provides an extensive application of various Markov mixture models to VaR for daily returns of major European stock markets, including out-of-sample backtesting. To accommodate the properties of daily returns, we consider both Gaussian and Student's t mixtures, and we compare the performance of both uni- and multivariate models under different parameter updating schemes. We find that a univariate mixture of two Student's t distributions performs best overall. However, by the example of the recent turmoil in financial markets, we also highlight a weak point of the approach. © 2009 Elsevier Inc. All rights reserved. © 2009 Elsevier B.V., All rights reserved.","Haas, M.",2009,10.1016/j.amc.2009.08.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349981419&doi=10.1016%2Fj.amc.2009.08.005&partnerID=40&md5=37f9b7ead5757561295b093089af7ee0,scopus
cd683a7eb3f21886,Valuing GM technologies using real options: the case of drought tolerant wheat in Australia,"In this article we seek to estimate the value of a partially-developed crop technology from the perspective of the firm developing the technology. Firms need this value estimation to decide whether their technology will earn a sufficient return in the market to justify investing in it. However, determining the (ex-ante) value of the technology before it is commercialised is challenging as the technology is not yet in the market and hence the demand function has not yet been defined. An alternative valuation method is required. We use risk premiums, Monte Carlo simulation and real options analysis and we demonstrate this combination of valuation tools on wheat that is currently being developed in Australia to be drought tolerant. The results indicate that this drought tolerant wheat variety is likely to be adopted by farmers in most regions and has a pre-commercialisation value that justifies continued investment in its development. We also identified South Australia as a region in which the new variety would not be sufficiently valuable to farmers to see them adopt it and we consider possible explanations for this outcome.","Wynn, Katherine; Spangenberg, German; Smith, Kevin F; Wilson, William",2018,10.1080/09537325.2018.1474194,None,proquest
5a945e5c94a9bfc5,Valuing the Treasury's Capital Assistance Program,"T he Capital Assistance Program (CAP) was created by the U. S. government in February 2009 to provide backup capital to large financial institutions unable to raise sufficient capital from private investors. Under the terms of the CAP, a participating bank receives contingent capital by issuing preferred shares to the Treasury combined with embedded options for both parties: The bank gets the option to redeem the shares or convert them to common equity, with conversion mandatory after seven years; the Treasury earns dividends on the preferred shares and gets warrants on the bank's common equity. We develop a contingent claims framework in which to estimate market values of these CAP securities. The interaction between the competing options held by the buyer and issuer of these securities creates a game between the two parties, and our approach captures this strategic element of the joint valuation problem and clarifies the incentives it creates. We apply our method to the 18 publicly held bank holding companies that participated in the Supervisory Capital Assessment Program (the stress test) launched together with the CAP. On average, we estimate that compared to a market transaction, the CAP securities carry a net value of approximately 30% of the capital invested for a bank participating to the maximum extent allowed under the terms of the program. We also find that the net value varies widely across banks. We compare our estimates with abnormal stock price returns for the stress test banks at the time the terms of the CAP were announced; we find correlations between 0.78 and 0.85, depending on the precise choice of period and set of banks included. These results suggest that our valuation aligns with shareholder perception of the value of the program, prompting questions about industry reactions and the overall impact of the program.","Glasserman, Paul; Wang, Zhenyu",2011,10.1287/mnsc.1110.1351,None,wos
2a226e9e781cf124,Variable Selection and Oversampling in the Use of Smooth Support Vector Machines for Predicting the Default Risk of Companies,"In the era of Basel II a powerful tool for bankruptcy prognosis is vital for banks. The tool must be precise but also easily adaptable to the bank's objectives regarding the relation of false acceptances (Type I error) and false rejections (Type II error). We explore the suitability of smooth support vector machines (SSVM), and investigate how important factors such as the selection of appropriate accounting ratios (predictors), length of training period and structure of the training sample influence the precision of prediction. Moreover, we show that oversampling can be employed to control the trade-off between error types, and we compare SSVM with both logistic and discriminant analysis. Finally, we illustrate graphically how different models can be used jointly to support the decision-making process of loan officers. Copyright (C) 2008 John Wiley & Sons, Ltd.","Haerdle, Wolfgang; Lee, Yuh-Jye; Schaefer, Dorothea; Yeh, Yi-Ren",2009,10.1002/for.1109,None,wos
8ac774f2ab9a9ab4,Volatility Expectations and Returns,"We provide evidence that agents have slow-moving beliefs about stock market volatility that lead to initial underreaction to volatility shocks followed by delayed overreaction. These dynamics are mirrored in the VIX and variance risk premiums, which reflect investor expectations about volatility, and are also supported in both surveys and firm-level option prices. We embed these expectations into an asset pricing model and find that the model can account for a number of stylized facts about market returns and return volatility that are difficult to reconcile, including a weak or even negative risk-return trade-off.","Lochstoer, Lars A.; Muir, Tyler",2022,10.1111/jofi.13120,None,wos
f0282a2efcf8a584,Volatility forecasts embedded in the prices of crude-oil options,"This paper evaluates the ability of alternative option-implied volatility measures to forecast crude-oil return volatility. We find that a corridor implied volatility measure that aggregates information from a narrow range of option contracts consistently outperforms forecasts obtained by the popular Black-Scholes and model-free volatility expectations, as well as those generated by a realized volatility model. This measure ranks favorably in regression-based tests, delivers the lowest forecast errors under different loss functions, and generates economically significant gains in volatility timing exercises. Our results also show that the Chicago Board Options Exchange's oil-VIX index performs poorly, as it routinely produces the least accurate forecasts.","Gilder, Dudley; Tsiaras, Leonidas",2020,10.1002/fut.22114,None,wos
339ab8be530e9be4,Volatility in equity markets and monetary policy rate uncertainty,"Asset pricing models assume the risk-free rate to be a key factor for equity prices. Hence, there should be a strong link between monetary policy rate uncertainty and equity return volatility, both in theory and data. This paper uses regression-based projections for realized variance to examine the relationship between short horizon forecasts of equity variance and proxies for monetary policy rate uncertainty. By assessing various projection models for UK, US and euro area equity indices, we show that the proxies for monetary policy rate uncertainty have a significant and positive predictive power for the equity return variance. Adding monetary policy rate uncertainty variables can significantly improve forecasting models for equity variance and volatility at weekly, monthly and even quarterly horizons. The findings imply that market views of short-term interest rate developments may indeed be embedded in equity prices and their variations. (C) 2017 The Bank of England. Published by Elsevier B.V. All rights reserved.","Kaminska, Iryna; Roberts-Sklar, Matt",2018,10.1016/j.jempfin.2017.09.008,None,wos
2212fd81e8d3b6aa,Volatility measures and Value-at-Risk,"We evaluate and compare the abilities of the implied volatility and historical volatility models to provide accurate Value-at-Risk forecasts. Our empirical tests on the S&P 500, Dow Jones Industrial Average and Nasdaq 100 indices over long time series of more than 20 years of daily data indicate that an implied volatility based Value-at-Risk cannot beat, and tends to be outperformed by, a simple GJR-GARCH based Value-at-Risk. This finding is robust to the use of the likelihood ratio, the dynamic quantile test or a statistical loss function for evaluating the Value-at-Risk performance.The poor performance of the option based Value-at-Risk is due to the volatility risk premium embedded in implied volatilities. We apply both non-parametric and parametric adjustments to correct for the negative price of the volatility risk. However, although this adjustment is effective in reducing the bias, it still does not allow the implied volatility to outperform the historical volatility models.These results are in contrast to the volatility forecasting literature, which favors implied volatilities over the historical volatility model. We show that forecasting the volatility and forecasting a quantile of the return distribution are two different objectives. While the implied volatility is useful for the earlier objective function, it is not for the latter, due to the non-linear and regime changing dynamics of the volatility risk premium. (C) 2017 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.","Bams, Dennis; Blanchard, Gildas; Lehnert, Thorsten",2017,10.1016/j.ijforecast.2017.04.004,None,wos
40ca5d0204bc68fe,War discourse and global equity returns,"This study investigates the asset pricing implications of war risks in global stock markets. We employ a novel war discourse index developed by Hirshleifer et al. (2023a), which captures market attention to war through news. Extending this approach to both developed and emerging markets, we uncover a significantly positive relation between war risks and global stock market excess returns, which is robust to a range of sensitivity checks. Our findings indicate that investor attention to war risks significantly influences equity premium in global markets. © 2024 Elsevier B.V., All rights reserved.","Wang, J.; Fang, Y.; Hu, X.; Zhong, A.",2024,10.1016/j.frl.2024.106068,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203652926&doi=10.1016%2Fj.frl.2024.106068&partnerID=40&md5=5190fb5a9dcd24cdbbd57eb075a3d053,scopus
e0ffccbdf271686e,Wasserstein barycenter regression for estimating the joint dynamics of renewable and fossil fuel energy indices,"In order to characterize non-linear system dynamics and to generate term structures of joint distributions, we propose a flexible and multidimensional approach, which exploits Wasserstein barycentric coordinates for histograms. We apply this methodology to study the relationships between the performance in the European market of the renewable energy sector and that of the fossil fuel energy one. Our methodology allows us to estimate the term structure of conditional joint distributions. This optimal barycentric interpolation can be interpreted as a posterior version of the joint distribution with respect to the prior contained in the past histograms history. Once the underlying dynamics mechanism among the set of variables are obtained as optimal Wasserstein barycentric coordinates, the learned dynamic rules can be used to generate term structures of joint distributions.","De Giuli, Maria Elena; Spelta, Alessandro",2023,10.1007/s10287-023-00436-4,None,proquest
cf31fbaecc9e1908,Wavelet Neural Network Model for Yield Spread Forecasting,"In this study, a hybrid method based on coupling discrete wavelet transforms (DWTs) and artificial neural network (ANN) for yield spread forecasting is proposed. The discrete wavelet transform (DWT) using five different wavelet families is applied to decompose the five different yield spreads constructed at shorter end, longer end, and policy relevant area of the yield curve to eliminate noise from them. The wavelet coefficients are then used as inputs into Levenberg-Marquardt (LM) ANN models to forecast the predictive power of each of these spreads for output growth. We find that the yield spreads constructed at the shorter end and policy relevant areas of the yield curve have a better predictive power to forecast the output growth, whereas the yield spreads, which are constructed at the longer end of the yield curve do not seem to have predictive information for output growth. These results provide the robustness to the earlier results.","Firdous Ahmad Shah; Debnath, Lokenath",2017,10.3390/math5040072,None,proquest
23076aa06e8f8d36,Weight of the Default Component of CDS Spreads: Avoiding Procyclicality in Credit Loss Provisioning Framework,"The current expected loss calculations have recently attracted considerable attention in the research on credit risk modeling, impairment provisioning, and financial networks’ stability. A new CDS-based approach to estimate current expected credit loss is proposed for low default portfolios, containing credit exposures to corporate issuers covered by publicly traded CDS contracts. First, a fraction of CDS spread related to a pure default compensation for different CDS maturities is assessed. Our results contrast with previous research. Second, based on the obtained historical weights of the default risk premium, a forward-looking term structure of the probabilities of default implied by the current CDS quotes is derived. The proposed approach covers both investment and noninvestment grade debt. The resulting framework is applied to a sample of corporate bonds. The developed methodology provides a useful tool, on one hand, for credit risk managers and balance-sheet preparers and, on the other hand, for regulators of financial markets as it sheds light on how procyclicality could be avoided in provisions.","Gubareva, Mariya",2019,10.1155/2019/7820618,None,proquest
5e5d1d9ac9087b48,What Does the Individual Option Volatility Smirk Tell Us About Future Equity Returns?,"The shape of the volatility smirk has significant cross-sectional predictive power for future equity returns. Stocks exhibiting the steepest smirks in their traded options underperform stocks with the least pronounced volatility smirks in their options by 10.9% per year on a risk-adjusted basis. This predictability persists for at least 6 months, and firms with the steepest volatility smirks are those experiencing the worst earnings shocks in the following quarter. The results are consistent with the notion that informed traders with negative news prefer to trade out-of-the-money put options, and that the equity market is slow in incorporating the information embedded in volatility smirks.","Xing, Yuhang; Zhang, Xiaoyan; Zhao, Rui",2010,10.1017/s0022109010000220,None,wos
ec360be29d8293a3,What Drives Short Rate Dynamics? A Functional Gradient Descent Approach,"Functional gradient descent (FGD), a recent technique coming from computational statistics, is applied to the estimation of the conditional moments of the short rate process with the goal of finding the main drivers of the drift and volatility dynamics. FGD can improve the accuracy of some reasonable starting estimates obtained using classical short rate models introduced in the literature. It exploits the predictive information of an enlarged set of variables, including yields at other maturities, time, and macroeconomic indicators. Fitting this methodology to the time series of monthly US 3-month Treasury bill rates, we find that the drift dynamics react mostly in a nonlinear way to changes in macroeconomic variables, whereas volatility dynamics are subjected to time-dependent regime-switches. Finally we show the superior performance of the final predictions obtained by applying FGD in a forecasting exercise.","Audrino, Francesco",2012,10.1007/s10614-011-9310-y,None,wos
960e01a37822bb97,What is the Effect of Restrictions Imposed by Principal Components Analysis on the Empirical Performance of Dynamic Term Structure Models?,"This paper investigates the effect of restrictions imposed by principal components analysis (PCA) on the empirical performance of dynamic term structure models (DTSM). The application of PCA maximizes the explained variance of a linear combination of bond yields by selecting weights that are as uncorrelated as possible. In the context of factor construction, this choice of weights imposes orthogonality on the state variable bringing about restrictions on model estimation. We quantify the effect of these restrictions, measured through internal consistency equations, on the empirical performance of DTSM contained within linear-affine and linear-quadratic state space formulations (SSF) characterized by Gaussian and non-Gaussian transition dynamics for the state variable. When looking across DTSM, we find the smallest effect of restrictions imposed by PCA on empirical performance when it is used in the context of a linear-affine SSF, and the state transition dynamics are postulated based upon the conditional mean and variance. We also document that the magnitude of this effect is more pronounced when the probability distribution for the data is described by the first four moments relative to just the first two and the parameter dependencies defining the relationship between bond yields and factors are more analytically or computationally complicated (e.g., involves a special function like the Bessel function or cumbersome algebraic manipulations). Suggestions for future research are provided. © 2025 Elsevier B.V., All rights reserved.","Juneja, J.",2025,10.1007/s10614-024-10644-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003372195&doi=10.1007%2Fs10614-024-10644-y&partnerID=40&md5=62f9386a35827a9677596c284837a0a1,scopus
d534573971c63b10,"What the current yield curve says, and what the future prices of energy do","Y Policymakers have always looked at the difference between the yields on long- and short-term Treasury securities as an indication of where the economy is heading. In this study, we extend the literature by examining the yield curve's ability to predict the short-term prices of crude oil and other energy products. Using linear and non-linear (parametric quantile) causality tests on daily data from 1986 to February 2020, our findings confirm that changes in the yield spread not only correlate with, but also drive the returns on crude oil, heating oil and natural gas in the short run. This short-run relationship is relatively absent from 1986 to 2003. However, since 2004, the relationship has remained quite strong, confirming that these products have been financialized. Market participants and policy makers may find our findings useful in understanding the nature of relationship between the shape of the term structure and future innovations in energy prices.","Idilbi-Bayaa, Yasmeen; Qadan, Mahmoud",2022,10.1016/j.resourpol.2021.102494,None,wos
be1da456434c76af,When there is no place to hide: Correlation risk and the cross-section of hedge fund returns,"Using a novel data set on correlation swaps, we study the relation between correlation risk, hedge fund characteristics, and their risk-return profile. We find that the ability of hedge funds to create market-neutral returns is often associated with a significant exposure to correlation risk, which helps to explain the large abnormal returns found in previous models. We also estimate a significant negative market price of correlation risk, which accounts for the cross-section of hedge fund excess returns. Finally, we detect a pronounced nonlinear relation between correlation risk exposure and the tail risk of hedge fund returns. © 2013 The Author 2013. Published by Oxford University Press on behalf of The Society for Financial Studies. All rights reserved. © 2019 Elsevier B.V., All rights reserved.","Buraschi, A.; Kosowski, R.; Trojani, F.",2014,10.1093/rfs/hht070,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892709151&doi=10.1093%2Frfs%2Fhht070&partnerID=40&md5=3a788d460fa87cfbf5f6abca17b1e105,scopus
e8e54ffb300f3e5d,"Which exogenous driver is informative in forecasting European carbon volatility: Bond, commodity, stock or uncertainty?","This study relies on 45 exogenous drivers to improve the accuracy in forecasting EUA volatility. Several popular linear and nonlinear predictive regressions, including individual factor analysis, the combination forecast method, the diffusion index model and the supervised learning method, are used to generate volatility forecasts at the monthly frequency. Our empirical results reveal that the diffusion index model and combination forecast method can hardly drive the EUA volatility in a data-rich world owing to worse forecasting performance of individual factors; however, the supervised learning method can successfully predict the EUA volatility. Additionally, the WilderHill new energy global innovation index, Euro corporate bond return spread, GSCI gold index and Euro Area government bond yield spread can extremely drive EUA volatility in terms of individual factor analysis, frequency of variable selection and factor importance. Our findings provide crucial implications to market participants and emission companies, who should pay more attention to the price movement of European bond market, gold and clean energy. © 2023 Elsevier B.V., All rights reserved.","Wang, J.; Guo, X.; Tan, X.; Chevallier, J.; Ma, F.",2023,10.1016/j.eneco.2022.106419,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143371148&doi=10.1016%2Fj.eneco.2022.106419&partnerID=40&md5=a98b91635a2961bde62e843cfeb069b3,scopus
1e13e1a829d5e1b8,Who Values Economist Forecasts? Evidence From Trading in Treasury Markets,"While economic forecasting is ubiquitous within the industry, its role in the trading process has received little attention in the literature. We examine how economist forecasts are related to trading activity in the OTC treasury bond market at the participant level. Consistent with models of heterogeneous opinions, we show that the forecasting economists employing institution places a disproportionately large reliance on the forecast. There is pervasive evidence that this reliance is asymmetric. Only forecasts which imply a fall in future treasury bond prices are associated with an abnormal trading reaction consistent with the forecast. Reference dependence and loss aversion offer one possible explanation for this asymmetric trading response. © 2021 Elsevier B.V., All rights reserved.","James, R.; Jarnecic, E.; Leung, H.",2022,10.1016/j.jfi.2021.100934,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117369955&doi=10.1016%2Fj.jfi.2021.100934&partnerID=40&md5=71ce8126b166106e851aa13340ffe07d,scopus
b79a2c7acc268fae,Wiener chaos expansion and numerical solutions of the Heath–Jarrow–Morton interest rate model,"In this paper, we propose and analyze a simple and fast numerical method for the solution of the stochastic Heath–Jarrow–Morton (HJM) interest rate model under the Musiela parameterization, based on theWiener chaos expansion (WCE). Through the proposed method, the infinite-dimensional HJM equation is approximated by a finite system of partial differential equations (PDEs), which can be addressed by standard techniques. To illustrate the general construction, we approximate the value of the US treasury bond in an HJM framework, and the results are compared with those derived by the Monte Carlo method and the ensemble Kalman filter. The proposed method is computationally efficient compared with the standard techniques, and it provides a convenient way to compute the statistical moments of the solution numerically. Numerical results and useful formulas for estimating the stochastic duration and immunization are presented. © 2017 Elsevier B.V., All rights reserved.","Kalpinelli, E.A.; Frangos, N.E.; Yannacopoulos, A.",2016,10.21314/jcf.2016.211,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973596637&doi=10.21314%2FJCF.2016.211&partnerID=40&md5=e9ecc7c14a8535386c2c97a43a8082bc,scopus
e4b77867f689035a,Would an earlier inception of OMT by the ECB have prevented the 2012 Greek default?,"To avert further debt crises following the Greek default of 2012, the European Central Bank (ECB) adopted outright purchases of sovereign bonds as part of its monetary policy regime. This paper examines whether an earlier inception of such purchases (OMT) could have prevented the observed Greek repudiation. To account for the extraordinary circumstances surrounding the Greek default, I construct a novel model of sovereign finance in which default is political and investors’ reliance on external credit ratings gives rise to slow moving crises. Estimating the model with Greek data, I find that an earlier inception of OMT plausibly could have prevented the observed default, but the resulting counterfactual Greek state would have been so fragile that, absent any further fiscal consolidation, eventual default was effectively inevitable. Moreover, the present Greek state remains sufficiently fragile that a quick return to a predominantly private financing scheme is not advisable. © 2025 Elsevier B.V., All rights reserved.","Mäder, N.",2025,10.1016/j.iref.2025.104356,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012113857&doi=10.1016%2Fj.iref.2025.104356&partnerID=40&md5=a0410bf8f90a8a60f3cb411b27d80bd5,scopus
4c58711a707af646,Yield Curve Estimation Based on Government Security Prices in the Croatian Financial Market,"This article investigates the estimation of the yield curve based on government security prices using the Nelson-Siegel model in the Croatian financial market. The yield curve was estimated for samples of government securities with and without currency clauses. Since the Croatian financial market is less developed characterized by limited trading activity in government bonds, Treasury bills were also included in the analysis. To examine the difference in the estimation of yield curve parameters between a less developed and a developed market, the U.S. sample was considered. The yield curve was estimated for the full US sample and for artificially created U.S. samples corresponding to the Croatian samples of government bonds with and without currency clauses. Despite the less developed Croatian financial market, it is possible to estimate the yield curve and derive meaningful economic interpretations from the estimates.","Orlovic, Zrinka; Zoricic, Davor; Golubic, Zrinka Lovretin",2024,10.2478/zireb-2024-0016,None,wos
190ed5fb32b9d0d7,Yield Curve Modeling: Applicability of the Traditional Factor Models for Sri Lanka Government Bonds,"The main aim of this study is to evaluate the effectiveness of two widely discussed yield curve models, the Nelson-Siegel model and the Nelson-Siegel-Svensson model, in estimating Sri Lanka Government Bond yields. The parameters for both models were estimated using the YieldCurve package in R-Studio. The average R-squared values were 96.25% for the Nelson-Siegel model and 98.75% for the Nelson-Siegel-Svensson model. However, neither model consistently achieved high R-squared values across the entire sample period. The Nelson-Siegel-Svensson model demonstrated greater consistency in R-squared values compared to the Nelson-Siegel model throughout the period. But the R-squared value declined in 2022 compared with the previous period for both models as the yield curve accompanied more twists and turns with volatile economic conditions. These results suggest that there is significant potential for developing more representative yield curve models or enhancing existing models by incorporating additional influential factors. The monetary authorities and Investment banks of the country would pay more attention to data-driven decision-making in the future to set up economic and monetary targets as well as to achieve hurdle rates for the client’s portfolios. Having an accurate yield curve model would be a play major role in this regard. © 2025 Elsevier B.V., All rights reserved.","Dayarathne, K.P.N.S.; Thayasivam, U.",2025,10.1007/s42979-025-04075-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008883628&doi=10.1007%2Fs42979-025-04075-1&partnerID=40&md5=bfd2bb858b8bff203220d422f64d79a5,scopus
4feca7e995018566,Yield Curve Point Triplets in Recession Forecasting,"Several studies have highlighted the yield curve's ability to forecast economic activity. These studies use the information provided by the slope of the yield curve-i.e., pairs of short- and long-term interest rates. In this paper, we construct three models for forecasting the positive and negative deviations of real US GDP from its long-run trend over the period from 1976Q3 to 2011Q4: one that uses only pairs of interest rates and two that draw on more than two points from the yield curve. We employ two alternative forecasting methodologies: the probit model, which is commonly used in this line of literature, and the support vector machines (SVM) approach from the area of machine learning. Our results show that we can achieve a 100% out-of-sample forecasting accuracy for negative output gaps (recessions) with both methodologies and an overall accuracy (both inflationary and unemployment gaps) of 80% in the case of the best SVM model. The forecasting performance of our model strengthens the existing evidence that the yield curve can be a useful tool for gauging future economic activity. © 2021 Elsevier B.V., All rights reserved.","Gogas, P.; Papadimitriou, T.; Chrysanthidou, E.",2015,10.1111/infi.12067,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940045257&doi=10.1111%2Finfi.12067&partnerID=40&md5=9fac416464a2ce0a8f7fa26d4a7513a9,scopus
416e57a3c9d256bd,Yield Spread and Economic Policy Uncertainty: Evidence from Japan,"In this paper, we adopt the nonlinear autoregressive distributed lags (NARDL) model extended by Shin et al. (2014) to investigate the relationship between the treasury yield spread and economic policy uncertainty (EPU) in Japan. This model helps us to explore the short- and long-run asymmetric reactions of explained variables through positive and negative partial sum decompositions of changes in the explanatory variable(s). In our research, the testing of the NARDL specification reveals the existence of a significant long-run asymmetric equilibrium between the yield spread and EPU in Japan. On the other hand, we find a significant positive nexus between the treasury yield spread and EPU reduction in the long run. We speculate that because of low inflation, a poor economic outlook and the low interest rate environment since 1990, financial agents are markedly sensitive to negative shocks resulting from EPU. This means that when facing a good economy, bond agents are quick to sell, especially with higher-risk long-term interest rate bonds. Meanwhile, because the Bank of Japan announced the Stock Purchasing Plan in October 2002 and from the point view of portfolio management, while the influence of a positive economic outlook dominates the negative outlook, flight from quality has no role in asset portfolio adjustment. The empirical implications are that the long history of unconventional monetary policy supports the demand for both bonds and stock markets. When taking the stock market into consideration, the correlations between the yield spread, EPU and stock market capture the full wealth effects of the low interest rate environment in Japan.","Wang, Mei-Chih; Kuo, Pao-Lan; Chen, Chan-Sheng; Chiu, Chien-Liang; Chang, Tsangyao",2020,10.3390/su12104302,None,wos
3ee28f55a1667475,Yield curve and recession forecasting in a machine learning framework,"In this paper, we investigate the forecasting ability of the yield curve in terms of the U.S. real GDP cycle. More specifically, within a Machine Learning framework, we use data from a variety of short (treasury bills) and long term interest rates (bonds) for the period from 1976:Q3 to 2011:Q4 in conjunction with the real GDP for the same period, to create a model that can successfully forecast output fluctuations (inflation and output gaps) around its long-run trend. We focus our attention in correctly forecasting the instances of output gaps referred for the purposes of our analysis here as recessions. In this effort, we applied a Support Vector Machines technique for classification. The results show that we can achieve an overall forecasting accuracy of 66.7 and 100_% accuracy in forecasting recessions. These results are compared to the alternative standard logit and probit model, to provide further evidence about the significance of our original model. Reprinted by permission of Springer","Gogas, Periklis; Papadimitriou, Theophilos; Matthaiou, Maria; Chrysanthidou, Efthymia",2015,10.1007/s10614-014-9432-0,None,proquest
7aed82193826f66e,Yield curve estimation of the nelson-siegel class model by using hybrid method with L-BFGS-B iterations approach,"This paper discussed about model extension in determines the yield curve. Determine of yield curve using Nelson-Siegel class model. This class model consisting of: 3-factor model, 4-factor model, the 5-factor model, and 6-factor model. 6-factor model is a model extended from 5-factor models. The extension aims to increase the level of accuracy in determine the yield curve. Nelson-Siegel class model is model that more difficult to estimate because it has two shape the parameters, i.e. the linear and nonlinear parameters. Extension of this model is done by adding the fourth hump into 5-factor model. In addition, we obtain new model, this model have local minimum multiple so that it is more difficult to be estimated. To estimate this model, we propose estimation using a hybrid method. Hybrid method is combines method of estimation the nonlinear least squares with constrained optimization, and then continued with L-BFGS-B iteration approach. Estimation of the class model was done by full estimation, i.e. estimating the linear parameters and nonlinear parameters simultaneously. Then, we calculated MSE, AIC, and BIC. The purpose of calculating this component is to determine the best of model. The best model obtainable if the models have component value which is smaller than the other models. This paper uses data from Indonesian government bonds. Based on data processing, we obtained the best model i.e. 6- factors model. © 2015 Elsevier B.V., All rights reserved.","Muslim; Rosadi, D.; Gunardi, G.; Abdurakhman, n.",2015,10.12988/ams.2015.43209,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929934326&doi=10.12988%2Fams.2015.43209&partnerID=40&md5=68f1e179c410a82458ca47a5b40c3e7f,scopus
ab0c1b13706fa110,Yield curve extrapolation with machine learning,"Yield curve extrapolation to unobservable tenors is a key technique for the market-consistent valuation of actuarial liabilities required by Solvency II and forthcoming similar regulations. Since the regulatory method, the Smith-Wilson method, is inconsistent with observable yield curve dynamics, parsimonious parametric models, the Nelson-Siegel model and its extensions, are often used for yield curve extrapolation in risk management. However, it is difficult for the parsimonious parametric models to extrapolate yield curves without excessive volatility because of their limited ability to represent observed yield curves with a limited number of parameters. To extend the representational capabilities, we propose a novel yield curve extrapolation method using machine learning. Using the long short-term memory architecture, we achieve purely data-driven yield curve extrapolation with better generalization performance, stability, and consistency with observed yield curve dynamics than the previous parsimonious parametric models on US and Japanese yield curve data. In addition, our method has model interpretability using the backpropagation algorithm. The findings of this study prove that neural networks, which have recently received considerable attention in mortality forecasting, are useful for yield curve extrapolation, where they have not been used before. © 2025 Elsevier B.V., All rights reserved.","Akiyama, S.; Matsuyama, N.",2025,10.1017/asb.2024.27,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210168150&doi=10.1017%2Fasb.2024.27&partnerID=40&md5=5439066d1de45cd8165ba925b1874d67,scopus
ce017e4020d255a3,Yield curve in an estimated nonlinear macro model,"This paper estimates a sticky price macro model with US macro and term structure data using Bayesian methods. The model is solved by a nonlinear method. The posterior distribution of the parameters in the model is found to be bi-modal. The degree of nominal rigidity is high at one mode (''sticky price mode'') but is low at the other mode (''flexible price mode''). I find that the degree of nominal rigidity is important for identifying macro shocks that affect the yield curve. When prices are more flexible, a slowly varying inflation target of the central bank is the main driver of the overall level of the yield curve by changing long-run inflation expectations. In contrast, when prices are more sticky, a highly persistent markup shock is the main driver. The posterior probability of each mode is sensitive to the use of observed proxies for inflation expectations. Ignoring additional information from survey data on inflation expectations significantly reduces the posterior probability of the flexible price mode. Incorporating this additional information suggests that yield curve fluctuations can be better understood by focusing on the flexible price mode. Considering nonlinearities of the model solution also increases the posterior probability of the flexible price mode, although to a lesser degree than using survey data information. All rights reserved, Elsevier",None,2011,10.1016/j.jedc.2011.03.003,None,proquest
40d5957f898788bd,ZONE-TARGETING MONETARY POLICY PREFERENCES AND FINANCIAL MARKET CONDITIONS: A FLEXIBLE NON-LINEAR POLICY REACTION FUNCTION OF THE SARB MONETARY POLICY,"We estimate a flexible model of the monetary policy reaction function of the South African Reserve Bank based on a representation of the policymaker's preferences that capture asymmetries and zone-targeting behaviours. We augment the analysis to allow for responses to financial market conditions over and above inflation and output stabilisation to address the current debate on the importance of financial asset prices in monetary policy decision making. The empirical results show that the monetary authorities' response to inflation is zone symmetric. Secondly, the monetary authorities' response to output is asymmetric with increased reaction during business cycle downturns relative to upturns. Thirdly, the monetary authorities pay close attention to the financial conditions index by placing an equal weight on financial market booms and recessions.","Naraidoo, Ruthira; Raputsoane, Leroi",2010,10.1111/j.1813-6982.2010.01256.x,None,wos
a54f7ef7d1224564,“Intelligent” finance and treasury management: what we can expect,"Artificial intelligence poses a particular challenge in its application to finance/treasury management because most treasury functions are no longer physical processes, but rather virtual processes that are increasingly highly automated. Most finance/treasury teams are knowledge workers who make decisions and conduct analytics within often dynamic frameworks that must incorporate environmental considerations (foreign exchange rates, GDP forecasts), internal considerations (growth needs, business trends), as well as the impact of any actions on related corporate decisions which are also highly complex (e.g., hedging, investing, capital structure, liquidity levels). Artificial intelligence in finance and treasury is thus most analogous to the complexity of a human nervous system as it encompasses far more than the automation of tasks. Similar to the human nervous system, AI systems in finance/treasury must manage data quickly and accurately, including the capture and classification of data and its integration into larger datasets. At present, the AI network neural system has been gradually improved and is widely used in many fields of treasury management, such as early warning of potential financial crisis, diagnosis of financial risk, control of financial information data quality and mining of hidden financial data, information, etc.","Polak Petr; Nelischer Christof; Guo Haochen; Robertson, David C",2020,10.1007/s00146-019-00919-6,None,proquest
