"Title","Subtitle","Author","Publication","SourceType","Publisher","Volume","Issue","PubDate","AlphaDate","StartPage","EndPage","PageRange","ISSN","EISSN","ISBN","Language","Abstract","DocumentUrl","DOI"
"Constant Proportion Portfolio Insurance Strategy in Southeast European Markets","","Agic-Sabeta, Elma","Business Systems Research","Scholarly Journals","","7","1","2016-03-01","2016","59","","59-80","18478344","","","ENG","Background: In today's highly volatile and unpredictable market conditions, there are very few investment strategies that may offer a certain form of capital protection. The concept of portfolio insurance strategies presents an attractive investment opportunity.Objectives: The main objective of this article is to test the use of portfolio insurance strategies in Southeast European (SEE) markets. A special attention is given to modelling non-risky assets of the portfolio.Methods/Approach: Monte Carlo simulations are used to test the buy-and-hold, the constant-mix, and the constant proportion portfolio insurance (CPPI) investment strategies. A covariance discretization method is used for parameter estimation of bond returns.Results: According to the risk-adjusted return, a conservative constant mix was the best, the buy-and-hold was the second-best, and the CPPI the worst strategy in bull markets. In bear markets, the CPPI was the best in a high-volatility scenario, whereas the buy-and-hold had the same results in low- and medium-volatility conditions. In no-trend markets, the buy-and-hold was the first, the constant mix the second, and the CPPI the worst strategy. Higher transaction costs in SEE influence the efficiency of the CPPI strategy.Conclusions: Implementing the CPPI strategy in SEE could be done by combining stock markets from the region with government bond markets from Germany due to a lack of liquidity of the government bond market in SEE.","https://www.proquest.com/docview/1819266075?accountid=12870&bdid=124553&_bd=eQfMFn%2B7JwLEI8%2FTg7ujfEJ9b7o%3D","https://doi.org/10.1515/bsrj-2016-0005"
"Forecasting market trends with neural networks","","Aiken, Milam; Bsat, Mohammad","Information Systems Management","Scholarly Journals","","16","4","1999-10-01","Fall 1999","42","","42-48","10580530","","","ENG","Neural networks are just one of the many technologies that are giving businesses a competitive edge.  Neural networks (NN) are a branch of artificial intelligence which has generated considerable interest across many disciplines during the past few years.  An NN is a nonlinear type of model which receives its inspiration from the neural architecture of the human brain.  Three sample neural networks are presented:  1.  real estate assessment, 2.  credit application evaluation, and 3.  Treasury Bill rate forecasting.","https://www.proquest.com/docview/214123586?accountid=12870&bdid=124553&_bd=v4KeDMRTyNqFqga04Z000S9c7aI%3D",""
"The economic value of advanced time series methods for modelling and trading 10-year government bonds","","Dunis, Christian L; Morrison, Vincent","European journal of finance","Undefined","","13","3-4","2007-04-01","Apr 2007","333","352","333-352","1351-847X","1351-847X","","ENG","The motivation for this paper is to determine the potential economic value of advanced modelling methods for devising trading decision tools for 10-year Government bonds. Two advanced methods are used: time-varying parameter models with the implementation of state space modelling using a Kalman filter and nonparametric nonlinear models with Neural Network Regression (NNR). These are benchmarked against more traditional forecasting techniques to ascertain their potential as a forecasting tool and their economic value as a base for a trading decision tool. The models were developed using data from the UK Gilt market, US T-Bond market and German Bund market. Using in-sample data from April 2001 to January 2003 to develop the models, their results were assessed using the out-of-sample period of January 2003 to June 2003. Performance evaluation was based upon forecasting accuracy measures and financial criteria using a simulated trading strategy incorporating realistic trading costs. It is concluded that for the time series studied and for the period under investigation, the performance of the advanced models is mixed. While the NNR models have the ability to forecast the 10-year Government bond yield and add economic value as a trading decision tool, the Kalman filter models' performance is not as conclusive. The Kalman filter models outperformed the traditional techniques using forecasting accuracy measures, however they did not perform as well in the simulated trading strategy. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/36799248?accountid=12870&bdid=124553&_bd=p%2ByQkVUWzbUEmdOXRcV%2FqyXzC0w%3D","https://doi.org/10.1080/13518470600880010"
"Forecasting the stock risk premium: A new statistical constraint","","Hao, Xianfeng; Wang, Yudong","Journal of Forecasting","Scholarly Journals","","42","7","2023-11-01","Nov 2023","1805","1822","1805-1822","02776693","","","ENG","We develop a new statistical constraint to improve the stock return forecasting performance of predictive models. This constraint uses a new objective function that combines the Huber loss function with the Ridge penalty. Out‐of‐sample results indicate that our constraint improves the predictive ability of the univariate models. The constrained univariate models significantly outperform the historical average benchmark model assuming no predictability. The forecast improvement based on the new constraint is also evident for multivariate information methods including forecast combination and diffusion index. The model is capable of capturing time‐varying risk which serves as the potential economic explanation of the improved return predictability. Our results are robust to different evaluation subsamples, validation sample lengths, and different risk aversion coefficients.","https://www.proquest.com/docview/2870820629?accountid=12870&bdid=124553&_bd=58aNYdjIX6dwNR3kfeMxiEICgmw%3D","https://doi.org/10.1002/for.2984"
"The Economic Value of Advanced Time Series Methods for Modelling and Trading 10-year Government Bonds","","Dunis, Christian L; Morrison, Vincent","The European Journal of Finance","Scholarly Journals","","13","4","2007-06-01","Jun 2007","333","","","1351847X","","","ENG","The motivation for this paper is to determine the potential economic value of advanced modelling methods for devising trading decision tools for 10-year Government bonds. Two advanced methods are used: time-varying parameter models with the implementation of state space modelling using a Kalman filter and nonparametric nonlinear models with Neural Network Regression (NNR). These are benchmarked against more traditional forecasting techniques to ascertain their potential as a forecasting tool and their economic value as a base for a trading decision tool. The models were developed using data from the UK Gilt market, US T-Bond market and German Bund market. Using in-sample data from April 2001 to January 2003 to develop the models, their results were assessed using the out-of-sample period of January 2003 to June 2003. Performance evaluation was based upon forecasting accuracy measures and financial criteria using a simulated trading strategy incorporating realistic trading costs. It is concluded that for the time series studied and for the period under investigation, the performance of the advanced models is mixed. While the NNR models have the ability to forecast the 10-year Government bond yield and add economic value as a trading decision tool, the Kalman filter models' performance is not as conclusive. The Kalman filter models outperformed the traditional techniques using forecasting accuracy measures, however they did not perform as well in the simulated trading strategy. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/215875801?accountid=12870&bdid=124553&_bd=DoVoVjurbWv1zOupEljQy9KACoM%3D",""
"Option-Based Estimation of the Price of Coskewness and Cokurtosis Risk","","Fournier, Mathieu; Jacobs, Kris; Karoui, Mehdi; Christoffersen, Peter","Journal of Financial and Quantitative Analysis","Scholarly Journals","","56","1","2021-02-01","Feb 2021","65","","","00221090","","","ENG","We show that the prices of risk for factors that are nonlinear in the market return can be obtained using index option prices. The price of coskewness risk corresponds to the market variance risk premium, and the price of cokurtosis risk corresponds to the market skewness risk premium. Option-based estimates of the prices of risk lead to reasonable values of the associated risk premia. An analysis of factor models with coskewness risk indicates that the new estimates of the price of risk improve the models' performance compared with regression-based estimates.","https://www.proquest.com/docview/2485545127?accountid=12870&bdid=124553&_bd=FdDIGac0qLa7A%2FIso%2F743WcN9Po%3D","https://doi.org/10.1017/S002210902000023X"
"Condition Prediction for Existing Educational Facilities Using Artificial Neural Networks and Regression Analysis","","Hassan, Ahmed M; Hassan, Ahmed M; Kareem Adel; Elhakeem, Ahmed; Elmasry, Mohamed I S","Buildings","Scholarly Journals","","12","10","2022-01-01","2022","1520","","","20755309","","","ENG","Infrastructural assets such as roads, bridges, and buildings make a considerable contribution to national economies. These assets deteriorate due to aging, environmental conditions, and other external factors. Maintaining the performance of an asset in line with rational repair strategies represents a considerable challenge for decision-makers, who may not pay attention to developing adequate maintenance plans or leave the assets unmaintained. Worldwide, organizations are under pressure to ensure the sustainability of their assets. Such organizations may burden their treasury with random maintenance operations, especially with a limited budget. This research aims to develop a generalized condition assessment approach to monitor and evaluate existing facility elements. The proposed approach represents a methodology to determine the element condition index (CI). The methodology is reinforced with an artificial neural network (ANN) model to predict the element deterioration. The performance of this model was evaluated by comparing the obtained predicted CIs with ordinary least squares (OLS) regression model results to choose the most accurate prediction technique. A case study was applied to a group of wooden doors. The ANN model showed reliable results with R2 values of 0.99, 0.98, and 0.99 for training, cross-validation, and testing sets, respectively. In contrast, the OLS model R2 value was 1.00. These results show the high prediction capability of both models with an advantage to the OLS model. Applying this approach to different elements can help decision-makers develop a preventive maintenance schedule and provide the necessary funds.","https://www.proquest.com/docview/2728448434?accountid=12870&bdid=124553&_bd=4%2FXzNOifA1M1M0iZ1pei73D3Qvk%3D","https://doi.org/10.3390/buildings12101520"
"Wavelet Neural Network Model for Yield Spread Forecasting","","Firdous Ahmad Shah; Debnath, Lokenath","Mathematics","Scholarly Journals","","5","4","2017-01-01","2017","72","","","22277390","","","ENG","In this study, a hybrid method based on coupling discrete wavelet transforms (DWTs) and artificial neural network (ANN) for yield spread forecasting is proposed. The discrete wavelet transform (DWT) using five different wavelet families is applied to decompose the five different yield spreads constructed at shorter end, longer end, and policy relevant area of the yield curve to eliminate noise from them. The wavelet coefficients are then used as inputs into Levenberg-Marquardt (LM) ANN models to forecast the predictive power of each of these spreads for output growth. We find that the yield spreads constructed at the shorter end and policy relevant areas of the yield curve have a better predictive power to forecast the output growth, whereas the yield spreads, which are constructed at the longer end of the yield curve do not seem to have predictive information for output growth. These results provide the robustness to the earlier results.","https://www.proquest.com/docview/1988600071?accountid=12870&bdid=124553&_bd=AYLKTmDsex0HAl4cgjTq8eKAjFM%3D","https://doi.org/10.3390/math5040072"
"Perspectives on the equity risk premium","","Siegel, Jeremy J","Financial analysts journal","Undefined","","61","6","2005-11-01","Nov 2005","61","73","61-73","0015-198X","0015-198X","","ENG","The equity risk premium has commanded the attention of professional economists and investment practitioners for decades. It is critical in financial economics; it determines asset allocations, projections of retirement and endowment wealth, and the cost of capital. Economists are still searching for a simple model that justifies the premium in face of the much lower volatility of aggregate economic data. Although the future equity risk premium is apt to be lower than it has been historically, U.S. equity returns of 2-3 percent over bonds will still amply reward those who will tolerate the short-term risk of stocks.","https://www.proquest.com/docview/36494180?accountid=12870&bdid=124553&_bd=tirAOkxPqHlsqoEwGEQNOCb40OE%3D",""
"Factor Investment or Feature Selection Analysis?","","Jifang Mai; Zhang, Shaohua; Zhang, Shaohua; Zhao, Haiqing; Pan, Lijun","Mathematics","Scholarly Journals","","13","1","2025-01-01","2025","9","","","22277390","","","ENG","This study has made significant findings in A-share market data processing and portfolio management. Firstly, by adopting the Lasso method and CPCA framework, we effectively addressed the problem of multicollinearity among feature indicators, with the Lasso method demonstrating superior performance in handling this issue, thus providing a new method for financial data processing. Secondly, Deep Feedforward Neural Networks (DFN) exhibited exceptional performance in portfolio management, significantly outperforming other evaluated machine learning methods, and achieving high levels of out-of-sample performance and Sharpe ratios. Additionally, we consistently identified price changes, earnings per share, net assets per share, and excess returns as key factors influencing predictive signals. Finally, this study combined the Lasso method with DFN, providing a new perspective and methodological support for asset pricing measurement in the financial field.","https://www.proquest.com/docview/3153800408?accountid=12870&bdid=124553&_bd=KcfDk29IhkHLYRJgEwdh3LX%2FTqY%3D","https://doi.org/10.3390/math13010009"
"Risk premia and seasonality in commodity futures","","Hevia, Constantino; Petrella, Ivan; Sola, Martin","Journal of Applied Econometrics","Scholarly Journals","","33","6","2018-09-01","Sep/Oct 2018","853","873","853-873","08837252","","","ENG","We develop and estimate a multifactor affine model of commodity futures that allows for stochastic seasonality. We document the existence of stochastic seasonal fluctuations in commodity futures and that properly accounting for the cost‐of‐carry curve requires at least three factors. We estimate the model using data on heating oil futures and analyze the contribution of the factors to risk premia. Correctly specifying seasonality as stochastic is important to avoid erroneously assigning those fluctuations to other risk factors. We also estimate a nonlinear version of the model that imposes the zero lower bound on interest rates and find similar results.","https://www.proquest.com/docview/2115224402?accountid=12870&bdid=124553&_bd=kaH8uyTdqlK3IfVToWMamYE8BFU%3D","https://doi.org/10.1002/jae.2631"
"Constructing Risk Analysis for Changes in China’s Local Government Bond System Based on SSP","","Xie, Ping; Zhang, Chunyan","Mobile Information Systems","Scholarly Journals","","2022","","2022-01-01","2022","","","","1574-017X","1875-905X","","ENG","The local government bond system of China has experienced a series of changes from its initial creation to its abolition and then to a recovery again. During the period, the central government always dominated the changing direction of the local government bond system. However, as fiscal decentralization reform has progressed, the institutional needs of local governments and investors have gradually gained attention. As a result, the size and variety of local government bonds are expanding. Through the introduction of analysis of system change based on situation structure performance (SSP), this paper uses Machine Learning (ML) approaches to predict the risk of government debt of China in the context of changing the local government bond system. Besides, this research work includes the comprehensive weight assignment for government debt hazard, fiscal revenue forecasting, default risk calculation, and finally an analysis of the validity of government debt hazard. The system may provide financial signal advice and strategy reference for dealing with hazards in early payment, organizing debt repayment significance order, optimizing fiscal revenue and cost structure, and so on.","https://www.proquest.com/docview/2704753953?accountid=12870&bdid=124553&_bd=yBV9Ditpd012FV1tQeGbxjK2Iho%3D","https://doi.org/10.1155/2022/4606905"
"A Neural Network Architecture for Maximizing Alpha in a Market Timing Investment Strategy","","Ospina-Holguin, Javier H; Padilla-Ospina, Ana M","IEEE Access","Scholarly Journals","","12","","2024-01-01","2024","119445","","119445-119463","21693536","","","ENG","In finance, assuming more risk often corresponds to the expectation of higher, compensating returns. In this setting, alpha stands out as one of the most prevalent and refined measures of risk-adjusted return ever postulated, allowing for the estimation of the excess return that cannot be explained by the risk factors impacting an asset. This article introduces a neural network architecture designed to formulate an investment strategy with the explicit goal of maximizing alpha. The strategy, centered around market timing, determines on a daily basis, based on past returns of the risky asset, whether to fully invest in the risky asset or opt for the risk-free alternative. The neural network architecture comprises two components: a policy network for strategy implementation and an evaluation network for long-term alpha computation during parameter optimization. Employing value-weighted US size decile portfolios as risky assets, the study achieves significant out-of-sample alphas ranging from 3.6% to 8.2% per year under the [Formula Omitted] asset pricing model (with a transaction cost assumption of one basis point). By construction, these alphas are not generated by risky asset growth. Robustness tests yield similar results with equal-weighted decile portfolios or under the Fama and French six-factor asset pricing model. Variations in transaction cost, number of past returns used as inputs, policy network design, or training sample size produce similar outcomes. This study underscores the effectiveness of reinforcement learning-inspired techniques in uncovering alpha in financial markets.","https://www.proquest.com/docview/3100616941?accountid=12870&bdid=124553&_bd=SalhcMlHDPbTI5UNUovUAS0WdPE%3D","https://doi.org/10.1109/ACCESS.2024.3446708"
"Predicting the Canadian Yield Curve Using Machine Learning Techniques","","Rayeni Ali; Naderi Hosein","International Journal of Financial Studies","Scholarly Journals","","13","3","2025-07-01","2025","170","","","22277072","","","ENG","This study applies machine learning methods to predict the Canadian yield curve using a comprehensive set of macroeconomic variables. Lagged values of the yield curve and a wide array of Canadian and international macroeconomic variables are utilized across various machine learning models. Hyperparameters are estimated to minimize mispricing across government bonds with different maturities. The Group Lasso algorithm outperforms the other models studied, followed by Lasso. In addition, the majority of the models outperform the Random Walk benchmark. The feature importance analysis reveals that oil prices, bond-related factors, labor market conditions, banks’ balance sheets, and manufacturing-related factors significantly drive yield curve predictions. This study is one of the few that uses such a broad array of macroeconomic variables to examine Canadian macro-level outcomes. It provides valuable insights for policymakers and market participants, with its feature importance analysis highlighting key drivers of the yield curve.","https://www.proquest.com/docview/3254534604?accountid=12870&bdid=124553&_bd=BUd2Xp4iBBsRqLDbBF7Qs3COyZw%3D","https://doi.org/10.3390/ijfs13030170"
"Macroeconomic Attention and Announcement Risk Premia","","Fisher, Adlai; Martineau, Charles; Sheng, Jinfei","The Review of Financial Studies","Scholarly Journals","","35","11","2022-11-01","Nov 2022","5057","5093","5057-5093","08939454","","","ENG","We construct macroeconomic attention indexes (MAI), which are new measures of attention to different macroeconomic risks, including unemployment and monetary policy. Individual MAI tend to increase around related announcements and following changes in related fundamentals. Further, bad news raises attention more than good news. For unemployment and FOMC, attention predicts announcement risk premiums and implied volatility changes with large economic magnitudes. Our findings support theories of endogenous attention and announcement risk premiums, while demonstrating future research directions, including that announcements can raise new concerns. Macroeconomic announcements are important not only for contents and timing but also for attention.Authors have furnished an Internet Appendix, which is available on the Oxford University Press Web site next to the link to the final published paper online.","https://www.proquest.com/docview/3238289066?accountid=12870&bdid=124553&_bd=W4RpZAlKwuYEBZ99loVo1c1llT0%3D","https://doi.org/10.1093/rfs/hhac011"
"Online Investor Sentiment via Machine Learning","","Cai, Zongwu; Chen, Pixiong; Chen, Pixiong","Mathematics","Scholarly Journals","","12","20","2024-01-01","2024","3192","","","22277390","","","ENG","In this paper, we propose utilizing machine learning methods to determine the expected aggregated stock market risk premium based on online investor sentiment and employing the multifold forward-validation method to select the relevant hyperparameters. Our empirical studies provide strong evidence that some machine learning methods, such as extreme gradient boosting or random forest, show significant predictive ability in terms of their out-of-sample performances with high-dimensional investor sentiment proxies. They also outperform the traditional linear models, which shows a possible unobserved nonlinear relationship between online investor sentiment and risk premium. Moreover, this predictability based on online investor sentiment has a better economic value, so it improves portfolio performance for investors who need to decide the optimal asset allocation in terms of the certainty equivalent return gain and the Sharpe ratio.","https://www.proquest.com/docview/3120734407?accountid=12870&bdid=124553&_bd=xLohUkuD6SSS%2F7LNkjOtgLo%2FBz0%3D","https://doi.org/10.3390/math12203192"
"Trading Macro-Cycles of Foreign Exchange Markets Using Hybrid Models","","Bin Ling, Joseph Zhi; Tsui, Albert K; Zhang, Zhaoyong","Sustainability","Scholarly Journals","","13","17","2021-01-01","2021","9820","","","20711050","","","ENG","Most existing studies on forecasting exchange rates focus on predicting next-period returns. In contrast, this study takes the novel approach of forecasting and trading the longer-term trends (macro-cycles) of exchange rates. It proposes a unique hybrid forecast model consisting of linear regression, multilayer neural network, and combination models embedded with technical trading rules and economic fundamentals to predict the macro-cycles of the selected currencies and investigate the predicative power and market timing ability of the model. The results confirm that the combination model has a significant predictive power and market timing ability, and outperforms the benchmark models in terms of returns. The finding that the government bond yield differentials and CPI differentials are the important factors in exchange rate forecasts further implies that interest rate parity and PPP have strong influence on foreign exchange market participants.","https://www.proquest.com/docview/2571539222?accountid=12870&bdid=124553&_bd=ZeFCNW3oSFzd1QSVgm2bDNdBRwk%3D","https://doi.org/10.3390/su13179820"
"Non-linear risk premia","","Peel, D A","Applied Financial Economics","Scholarly Journals","","3","3","1993-09-01","Sep 1993","201","","201","09603107","","","ENG","Empirical evidence is provided that the pre-whitened forecast errors for 7 sterling exchange rates sampled monthly are parsimoniously modeled by bilinear processes.  Assuming rational expectations, this result implies that there are non-linear time-varying risk premia.  This result can offer one explanation for the new empirical finding that the squared forward premium is a significant determinant of the forecast error.","https://www.proquest.com/docview/197177840?accountid=12870&bdid=124553&_bd=2CM31JVEgIk8xQNAKuZcsrrrO4Y%3D",""
"Exploration of Stock Portfolio Investment Construction Using Deep Learning Neural Network","","Xie, Zizheng; Wang, Yi","Computational Intelligence and Neuroscience : CIN","Scholarly Journals","","2022","","2022-01-01","2022","","","","1687-5265","1687-5273","","ENG","To study the intelligent and efficient stock portfolio in China’s financial market, based on the relevant theories such as deep learning (DL) neural network (NN) and stock portfolio, this study selects 111 stable stocks from the constituent stocks of the China Security Index (CSI) 300 from January 1, 2018, to December 31, 2021, as the research samples. Then, it analyzes these research samples and imports the relevant data of 111 stocks into the DL NN model. The corresponding prediction results of stock prices are obtained. Finally, the stock portfolio model based on DL NN is compared with the data results of the Shanghai Stock Exchange (SSE) 50 Index and CSI 500 Index. The results show that the closing prices of the selected 111 stocks are relatively stable and fluctuate up and down around the horizontal axis, and the positive and negative returns are relatively balanced, roughly between −5% and 5%. There is a phenomenon of fluctuation aggregation to a certain extent. Comparing the prediction results of different models reveals that the prediction results of model c are closest to the actual stock price trend. Comparing the relevant returns of the proposed stock portfolio with other stocks uncovers that the annualized return of the stock portfolio based on the DL NN model is 47.44%. The sharp ratio is 1.52, the maximum pullback is 18.15%, the monthly excess return is 3.11%, and the information ratio is 0.82. Compared with other indexes, the proposed stock portfolio shows the best results. Therefore, the proposal of the stock portfolio based on DL NN provides a theoretical basis for the development of the financial field in the future.","https://www.proquest.com/docview/2667626059?accountid=12870&bdid=124553&_bd=STsfkx5FydnAbdCIpwi8sG8yoWA%3D","https://doi.org/10.1155/2022/7957097"
"Forecasting government bond spreads with heuristic models: evidence from the Eurozone periphery","","Filipa Da Silva Fernandes; Stasinakis, Charalampos; Zekaite, Zivile","Annals of Operations Research","Scholarly Journals","","282","1-2","2019-11-01","Nov 2019","87","118","87-118","02545330","","","ENG","This study investigates the predictability of European long-term government bond spreads through the application of heuristic and metaheuristic support vector regression (SVR) hybrid structures. Genetic, krill herd and sine–cosine algorithms are applied to the parameterization process of the SVR and locally weighted SVR (LSVR) methods. The inputs of the SVR models are selected from a large pool of linear and non-linear individual predictors. The statistical performance of the main models is evaluated against a random walk, an Autoregressive Moving Average, the best individual prediction model and the traditional SVR and LSVR structures. All models are applied to forecast daily and weekly government bond spreads of Greece, Ireland, Italy, Portugal and Spain over the sample period 2000–2017. The results show that the sine–cosine LSVR is outperforming its counterparts in terms of statistical accuracy, while metaheuristic approaches seem to benefit the parameterization process more than the heuristic ones.","https://www.proquest.com/docview/2015635137?accountid=12870&bdid=124553&_bd=dWOpo9JcLryl%2BBMZJ9Y3WERwNSA%3D","https://doi.org/10.1007/s10479-018-2808-0"
"Research on RMB exchange rate forecast based on the neural network model and the Nelson–Siegel model","","Hua Rui; Hu Wenzhe; Zhao Xiuju","Risk Management","Scholarly Journals","","22","3","2020-09-01","Sep 2020","219","237","219-237","14603799","","","ENG","This paper expands the neural network model to predict exchange rate based on the factors extracted from the Nelson–Siegel model. Based on the theory about exchange rate forecasting, interest could be used to predict the movement of exchange rate. Therefore, this paper analyzes the interest rate term structure factors based on the US and China yield curves data, then uses the Nelson–Siegel model to extract the factors of the interest rate term structure. Finally, the factors of yield curves are used as input data to of the neural network model. And the mean forecasting squared errors, mean absolute errors, mean absolute percentage errors of neural network model, Nelson–Siegel regression model, and ARIMA model are compared. The results show that the neural network model has a superior ability to explain the exchange rate fluctuations of the CNY and USD, and the prediction ability is better than the exchange rate prediction ability of the Nelson–Siegel regression model and ARIMA model.","https://www.proquest.com/docview/2431394647?accountid=12870&bdid=124553&_bd=f%2Fw%2Fi86XPJU7jKcgBiZTRjN89dM%3D","https://doi.org/10.1057/s41283-020-00062-3"
"Autoencoder-Based Three-Factor Model for the Yield Curve of Japanese Government Bonds and a Trading Strategy","","Suimon, Yoshiyuki; Sakaji, Hiroki; Izumi, Kiyoshi; Matsushima, Hiroyasu","Journal of Risk and Financial Management","Scholarly Journals","","13","4","2020-01-01","2020","82","","","19118066","","","ENG","Interest rates are representative indicators that reflect the degree of economic activity. The yield curve, which combines government bond interest rates by maturity, fluctuates to reflect various macroeconomic factors. Central bank monetary policy is one of the significant factors influencing interest rate markets. Generally, when the economy slows down, the central bank tries to stimulate the economy by lowering the policy rate to establish an environment in which companies and individuals can easily raise funds. In Japan, the shape of the yield curve has changed significantly in recent years following major changes in monetary policy. Therefore, an increasing need exists for a model that can flexibly respond to the various shapes of yield curves. In this research, we construct a three-factor model to represent the Japanese yield curve using the machine learning approach of an autoencoder. In addition, we focus on the model parameters of the intermediate layer of the neural network that constitute the autoencoder and confirm that the three automatically generated factors represent the “Level,” “Curvature,” and “Slope” of the yield curve. Furthermore, we develop a long–short strategy for Japanese government bonds by setting their valuation with the autoencoder, and we confirm good performance compared with the trend-follow investment strategy.","https://www.proquest.com/docview/2395389487?accountid=12870&bdid=124553&_bd=n8jfP%2FFPeHabM366LlWEttW01%2Bo%3D","https://doi.org/10.3390/jrfm13040082"
"Forecasting sovereign risk in the Euro area via machine learning","","Belly, Guillaume; Boeckelmann, Lukas; Carlos Mateo Caicedo Graciano; Alberto Di Iorio; Istrefi, Klodiana; Siakoulis, Vasileios; Arthur Stalla‐Bourdillon","Journal of Forecasting","Scholarly Journals","","42","3","2023-04-01","Apr 2023","657","684","657-684","02776693","","","ENG","We test the usefulness of machine learning (ML) for the valuation and pricing of sovereign risk in the Euro area along two important dimensions: i) its predictive accuracy compared with traditional econometric methods, and ii) its assessment of the main economic factors underlying market perceptions of sovereign risk.We find that ML techniques can capture the dynamics inherent in the market valuation of country risk far more efficiently than traditional econometric models, both in the cross‐section and in the time series. Moreover, we show that public sentiment about financial news, redenomination fears and the degree of hawkishness/dovishness expressed in the ECB president's speeches are major contributors to sovereign bond spreads. We also confirm that macroeconomic and global financial factors affect sovereign risk assessment and the corresponding formation of sovereign spreads.","https://www.proquest.com/docview/2782854180?accountid=12870&bdid=124553&_bd=IdQPmexeijLn05Gaf3jWgGNRhXA%3D","https://doi.org/10.1002/for.2938"
"Predicting Chinese bond risk premium with machine learning","","Zhai, Jia; Xi, Jiahui; Wen, Conghua; Lu, Zong","The European Journal of Finance","Scholarly Journals","","31","7","2025-05-01","May 2025","919","955","919-955","1351847X","","","ENG","This paper investigates whether bond yield curve and macroeconomic factors have nonlinear relationships with bond risk premia in the Chinese bond market. We apply machine learning approaches to forecast Chinese treasury bond one-year holding period excess returns. Our results show that the bond yield curve has significant nonlinear predictive relationships with bond risk premia. We find evidence that ‘monetary policy’ and ‘tax’ macroeconomic groups have stronger nonlinear relationships with risk premia while ‘invest’ macroeconomic factors matter more for bonds with longer maturities. This paper provides statistical evidence for a significant relationship between expected bond risk premia and several economic drivers including range of forecast of GDP and bond volatility variables. We further document the economic values of our forecasting results by showing they can generate statistically higher certain equivalent values than those from the benchmark forecast.","https://www.proquest.com/docview/3199717560?accountid=12870&bdid=124553&_bd=PXstOX2ZA0p1BoZPBy5ELhfUwWI%3D","https://doi.org/10.1080/1351847X.2024.2446719"
"Forecasting ETF Performance: A Comparative Study of Deep Learning Models and the Fama-French Three-Factor Model","","Shih, Kuang-Hsun; Yi-Hsien, Wang; Yi-Hsien, Wang; I-Chen, Kao; Fu-Ming, Lai","Mathematics","Scholarly Journals","","12","19","2024-01-01","2024","3158","","","22277390","","","ENG","The global financial landscape has witnessed a significant shift towards Exchange-Traded Funds (ETFs), with their market capitalization surpassing USD 10 trillion in 2023, due to advantages such as low management fees, high liquidity, and broad market exposure. As ETFs become increasingly central to investment strategies, accurately forecasting their performance has become crucial. This study addresses this need by comparing the efficacy of deep learning models against the traditional Fama-French three-factor model in predicting daily ETF returns. The methodology employs eight artificial neural network architectures, including ANN, LSTM, GRU, CNN, and their variants, implemented in Python and applied to data ranging from 2010 to 2020, while also exploring the impact of additional factors on forecast accuracy. Empirical results reveal that LSTM and the Fama-French three-factor model exhibit a superior performance in ETF return prediction. This study contributes to the literature on financial forecasting and offers practical insights into investment decision making. By leveraging advanced artificial intelligence techniques, this study aims to enhance the toolkit available for ETF performance analysis, potentially improving investment strategies in this dynamic market segment.","https://www.proquest.com/docview/3116655504?accountid=12870&bdid=124553&_bd=B0FmA%2Fvxf36riWzQepAZIcORYRs%3D","https://doi.org/10.3390/math12193158"
"Forecasting annual excess stock returns via an adaptive network-based fuzzy inference system","","Trinkle, Brad S","Intelligent Systems in Accounting, Finance and Management","Scholarly Journals","","13","3","2005-07-01","Jul-Sep 2005","165","","165-177","15501949","","","ENG","In this study, an adaptive network-based fuzzy inference system (ANFIS) and a neural network were tested for the ability of these techniques to forecast the annual excess returns of three large publicly traded companies from a time series of said returns. The predictive ability of these techniques was compared with that of an autoregressive moving average (ARMA) model. The Fair-Shiller test was used in the comparisons in order to obtain results that were not subjective and so that conclusions could be made regarding the information used by the techniques in the generation of their forecasts. Since predictive ability does not translate to profitability, a simple trading strategy was used to determine the ability to generate profits from trading upon the forecasts of the respective techniques. As hypothesized, the ANFIS and neural network techniques are able to generate forecasts with significant predictive ability. However, neither technique dominates the other or the ARMA model. In tests of the ability of the techniques to generate profits from their forecasts, a simple trading strategy was used (trading on the predicted sign of the return). The ANFIS and the neural network generated profits in all of the trading scenarios.","https://www.proquest.com/docview/214366502?accountid=12870&bdid=124553&_bd=TwbRYMWBYX1SzlguipE%2FQnY4jHA%3D",""
"Fluctuations and Forecasting of Carbon Price Based on A Hybrid Ensemble Learning GARCH-LSTM-Based Approach: A Case of Five Carbon Trading Markets in China","","Liu, Sha; Liu, Sha; Zhang, Yiting; Wang, Junping; Feng, Danlei","Sustainability","Scholarly Journals","","16","4","2024-01-01","2024","1588","","","20711050","","","ENG","Carbon trading risk management and policy making require accurate forecasting of carbon trading prices. Based on the sample of China’s carbon emission trading pilot market, this paper firstly uses the Augmented Dickey–Fuller test and Autoregressive conditional heteroscedasticity model to test the stationarity and autocorrelation of carbon trading price returns, uses the Generalized Autoregressive Conditional Heteroscedasticity family model to analyze the persistence, risk and asymmetry of carbon trading price return fluctuations, and then proposes a hybrid prediction model neural network (generalized autoregressive conditional heteroscedasticity–long short-term memory network) due to the shortcomings of GARCH models in carbon price fluctuation analysis and prediction. The model is used to predict the carbon trading price. The results show that the carbon trading pilots have different degrees of volatility aggregation characteristics and the volatility persistence is long, among which only the Shanghai and Beijing carbon trading markets have risk premiums. The other pilot returns have no correlation with risks, and the fluctuations of carbon trading prices and returns are asymmetrical. The prediction results of different models show that the root mean square error (RMSE) of Hubei, Shenzhen and Shanghai carbon trading pilots based on the GARCH-LSTM model is significantly lower than that of the single GARCH model, and the RMSE values are reduced by 0.0006, 0.2993 and 0.0151, respectively. The RMSE in the three pilot markets improved by 0.0007, 0.3011 and 0.0157, respectively, compared to the standalone LSTM model. At the same time, compared with the single model, the GARCH-LSTM model significantly increased the R^2 value in Hubei (0.2000), Shenzhen (0.7607), Shanghai (0.0542) and Beijing (0.0595). Therefore, compared with other models, the GARCH-LSTM model can significantly improve the prediction accuracy of carbon price and provide a new idea for scientifically predicting the fluctuation of financial time series such as carbon price.","https://www.proquest.com/docview/2931098013?accountid=12870&bdid=124553&_bd=E07W64HdtnNHDnLeUiEzL3HPt48%3D","https://doi.org/10.3390/su16041588"
"Estimating time-varying risk premia in UK long-term government bonds","","Steeley, J M","Applied financial economics","Undefined","","14","5","2004-03-01","Mar 2004","367","373","367-373","0960-3107","0960-3107","","ENG","Simple models of time-varying risk premia are used to measure the risk premia in long-term UK government bonds. The parameters of the models can be estimated using nonlinear seemingly unrelated regression (NL-SUR), which permits efficient use of information across the entire yield curve and facilitates the testing of various cross-sectional restrictions. The estimated time-varying premia are found to be substantially different to those estimated using models that assume constant risk premia. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/37885237?accountid=12870&bdid=124553&_bd=so%2FWSl%2F3o9MTLBl%2FFT4Y1dNf6ec%3D",""
"Asset Pricing, Higher Moments, and the Market Risk Premium: A Note","","Sears, R Stephen; Wei, K C John","The Journal of Finance","Scholarly Journals","","40","4","1985-09-01","Sep 1985","1251","","1251","00221082","","","ENG","Following the work of Rubinstein (1973), Kraus and Litzenberger (1976) developed and tested a linear 3-moment pricing model, finding the additional variable (coskewness) to explain the empirical anomalies of the 2-moment capital asset pricing model (CAPM).  The 3-moment model was retested by Friend and Westerfield (1980) with mixed results.  The present analysis seeks to examine why the market risk premium may influence tests of asset pricing models with higher moments.  When skewness is incorporated into a pricing model developed within the usual 2-fund separation assumptions, the market risk premium enters the pricing equation in a nonlinear fashion and is implicit in the estimation of each moment's coefficient.  Unless this nonlinearity is recognized, erroneous conclusions may be drawn regarding the empirical results of such models.","https://www.proquest.com/docview/194703255?accountid=12870&bdid=124553&_bd=qFoos%2Bo20mXGKU7K%2F8FQwoxdR6w%3D",""
"Empirical Asset Pricing via Machine Learning","","Gu, Shihao; Kelly, Bryan; Xiu, Dacheng","The Review of Financial Studies","Scholarly Journals","","33","5","2020-05-01","May 2020","2223","2273","2223-2273","08939454","","","ENG","We perform a comparative analysis of machine learning methods for the canonical problem of empirical asset pricing: measuring asset risk premiums. We demonstrate large economic gains to investors using machine learning forecasts, in some cases doubling the performance of leading regression-based strategies from the literature. We identify the best-performing methods (trees and neural networks) and trace their predictive gains to allowing nonlinear predictor interactions missed by other methods. All methods agree on the same set of dominant predictive signals, a set that includes variations on momentum, liquidity, and volatility.Authors have furnished an Internet Appendix, which is available on the Oxford University Press Web site next to the link to the final published paper online.","https://www.proquest.com/docview/3238286428?accountid=12870&bdid=124553&_bd=CJaS61m5WfAKltWArwvYwk3LuHY%3D","https://doi.org/10.1093/rfs/hhaa009"
"Quadrature-Based Methods for Obtaining Approximate Solutions to Nonlinear Asset Pricing Models","","Tauchen, George; Hussey, Robert","Econometrica","Scholarly Journals","","59","2","1991-03-01","Mar 1991","371","","371","00129682","","","ENG","A discrete state-space approximation method for a specific class of nonlinear rational expectations models is developed.  The method works by using numerical quadrature rules to approximate the integral operators that arise in stochastic intertemporal models.  The method is particularly useful for approximating asset pricing models and has potential applications in other problems as well.  An empirical application uses the method to examine the relationship between the risk premium and the conditional variability of the equity return.  In particular, a time series model with conditional heteroskedasticity is estimated for annual per capita consumption.  This fitted time series model is taken as input to the discretization technique to make calibration of the Markov chain realistic.  With the calibration of the Markov chain, a positive relationship is found between the risk premium of the equity return and its conditional variability given current and lagged consumption.","https://www.proquest.com/docview/203888271?accountid=12870&bdid=124553&_bd=JkwXSXHjgcAJFRUtHInFuKd529U%3D",""
"The relationship between risk-neutral and actual default probabilities: the credit risk premium","","Heynderickx, W; Cariboni, J; Schoutens, W; Smits, B","Applied economics","Undefined","","48","42","2016-01-01","0, 2016","4066","4066","4066","0003-6846","0003-6846","","ENG","The study investigates empirically the relationship between the risk-neutral measure Q and the real-world measure P. We study the ratio between the risk-neutral and actual default intensities, which we call the coverage ratio or the relative credit risk premium. Actual default intensities are derived from rating agencies annual transition matrices, while risk-neutral default intensities are bootstrapped from CDS quotes of European corporates. We quantify the average risk premium and its changes over time. Compared to related literature, special attention is given to the effects of the recent financial and European sovereign crises. We find that average credit risk premia rose substantially and that post-crisis levels are still higher than those observed before the financial crisis. This observation is especially true for high-quality debt and if it persists, it will have an impact on corporates funding costs. The quantification and revision of risk premia contributes to the discussion of the credit spread puzzle and could give extra insights in valuation models that start from real-world estimates. Our work is furthermore important in the context of state aid assessment. The real economic value (REV) methodology, applied by the European Commission to evaluate impaired portfolios, is based on a long-term average risk premium. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/1816866776?accountid=12870&bdid=124553&_bd=1qLA8HAXtoiNE9lvbgtddrnOUKs%3D",""
"Neural forecasting of the Italian sovereign bond market with economic news","","Consoli, Sergio; Luca Tiozzo Pezzoli; Tosetti, Elisa","Journal of the Royal Statistical Society. Series A, Statistics in Society","Scholarly Journals","","185","S2","2022-12-01","Dec 2022","S197","S224","S197-S224","09641998","","","ENG","In this paper, we employ economic news within a neural network framework to forecast the Italian 10‐year interest rate spread. We use a big, open‐source, database known as Global Database of Events, Language and Tone to extract topical and emotional news content linked to bond markets dynamics. We deploy such information within a probabilistic forecasting framework with autoregressive recurrent networks (DeepAR). Our findings suggest that a deep learning network based on long short‐term memory cells outperforms classical machine learning techniques and provides a forecasting performance that is over and above that obtained by using conventional determinants of interest rates alone.","https://www.proquest.com/docview/2759587409?accountid=12870&bdid=124553&_bd=m6kmydhJBrhUnIrPSEkNqzX7spM%3D","https://doi.org/10.1111/rssa.12813"
"Stock return prediction with multiple measures using neural network models","","Wang, Cong","Financial Innovation","Scholarly Journals","","10","1","2024-12-01","Dec 2024","72","","72","21994730","","","ENG","In the field of empirical asset pricing, the challenges of high dimensionality, non-linear relationships, and interaction effects have led to the increasing popularity of machine learning (ML) methods. This study investigates the performance of ML methods when predicting different measures of stock returns from various factor models and investigates the feature importance and interaction effects among firm-specific variables and macroeconomic factors in this context. Our findings reveal that neural network models exhibit consistent performance across different stock return measures when they rely solely on firm-specific characteristic variables. However, the inclusion of macroeconomic factors from the financial market, real economic activities, and investor sentiment leads to substantial improvements in the model performance. Notably, the degree of improvement varies with the specific measures of stock returns under consideration. Furthermore, our analysis indicates that, after the inclusion of macroeconomic factors, there is a dissimilarity in model performance, variable importance, and interaction effects among macroeconomic and firm-specific variables, particularly concerning abnormal returns derived from the Fama–French three- and five-factor models compared with excess returns. This divergence is primarily attributed to the extent to which these factor models remove the variance associated with the macroeconomic variables. These findings collectively offer valuable insights into the efficacy of neural network models for stock return predictions and contribute to a deeper understanding of the intricate relationship between factor models, stock returns, and macroeconomic conditions in the domain of empirical asset pricing.","https://www.proquest.com/docview/3062788092?accountid=12870&bdid=124553&_bd=RCTsLTp7WX1fQjqgJHt4km5CaDE%3D","https://doi.org/10.1186/s40854-023-00608-w"
"Term structure estimation with liquidity-adjusted Affine Nelson Siegel model: A nonlinear state space approach applied to the Indian bond market","","Kumar, Sudarshan; Virmani, Vineet","Applied Economics","Scholarly Journals","","54","6","2022-02-01","Feb 2022","648","669","648-669","00036846","","","ENG","Efficient term structure estimation in emerging markets is difficult not only because of overall lack of liquidity, but also because of the concentration of liquidity in a few securities. Using the arbitrage-free Affine Nelson-Siegel model, we explicitly incorporate this phenomenon using a proxy for liquidity based on observable data in the bond pricing function and estimate the term structure for Indian Government bond markets in a nonlinear state space setting using the Unscented Kalman Filter. We find strong empirical evidence in support of the extended model with both i) a better in-sample fit to bond prices, and ii) the likelihood ratio test rejecting the restrictions assumed in the standard AFNS specification. In an alternative specification, we also model liquidity as a latent risk factor within the AFNS framework. The estimated latent liquidity factor is found to be strongly correlated with the standard market benchmarks of overall liquidity and the India VIX index.","https://www.proquest.com/docview/2623192708?accountid=12870&bdid=124553&_bd=GqntH1cOOhQCrwcvvsua%2BsMT5S4%3D","https://doi.org/10.1080/00036846.2021.1967866"
"Portfolio Selection and Optimization through Neural Networks and Markowitz Model: A Case of Pakistan Stock Exchange Listed Companies","","Iqbal, Javed; Moeed Ahmad Sandhu; Amin, Shaheera; Manzoor, Alia","Review of Economics and Development Studies","Scholarly Journals","","5","1","2019-01-01","2019","183","","183-196","25199692","","","ENG","This paper used artificial neural networks (ANNs) time series predictor for approximating returns of Pakistan Stock Exchange (PSX) listed 100 companies. These projected returns are then substituted into expected returns in the Markowitz’s Mean Variance (MV) portfolio Model. For comparison empirical data used is closing prices of PSX listed stocks, Karachi Inter Bank Offer Rates (KIBOR) as risk free rate and KSE-all share index as benchmark. The Portfolio returns are compared for two datasets by employing various constraints like budget, transaction costs, and turnover constraints. The value of portfolios is measured through Sharpe ratio and Information ratio. Both Sharpe and Information ratios support use of ANNs as return predictor and optimisation tool over simple MV model implemented for empirical data as well as predicted data. ANNs framework performed better in both Long and Short positions and its portfolio returns are significantly higher as compared with MV.","https://www.proquest.com/docview/2583836339?accountid=12870&bdid=124553&_bd=C8vVTvT7JI0qItjOmAgEjFMJpes%3D","https://doi.org/10.26710/reads.v5i1.354"
"Asset Returns: Reimagining Generative ESG Indexes and Market Interconnectedness","","Dash, Gordon; Dash, Gordon; Kajiji, Nina; Kamdem, Bruno G","Journal of Risk and Financial Management","Scholarly Journals","","17","10","2024-01-01","2024","463","","","19118066","","","ENG","Financial economists have long studied factors related to risk premiums, pricing biases, and diversification impediments. This study examines the relationship between a firm’s commitment to environmental, social, and governance principles (ESGs) and asset market returns. We incorporate an algorithmic protocol to identify three nonobservable but pervasive E, S, and G time-series factors to meet the study’s objectives. The novel factors were tested for information content by constructing a six-factor Fama and French model following the imposition of the isolation and disentanglement algorithm. Realizing that nonlinear relationships characterize models incorporating both observable and nonobservable factors, the Fama and French model statement was estimated using an enhanced shallow-learning neural network. Finally, as a post hoc measure, we integrated explainable AI (XAI) to simplify the machine learning outputs. Our study extends the literature on the disentanglement of investment factors across two dimensions. We first identify new time-series-based E, S, and G factors. Second, we demonstrate how machine learning can be used to model asset returns, considering the complex interconnectedness of sustainability factors. Our approach is further supported by comparing neural-network-estimated E, S, and G weights with London Stock Exchange ESG ratings.","https://www.proquest.com/docview/3120673976?accountid=12870&bdid=124553&_bd=1BOUhCFErqjY0mlXaJfcidPcLpc%3D","https://doi.org/10.3390/jrfm17100463"
"Infering the forward looking equity risk premium from derivative prices","","Bhar, Ramaprasad; Chiarella, Carl; Runggaldier, Wolfgang J","Studies in nonlinear dynamics and econometrics","Undefined","","8","1","2004-03-01","Mar 2004","","","","1558-3708","1558-3708","","ENG","This paper considers the measurement of the equity risk premium in financial markets from a new perspective that picks up on a suggestion from Merton (1980) to use implied volatility of options on a market portfolio as a direct 'ex-ante' estimate for market variance, and hence the risk premium. Here the time variation of the unobserved risk premium is modelled by a system of stochastic differential equations connected by arbitrage arguments between the spot equity market, the index futures and options on index futures. We motivate and analyse a mean-reverting form for the dynamics of the risk premium. Since the risk premium is not directly observable, information about its time varying conditional distribution is extracted using an unobserved component state space formulation of the system and Kalman filtering methodology. In order to cater for the time variation of volatility we use the option implied volatility in the dynamic equations for the index and its derivatives. This quantity is in a sense treated as a signal that impounds the market's 'ex-ante', forward looking, view on the equity risk premium. The results using monthly U.S. market data over the period January 1995 to June 2003 are presented and the model fit is found to be statistically significant using a number of measures. Comparisons with ex-post returns indicate that such historical measures may be understating the market risk premium. Reprinted by permission of Berkeley Electronic Press","https://www.proquest.com/docview/37873545?accountid=12870&bdid=124553&_bd=X21llWFLeU0P1Ar%2B941%2FLuoU9m4%3D",""
"Bond Market Prediction using an Ensemble of Neural Networks","","Parekh, Bhagya; Shah, Naineel; Mehta, Rushabh; Shah, Harshil","International Journal of Computer Applications","Undefined","Foundation of Computer Science, 244 5th Avenue, # 1526, New York, NY 10001, USA India","82","4","2013-01-01","2013","","","","","0975-8887","","ENG","The characteristics of a successful financial forecasting system are the exploitation of inefficiencies of a given market and the precise application to that market. Overwhelming evidence indicates that opportunities exist for consistent positive returns over a given period of time. This project aims to provide means for the yield curve projection of government bonds. An ensemble of networks such as back propagation, radial basis function, linear regression, is used to predict the yield. The yield is forecasted using technical analysis using historical data and the output is tested for accuracy and accordingly assigned weights. Using the ensemble of neural networks, accuracy has been tried to be maximized and offer near to actual prediction. Using the yield curve, the investor can assess not only the yield of that bond, but can also the interest rates, and hence, has a very useful tool in his hand for investment purpose, thus making decisions about whether to invest or not , and if invest then when to invest. The yield curve prediction not only provides the investor a tool to make investment decisions in bond market, but it also serves as a tool to gauge the macroeconomic conditions of the country and hence predict the movement in various other markets as well, and hence make investment decisions accordingly.","https://www.proquest.com/docview/1475549637?accountid=12870&bdid=124553&_bd=vK3yFnLw639XUHRVxj76ErP6JU4%3D","https://doi.org/10.5120/14105-2144"
"Re‐Investigating the UIP Hypothesis: Recent Evidence From BRICS Economies","","Bhatia, Madhur","Economic Notes","Scholarly Journals","","54","1","2025-02-01","Feb 2025","","","","03915026","","","ENG","The study re‐investigates the existence of the Uncovered interest parity (UIP) hypothesis and substantially adds to the literature by offering the most recent evidence during the period from 2000 to 2022 from developing and emerging economies. The study further augments the literature by extending the standard UIP hypothesis to account for the monetary policy stance and risk premium. The estimates of nonlinear autoregressive distributed lag (NARDL) and component generalised autoregressive conditional heteroscedasticity (C‐GARCH) show that the UIP hypothesis does not exist in any of the BRICS economies. Nevertheless, after accounting for the risk premium and monetary policy stance using inflation levels, the interest rate differential significantly and positively influences the expected changes in the spot exchange rates. This indicates three important aspects: first, the necessity of risk premium to make up for the higher risk that comes with holding the foreign bond for the benefit of domestic investors. Second that the UIP puzzle does not hold, such that higher interest differential depreciates the domestic currency. Third, the analysis underscores the substantial and direct impact of US inflation level, particularly for Brazil, Russia and India, in determining the changes in the spot exchange rate. These insights hold crucial implications for policymakers and regulators.","https://www.proquest.com/docview/3170632976?accountid=12870&bdid=124553&_bd=C1fruDAM9Em0O7bf4BY1Bx%2FND48%3D","https://doi.org/10.1111/ecno.70002"
"Can Ensemble Machine Learning Methods Predict Stock Returns for Indian Banks Using Technical Indicators?","","Mohapatra, Sabyasachi; Mohapatra, Sabyasachi; Mukherjee, Rohan; Roy, Arindam; Sengupta, Anirban; Puniyani, Amit","Journal of Risk and Financial Management","Scholarly Journals","","15","8","2022-01-01","2022","350","","","19118066","","","ENG","This paper develops ensemble machine learning models (XGBoost, Gradient Boosting, and AdaBoost in addition to Random Forest) for predicting stock returns of Indian banks using technical indicators. These indicators are based on three broad categories of technical analysis: Price, Volume, and Turnover. Various error metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), Mean Absolute Percentage Error (MAPE), Root-Mean-Squared-Error (RMSE) have been used to check the performance of the models. Results show that the XGBoost algorithm performs best among the four ensemble models. The mean of absolute error and the root-mean-square -error vary around 3–5%. The feature importance plots generated by the models depict the importance of the variables in predicting the output. The proposed machine learning models help traders, investors, as well as portfolio managers, better predict the stock market trends and, in turn, the returns, particularly in banking stocks minimizing their sole dependency on macroeconomic factors. The techniques further assist the market participants in pre-empting any price-volume action across stocks irrespective of their size, liquidity, or past turnover. Finally, the techniques are incredibly robust and display a strong capability in predicting trend forecasts, particularly with any large deviations.","https://www.proquest.com/docview/2706209407?accountid=12870&bdid=124553&_bd=WFcSgQy24BH%2BApq0H9BZwfg7w3M%3D","https://doi.org/10.3390/jrfm15080350"
"Financial conditions, macroeconomic factors and disaggregated bond excess returns","","Fricke, Christoph; Menkhoff, Lukas","Journal of banking and finance","Undefined","","58","","2015-09-01","Sep 2015","80","94","80-94","0378-4266","0378-4266","","ENG","Bond excess returns can be predicted by macro factors, however, large parts remain still unexplained. We apply a novel term structure model to decompose bond excess returns into expected excess returns (risk premia) and the innovation part. In order to explore these risk premia and innovations, we complement macro variables by financial condition variables as possible determinants of bond excess returns. We find that the expected part of bond excess returns is driven by macro factors, whereas innovations seem to be mainly influenced by financial conditions, before and after the financial crisis. Thus, financial conditions, such as financial stress, deserve attention when analyzing bond excess returns. All rights reserved, Elsevier","https://www.proquest.com/docview/1718086907?accountid=12870&bdid=124553&_bd=uPBVa%2Fj%2FedutNTRWNircNgdxYyU%3D",""
"Forecasting stock prices changes using long-short term memory neural network with symbolic genetic programming","","Li, Qi; Kamaruddin, Norshaliza; Yuhaniz, Siti Sophiayati; Al-Jaifi, Hamdan Amer Ali","Scientific Reports (Nature Publisher Group)","Scholarly Journals","","14","1","2024-01-01","2024","422","","422","20452322","","","ENG","This study introduces an augmented Long-Short Term Memory (LSTM) neural network architecture, integrating Symbolic Genetic Programming (SGP), with the objective of forecasting cross-sectional price returns across a comprehensive dataset comprising 4500 listed stocks in the Chinese market over the period from 2014 to 2022. Using the S&P Alpha Pool Dataset for China as basic input, this architecture incorporates data augmentation and feature extraction techniques. The result of this study demonstrates significant improvements in Rank Information coefficient (Rank IC) and IC information ratio (ICIR) by 1128% and 5360% respectively when it is applied to fundamental indicators. For technical indicators, the hybrid model achieves a 206% increase in Rank IC and an impressive surge of 2752% in ICIR. Furthermore, the proposed hybrid SGP-LSTM model outperforms major Chinese stock indexes, generating average annualized excess returns of 31.00%, 24.48%, and 16.38% compared to the CSI 300 index, CSI 500 index, and the average portfolio, respectively. These findings highlight the effectiveness of SGP-LSTM model in improving the accuracy of cross-sectional stock return predictions and provide valuable insights for fund managers, traders, and financial analysts.","https://www.proquest.com/docview/2909358036?accountid=12870&bdid=124553&_bd=WZ7FetaUUEh5JWoAtH2rjvBowdo%3D","https://doi.org/10.1038/s41598-023-50783-0"
"LSTM–GARCH Hybrid Model for the Prediction of Volatility in Cryptocurrency Portfolios","","","Computational Economics","Scholarly Journals","","63","4","2024-04-01","Apr 2024","1511","1542","1511-1542","09277099","","","ENG","In the present work, the volatility of the leading cryptocurrencies is predicted through generalised autoregressive conditional heteroskedasticity (GARCH) models, multilayer perceptron (MLP), long short-term memory (LSTM), and hybrid models of the type LSTM and GARCH, where parameters of the GARCH family are included as features of LSTM models. The study period covered the scenario of the World Health Organization pandemic declaration around March 2020 at hourly frequency. We have found that the different variants of deep neural network models outperform those of the GARCH family in the sense of the hetorerocedastic error, and absolute and squared error (HSE). Under the sharpe ratio, the volatility forecasting of a uniform portfolio at long horizons systematically outperforms the stablecoin Tether, which is considered here as the risk-free asset. Also, including transaction volume helps reduce the value at risk or loss probability for the uniform portfolio. Moreover, in a minimum variance portfolio, it is observed that before the pandemic declaration, a large proportion of the capital was allocated to bitcoin (BTC). In contrast, after March 2020, the portfolio is more diversified with short positions for BTC. Moreover, the MLP models give the best predictive results, although not statistically different in accuracy compared to the LSTM and LSTM–GARCH versions under the Diebold–Mariano test. In sum, MLP models outperform most stylised financial models and are less computationally expensive than more complex neural networks. Therefore, simple learning models are suggested in highly non-linear time series volatility forecasts as it is the cryptocurrency market.","https://www.proquest.com/docview/3042256280?accountid=12870&bdid=124553&_bd=QSZ2RYPlhcQeKLSDUbAKymhyj44%3D","https://doi.org/10.1007/s10614-023-10373-8"
"Neural Ordinary Differential Equation Networks for Fintech Applications Using Internet of Things","","Li, Jiacheng; Chen, Wei; Liu, Yican; Yang, Junmei; Zeng, Delu; Zhou, Zhiheng","IEEE Internet of Things Journal","Scholarly Journals","","11","12","2024-01-01","2024","21763","","21763-21772","23274662","","","ENG","The Internet of Things (IoT) technology is becoming increasingly pivotal in the financial services sector, with a growing number of algorithms being employed in high-frequency trading. High-frequency prediction in financial time series prediction presents a promising avenue of research. From convolutional neural networks to recurrent neural networks, deep learning have demonstrated exceptional capabilities in capturing the nonlinear characteristics of stock markets, thereby achieving high performance in stock index prediction. In this article, we employ ODE-LSTM model for high-frequency price forecasting, predicting stock price data across various time scales, including 1-, 5-, and 30-min frequencies. This approach introduces a novel concept, wherein the long short-term memory (LSTM) model is integrated with Neural ordinary differential equations (ODEs) to manage the hidden state and augment model interpretability. Over the course of 7 months, we achieved a 41.79% excess return on a simulated trading platform, with a daily average excess return of 0.30%, showcasing the commendable performance of our model and strategy.","https://www.proquest.com/docview/3065466036?accountid=12870&bdid=124553&_bd=MDNQ3wY8OHtcv3rHLVl4F%2BZ8FUI%3D","https://doi.org/10.1109/JIOT.2024.3376748"
"Economic Evaluation and Risk Premium Estimation of Rainfed Soybean under Various Planting Practices in a Semi-Humid Drought-Prone Region of Northwest China","","Liao, Zhenqi; Shengzhao Pei; Bai, Zhentao; Lai, Zhenlin; Wen, Lei; Zhang, Fucang; Li, Zhijun; Fan, Junliang","Agronomy","Scholarly Journals","","13","11","2023-01-01","2023","2840","","","20734395","","","ENG","Economic benefits and risk premiums significantly affect the production system decision making of farmers and government departments. This study evaluated the economic feasibility and estimated the risk premium of 12 rainfed soybean production systems with various planting densities, fertilization rates and planting patterns by considering the impact of soybean price fluctuation. There were two planting densities (D1: 160,000 plants ha−1 and D2: 320,000 plants ha−1), two fertilization rates (F1: 20 kg ha−1 N, 30 kg ha−1 P, 30 kg ha−1 K; F2: 40 kg ha−1 N, 60 kg ha−1 P, 60 kg ha−1 K) and three planting patterns (F+W0: flat cultivation with no irrigation; R+W0: plastic-mulched ridge-furrow cultivation (PMRF) with no irrigation; R+W1: PMRF with supplemental irrigation of 30 mm at the pod-filling stage). Based on the two-year (2019–2020) field data in a semi-humid drought-prone region of northwest China and soybean price fluctuation from January 2014 to June 2021, the net income (NI) was calculated by considering the impact of soybean price fluctuation and assuming constant soybean production costs. The net present value (NPV) method and the stochastic efficiency with respect to a function (SERF) method were used to evaluate the profitability of protective alternatives and the risk of these alternatives. The results showed that the 12 proposed soybean production systems were economically feasible. Reducing the fertilization rate reduced the input costs, but it did not necessarily result in a decrease in soybean yield and NI. The payback period of all production systems was within two years for farmers investing through loans. High-fertilizer and high-density production systems made personal investment obtain the highest economic benefit in this study, which was not the best investment strategy from the perspective of production-to-investment ratio and environmental protection departments. The preferences of farmers with various risk aversion and environmental protection departments in terms of risk premium were also proposed. The economic and risk assessment framework of this study can enhance the understanding of the adjustment of production systems from different perspectives, and provide strategies for promoting the protection of economic, environmental and socially sustainable agricultural systems.","https://www.proquest.com/docview/2892941013?accountid=12870&bdid=124553&_bd=D1KKKyGf6sDKuQtjLJsjI1tDzBg%3D","https://doi.org/10.3390/agronomy13112840"
"A dynamic target volatility strategy for asset allocation using artificial neural networks","","Kim, Youngmin; Enke, David","The Engineering Economist","Scholarly Journals","","63","4","2018-10-01","Oct/Dec 2018","273","","273-290","0013791X","","","ENG","A challenge to developing data-driven approaches in finance and trading is the limited availability of data because periods of instability, such as during financial market crises, are relatively rare. This study applies a stability-oriented approach (SOA) based on statistical tests to compare data for the current period to a past set of data for a stable period, providing higher reliability due to a more abundant source of data. Based on an SOA, this study uses an artificial neural network (ANN), which is one of the commonly applied machine learning algorithms, for simultaneously forecasting the volatility and classifying the level of market stability. In addition, this study develops a dynamic target volatility strategy for asset allocation using an ANN to enhance the ability of a target volatility strategy that is established for automatically allocating capital between a risky asset and a risk-free cash position. In order to examine the impact of the proposed strategy, the results are compared to the buy-and-hold strategy, the static asset allocation strategy, and the conventional target volatility strategy using different volatility forecasting methodologies. An empirical case study of the proposed strategy is simulated in both the Korean and U.S. stock markets.","https://www.proquest.com/docview/2203235064?accountid=12870&bdid=124553&_bd=N8%2BvcCoft%2FShOO2tEeS7uYZrmMQ%3D","https://doi.org/10.1080/0013791X.2018.1461287"
"Pricing Climate Change Exposure","","Sautner, Zacharias; van Lent, Laurence; Vilkov, Grigory; Zhang, Ruishen","Management Science","Scholarly Journals","","69","12","2023-12-01","Dec 2023","7540","","","00251909","","","ENG","We estimate the risk premium for firm-level climate change exposure among S&P 500 stocks and its time-series evolution between 2005 to 2020. Exposure reflects the attention paid by market participants in earnings calls to a firm's climate-related risks and opportunities. When extracted from realized returns, the unconditional risk premium is insignificant but exhibits a period with a positive risk premium before the financial crisis and a steady increase thereafter. Forward-looking expected return proxies deliver an unconditionally positive risk premium with maximum values of 0.5%–1% p.a., depending on the proxy, between 2011 and 2014. The risk premium has been lower since 2015, especially when the expected return proxy explicitly accounts for the higher opportunities and lower crash risks that characterize high-exposure stocks. This finding arises as the priced part of the risk premium primarily originates from uncertainty about climate-related upside opportunities. In the time series, the risk premium is negatively associated with green innovation; Big Three holdings; and environmental, social, and governance fund flows and positively associated with climate change adaptation programs.","https://www.proquest.com/docview/2903932737?accountid=12870&bdid=124553&_bd=%2FMy0BtoEixX%2Bnsk0v3jE6s%2FPvZo%3D","https://doi.org/10.1287/mnsc.2023.4686"
"Monetary base and federal government debt in the long‐run: A non‐linear analysis","","Haydory Akbar Ahmed","Bulletin of Economic Research","Scholarly Journals","","72","2","2020-04-01","Apr 2020","167","184","167-184","03073378","","","ENG","Government bonds are usually traded between the financial institutions and the Fed during the open market operations. These operations impact the bank reserves, subsequently influencing the monetary base. The monetary base and government bonds may portray a common trend and government debt could potentially bind the central bank to debt monetization. This paper, using monthly data on federal government debt and the monetary base from 1947:1 to 2018:10, investigates the presence of a long‐run equilibrium relationship between the two variables and as to how the long‐run equilibrium relationship vary in the short‐run. Threshold cointegration tests find evidence of a long‐run equilibrium relationship. Estimates of the threshold vector error‐correction model find statistically significant evidence of contraction in the monetary base growth in the short‐run in regime 1. In regime 2, the growth in the monetary base does not adjust to accommodate faster government debt growth. These estimates find no evidence of debt monetization or otherwise in either of the regimes in the United States. The Fed, by reducing the monetary base, perhaps focuses more on the inflation target. The findings also suggest a potential scenario where the Fed and the fiscal authority are not conjoined with each other in their operations.","https://www.proquest.com/docview/2394781333?accountid=12870&bdid=124553&_bd=TDu69gRjk7%2BEQ9hIb3m3YUFNiWM%3D","https://doi.org/10.1111/boer.12216"
"Probabilistic forecasts of volatility and its risk premia","","Maneesoonthorn, W; Martin, G M; Forbes, C S; Grose, S D","Journal of econometrics","Undefined","","171","2","2012-12-01","Dec 2012","217","236","217-236","0304-4076","0304-4076","","ENG","The object of this paper is to produce distributional forecasts of asset price volatility and its associated risk premia using a non-linear state space approach. Option and spot market information on the latent variance process is captured by using dual 'model-free' variance measures to define a bivariate observation equation in the state space model. The premium for variance diffusive risk is defined as linear in the latent variance (in the usual fashion) whilst the premium for variance jump risk is specified as a conditionally deterministic dynamic process, driven by a function of past measurements. The inferential approach adopted is Bayesian, implemented via a Markov chain Monte Carlo algorithm that caters for the multiple sources of non-linearity in the model and for the bivariate measure. The method is applied to spot and option price data on the S&P500 index from 1999 to 2008, with conclusions drawn about investors' required compensation for variance risk during the recent financial turmoil. The accuracy of the probabilistic forecasts of the observable variance measures is demonstrated, and compared with that of forecasts yielded by alternative methods. To illustrate the benefits of the approach, it is used to produce forecasts of prices of derivatives on volatility itself. In addition, the posterior distribution is augmented by information on daily returns to produce value at risk predictions. Linking the variance risk premia to the risk aversion parameter in a representative agent model, probabilistic forecasts of (approximate) relative risk aversion are also produced. All rights reserved, Elsevier","https://www.proquest.com/docview/1171850023?accountid=12870&bdid=124553&_bd=YW1qW67anj%2BwRa1mH%2BD5r96n5Mk%3D","https://doi.org/10.1016/j.jeconom.2012.06.006"
"Experimental Evidence on Socioeconomic Differences in Risk‐Taking and Risk Premiums","","Li, Zheng","Economic Record","Scholarly Journals","","96","313","2020-06-01","Jun 2020","140","152","140-152","00130249","","","ENG","Using a route choice experiment with embedded travel time variability, this study empirically estimates car commuters’ risk attitudes and taste preferences within a nonlinear mixed logit model. In addition to the identified overall risk‐taking behaviour, we find that risk attitudes covary with some sociodemographic characteristics, that is, older commuters are more risk‐taking than young ones and higher‐income commuters are less risk‐taking than low‐income ones. The implications of accounting for systematic risk attitude heterogeneity for valuing travellers’ willingness to pay for travel time improvement are also discussed.","https://www.proquest.com/docview/2410603366?accountid=12870&bdid=124553&_bd=s3kAIN9d4wrz3J%2BlxOSu%2FhKezDI%3D","https://doi.org/10.1111/1475-4932.12544"
"Do Forecast Errors or Term Premia Really Make the Difference Between Long and Short Rates?","","Startz, Richard","Journal of Financial Economics","Scholarly Journals","","10","3","1982-11-01","Nov 1982","323","","323","0304405X","","","ENG","Forward rates in the term structure of interest include predictions of future spot rates as well as, possibly, term premia.  Realized spot rates include forecasted spot rates as well as forecast errors.  Under rational expectations, forecast errors are not predictable.  By forecasting spot rates utilizing publicly available information, bounds on the variation of forecast errors and term premia are obtained.  For one-month treasury bill rates, one- to two-thirds of the variation in the difference between forward rates and realized spot rates is a result of variation in term premia.  The evidence reveals something of the potential value of economic analysis in the presence of efficient financial markets.  A planner interested in future short rates would be wise not to take today's implied forward rate as an estimator.  Concurrent with the large variation in the premium, it is observed that typical market forecasting errors are much smaller than had been previously thought.  For forecasting long rates into the relatively near future, simple use of the term structure is quite reasonable.  For longer-term forecasts, attention to changes in the market premium is essential.","https://www.proquest.com/docview/231764219?accountid=12870&bdid=124553&_bd=FQcTeb34PnTKcy1P%2B6cT%2BAGaaGk%3D",""
"Baltic Dry Index Estimation With NARX Neural Network Model","","Kılınç, Gamze; Kocabıyık, Turan; Karaatlı, Meltem","Ekonomika","Scholarly Journals","","102","1","2023-01-01","2023","60","80","60-80","13921258","","","ENG","Abstract. BDI is a global trade indicator followed by those interested in maritime trade. But it has volatility, seasonality, and uncertain cyclicality. For this reason, in this study, the BDI has been estimated to provide preliminary information to those interested in maritime trade. NARX Neural Network which performs successfully in complex and nonlinear real-life problems is used. In addition, the NARX neural network model has not been found in a previous study used for BDI estimation. Eleven independent variables are used in this study, what increases the predictive power. Independent variables are Bloomberg Commodities Index (BCOM), Twitter-Based Economic Uncertainty Index (TEU), Twitter-Based Market Uncertainty Index (TMU), S&P 500 Index, MSCI World Index, €/$ Parity, VIX (CBOE), US 10-Year Bond Yield (%), Brent Oil (USD/Barrel), Economic Uncertainty Index and World Trade Volume (USD Billion). The Twitter-Based Economic Uncertainty Index (TEU) and Twitter-Based Market Uncertainty Index (TMU), which were not used before in BDI estimation studies, were included in the analysis and contributed to the literature. The data set contains daily data for the period 9.07.2012-31.08.2020. 11-day estimate values covering 1.09.2020-15.09.2020 are calculated. MAPE, MAE and RMSE performance criteria were calculated for the estimation values. Value of MAPE (2.96%), value of MAE (36.6%) and value of RMSE (46.68) were obtained. As a result, the estimate values were compared with the actual values.","https://www.proquest.com/docview/2834503792?accountid=12870&bdid=124553&_bd=46vJAqy3x2K3ImYd%2BJgV6oxHEbs%3D","https://doi.org/10.15388/Ekon.2023.102.1.4"
"Statistical actuarial estimation of the Capitation Payment Unit from copula functions and deep learning: historical comparability analysis for the Colombian health system, 2015–2021","","Espinosa, Oscar; Bejarano, Valeria; Ramos, Jeferson; Martínez, Boris","Health Economics Review","Scholarly Journals","","13","1","2023-12-01","Dec 2023","15","","15","21911991","","","ENG","The Capitation Payment Unit (CPU) financing mechanism constitutes more than 70% of health spending in Colombia, with a budget allocation of close to 60 trillion Colombian pesos for the year 2022 (approximately 15.7 billion US dollars). This article estimates actuarially, using modern techniques, the CPU for the contributory regime of the General System of Social Security in Health in Colombia, and compares it with what is estimated by the Ministry of Health and Social Protection. Using freely available information systems, by means of statistical copulas functions and artificial neural networks, pure risk premiums are calculated between 2015 and 2021. The study concludes that the weights by risk category are systematically different, showing historical pure premiums surpluses in the group of 0–1 years and deficits (for the regions normal and cities) in the groups over 54 years of age.","https://www.proquest.com/docview/2779575049?accountid=12870&bdid=124553&_bd=bepU%2B4wnXICDukKV%2Btxz0SVMUT4%3D","https://doi.org/10.1186/s13561-022-00416-5"
"Option-Based Estimation of the Price of Coskewness and Cokurtosis Risk","","Christoffersen, Peter; Fournier, Mathieu; Jacobs, Kris; Karoui, Mehdi","Journal of Financial and Quantitative Analysis","Scholarly Journals","","56","1","2021-02-01","Feb 2021","65","91","65-91","00221090","","","ENG","We show that the prices of risk for factors that are nonlinear in the market return can be obtained using index option prices. The price of coskewness risk corresponds to the market variance risk premium, and the price of cokurtosis risk corresponds to the market skewness risk premium. Option-based estimates of the prices of risk lead to reasonable values of the associated risk premia. An analysis of factor models with coskewness risk indicates that the new estimates of the price of risk improve the models’ performance compared with regression-based estimates.","https://www.proquest.com/docview/2730669619?accountid=12870&bdid=124553&_bd=acNdMNJaDthLMzeMr8HEzd1DHT4%3D","https://doi.org/10.1017/S002210902000023X"
"U.S. vertically integrated electric utility greenhouse gas emissions and carbon risk premiums around the Paris Accord","","Michelfelder, Richard A; Pilotte, Eugene A. https://orcid.org/0000-0001-6111-1853","Energy Policy","Undefined","Elsevier Ltd","195 p.114346-","","2024-12-01","Dec 2024","","","","0301-4215","0301-4215","","ENG","We study the pricing of greenhouse gas emissions of vertically integrated producers of electricity around the Paris Accord (PA). We study whether emissions are priced by financial markets, providing a market-based incentive for firms to reduce their carbon footprints and if the heightened attention on climate change post-Paris Accord (PA) impacts the size of the “carbon risk premium.” We focus on electricity generators, because they are responsible for the largest share of emissions and emissions reductions in the U.S. and are highly exposed to regulatory, physical, and stranded asset risks. We find the cost of carbon risk is reflected in the returns of vertically integrated electric utilities. The post-PA period provides the strongest evidence that carbon risk is priced. We find that equity markets provide incentives for power producers to reduce emissions, as reductions in emissions are associated with reductions in required returns on equity (increases in equity market values). The challenge for regulators is how to respond in rate cases. Lowering a utility's regulated return to reflect lower market estimates of the return on equity would dilute the market-based incentive for emissions reductions. Adding a longer-term return incentive for continued investment in emissions reductions would reinforce the market incentive.","https://www.proquest.com/docview/3154236243?accountid=12870&bdid=124553&_bd=VWpAIaiZHnHUGpNFiugqWH91how%3D","https://doi.org/10.1016/j.enpol.2024.114346"
"A prediction model for the secure issuance scale of Chinese local government bonds","","Bowen, Jia; Wu, Jiaying; Du, Juan; Ji, Yun; Zhu, Lina","Kybernetes","Scholarly Journals","","50","5","2021-05-30","2021","1125","1143","1125-1143","0368492X","","","ENG","PurposeThe purpose of this paper is to calculate the local guaranteed fiscal revenue with the local fiscal revenue of 31 provinces, and predict their guaranteed fiscal revenue in 2018 with the artificial neural network (ANN).Design/methodology/approachThe principal components analysis (PCA), particle swarm optimization (PSO) and extreme learning machine (ELM) model was designed to produce the inputs of KMV model. Then the KMV model was used for obtaining the default probabilities under different issuance scales. Data were collected from Wind Database. MATLAB 2018b and SPSS 22 were used in the field of modeling and results analysis.FindingsThis study’s findings show that PCA–PSO–ELM proposed in this research has the highest accuracy in terms of the prediction compared with ELM, back propagation neural network and auto regression. And PCA–PSO–ELM–KMV model can calculate the secure issuance scale of local government bonds effectively.Practical implicationsThe sustainability forecast in this study can help local governments effectively control the scale of debt issuance, strengthen the budget management of local debt and establish the corresponding risk warning mechanism, which could make local governments maintain good credit ratings.Originality/valueThis study sheds new light on helping local governments avoid financial risks effectively, and it is conducive to establish a debt repayment reserve system for local governments and the proper arrangement for stock debt.","https://www.proquest.com/docview/2774438354?accountid=12870&bdid=124553&_bd=UvYbUjEfrEGF9xv%2FL7%2FD4zcyKi0%3D","https://doi.org/10.1108/K-10-2019-0699"
"Early Warning of Systemic Financial Risk of Local Government Implicit Debt Based on BP Neural Network Model","","Zhao, Yinglan; Li, Yi; Chen, Feng; Gong, Chi; Gong, Chi; Tan, Hongru","Systems","Scholarly Journals","","10","6","2022-01-01","2022","207","","","20798954","","","ENG","In recent years, local governments have boosted their local economies by raising large amounts of debt. Even though the state further strictly controls local government debt, the hidden debt formed by the local government borrowing in disguised form can infect systemic financial risks, creating an urgent need to carry out risk warning based on local government hidden debt. The paper uses the macro indicators of local government implicit debt risk at the prefecture-level city level, and introduces the micro indicators of PPP projects, financing platform bank debt, and urban investment debt to establish a BP neural network model. We not only study the contagion effect of local government hidden debt on systemic financial risks, but also predict the systemic financial risks in 2019 and construct an early warning risk system based on the prefecture-level city data from 2015 to 2018. In addition, the early warning effect of local government implicit debt on systemic financial risk under different stress scenarios is investigated. The study found that the implicit debt risk of local governments, the scale of financing platform bank debt, the scale of PPP, and the scale of urban investment bonds have a significant impact on systemic financial risks. The neural network model constructed by introducing these four variables at the same time can better predict the level of systemic financial risk. The model can also accurately predict the changes in systemic financial risks under the stress test of the increase in hidden debt of different local governments, and has a good early warning effect.","https://www.proquest.com/docview/2756812567?accountid=12870&bdid=124553&_bd=ooD8Z%2B6GOJJmMA4kesY2F2quQEU%3D","https://doi.org/10.3390/systems10060207"
"Predictability of sugar futures: evidence from the Indian commodity market","","Prabhati Kumari Misra; Goswami, Kishor","Agricultural Finance Review","Scholarly Journals","","75","4","2015-10-01","2015","552","564","552-564","00021466","","","ENG","Purpose – The forecasting power of commodity futures is a matter of intensive research as evidenced by a number of related publications. The purpose of this paper is to illustrate how advanced forecasting techniques improve the predictability of sugar futures in the Indian commodity market. Design/methodology/approach – The forward premium is estimated using ordinary least square regression technique. Different linear and nonlinear models are used to forecast the sugar future spot prices from the futures prices. The forecasting accuracy of each pair of models is then compared by estimating the corresponding Diebold-Mariano test statistics. Findings – From the estimated forward premiums, it is found that there is more volatility toward the date of maturity for a three-month horizon compared to six-month, and 12-month horizons. It is established that the futures prices of sugar, when used in a model, are able to generate better forecasts for the future spot prices. Moreover, the forecasting accuracy is found to be better for a shorter futures horizon. Research limitations/implications – The present study is restricted only to sugar. If sufficient data are available, the same study could be extended to other commodities as well. The findings imply that technical traders would benefit by using advanced forecasting techniques along with futures prices of sugar to determine the expected future spot prices. Practical implications – The findings in this paper suggest that though simple statistical models may be adopted to relate future spot prices to futures prices, more accurate prediction of the price behavior is possible with advanced forecasting methods like the artificial neural network. Social implications – The findings will help market participants such as traders to be better informed about the future spot prices and hence get a better deal. Originality/value – This is one of the first investigations to assess the predictability of commodity futures by employing advanced forecasting techniques.","https://www.proquest.com/docview/2076937378?accountid=12870&bdid=124553&_bd=9QzD8aBFkVd%2BKHaQyHTpKAL7xz8%3D","https://doi.org/10.1108/AFR-02-2014-0002"
"Bond Risk Premiums with Machine Learning","","Bianchi, Daniele; Büchner, Matthias; Tamoni, Andrea","The Review of Financial Studies","Scholarly Journals","","34","2","2021-02-01","Feb 2021","1046","1089","1046-1089","08939454","","","ENG","We show that machine learning methods, in particular, extreme trees and neural networks (NNs), provide strong statistical evidence in favor of bond return predictability. NN forecasts based on macroeconomic and yield information translate into economic gains that are larger than those obtained using yields alone. Interestingly, the nature of unspanned factors changes along the yield curve: stock- and labor-market-related variables are more relevant for short-term maturities, whereas output and income variables matter more for longer maturities. Finally, NN forecasts correlate with proxies for time-varying risk aversion and uncertainty, lending support to models featuring both channels.","https://www.proquest.com/docview/3238286564?accountid=12870&bdid=124553&_bd=eNzGMxw7x2RT6mAjw8%2F1GCqKibk%3D","https://doi.org/10.1093/rfs/hhaa062"
"Navigating the Complexity of Money Laundering: Anti–money Laundering Advancements with AI/ML Insights","","Gandhi, Hitarth; Tandon, Kevin; Gite, Shilpa; Pradhan, Biswajeet; Alamri, Abdullah","International Journal on Smart Sensing and Intelligent Systems","Scholarly Journals","","17","1","2024-01-01","2024","","","","11785608","","","ENG","This study explores the fusion of artificial intelligence (AI) and machine learning (ML) methods within anti–money laundering (AML) frameworks using data from the US Treasury’s Financial Crimes Enforcement Network (FinCEN). ML and deep learning (DL) algorithms—such as random forest classifier, elastic net regressor, least absolute shrinkage and selection operator (LASSO) regression, gradient boosting regressor, linear regression, multilayer perceptron (MLP) classifier, convolutional neural network (CNN), random forest regressor, and K-nearest neighbor (KNN)—were used to forecast variables such as state, year, and transaction types (credit card and debit card). Hyperparameter tuning through grid search and randomized search was used to optimize model performance. The results demonstrated the efficacy of AI/ML algorithms in predicting temporal, spatial, and industry-specific money-laundering patterns. The random forest classifier achieved 99.99% average accuracy in state prediction, while the gradient boosting regressor and random forest classifier excelled in predicting year and state simultaneously, and credit card transactions, respectively. MLP and CNN showed promise in the context of debit card transactions. The gradient boosting regressor performed competitively with low mean squared error (MSE) (2.9) and the highest R-squared (R2) value of 0.24, showcasing its pattern-capturing proficiency. Logistic regression and random forest classifier performed well in predicting credit card transactions, with area under the receiver operating characteristic curve (ROC_AUC) scores of 0.55 and 0.53, respectively. For debit card prediction, MLP achieved a precision of 0.55 and recall of 0.42, while CNN showed a precision of 0.6 and recall of 0.54, highlighting their effectiveness. The study recommends interpretability, hyperparameter optimization, specialized models, ensemble methods, data augmentation, and real-time monitoring for improved adaptability to evolving financial crime patterns. Future improvements could include exploring the integration of blockchain technology in AML.","https://www.proquest.com/docview/3089917777?accountid=12870&bdid=124553&_bd=T4M3YatvJX0s3ZZXLEUdZq3IjEc%3D","https://doi.org/10.2478/ijssis-2024-0024"
"Out-of-Sample Predictability of the Equity Risk Premium","","de Almeida, Daniel; de Almeida, Daniel; Ana-Maria Fuertes; Ana-Maria Fuertes; Hotta, Luiz Koodi; Hotta, Luiz Koodi; Hotta, Luiz Koodi","Mathematics","Scholarly Journals","","13","2","2025-01-01","2025","257","","","22277390","","","ENG","A large set of macroeconomic variables have been suggested as equity risk premium predictors in the literature. Acknowledging the different predictability of the equity premium in expansions and recessions, this paper proposes an approach that combines equity premium forecasts from two-state regression models using an agreement technical indicator as the observable state variable. A comprehensive out-of-sample forecast evaluation exercise based on statistical and economic loss functions demonstrates the superiority of the proposed approach versus combined forecasts from linear models or Markov switching models and forecasts from machine learning methods such as random forests and gradient boosting. The parsimonious state-dependent aspect of risk premium forecasts delivers large improvements in forecast accuracy. The results are robust to sub-period analyses and different investors’ risk aversion levels.","https://www.proquest.com/docview/3159526089?accountid=12870&bdid=124553&_bd=3uAt1exn8%2Bj56gEqGXVQY4fh%2FYs%3D","https://doi.org/10.3390/math13020257"
"Application of QGA-BP Neural Network in Debt Risk Assessment of Government Platforms","","Li, Qingping; Liu, Ming; Zhang, Yao","International Journal of Information Technology and Web Engineering","Scholarly Journals","","19","1","2024-01-01","2024","1","18","1-18","1554-1045","","","ENG","How to correctly understand the existence of local government debt, study its risk classification and impact, give full play to the “dual nature” of debt with a full-caliber indicator system, and avoid debt risks to the greatest extent. That is the research direction of this article. In order to improve the accuracy and efficiency of risk assessment and effectively reduce the debt risk of government platform companies, a risk assessment method based on optimized back-propagation (BP) neural network is proposed. First, the method uses quantum genetic algorithm (quantum genetic algorithm, QGA) to adjust and determine the initial weight and threshold of BP neural network and realize the optimization of BP neural network model parameter setting. Then, the QGA-BP debt risk assessment of government platforms is verified that it performs well in the debt risk prediction of government platform companies, and its prediction accuracy and prediction speed are improved.","https://www.proquest.com/docview/2907996472?accountid=12870&bdid=124553&_bd=NH23vAH58UIeMCJkmZXSbyBtqoU%3D","https://doi.org/10.4018/IJITWE.335124"
"A semiparametric model for the systematic factors of portfolio credit risk premia","","Giammarino, Flavia; Barrieu, P","Journal of empirical finance","Undefined","","16","4","2009-09-01","Sep 2009","655","670","655-670","0927-5398","0927-5398","","ENG","The aim of this paper is to investigate the empirical relationship between daily fluctuations in the risk premium for holding a large diversified credit portfolio, which we approximate by a benchmark credit index, and some tradeable market factors which capture systematic risk. The analysis is based on an adaptive nonparametric modelling approach which allows for the data-driven estimation of the nonlinear dynamic relationship between portfolio credit risk premia and their hypothetical components. Our main finding is that the empirical weights of the systematic factors display sudden jumps during market crises and a less intense time-dependent behaviour during normal market conditions. In addition, we find that during market crises the directions of the empirical relationships are often inconsistent with ordinary economic intuition, as they are influenced by the specific circumstances of financial markets distress. All rights reserved, Elsevier","https://www.proquest.com/docview/37191047?accountid=12870&bdid=124553&_bd=1I%2BtLACISHZ6y8jIre8%2FpDKfbKY%3D","https://doi.org/10.1016/j.jempfin.2009.05.001"
"Counting the investor vote: political business cycle effects on sovereign bond spreads in developing countries","","Vaaler, Paul M; Schrage, Burkhard N; Block, Steven A","Journal of international business studies","Undefined","","36","1","2005-01-01","Jan 2005","62","88","62-88","0047-2506","0047-2506","","ENG","International business research has paid scant attention to whether and how electoral politics and economic policies affect foreign investment risk assessment, particularly in developing countries, where the last decade has seen both considerable foreign investment and domestic progress toward democratization and electoral competitiveness. We respond with development and testing of a framework using partisan and opportunistic political business cycle (PBC) theory to predict the investment risk perceived by investors holding sovereign bonds during 19 presidential elections in 12 developing countries from 1994 to 2000. Consistent with our framework, we find that bondholders perceive higher (lower) investment risk in the form of higher (lower) credit spreads on their sovereign bonds as right-wing (left-wing) political incumbents appear more likely to be replaced by left-wing (right-wing) challengers. For international business research, our findings illustrate the promise of PBC theory in explaining the election-period behavior of sovereign bondholders and, perhaps, other investors who also 'vote' in developing country elections and can substantially influence the price and availability of capital there. For developing country investors and states, our findings highlight the financial effects of democracy in action, and underscore the importance of state communication with investors during election periods. Reprinted by permission of Palgrave Macmillan Ltd.","https://www.proquest.com/docview/38122112?accountid=12870&bdid=124553&_bd=o2Swd2nCX%2Bx8uYsEbDUNeCVwvZc%3D",""
"Machine-Learning-Based Return Predictors and the Spanning Controversy in Macro-Finance","","Huang, Jing-Zhi; Shi, Zhan","Management Science","Scholarly Journals","","69","3","2023-03-01","Mar 2023","1780","","","00251909","","","ENG","We propose a two-step machine learning algorithm-the Supervised Adaptive Group LASSO (SAGLasso) method-that is suitable for constructing parsimonious return predictors from a large set of macro variables. We apply this method to government bonds and a set of 917 macro variables and construct a new, transparent, and easy-to-interpret macro variable with significant out-of-sample predictive power for excess bond returns. This new macro factor, termed the SAGLasso factor, is a linear combination of merely 30 selected macro variables out of 917. Furthermore, it can be decomposed into three sublevel factors: a novel housing factor, an employment factor, and an inflation factor. Importantly, the predictive power of the SAGLasso factor is robust to bond yields, namely, the SAGLasso factor is not spanned by bond yields. Moreover, we show that the unspanned variation of the SAGLasso factor cannot be attributed to yield measurement error or macro measurement error. The SAGLasso factor therefore provides a potential resolution to the spanning controversy in the macro-finance literature.","https://www.proquest.com/docview/2787670940?accountid=12870&bdid=124553&_bd=%2Bha%2BGm0p65KTl4RKmD14iJ4q7Tc%3D","https://doi.org/10.1287/mnsc.2022.4386"
"The role of supervised learning in the decision process to fair trade US municipal debt","","Dash, Gordon H; Kajiji, Nina; Vonella, Domenic","EURO Journal on Decision Processes","Scholarly Journals","","6","1-2","2018-06-01","Jun 2018","139","168","139-168","21939438","","","ENG","Determining a fair price and an appropriate timescale to trade municipal debt is a complex decision. This research uses data informatics to explore transaction characteristics and trading activity of investment grade US municipal bonds. Using the relatively recent data stream distributed by the Municipal Securities Rulemaking Board, we provide an institutional summary of market participants and their trading behavior. Subsequently, we focus on a sample of AAA bonds to derive a new methodology to estimate a trade-weighted benchmark municipal yield curve. The methodology integrates the study of ridge regression, artificial neural networks, and support vector regression. We find an enhanced radial basis function artificial neural network outperforms alternate methods used to estimate municipal term structure. This result forms the foundation for establishing a decision theory on optimal municipal bond trading. Using multivariate modeling of a liquidity domain measured across three dependent variables, we investigate the proposed decision theory by estimating weekly production-theoretic bond liquidity returns to scale. Across the three liquidity measures and for almost all weeks investigated, bond trading liquidity is elastic with respect to the modeled factors. This finding leads us to conclude that an optimal trading policy for municipal debt can be implemented on a weekly timescale using the elasticity estimates of bond price, trade size, risk, days-to-maturity, and the macroeconomic influences of labor in the workforce and building activity.","https://www.proquest.com/docview/2009849722?accountid=12870&bdid=124553&_bd=uJm5cejvPqDIwFbXjGxFCjjo550%3D","https://doi.org/10.1007/s40070-018-0079-2"
"Risk Assessments and Risk Premiums in the Eurodollar Market","","Feder, Gershon; Ross, Knud","Journal of Finance","Undefined","Wiley-Blackwell, 111 River Street Hoboken NJ 07030-5774 United States","37","3","1982-06-01","Jun 1982","679","691","679-691","0022-1082","1540-6261","","ENG","Increasing awareness of the potential risks involved in lending to heavily indebted governments focuses attention on credit pricing in the Eurodollar market. This paper utilizes a recent survey of country-by-country risk assessments as perceived by lenders to show that a systematic relationship exists between these assessments and interest rates in the Euromarket. The relationship is derived from an underlying model described in the paper. The estimated parameters verify a number of hypotheses, providing insights on the loss rates lenders expect to incur in case of default.","https://www.proquest.com/docview/1032898151?accountid=12870&bdid=124553&_bd=78uZ7%2FQw%2B9cWcKfrV36ezadYopg%3D","https://doi.org/10.1111/j.1540-6261.1982.tb02217.x"
"A Comparison of Risk-Premium Forecasts Implied by Parametric Versus Nonparametric Conditional Mean Estimators","","McCurdy, Thomas H; Stengos, Thanasis","Journal of Econometrics","Scholarly Journals","","51","1,2","1992-04-01","Apr/May 1992","225","","225","03044076","","","ENG","Parametric estimates of a time-varying risk premium model are computed.  The one-step-ahead forecasts implied by that model are compared with those given by a nonparametric kernel estimator of the conditional mean function.  The conditioning information used for the nonparametric analysis is that implied by the theoretical model of time-varying risk.  Thus, the kernel estimator is used, in conjunction with a nonparametric diagnostic test for in-sample residual nonlinear structure, to assess the adequacy of the parametric model in capturing any structure in the excess returns.  The results support the parametric specification of an asset pricing model in which the conditional beta is the ratio of the relevant components of the conditional covariance matrix of returns modeled as a bivariate generalized ARCH (autoregressive conditional heteroskedasticity) process.  The parametric estimator of the risk premia has somewhat more out-of-sample forecasting ability than does the kernel estimator.","https://www.proquest.com/docview/196612950?accountid=12870&bdid=124553&_bd=wXLf%2FajHRRyQ2WMC10F3l9bHZ5Q%3D",""
"The efficacy of neural networks in predicting returns on stock and bond indices","","Desai, Vijay S; Bharati, Rakesh","Decision Sciences","Scholarly Journals","","29","2","1998-04-01","Spring 1998","405","","405-425","00117315","","","ENG","Two recently developed tests are used to identify neglected nonlinearity in the relationship between excess returns on 4 asset classes and several economic and financial variables.  Having found some evidence of possible nonlinearity, it was then investigated whether the predictive power of these variables could be enhanced by using neutral network models instead of liner regression or GARCH models.  Some evidence of nonlinearity in the relationships between the explanatory variables and large stocks and corporate bonds was found.  It was also found that the GARCH models are conditionally efficient with respect to neural network models, but the neural network models outperform GARCH models if financial performance measures are used.  It was found that the neural network forecasts are conditionally efficient with respect to linear regression models for large stocks and corporate bonds, whereas the evidence is not statistically significant for small stocks and intermediate-term government bonds.","https://www.proquest.com/docview/198104885?accountid=12870&bdid=124553&_bd=4tUrTqRAwxGGbqvy55%2Bn8DGv884%3D",""
"Economic Evaluation and Risk Premium Estimation of Rainfed Soybean under Various Planting Practices in a Semi-Humid Drought-Prone Region of Northwest China","","Liao, Zhenqi; Pei, Shengzhao; Bai, Zhentao; Lai, Zhenlin; Wen, Lei; Zhang, Fucang; Li, Zhijun; Fan, Junliang","Agronomy","Undefined","Multidisciplinary Digital Publishing Institute","13","11","2023-11-18","Nov 18, 2023","","","","2073-4395","2073-4395","","ENG","Economic benefits and risk premiums significantly affect the production system decision making of farmers and government departments. This study evaluated the economic feasibility and estimated the risk premium of 12 rainfed soybean production systems with various planting densities, fertilization rates and planting patterns by considering the impact of soybean price fluctuation. There were two planting densities (D₁: 160,000 plants ha⁻¹ and D₂: 320,000 plants ha⁻¹), two fertilization rates (F₁: 20 kg ha⁻¹ N, 30 kg ha⁻¹ P, 30 kg ha⁻¹ K; F₂: 40 kg ha⁻¹ N, 60 kg ha⁻¹ P, 60 kg ha⁻¹ K) and three planting patterns (F+W₀: flat cultivation with no irrigation; R+W₀: plastic-mulched ridge-furrow cultivation (PMRF) with no irrigation; R+W₁: PMRF with supplemental irrigation of 30 mm at the pod-filling stage). Based on the two-year (2019–2020) field data in a semi-humid drought-prone region of northwest China and soybean price fluctuation from January 2014 to June 2021, the net income (NI) was calculated by considering the impact of soybean price fluctuation and assuming constant soybean production costs. The net present value (NPV) method and the stochastic efficiency with respect to a function (SERF) method were used to evaluate the profitability of protective alternatives and the risk of these alternatives. The results showed that the 12 proposed soybean production systems were economically feasible. Reducing the fertilization rate reduced the input costs, but it did not necessarily result in a decrease in soybean yield and NI. The payback period of all production systems was within two years for farmers investing through loans. High-fertilizer and high-density production systems made personal investment obtain the highest economic benefit in this study, which was not the best investment strategy from the perspective of production-to-investment ratio and environmental protection departments. The preferences of farmers with various risk aversion and environmental protection departments in terms of risk premium were also proposed. The economic and risk assessment framework of this study can enhance the understanding of the adjustment of production systems from different perspectives, and provide strategies for promoting the protection of economic, environmental and socially sustainable agricultural systems.","https://www.proquest.com/docview/3040377666?accountid=12870&bdid=124553&_bd=GboXd03YeKhTw6D5e68z5iz01Qs%3D","https://doi.org/10.3390/agronomy13112840"
"Financial Stock Investment Management Using Deep Learning Algorithm in the Internet of Things","","Fan, Jianjuan; Shen, Peng","Computational Intelligence and Neuroscience : CIN","Scholarly Journals","","2022","","2022-01-01","2022","","","","1687-5265","1687-5273","","ENG","This paper aims to explore a new model to study financial stock investment management (SIM) and obtain excess returns. Consequently, it proposes a financial SIM model using deep Q network (DQN) as reinforcement earning (RL) algorithm and Long Short-Term Memory (LSTM) as deep neural network (DNN). Then, after training and optimization, the proposed model is back-tested. The research findings are as follows: the LSTM neural network (NN)-based model will import the observation of the market at each time and the change of transaction information over time. The LSTM network can find and learn the potential relationship between time series data. There are two hidden layers and one output layer in the model. The hidden layer is an LSTM structure and the output layer is the fully connected NN. DQN algorithm first stores the experience sample data of the agent-environment interaction into the experience pool. It then randomly selects a small batch of data from the experience pool to train the network. Doing so removes the correlation and dependence between samples so that the DNN model can better learn the value function in the RL task. The model can predict the future state according to historical information and decide which actions to take in the next step. Meanwhile, five stocks of Chinese A-shares are selected to form an asset pool. The initial 500,000 amount of the account is divided into five equal shares, which are invested and traded. Overall, the model account’s rate of return (RoR) during the back-test is 32.12%. The Shanghai Stock Exchange (SSI) has risen by 19.157% in the same period. Thus, the model’s performance has exceeded the SSI’s in the same period. E stock has the maximum RoR of 78.984%. The RoR of A, B, and C stocks is 54.129%, 11.594%, and 9.815%, respectively. B stock presents a minimum RoR of 6.084%. All these stocks have got positive returns. Therefore, the proposed financial SIM based on the DL algorithm is scientific and feasible. The research content has certain significant reference for the DL-based financial SIM.","https://www.proquest.com/docview/2693570945?accountid=12870&bdid=124553&_bd=a8HvzRW7EkKP1EBUOHKlxZh59Ok%3D","https://doi.org/10.1155/2022/4514300"
"Combining heterogeneous classifiers for stock selection","","Albanis, George; Batchelor, Roy","Intelligent Systems in Accounting, Finance and Management","Scholarly Journals","","15","1/2","2007-01-01","Jan-Jun 2007","1","","","15501949","","","ENG","Combining unbiased forecasts of continuous variables necessarily reduces the forecast error variance below that of a typical individual forecast. However, this does not necessarily hold for forecasts of discrete variables, or where the costs of errors are not directly related to the error variance. This paper investigates the benefits of combining forecasts of outperforming shares, based on one linear and four non-linear statistical classification techniques, including neural network and recursive partitioning methods. All produce excess returns. Combining by simple 'majority voting' improves accuracy and profitability. Much greater gains come from applying the 'unanimity principle', whereby a share is not held in the high-performing portfolio unless all classifiers agree. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/214382190?accountid=12870&bdid=124553&_bd=VZDXn%2F2voqS3Ax3THTmPbOc6t%2B0%3D",""
"Examination and Modification of Multi-Factor Model in Explaining Stock Excess Return with Hybrid Approach in Empirical Study of Chinese Stock Market","","Liu, Huazhang","Journal of Risk and Financial Management","Scholarly Journals","","12","2","2019-01-01","2019","91","","","19118066","","","ENG","To search significant variables which can illustrate the abnormal return of stock price, this research is generally based on the Fama-French five-factor model to develop a multi-factor model. We evaluated the existing factors in the empirical study of Chinese stock market and examined for new factors to extend the model by OLS and ridge regression model. With data from 2007 to 2018, the regression analysis was conducted on 1097 stocks separately in the market with computer simulation based on Python. Moreover, we conducted research on factor cyclical pattern via chi-square test and developed a corresponding trading strategy with trend analysis. For the results, we found that except market risk premium, each industry corresponds differently to the rest of six risk factors. The factor cyclical pattern can be used to predict the direction of seven risk factors and a simple moving average approach based on the relationships between risk factors and each industry was conducted in back-test which suggested that SMB (size premium), CMA (investment growth premium), CRMHL (momentum premium), and AMLH (asset turnover premium) can gain positive return.","https://www.proquest.com/docview/2548589692?accountid=12870&bdid=124553&_bd=n31MRJhYJZTE8eWtx6bfLEYBPZg%3D","https://doi.org/10.3390/jrfm12020091"
"Probabilistic forecasts of volatility and its risk premia","","Maneesoonthorn, Worapree; Martin, Gael M; Forbes, Catherine S; Grose, Simone D","Journal of econometrics","Undefined","Elsevier B.V.","171","2 p.217-236","2012-12-01","Dec 2012","217","236","p. 217-236","0304-4076","0304-4076","","ENG","The object of this paper is to produce distributional forecasts of asset price volatility and its associated risk premia using a non-linear state space approach. Option and spot market information on the latent variance process is captured by using dual ‘model-free’ variance measures to define a bivariate observation equation in the state space model. The premium for variance diffusive risk is defined as linear in the latent variance (in the usual fashion) whilst the premium for variance jump risk is specified as a conditionally deterministic dynamic process, driven by a function of past measurements. The inferential approach adopted is Bayesian, implemented via a Markov chain Monte Carlo algorithm that caters for the multiple sources of non-linearity in the model and for the bivariate measure. The method is applied to spot and option price data on the S&P500 index from 1999 to 2008, with conclusions drawn about investors’ required compensation for variance risk during the recent financial turmoil. The accuracy of the probabilistic forecasts of the observable variance measures is demonstrated, and compared with that of forecasts yielded by alternative methods. To illustrate the benefits of the approach, it is used to produce forecasts of prices of derivatives on volatility itself. In addition, the posterior distribution is augmented by information on daily returns to produce value at risk predictions. Linking the variance risk premia to the risk aversion parameter in a representative agent model, probabilistic forecasts of (approximate) relative risk aversion are also produced.","https://www.proquest.com/docview/1705441018?accountid=12870&bdid=124553&_bd=nH4iR%2FwNn330K1jFEaUFJi%2F3pqQ%3D","https://doi.org/10.1016/j.jeconom.2012.06.006"
"Asset Returns Under Model Uncertainty: Evidence from the Euro Area, the US and the UK","","Sousa, João M; Sousa, Ricardo M","Computational Economics","Scholarly Journals","","54","1","2019-06-01","Jun 2019","139","176","139-176","09277099","","","ENG","We analyze predictability of risk premium in the context of model uncertainty. Using data for the euro area, the US and the UK, we show that there is a large amount of model uncertainty and one can improve the forecasts of stock returns with a Bayesian Model Averaging (BMA) approach. The empirical evidence for the euro area suggests that several macroeconomic, financial and macro-financial variables are consistently among the most prominent determinants of risk premium. As for the US, only a few number of predictors play an important role. In the case of the UK, future stock returns are better forecasted by financial variables. These results are corroborated for both the M-open and the M-closed perspectives, different model priors and in the context of “in-sample” and “out-of-sample” forecasting. Finally, we highlight that the predictive ability of the BMA framework is stronger at longer periods, and clearly outperforms the constant expected returns and the autoregressive benchmark models.","https://www.proquest.com/docview/2223101269?accountid=12870&bdid=124553&_bd=uVR1MjKEbJfxiG2n7jRQbETIF1k%3D","https://doi.org/10.1007/s10614-017-9696-2"
"DEEP NEURAL NETWORKS METHODS FOR ESTIMATING MARKET MICROSTRUCTURE AND SPECULATIVE ATTACKS MODELS: THE CASE OF GOVERNMENT BOND MARKET","","ALAMINOS, DAVID; SALAS, MARÍA BELÉN; FERNÁNDEZ-GÁMEZ, MANUEL A","The Singapore Economic Review","Scholarly Journals","","70","4","2025-06-01","Jun 2025","","","","02175908","","","ENG","A sovereign bond market offers a wide range of opportunities for public and private sector financing and has drawn the interest of both scholars and professionals as they are the main instrument of most fixed-income asset markets. Numerous works have studied the behavior of sovereign bonds at the microeconomic level, given that a domestic securities market can enhance overall financial stability and improve financial market intermediation. Nevertheless, they do not deepen methods that identify liquidity risks in bond markets. This study introduces a new model for predicting unexpected situations of speculative attacks in the government bond market, applying methods of deep learning neural networks, which proactively identify and quantify financial market risks. Our approach has a strong impact in anticipating possible speculative actions against the sovereign bond market and liquidity risks, so the aspect of the potential effect on the systemic risk is of high importance.","https://www.proquest.com/docview/3229684290?accountid=12870&bdid=124553&_bd=yfZ5IDaSbmliJWiFm7KxjLjOWnY%3D","https://doi.org/10.1142/S0217590822480034"
"Estimating global bank network connectedness","","Demirer, Mert; Diebold, Francis X; Liu, Laura; Yilmaz, Kamil","Journal of Applied Econometrics","Scholarly Journals","","33","1","2018-01-01","Jan/Feb 2018","1","15","1-15","08837252","","","ENG","We use LASSO methods to shrink, select, and estimate the high‐dimensional network linking the publicly traded subset of the world's top 150 banks, 2003–2014. We characterize static network connectedness using full‐sample estimation and dynamic network connectedness using rolling‐window estimation. Statically, we find that global bank equity connectedness has a strong geographic component, whereas country sovereign bond connectedness does not. Dynamically, we find that equity connectedness increases during crises, with clear peaks during the Great Financial Crisis and each wave of the subsequent European Debt Crisis, and with movements coming mostly from changes in cross‐country as opposed to within‐country bank linkages.","https://www.proquest.com/docview/2006700647?accountid=12870&bdid=124553&_bd=%2F6vc%2BWfvnAyo4VGNoMW0knxqVKQ%3D","https://doi.org/10.1002/jae.2585"
"Credit Pit Detection in Subordinate Securities: A French Perspective","","Jain, Sfoorti","Ushus Journal of Business Management","Scholarly Journals","","18","3","2019-01-01","2019","65","","65-85","09753311","","","ENG","The purpose of this research is to prepare a predictive model for identifying credit crisis using an artificial neural network. The paper also aims to find out the driver and driven relationship between various financial instruments like CDS, FRA, IRS, and the Volatility index (VCAC) and government securities for France. The model, thus, is directed towards finding a threshold for credit pit events and linking various events corresponding to that dates where the threshold is breached to validate the accuracy and usefulness of the model. From the research, it is found that for France, the CDS-FRA-VCAC model derives the threshold for VCAC to indicate the probability of credit crisis or financial market crash. It is also found that sovereign bonds have a huge impact on France economy including various derivatives. This is probably why the Eurozone debt crisis impacted France much more than the 2008 financial crash.","https://www.proquest.com/docview/2501471554?accountid=12870&bdid=124553&_bd=EiWpi2wL7t5FzgJhdkFk7VsyX9A%3D","https://doi.org/10.12725/ujbm.48.6"
"Joint Estimation of Factor Sensitivities and Risk Premia for the Arbitrage Pricing Theory; Discussion","","Burmeister, Edwin; McElroy, Marjorie B; Brown, Stephen J","The Journal of Finance","Scholarly Journals","","43","3","1988-07-01","Jul 1988","721","","721","00221082","","","ENG","Both measured and unmeasured factors are used to estimate a linear factor model (LFM), the arbitrage pricing theory (APT), and a capital asset pricing model (CAPM).  The analysis shows that the January effect is an important determinant of expected returns.  A January effect exists that is not explained by the set of factors used.  Including or excluding a January effect has no appreciable influence on these results of nested testing: 1.  The CAPM restrictions on the APT are rejected.  2.  The APT restrictions on the LFM are not rejected.  A similarity between iterated nonlinear weighted least squares and iterated nonlinear seemingly unrelated regressions probably indicates that it is empirically tolerable to assume a diagonal covariance matrix.  In a comment, Brown says this research has developed new and innovative methods of jointly estimating factor sensitivities and risk premia.","https://www.proquest.com/docview/194704942?accountid=12870&bdid=124553&_bd=z2reCjV7noMqoQu0jckplIJCwgk%3D",""
"The Pricing of Interest-Rate Risk: Evidence from the Stock Market","","Sweeney, Richard J; Warga, Arthur D","The Journal of Finance","Scholarly Journals","","41","2","1986-06-01","Jun 1986","393","","393","00221082","","","ENG","The issue of whether firms are required to pay an ex ante premium to investors for bearing the risk of interest-rate changes is considered.  The framework is a 2-factor arbitrage pricing theory model with the market and changes in the yield on long-term government bonds as factors.  Full information maximum likelihood estimation is used on groups of 25 individual firms, with both cross-equation constraints and within-equation nonlinear constraints on the parameters.  Evidence is found that changes in government bond yields clearly affect ex post returns to electric utilities and that this phenomenon is concentrated to a much larger degree in this particular industry than in New York Stock Exchange firms as a whole.  The interest rate factor can be regarded as equal to unanticipated changes in expected inflation plus changes in the real rate of interest.  Several mechanisms, particularly regulatory lags, are considered responsible for the effect.","https://www.proquest.com/docview/194704700?accountid=12870&bdid=124553&_bd=FucdYwWcE%2Bc4s%2FYDxRcB20n6loQ%3D",""
"Risk factors selection with data mining methods for insurance premium ratemaking·","","Omerašević, Amela; Selimović, Jasmina","Zbornik Radova Ekonomski Fakultet u Rijeka","Scholarly Journals","","38","2","2020-01-01","2020","667","696","667-696","1331-8004","","","ENG","Osiguravajuća društva koja su prva usvojila primjenu metoda rudarenja podataka u svom poslovanju postali su konkurentniji na tržištu osiguranja. Metode rudarenja podataka osiguravajućoj industriji pružaju brojne prednosti: kraće vrijeme obrade podataka, sofisticiranije metode za precizniju analizu podataka, bolje donošenje odluka itd. Osiguravajuća društva koriste metode rudarenja podataka u razne svrhe, od marketinških kampanja do sprečavanja prijevara, a med strok signu prvima je ta metoda bila u postupku odred strok signivanja premija osiguranja. Primjena metode rudarenja podataka u ovom radu ima za cilj poboljšati rezultate u procesu izračuna stope premije neživotnih osiguranja. Poboljšanje se ogleda u odabiru varijabli predvid strok signanja ili faktora rizika koji utječu na stope premija osiguranja. Istražene su sljedeće metode rudarenja podataka za odabir varijabli predvid strok signanja: Postepena regresija, Stabla odlučivanja i Neuronske mreže. Za izračun premijskih stopa korišteni su Generalizirani linearni modeli (GLM), koji su danas glavni statistički model odred strok signivanja premija neživotnih osiguranja u većini razvijenih tržišta osiguranja u svijetu.","https://www.proquest.com/docview/2477759617?accountid=12870&bdid=124553&_bd=7G8GCMQHQhqFgOOfx2qZRtc8odc%3D","https://doi.org/10.18045/zbefri.2020.2.667"
"Estimating time-varying risk premia in UK long-term government bonds","","Steeley, J M","Applied Financial Economics","Undefined","Routledge, Inc.","14","5","2004-03-01","Mar 1, 2004","367","373","367-373","0960-3107","0960-3107","","ENG","Simple models of time-varying risk premia are used to measure the risk premia in long-term UK government bonds. The parameters of the models can be estimated using nonlinear seemingly unrelated regression (NL-SUR), which permits efficient use of information across the entire yield curve and facilitates the testing of various cross-sectional restrictions. The estimated time-varying premia are found to be substantially different to those estimated using models that assume constant risk premia.","https://www.proquest.com/docview/17968476?accountid=12870&bdid=124553&_bd=gwliroG13CoPlOudIFxZBhEF%2FgQ%3D",""
"Nonlinearities in the relation between the equity risk premium and the term structure","","Boudoukh, Jacob; Richardson, Matthew; Whitelaw, Robert F","Management Science","Scholarly Journals","","43","3","1997-03-01","Mar 1997","371","","371-385","00251909","","","ENG","The relation between the conditional expected equity risk premium and the slope of the term structure of interest rates is investigated.  Theoretically, these variables are linked, the relation may be nonlinear, and negative risk premiums are consistent with equilibrium.  Given these implications, a nonparametric estimation technique is employed to document the empirical relation between the risk premium and the slope of the term structure using almost 200 years of data.  Of particular interest, the risk premium is increasing in the term structure slope; however, for either small or negative slopes, the risk premium is much more sensitive to changes in interest rates.  In addition, the empirical results imply negative expected equity risk premiums for some inverted term structures.  Variations in the risk premium do not appear to be related to variations in the variance of equity returns.  These features are illustrated in a stylized consumption-based model, and the economic intuition behind the results is provided.","https://www.proquest.com/docview/213162724?accountid=12870&bdid=124553&_bd=eMW85ZTsH01GtohdVhwqJW1%2FCQY%3D",""
"Corrigendum: Bond Risk Premiums with Machine Learning","","Bianchi, Daniele; Büchner, Matthias; Hoogteijling, Tobias; Tamoni, Andrea","The Review of Financial Studies","Scholarly Journals","","34","2","2021-02-01","Feb 2021","1090","1103","1090-1103","08939454","","","ENG","In this note we revisit the empirical results in Bianchi, Büchner, and Tamoni (2020) after correcting for using information not available at the time the forecast was made. Although we note a decrease in out-of-sample $R^2$, the revised analysis confirms that bond excess return predictability from neural networks remains statistically and economically significant.","https://www.proquest.com/docview/3238286620?accountid=12870&bdid=124553&_bd=92NRWaE0qSGlYTnXCg3NSFGOcLc%3D","https://doi.org/10.1093/rfs/hhaa098"
"A non-knotty inflation risk premium model","","Machado Vicente, José Valentim","Applied Economics","Scholarly Journals","","55","28","2023-06-01","Jun 2023","3271","3278","3271-3278","00036846","","","ENG","In this article, I estimate the inflation risk premium (IRP) using a low-dimensional arbitrage-free dynamic model through a novel strategy. Instead of modelling the nominal and real yields jointly, I make assumptions about the short-term inflation rate. More specifically, I assume it follows a Gaussian process. This framework has a closed-form expression for IRP. Since inflation yields are not observed, to estimate the model parameters I approximate them by the break-even inflation rate. This approximation works well because the convexity correction is very small. I find that the estimated IRP is strongly correlated with those obtained using surveys or more complex models. Therefore, I provide an easier procedure to obtain IRP, avoiding the cumbersome estimation process of high-order models.","https://www.proquest.com/docview/2805748754?accountid=12870&bdid=124553&_bd=WGgVn5UYB5dGdHIIcwtr%2BeW7O%2B0%3D","https://doi.org/10.1080/00036846.2022.2111023"
"Risks and risk premiums of GE corn: A macromarketing framework","","Nganje, William; Fosu","Ecological economics","Undefined","Elsevier B.V.","201 p.107560-","","2022-11-01","Nov 2022","","","","0921-8009","0921-8009","","ENG","It has been more than two decades since genetic engineered (GE) corn has been introduced in the United States and Spain. Despite the wide scale adoption of GE corn, (92% of planted acreage in the US in 2017), biodiversity conservation, environmental protection goals, and food safety continue to surface as potential risk factors. We developed a macromarketing framework to provide a linkage between the consumers, producers, and societal impacts of GE corn. An empirical Arbitrage Pricing Model (APT) was used to quantify risks and risk premiums associated with GE corn production. The risk premium deduced from the APT model provides a measure of intrinsic compensation for taking on higher or lower risks by participants in the marketing system. An Auto-Regressive Distributed Lag (ARDL) regression estimation of the APT model reveals that GE causes corn prices to go down due to increase supply, but significantly reduced the risk premium for producing corn in the United States. GE corn also provided environmental beneficial outcomes by reducing the use of fertilizers.","https://www.proquest.com/docview/2718355870?accountid=12870&bdid=124553&_bd=007NhzUo9Yj0JGsSkkqC%2FN3W%2FsU%3D","https://doi.org/10.1016/j.ecolecon.2022.107560"
"A non-linear dynamic model of the variance risk premium","","Eraker, Bjørn; Wang, Jiakou","Journal of econometrics","Undefined","Elsevier B.V.","187","2 p.547-556","2015-08-01","Aug 2015","547","556","p. 547-556","0304-4076","0304-4076","","ENG","We propose a new class of non-linear diffusion processes for modeling financial markets data. Our non-linear diffusions are obtained as transformations of affine processes. We show that asset-pricing and estimation is possible and likelihood estimation is straightforward. We estimate a non-linear diffusion model for the VIX index under both the objective measure and the risk-neutral measure where the latter is obtained from futures prices. We find evidence of significant non-linearity under both measures. We define the difference between the P and Q drift as a measure of the variance risk premium and show that it has strong predictive power for stock returns.","https://www.proquest.com/docview/2189533828?accountid=12870&bdid=124553&_bd=EnmRWbS9DVc5hdglEIf%2FYgXW3C8%3D","https://doi.org/10.1016/j.jeconom.2015.02.038"
"A comparison of multitask and single task learning with artificial neural networks for yield curve forecasting","","Nunes, Manuel; Gerding, Enrico; McGroarty, Frank; Niranjan, Mahesan","Expert Systems with Applications","Scholarly Journals","","119","","2019-04-01","Apr 1, 2019","362","","","0957-4174","","","ENG","The yield curve is the centrepiece in bond markets, a massive asset class with an overall size of USD 100 trillion that remains relatively under-investigated using machine learning. This paper is the first comprehensive study using artificial neural networks in the context of yield curve forecasting. Specifically, two models were used for forecasting the European yield curve: multivariate linear regression and multilayer perceptron (MLP), at five forecasting horizons, from next day to 20 days ahead. Five variants of the MLP were analysed with different sets of features: target to predict (univariate); the most relevant features; all generated features; and the former two incorporating synthetic data generated by the linear regression model. Additionally, two different techniques of multitask learning were employed: simultaneous modelling and transformation into multiple single task learning. The results show that considering all forecasting horizons, the MLP using the most relevant features achieved the best results and the addition of synthetic data tends to improve accuracy. Furthermore, different targets and forecasting horizons resulted in different relevant features, reinforcing the importance of custom-built models. In the two multitask learning methodologies no clear differentiation could be demonstrated, and several explaining factors are identified. Overall, the outcome is very encouraging for the development of better forecasting systems for fixed income markets.","https://www.proquest.com/docview/2172144173?accountid=12870&bdid=124553&_bd=GQIX3qb%2FzWGMNgh6dQno3jhKgw4%3D","https://doi.org/10.1016/j.eswa.2018.11.012"
"Do macroeconomic factors help in predicting international equity risk premia?: Testing the out-of-sample accuracy of linear and nonlinear forecasts","","Dropsy, Vincent","Journal of Applied Business Research","Scholarly Journals","","12","3","1996-07-01","Summer 1996","120","","120","0892-7626","","","ENG","A study investigates whether macroeconomic variables can improve the predictability of equity risk premia.  Ex ante forecasts of excess returns are generated recursively from both linear regression analysis and nonlinear neural networks.  Empirical results suggest that these forecasts are superior to the random walk predictor at almost all horizons in the US, Japanese, British and German stock markets.  However, there does not appear to be a significant difference between linear and nonlinear forecasts.","https://www.proquest.com/docview/227610028?accountid=12870&bdid=124553&_bd=IM%2Fy3RmOSDC79zS%2FJlue05P%2BAD0%3D",""
"Building Risk into the Mitigation/Adaptation Decisions simulated by Integrated Assessment Models","","Markandya, Anil; De Cian, Enrica; Drouet, Laurent; Polanco-Martínez, Josué M; Bosello, Francesco","Environmental and Resource Economics","Scholarly Journals","","74","4","2019-12-01","Dec 2019","1687","1721","1687-1721","09246460","","","ENG","This paper proposes an operationally simple and easily generalizable methodology to incorporate climate change damage uncertainty into Integrated Assessment Models (IAMs). First uncertainty is transformed into a risk measure by extracting damage distribution means and variances from an ensemble of socio economic and climate change scenarios. Then a risk premium is computed under different degrees of risk aversion, quantifying what society would be willing to pay to insure against the uncertainty of the damages. Our estimates show that the premium for the risk is a potentially significant addition to the “standard average damage”, but highly sensitive to the attitudes toward risk. In the last research phase, the risk premium is incorporated into the climate change damage function of a widely used IAM which shows, consequently, a substantial increase in both mitigation and adaptation efforts, reflecting a more precautionary attitude by the social planner. Interestingly, adaptation is stimulated more than mitigation in the first half of this century, while the situation reverses afterwards.","https://www.proquest.com/docview/2315198985?accountid=12870&bdid=124553&_bd=VqRfY9iHLEQhA6yab3VfNqNmUYA%3D","https://doi.org/10.1007/s10640-019-00384-1"
"Forecasting Government Bond Yields with Neural Networks Considering Cointegration","","Wegener, Christoph; Christian von Spreckelsen; Basse, Tobias; Hans‐Jörg von Mettenheim","Journal of Forecasting","Scholarly Journals","","35","1","2016-01-01","Jan 2016","86","92","86-92","02776693","","","ENG","This paper discusses techniques that might be helpful in predicting interest rates and tries to evaluate a new hybrid forecasting approach. Results of examining government bond yields in Germany and France reported in this study indicate that a hybrid forecasting approach which combines techniques of cointegration analysis with neural network (NN) forecasting models can produce superior results to the use of NN forecasting models alone. The findings documented in this paper could be a consequence of the fact that examining differenced data under certain conditions will lead to a loss of information and that the inclusion of the error correction term from the cointegration model can help to cope with this problem. The paper also discusses some possibly interesting directions for further research. Copyright © 2015 John Wiley & Sons, Ltd.","https://www.proquest.com/docview/2111827351?accountid=12870&bdid=124553&_bd=9XYnIN5%2B%2Ff%2FvvaCaoAjnZ1EZ9cg%3D","https://doi.org/10.1002/for.2385"
"Term Structure Modeling and Forecasting of Government Bond Yields","","Ullah, Wali; Matsuda, Yasumasa; Tsukuda, Yoshihiko","Economic Papers: A Journal of Applied Economics and Policy","Undefined","Wiley-Blackwell Publishing Asia","32","4","2013-12-01","December 2013","535","560","535-560","0812-0439","0812-0439","","ENG","Accurate modelling and precise estimation of the term structure of interest rate are of crucial importance in many areas of finance and macroeconomics as it is the most important factor in the capital market and probably the economy. This study compares the in-sample fit and out-of-sample forecast accuracy of the Cox-Ingersoll-Ross (CIR) and Nelson-Siegel models. For the in-sample fit, there is a significant lack of information on the short-term CIR model. The CIR model should also be considered too poor to describe the term structure in a simulation-based context. It generates a downward slope average yield curve. Contrary to CIR model, Nelson-Siegel model is not only compatible to fit attractively the yield curve but also accurately forecast the future yield for various maturities. Furthermore, the non-linear version of the Nelson-Siegel model outperforms the linearised one. In a simulation-based context, the Nelson-Siegel model is capable to replicate most of the stylised facts of the Japanese market yield curve. Therefore, it turns out that the Nelson-Siegel model (non-linear version) could be a good candidate among various alternatives to study the evolution of the yield curve in Japanese market. Adapted from source document.","https://www.proquest.com/docview/1541995202?accountid=12870&bdid=124553&_bd=IYHLKs9%2BH1vTeYFThXiFV%2Fa5tTA%3D","https://doi.org/10.1111/1759-3441.12046"
"A Comparison of Neural Network, Statistical Methods, and Variable Choice for Life Insurers' Financial Distress Prediction","","Brockett, Patrick L; Golden, Linda L; Jang, Jaeho; Yang, Chuanhou","Journal of Risk and Insurance","Undefined","Blackwell Publishing Ltd., 9600 Garsington Road Oxford OX4 2DQ UK, [URL:http://www.blackwellpublishing.com]","73","3","2006-09-01","Sep 2006","397","419","397-419","0022-4367","1539-6975","","ENG","This study examines the effect of the statistical-mathematical model selected and the variable set considered on the ability to identify financially troubled life insurers. Models considered are two artificial neural network methods (back-propagation and learning vector quantization (LVQ)) and two more standard statistical methods (multiple discriminant analysis and logistic regression analysis). The variable sets considered are the insurance regulatory information system (IRIS) variables, the financial analysis solvency tracking (FAST) variables, and Texas early warning information system (EWIS) variables, and a data set consisting of twenty-two variables selected by us in conjunction with the research staff at TDI and a review of the insolvency prediction literature. The results show that the back-propagation (BP) and LVQ outperform the traditional statistical approaches for all four variable sets with a consistent superiority across the two different evaluation criteria (total misclassification cost and resubstitution risk criteria), and that the twenty-two variables and the Texas EWIS variable sets are more efficient than the IRIS and the FAST variable sets for identification of financially troubled life insurers in most comparisons.","https://www.proquest.com/docview/19529059?accountid=12870&bdid=124553&_bd=vfTF8xFcJ4hrvLL3imXiTVtH2Vk%3D","https://doi.org/10.1111/j.1539-6975.2006.00181.x"
"The Forward Exchange Rate and Macroeconomics","","Stulz, Rene M","Journal of International Economics","Scholarly Journals","","12","3,4","1982-05-01","May 1982","285","","285","00221996","","","ENG","The question of whether the forward exchange rate is an unbiased predictor of the future spot rate has received much attention.  The conventional view - that the risk premium on the forward exchange rate is linked with the net foreign investment of the domestic country - has been strongly challenged.  A new view implies that this risk premium depends on the outside supply of nominal assets.  Frankel (1979) has shown that: 1.  If outside nominal assets exist, the forward rate contains a risk premium, and thus is a biased predictor of the future spot rate.  2.  If the exchange rate is correlated with the value of real assets, again a risk premium exists.  Both the conventional and the new wisdom on the risk premium contained in the forward exchange rate are re-examined.  If the real exchange rate changes through time, the forward rate may contain a risk premium in the absence of outside assets or of a correlation between the exchange rate and the value of real assets.  Exchange rate dynamics that imply that today's exchange rate is correlated with the expected rate of change of the exchange rate or with the expected returns of some risky assets in general imply the existence of a risk premium on the forward exchange rate.  Generally, the risk premium is an increasing function of the correlation of changes in the domestic exchange rate with changes in world real consumption.","https://www.proquest.com/docview/225176564?accountid=12870&bdid=124553&_bd=OIgOLXjD1FG%2Bvlq03rDFYh%2FCoxQ%3D",""
"Forecasting the equity risk premium: the role of technical indicators","","Neely, Christopher J; Rapach, David E; Tu, Jun; Zhou, Guofu","Management science","Undefined","","60","7","2014-07-01","Jul 2014","1772","1791","1772-1791","0025-1909","0025-1909","","ENG","Academic research relies extensively on macroeconomic variables to forecast the U.S. equity risk premium, with relatively little attention paid to the technical indicators widely employed by practitioners. Our paper fills this gap by comparing the predictive ability of technical indicators with that of macroeconomic variables. Technical indicators display statistically and economically significant in-sample and out-of-sample predictive power, matching or exceeding that of macroeconomic variables. Furthermore, technical indicators and macroeconomic variables provide complementary information over the business cycle: technical indicators better detect the typical decline in the equity risk premium near business-cycle peaks, whereas macroeconomic variables more readily pick up the typical rise in the equity risk premium near cyclical troughs. Consistent with this behavior, we show that combining information from both technical indicators and macroeconomic variables significantly improves equity risk premium forecasts versus using either type of information alone. Overall, the substantial countercyclical fluctuations in the equity risk premium appear well captured by the combined information in technical indicators and macroeconomic variables. Reprinted by permission of the Institute for Operations Research and Management Science (INFORMS)","https://www.proquest.com/docview/1554209494?accountid=12870&bdid=124553&_bd=SD39b2NOy74AP2VW6v657w9VAuU%3D",""
"Joint Estimation Of Factor Sensitivities And Risk Premia Fo","","Burmeister, Edwin; McElroy, Marjorie B; Brown, Stephen J","The Journal of Finance","Scholarly Journals","","43","3","1988-07-01","Jul 1988","721","","721","00221082","","","ENG","Both measured and unmeasured factors are used to estimate a linear factor model (LFM), the arbitrage pricing theory (APT), and a capital asset pricing model (CAPM).  The analysis shows that the January effect is an important determinant of expected returns.  A January effect exists that is not explained by the set of factors used.  Including or excluding a January effect has no appreciable influence on these results of nested testing: 1.  The CAPM restrictions on the APT are rejected.  2.  The APT restrictions on the LFM are not rejected.  A similarity between iterated nonlinear weighted least squares and iterated nonlinear seemingly unrelated regressions probably indicates that it is empirically tolerable to assume a diagonal covariance matrix.  In a comment, Brown says this research has developed new and innovative methods of jointly estimating factor sensitivities and risk premia.","https://www.proquest.com/docview/194705488?accountid=12870&bdid=124553&_bd=jZjzAw7SJWFLMU2Qy1tfNRsI5BY%3D",""
"Unconventional Monetary Policy in the Euro Zone","","Driffill, John","Open Economies Review","Scholarly Journals","","27","2","2016-04-01","Apr 2016","387","","387-404","09237992","","","ENG","The European Central Bank adopted a policy of quantitative easing early in 2015, long after the US and UK, and after implementing a succession of measures to increase liquidity in the Euro zone financial markets, none of which proved sufficient eventually. The paper draws out lessons for the Euro zone from US and UK experience. Numerous event studies have been undertaken to uncover the effects of QE on yields on and prices of financial assets. Estimated effects on long-term government bond yields are then converted into the size of the cut in the policy rate that would normally have been needed to produce them. From these implicit cuts in policy rates, estimates of the effect on GDP and inflation are generated. Euro zone QE appears to have had a much smaller effect on bond yields for the core members states than did QE in the US or UK. Therefore its effects on output and inflation are likely to be proportionately smaller. Its effects on long-term government bond yields in periphery members are greater. QE is compressing interest differential among Euro zone member states. The dangers of QE to which various commentators draw attention, that it creates a danger of inflation in the future, that it creates asset price bubbles, that it allows zombie firms and banks to survive, slowing down the process of adjustment, seem remote. Meanwhile it makes a useful contribution to cutting the costs of debt service and allowing member states more fiscal room for maneouvre.","https://www.proquest.com/docview/1771720498?accountid=12870&bdid=124553&_bd=VF%2BjRVElTzTz%2BTTpZceaTgZfWI0%3D","https://doi.org/10.1007/s11079-016-9393-0"
"Credit Debt Default Risk Assessment Based on the XGBoost Algorithm: An Empirical Study from China","","Wang, Jun; Wei, Rong; Zhang, Zhuo; Dong Mei","Wireless Communications & Mobile Computing (Online)","Scholarly Journals","","2022","","2022-01-01","2022","","","","1530-8669","1530-8677","","ENG","The bond market is an important part of China’s capital market. However, defaults have become frequent in the bond market in recent years, and consequently, the default risk of Chinese credit bonds has become increasingly prominent. Therefore, the assessment of default risk is particularly important. In this paper, we utilize 31 indicators at the macroeconomic level and the corporate microlevel for the prediction of bond defaults, and we conduct principal component analysis to extract 10 principal components from them. We use the XGBoost algorithm to analyze the importance of variables and assess the credit debt default risk based on the XGBoost prediction model through the calculation of evaluation indicators such as the area under the ROC curve (AUC), accuracy, precision, recall, and F1-score, in order to evaluate the classification prediction effect of the model. Finally, the grid search algorithm and k-fold cross-validation are used to optimize the parameters of the XGBoost model and determine the final classification prediction model. Existing research has focused on the selection of bond default risk prediction indicators and the application of XGBoost algorithm in default risk prediction. After optimization of the parameters, the optimized XGBoost algorithm is found to be more accurate than the original algorithm. The grid search and k-fold cross-validation algorithms are used to optimize the XGBoost model for predicting the default risk of credit bonds, resulting in higher accuracy of the proposed model. Our research results demonstrate that the optimized XGBoost model has a significantly improved prediction accuracy, compared to the original model, which is beneficial to improving the prediction effect for practical applications.","https://www.proquest.com/docview/2643812718?accountid=12870&bdid=124553&_bd=K8UHoYMG5E74P5SHnmI%2BWKvmnBU%3D","https://doi.org/10.1155/2022/8005493"
"Neural network prediction of crude oil futures using B-splines","","Butler, Sunil; Kokoszka, Piotr; Miao, Hong; Shang, Han Lin","Energy Economics","Scholarly Journals","","94","","2021-02-01","Feb 2021","1","","","01409883","","","ENG","We propose two ways to improve the forecasting accuracy of a focused time-delay neural network (FTDNN) that forecasts the term structure of crude oil futures. Our results show that a convergence based FTDNN makes consistently more accurate predictions than the fixed-epoch FTDNN in Barunik and Malinska (2016). Further, we suggest using basis splines (B-splines), instead of Nelson-Siegel functions, to fit the term structure curves. The empirical results show that the B-spline expansions lead to consistently better 1 and 3 months ahead predictions compared to the convergence based FTDNN. We also explore conditions under which the B-spline based approach may be better for longer-term predictions.","https://www.proquest.com/docview/2522847905?accountid=12870&bdid=124553&_bd=g6nloZab1EDCNo9FtmhW2qKVrug%3D","https://doi.org/10.1016/j.eneco.2020.105080"
"Stock selection with random forest: An exploitation of excess return in the Chinese stock market","","Tan, Zheng; Yan, Ziqin; Zhu, Guangwei","Heliyon","Undefined","","5","8","2019-08-01","Aug 2019","e02310","","e02310","2405-8440","2405-8440","","ENG","In recent years, a variety of research fields, including finance, have begun to place great emphasis on machine learning techniques because they exhibit broad abilities to simulate more complicated problems. In contrast to the traditional linear regression scheme that is usually used to describe the relationship between the stock forward return and company characteristics, the field of finance has experienced the rapid development of tree-based algorithms and neural network paradigms when illustrating complex stock dynamics. These nonlinear methods have proved to be effective in predicting stock prices and selecting stocks that can outperform the general market. This article implements and evaluates the robustness of the random forest (RF) model in the context of the stock selection strategy. The model is trained for stocks in the Chinese stock market, and two types of feature spaces, fundamental/technical feature space and pure momentum feature space, are adopted to forecast the price trend in the long run and the short run, respectively. It is evidenced that both feature paradigms have led to remarkable excess returns during the past five out-of-sample period years, with the Sharpe ratios calculated to be 2.75 and 5 for the portfolio net value of the multi-factor space strategy and momentum space strategy, respectively. Although the excess return has weakened in recent years with respect to the multi-factor strategy, our findings point to a less efficient market that is far from equilibrium.In recent years, a variety of research fields, including finance, have begun to place great emphasis on machine learning techniques because they exhibit broad abilities to simulate more complicated problems. In contrast to the traditional linear regression scheme that is usually used to describe the relationship between the stock forward return and company characteristics, the field of finance has experienced the rapid development of tree-based algorithms and neural network paradigms when illustrating complex stock dynamics. These nonlinear methods have proved to be effective in predicting stock prices and selecting stocks that can outperform the general market. This article implements and evaluates the robustness of the random forest (RF) model in the context of the stock selection strategy. The model is trained for stocks in the Chinese stock market, and two types of feature spaces, fundamental/technical feature space and pure momentum feature space, are adopted to forecast the price trend in the long run and the short run, respectively. It is evidenced that both feature paradigms have led to remarkable excess returns during the past five out-of-sample period years, with the Sharpe ratios calculated to be 2.75 and 5 for the portfolio net value of the multi-factor space strategy and momentum space strategy, respectively. Although the excess return has weakened in recent years with respect to the multi-factor strategy, our findings point to a less efficient market that is far from equilibrium.","https://www.proquest.com/docview/2282501745?accountid=12870&bdid=124553&_bd=D7GD23Q2Dfjy%2BymOdMM26wjeV6E%3D","https://doi.org/10.1016/j.heliyon.2019.e02310"
"A Rigorous Statistical Comparison of Deep Learning Models for US Treasury Yield Prediction","","Rani, Indu; Verma, Neetu; Verma, Chandan Kumar","Operations Research Forum","Scholarly Journals","","6","3","2025-09-01","Sep 2025","103","","103","26622556","","","ENG","The intrinsic nonlinearity and dynamic relationships in interest rate fluctuations present a substantial challenge when forecasting financial time series, particularly US Treasury yields. These intricate relationships are sometimes not adequately captured by traditional econometric models. In recent years, deep learning (DL) methodologies have gained prominence in the financial market, offering advanced predictive capabilities by modeling high-dimensional dependencies and nonlinear interactions inside yield curves. To enhance the predictive accuracy of short-term (13-week) and long-term (5-year) US Treasury yields, this study leverages advanced deep learning models, including convolutional neural networks (CNNs), long short-term memory (LSTM) networks, and gated recurrent units (GRUs). A comprehensive statistical evaluation is performed to assess model performance through key error metrics such as root mean squared error (RMSE), mean squared error (MSE), mean absolute error (MAE), the coefficient of determination (R2), maximum error, and minimum error, as well as SAFE metrics (Sustainability, Accuracy, Fairness, Explainability) for a holistic assessment. To ensure a robust comparison, we employed the paired t-test to determine if the differences in model predictions are statistically significant. Additionally, we analyzed correlation metrics using Pearson and Spearman coefficients, which evaluate the models’ ability to capture both linear dependencies and ranking trends in yield fluctuations. This rigorous framework not only benchmarks the predictive power of each model but also provides deeper insights into their effectiveness in forecasting treasury yields across different time horizons.","https://www.proquest.com/docview/3233593226?accountid=12870&bdid=124553&_bd=VaVBh45mT1EMXCf3cY4%2F7uat%2Bis%3D","https://doi.org/10.1007/s43069-025-00497-y"
"Equity returns of financial institutions and the pricing of interest rate risk","","Staikouras, S K","Applied financial economics","Undefined","","15","7","2005-04-01","Apr 2005","499","508","499-508","0960-3107","0960-3107","","ENG","This study investigates the issue of whether financial intermediaries' common stock returns incorporate a risk premium for their inherent exposure to unexpected changes in interest rates. A wide range of financial institutions is employed to test the hypothesis that the interest rate risk is priced by capital markets. In addition, the above sample is extended by incorporating firms from the non-financial sector. A two-factor model with the market portfolio and the changes in market yields, as exogenously specified risk variables, is employed. The model is estimated via a seemingly unrelated regression estimation (SURE) framework with both cross-equation restrictions and within equation nonlinear constraints on the parameters. The findings indicate that financial institutions' equity returns incorporate a risk premium for their exposure to market yields' surprises. The return generating function of the insurance business could be further explained by an additional factor such as currency movements. It is also empirically supported that the market premium drops out from the estimation process. When commercial and industrial firms are included in the estimation process, the findings unveil a reduction in the magnitude of the interest rate risk premium. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/38137380?accountid=12870&bdid=124553&_bd=TkTfpGAMzxWR6uYgQdhJY8KyTz4%3D",""
"A hybrid novel framework for flood disaster risk control in developing countries based on smart prediction systems and prioritized scenarios","","Akbarian, Hadi; Gheibi, Mohammad https://orcid.org/0000-0003-1987-5790; Hajiaghaei-Keshteli, Mostafa https://orcid.org/0000-0002-9988-2626; Rahmani, Mojtaba https://orcid.org/0000-0002-7979-5904","Journal of environmental management","Undefined","Elsevier Ltd","312 p.114939-","","2022-06-15","Jun 15, 2022","","","","0301-4797","0301-4797","","ENG","A Decision Support System (DSS) is a highly efficient concept for managing complex objects in nature or human-made phenomena. The main purpose of the present study is related to designing and implementation of real-time monitoring, prediction, and control system for flood disaster management as a DSS. Likewise, the problem of statement in the research is correlated to implementation of a system for different climates of Iran as a unique flood control system. For the first time, this study coupled hydrological data mining, Machine Learning (ML), and Multi-Criteria Decision Making (MCDM) as smart alarm and prevention systems. Likewise, it created the platform for conditional management of floods in Iran's different clusters of climates. According to the KMeans clustering system, which determines homogeneity of the hydrology of a specific region, Iran's rainfall is heterogeneous with 0.61 score, which is approved high efficiency of clustering in a vast country such as Iran with four seasons and different climates. In contrast, the relation of rainfall and flood disaster is evaluated by Nearest Neighbors Classification (NNC), Stochastic Gradient Descent (SGD), Gaussian Process Classifier (GPC), and Neural Network (NN) algorithms which have an acceptable correlation coefficient with a mean of 0.7. The machine learning outputs demonstrated that based on valid data existence problems in developing countries, just with verified precipitation records, the flood disaster can be estimated with high efficiency. In the following, Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) method as a Game Theory (GT) technique ranked the preventive flood damages strategies through three social (Se 1), environmental (Se 2), and economic (Se 3) crises scenarios. The solutions of flood disaster management are collected from literature review, and the opinion approves them of 9 senior experts who are retired from a high level of water resource management positions of Iran. The outcomes of the TOPSIS method proved that National announcement for public-institutional participation for rapid response and funding (G1-2), Establishment of delay structures to increase flood focus time to give the animals in the ecosystem the opportunity to escape to the upstream points and to preserve the habitat (G 2–8), and Granting free national financial resources by government agencies in order to rebuild sensitive infrastructure such as railways, hospitals, schools, etc. to the provincial treasury (G3-10) are selected as the best solution of flood management in Social, Environmental, and Economic crises, respectively. Finally, the collected data are categorized in Social, Environmental, and Economic aspects as three dimensions of Sustainable Development Goals (SDGs) and ranked based on the opinion of 32 experts in the five provinces of present case studies.","https://www.proquest.com/docview/2648868455?accountid=12870&bdid=124553&_bd=5B%2BnJNpOulImUmFmMok8BL8xv3o%3D","https://doi.org/10.1016/j.jenvman.2022.114939"
"Exploration of Stock Portfolio Investment Construction Using Deep Learning Neural Network","","Xie, Zizheng; Wang, Yi","Computational intelligence and neuroscience","Undefined","","2022","","2022-01-01","Jan 2022","7957097","","7957097","1687-5273","","","ENG","To study the intelligent and efficient stock portfolio in China's financial market, based on the relevant theories such as deep learning (DL) neural network (NN) and stock portfolio, this study selects 111 stable stocks from the constituent stocks of the China Security Index (CSI) 300 from January 1, 2018, to December 31, 2021, as the research samples. Then, it analyzes these research samples and imports the relevant data of 111 stocks into the DL NN model. The corresponding prediction results of stock prices are obtained. Finally, the stock portfolio model based on DL NN is compared with the data results of the Shanghai Stock Exchange (SSE) 50 Index and CSI 500 Index. The results show that the closing prices of the selected 111 stocks are relatively stable and fluctuate up and down around the horizontal axis, and the positive and negative returns are relatively balanced, roughly between -5% and 5%. There is a phenomenon of fluctuation aggregation to a certain extent. Comparing the prediction results of different models reveals that the prediction results of model c are closest to the actual stock price trend. Comparing the relevant returns of the proposed stock portfolio with other stocks uncovers that the annualized return of the stock portfolio based on the DL NN model is 47.44%. The sharp ratio is 1.52, the maximum pullback is 18.15%, the monthly excess return is 3.11%, and the information ratio is 0.82. Compared with other indexes, the proposed stock portfolio shows the best results. Therefore, the proposal of the stock portfolio based on DL NN provides a theoretical basis for the development of the financial field in the future.To study the intelligent and efficient stock portfolio in China's financial market, based on the relevant theories such as deep learning (DL) neural network (NN) and stock portfolio, this study selects 111 stable stocks from the constituent stocks of the China Security Index (CSI) 300 from January 1, 2018, to December 31, 2021, as the research samples. Then, it analyzes these research samples and imports the relevant data of 111 stocks into the DL NN model. The corresponding prediction results of stock prices are obtained. Finally, the stock portfolio model based on DL NN is compared with the data results of the Shanghai Stock Exchange (SSE) 50 Index and CSI 500 Index. The results show that the closing prices of the selected 111 stocks are relatively stable and fluctuate up and down around the horizontal axis, and the positive and negative returns are relatively balanced, roughly between -5% and 5%. There is a phenomenon of fluctuation aggregation to a certain extent. Comparing the prediction results of different models reveals that the prediction results of model c are closest to the actual stock price trend. Comparing the relevant returns of the proposed stock portfolio with other stocks uncovers that the annualized return of the stock portfolio based on the DL NN model is 47.44%. The sharp ratio is 1.52, the maximum pullback is 18.15%, the monthly excess return is 3.11%, and the information ratio is 0.82. Compared with other indexes, the proposed stock portfolio shows the best results. Therefore, the proposal of the stock portfolio based on DL NN provides a theoretical basis for the development of the financial field in the future.","https://www.proquest.com/docview/2667785818?accountid=12870&bdid=124553&_bd=S1JNgOX%2FFpnYZ2f%2FFjS9xUMRxC4%3D","https://doi.org/10.1155/2022/7957097"
"Stock Selection Using Machine Learning Based on Financial Ratios","","Tsai, Pei-Fen; Cheng-Han, Gao; Yuan, Shyan-Ming","Mathematics","Scholarly Journals","","11","23","2023-01-01","2023","4758","","","22277390","","","ENG","Stock prediction has garnered considerable attention among investors, with a recent focus on the application of machine learning techniques to enhance predictive accuracy. Prior research has established the effectiveness of machine learning in forecasting stock market trends, irrespective of the analytical approach employed, be it technical, fundamental, or sentiment analysis. In the context of fiscal year-end selection, the decision may initially seem straightforward, with December 31 being the apparent choice, as discussed by B. Kamp in 2002. The primary argument for a uniform fiscal year-end centers around comparability. When assessing the financial performance of two firms with differing fiscal year-ends, substantial shifts in the business environment during non-overlapping periods can impede meaningful comparisons. Moreover, when two firms merge, the need to synchronize their annual reporting often results in shorter or longer fiscal years, complicating time series analysis. In the US S&P stock market, misaligned fiscal years lead to variations in report publication dates across different industries and market segments. Since the financial reporting dates of US S&P companies are determined independently by each listed entity, relying solely on these dates for investment decisions may prove less than entirely reliable and impact the accuracy of return prediction models. Hence, our interest lies in the synchronized fiscal year of the TW stock market, leveraging machine learning models for fundamental analysis to forecast returns. We employed four machine learning models: Random Forest (RF), Feedforward Neural Network (FNN), Gated Recurrent Unit (GRU), and Financial Graph Attention Network (FinGAT). We crafted portfolios by selecting stocks with higher predicted returns using these machine learning models. These portfolios outperformed the TW50 index benchmarks in the Taiwan stock market, demonstrating superior returns and portfolio scores. Our study’s findings underscore the advantages of using aligned financial ratios for predicting the top 20 high-return stocks in a mid-to-long-term investment context, delivering over 50% excess returns across the four models while maintaining lower risk profiles. Using the top 10 high-return stocks produced over 100% relative returns with an acceptable level of risk, highlighting the effectiveness of employing machine learning techniques based on financial ratios for stock prediction.","https://www.proquest.com/docview/2899423534?accountid=12870&bdid=124553&_bd=t5IoWCehLjCSKvP%2Fs2iD62S6fYI%3D","https://doi.org/10.3390/math11234758"
"A Machine-Learning-Based Approach for Natural Gas Futures Curve Modeling","","Castello, Oleksandr; Castello, Oleksandr; Resta, Marina","Energies","Scholarly Journals","","16","12","2023-01-01","2023","4746","","","19961073","","","ENG","This work studies the term structure dynamics in the natural gas futures market, focusing on the Dutch Title Transfer Facility (TTF) daily futures prices. At first, using the whole dataset, we compared the in-sample fitting performance of three models: the four-factor dynamic Nelson–Siegel–Svensson (4F-DNSS) model, the five-factor dynamic De Rezende–Ferreira (5F-DRF) model, and the B-spline model. Our findings suggest that B-spline is the method that achieves the best in-line fitting results. Then, we turned our attention to forecasting, using data from 20 January 2011 to 13 May 2022 as the training set and the remaining data, from 16 May to 13 June 2022, for day-ahead predictions. In this second part of the work we combined the above mentioned models (4F-DNSS, 5F-DRF and B-spline) with a Nonlinear Autoregressive Neural Network (NAR-NN), asking the NAR-NN to provide parameter tuning. All the models provided accurate out-of-sample prediction; nevertheless, based on extensive statistical tests, we conclude that, as in the previous case, B-spline (combined with an NAR-NN) ensured the best out-of-sample prediction.","https://www.proquest.com/docview/2829799487?accountid=12870&bdid=124553&_bd=6p1MftjO3fh0foEAFywlAzmtQTA%3D","https://doi.org/10.3390/en16124746"
"Predicting EU energy industry excess returns on EU market index via a constrained genetic algorithm","","Kaucic, Massimiliano","Computational economics","Undefined","","34","2","2009-09-01","Sep 2009","173","193","173-193","0927-7099","0927-7099","","ENG","This article introduces an automated procedure to simultaneously select variables and detect outliers in a dynamic linear model using information criteria as objective functions and diagnostic tests as constraints for the distributional properties of errors. A robust scaling method is considered to take into account the sensitiveness of estimates to abnormal data. A genetic algorithm is developed to these purposes. Two examples are presented where models are designed to produce short-term forecasts for the excess returns of the MSCI Europe Energy sector on the MSCI Europe index and a recursive estimation-window is used to shed light on their predictability performances. In the first application the data-set is obtained by a reduction procedure from a very large number of leading macro indicators and financial variables stacked at various lags, while in the second the complete set of 1-month lagged variables is considered. Results show a promising capability to predict excess sector returns through the selection, using the proposed methodology, of most valuable predictors. Reprinted by permission of Springer","https://www.proquest.com/docview/37197350?accountid=12870&bdid=124553&_bd=qKU3uIYHbJR9YinSMjyPlTs%2BF08%3D","https://doi.org/10.1007/s10614-009-9176-4"
"On the Effects of Sterilized Intervention: An Analysis of Weekly Data","","Rogoff, Kenneth","Journal of Monetary Economics","Scholarly Journals","","14","2","1984-09-01","Sep 1984","133","","133","03043932","","","ENG","Attention is focused on the question of whether sterilized intervention can affect the exchange rate by shifting exchange rate risk between public and private sector portfolios.  An attempt is made to improve on the treatment of time aggregation by using higher frequency (weekly) data to detect a portfolio balance effect in the Canadian dollar/US dollar exchange rate risk premium.  The results, however, are no more definitive than those obtained in studies using lower frequency data.  This study also improves on earlier flexible-exchange-rate, portfolio-balance research by implementing an appropriate instrumental variables technique (2-step, 2-stage least squares).","https://www.proquest.com/docview/205826194?accountid=12870&bdid=124553&_bd=R1p3cvtUA7FpPuL95%2FMxodQtszE%3D",""
"A Study of Stock Market Predictability Based on Financial Time Series Models","","Yu, Yan","Mobile Information Systems","Scholarly Journals","","2022","","2022-01-01","2022","","","","1574-017X","1875-905X","","ENG","In today’s era of economic globalization and financial integration, the stock market is constantly complex, showing many deviations that cannot be explained by classical financial analysis, but at the same time, some classic financial statistical features have striking similarities. This suggests that although the stock market is intricate, there are universal laws that can be found through data mining to find its underlying operating rules. In this paper, we construct financial time series models such as ARIMA, ARCH, and GARCH to predict the stock market price fluctuations and trends. The ARIMA model is used to fit the linear financial time series, and the GARCH model is used to fit the nonlinear time series residuals. The results show that the integrated tree model based on the idea of weight voting has high accuracy in predicting stock market bulls and bears, with XGBoost prediction accuracy up to 96%, and the neural network model is also very effective, with an accuracy rate of over 90%.","https://www.proquest.com/docview/2707457576?accountid=12870&bdid=124553&_bd=p2tXJQnn%2FXuRYbNFoQKs6LydNrE%3D","https://doi.org/10.1155/2022/8077277"
"The impact of uncertainty on aggregate investment spending:","","","Journal of Money, Credit, and Banking","Scholarly Journals","","25","1","1993-02-01","Feb 1993","30","","30","00222879","","","ENG","The view that increases in uncertainty depress investment spending has a long history in economics and is widespread in popular press accounts of the business cycle.  Although the uncertainty-investment relationship has received much attention, there is little consensus about how uncertainty affects investment spending.  A study explores the empirical relationship between uncertainty and aggregate investment spending.  Using the risk premium embedded in the term structure to measure uncertainty about interest rates and other macroeconomic variables, 2 principal conclusions emerge: 1.  Uncertainty has a negative and statistically significant impact on investment spending.  2.  Uncertainty has a larger impact on investment that does the cost of capital ratio or average q.  The first conclusion holds only to the extent that the risk premium provides a satisfactory proxy for uncertainty and the market's interest rate expectations are accurately measured by the Goldsmith-Nagan forecasts.  The 2nd conclusion is conditioned on the assumption that the cost of capital and average q have been accurately measured.","https://www.proquest.com/docview/195360054?accountid=12870&bdid=124553&_bd=FTU8O8QtHeMmv7gfF5QgjncJwa4%3D",""
"Bayesian Factor-adjusted Sparse Regression","","Fan, Jianqing; Jiang, Bai; Sun, Qiang","Journal of econometrics","Undefined","","230","1","2022-09-01","Sep 2022","3","","3-19","0304-4076","0304-4076","","ENG","Many sparse regression methods are based on the assumption that covariates are weakly correlated, which unfortunately do not hold in many economic and financial datasets. To address this challenge, we model the strongly-correlated covariates by a factor structure: strong correlations among covariates are explained by common factors and the remaining variations are interpreted as idiosyncratic components. We then propose a factor-adjusted sparse regression model with both common factors and idiosyncratic components as decorrelated covariates and develop a semi-Bayesian method. Parameter estimation rate-optimality and model selection consistency are established by non-asymptotic analyses. We show on simulated data that the semi-Bayesian method outperforms its Lasso analogue, manifests insensitivity to the overestimates of the number of common factors, pays a negligible price when covariates are not correlated, scales up well with increasing sample size, dimensionality and sparsity, and converges fast to the equilibrium of the posterior distribution. Numerical results on a real dataset of U.S. bond risk premia and macroeconomic indicators also lend strong supports to the proposed method.Many sparse regression methods are based on the assumption that covariates are weakly correlated, which unfortunately do not hold in many economic and financial datasets. To address this challenge, we model the strongly-correlated covariates by a factor structure: strong correlations among covariates are explained by common factors and the remaining variations are interpreted as idiosyncratic components. We then propose a factor-adjusted sparse regression model with both common factors and idiosyncratic components as decorrelated covariates and develop a semi-Bayesian method. Parameter estimation rate-optimality and model selection consistency are established by non-asymptotic analyses. We show on simulated data that the semi-Bayesian method outperforms its Lasso analogue, manifests insensitivity to the overestimates of the number of common factors, pays a negligible price when covariates are not correlated, scales up well with increasing sample size, dimensionality and sparsity, and converges fast to the equilibrium of the posterior distribution. Numerical results on a real dataset of U.S. bond risk premia and macroeconomic indicators also lend strong supports to the proposed method.","https://www.proquest.com/docview/2681449437?accountid=12870&bdid=124553&_bd=aiy%2FvACLN9La2ensBoh%2Bht8nUpc%3D","https://doi.org/10.1016/j.jeconom.2020.06.012"
"Improving the Accuracy of Forecasting the TSA Daily Budgetary Fund Balance Based on Wavelet Packet Transforms","","Karaev, Alan K; Gorlova, Oksana S; Sedova, Marina L; Ponkratov, Vadim V; Shmigol, Nataliya S; Demidova, Svetlana E","Journal of Open Innovation : Technology, Market, and Complexity","Scholarly Journals","","8","3","2022-01-01","2022","107","","","21998531","","","ENG","Improving the accuracy of cash flow forecasting in the TSA is the key to fulfilling government payment obligations, minimizing the cost of maintaining the cash reserve, providing the absence of outstanding debt accumulation, and ensuring investment in various financial instruments to obtain additional income. The article describes a method for improving the accuracy of forecasting a time series composed of daily budgetary fund balances in the TSA, based on its preliminary decomposition using a discrete wavelet packet transform of the Daubechies family. This makes it possible to increase the accuracy of traditional forecasting methods from 80% to more than 96%. The decomposition level varied from one to eight to minimize the mean absolute error and improve the forecasting accuracy. Calculations of statistical tests for adequacy confirm the effectiveness of the proposed method for improving forecasting accuracy. The scientific novelty of the proposed method for improving the forecasting accuracy of time series from daily budgetary fund balances in the TSA lies in proving the need for preliminary timeseries decomposition and subsequent construction of forecasts for the obtained parts, resulting in high forecasting accuracy. The result differs significantly from traditional econometric methods (ARIMA/SARIMA), characterized by a much lower accuracy (50–80%) and a decrease in forecasting accuracy with an increase in the forecast horizon. This article is novel, as it forms a new approach to solving the problem of increasing the efficiency of using budgetary funds, associated with improving the accuracy of forecasting daily budgetary fund balance in the TSA.","https://www.proquest.com/docview/2716549868?accountid=12870&bdid=124553&_bd=pStrqWNwhR5FtfBIBIjlPpidt1g%3D","https://doi.org/10.3390/joitmc8030107"
"Event-based approach for probabilistic agricultural drought risk assessment under rainfed conditions","","Quijano, Juan A; Jaimes, Miguel A; Torres, Marco A; Reinoso, Eduardo; Castellanos, Luisarturo; Escamilla, Jesus; Ordaz, Mario","Natural Hazards","Undefined","Springer Science+Business Media, Van Godewijckstraat 30 Dordrecht 3311 GX Netherlands","76","2","2015-03-01","March 2015","1297","1318","1297-1318","0921-030X","1573-0840","","ENG","An event-based approach for the probabilistic risk assessment of agricultural drought under rainfed conditions to estimate the economic impact is proposed. The risk parameters are evaluated in an event-based probabilistic framework for a set of hazard events; these results are probabilistically integrated including, in a formal way, all uncertainties related to every part of the process. The hazard is defined as a stochastic or historic set of events, collectively exhaustive and mutually exclusive, that describes the spatial distribution, the annual frequency, and the randomness of the hazard intensity. The risk is expressed in different economic terms: the average annual loss (or pure risk premium) and the loss exceedance curve; these metrics are of particular importance for risk retention (financing) schemes or risk transfer instruments. As an illustrative example, this approach is applied to probabilistic drought risk assessment of maize under rainfed conditions in Mexico. These results are the base of further studies in defining strategies for financial protection against agricultural losses and disasters.","https://www.proquest.com/docview/1668265485?accountid=12870&bdid=124553&_bd=zUpTetsoG8Pr7Th4I%2FzHRJW7GlI%3D","https://doi.org/10.1007/s11069-014-1550-4"
"A non-linear dynamic model of the variance risk premium","","Eraker, Bjørn; Wang, Jiakou","Journal of econometrics","Undefined","","187","2","2015-08-01","Aug 2015","547","547","547","0304-4076","0304-4076","","ENG","We propose a new class of non-linear diffusion processes for modeling financial markets data. Our non-linear diffusions are obtained as transformations of affine processes. We show that asset-pricing and estimation is possible and likelihood estimation is straightforward. We estimate a non-linear diffusion model for the VIX index under both the objective measure and the risk-neutral measure where the latter is obtained from futures prices. We find evidence of significant non-linearity under both measures. We define the difference between the P and Q drift as a measure of the variance risk premium and show that it has strong predictive power for stock returns. All rights reserved, Elsevier","https://www.proquest.com/docview/1710255167?accountid=12870&bdid=124553&_bd=e24%2F%2Fp%2FQzd2XUkSuW3U2peMOA0k%3D",""
"Fiscal multipliers in South Africa after the global financial crisis","","van Rensburg, Theo Janse; de Jager, Shaun; Makrelov, Konstantin Hristov","South African Journal of Economic and Management Sciences","Scholarly Journals","","25","1","2022-01-01","2022","n/a","","","10158812","","","ENG","Background: South Africa’s fiscal position has deteriorated considerably over the last 10 years, with debt levels reaching historical highs in the post-apartheid period. National Treasury’s intentions for fiscal consolidation have again drawn attention to the fiscal multiplier literature.Aim: The aim in the study is to calculate the size of fiscal expenditure multipliers over the period 2009 to 2019, taking into account the specific economic conditions and the funding choices of government.Setting: In the study fiscal policy is considered at a time when the debt to gross domestic product (GDP) ratio was rising rapidly.Methods: We use an econometric model to calculate the fiscal multipliers over the past decade. Our estimates take account of the specific fiscal conditions for each year, in particular the changing relationship between debt and the sovereign risk premia as well as the impact of tax increases.Results: The model suggests that the fiscal multiplier declined from 1.5 in 2010 to around zero in 2019 as the debt levels became progressively more unsustainable and large tax increases muted the aggregate demand effects from higher government expenditure.Conclusion: The low fiscal multipliers suggest that fiscal consolidation will be less costly in terms of growth forgone than generally perceived.JEL classification: C50, E62, H62, H63","https://www.proquest.com/docview/2748494173?accountid=12870&bdid=124553&_bd=zs5YTPF6I%2Bwwu9iN8enP6zQ13Jg%3D","https://doi.org/10.4102/sajems.v25i1.4191"
"Predicting EU Energy Industry Excess Returns on EU Market Index via a Constrained Genetic Algorithm","","Kaucic, Massimiliano","Computational Economics","Undefined","Springer-Verlag, Tiergartenstrasse 17 Heidelberg 69121 Germany","34","2","2009-09-01","Sep 2009","173","193","173-193","0927-7099","1572-9974","","ENG","This article introduces an automated procedure to simultaneously select variables and detect outliers in a dynamic linear model using information criteria as objective functions and diagnostic tests as constraints for the distributional properties of errors. A robust scaling method is considered to take into account the sensitiveness of estimates to abnormal data. A genetic algorithm is developed to these purposes. Two examples are presented where models are designed to produce short-term forecasts for the excess returns of the MSCI Europe Energy sector on the MSCI Europe index and a recursive estimation-window is used to shed light on their predictability performances. In the first application the data-set is obtained by a reduction procedure from a very large number of leading macro indicators and financial variables stacked at various lags, while in the second the complete set of 1-month lagged variables is considered. Results show a promising capability to predict excess sector returns through the selection, using the proposed methodology, of most valuable predictors.","https://www.proquest.com/docview/20778568?accountid=12870&bdid=124553&_bd=qUEbVMG23pXwxv9ZeBmCHg1oFnY%3D","https://doi.org/10.1007/s10614-009-9176-4"
"Estimating volatility from ATM options with lognormal stochastic variance and long memory","","Cardinali, Alessandro","Applied financial economics","Undefined","","22","9","2012-05-01","May 2012","733","748","733-748","0960-3107","0960-3107","","ENG","In this article we propose a nonlinear state space representation to model At-The-Money (ATM) implied volatilities and to estimate the unobserved Stochastic Volatility (SVOL) for the underlying asset. We derive a polynomial measurement model relating fractionally cointegrated implied and spot volatilities. We then use our state space representation to obtain Maximum Likelihood (ML) estimates of the short-memory model parameters, and for filtering the fractional spot volatility. We are also able to estimate the average volatility risk premia. We applied our methodology to implied volatilities on eurodollar options, from which we filter the unobserved spot local variance. These data arise from Over The Counter (OTC) transactions that account for high liquidity. For these data, we estimated a positive average volatility risk premia, which is consistent with the Intertemporal Capital Asset Pricing Model (ICAPM) setup of Merton (1973). We also had evidence of highly nonlinear relation between eurodollar spot and implied volatilities. From a methodological and computational point of view, the likelihood function, and all the iterative procedures associated with it, converged uniformly in the parameter space at very little computational expense. We illustrated the effectiveness of our approach by evaluating the approximated Information matrix, the Hotelling's T2 test along with other diagnostic procedures. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/1021120156?accountid=12870&bdid=124553&_bd=1yGPJstCXZmAWdGqx0YlLrzqtHY%3D","https://doi.org/10.1080/09603107.2011.624082"
"Navigating Inflation Challenges: AI-Based Portfolio Management Insights","","Bareith, Tibor; Tatay, Tibor; Tatay, Tibor; Vancsura, László","Risks","Scholarly Journals","","12","3","2024-01-01","2024","46","","","22279091","","","ENG","After 2010, the consumer price index fell to a low level in the EU. In the euro area, it remained low between 2010 and 2020. The European Central Bank has even had to take action against the emergence of deflation. The situation changed significantly in 2021. Inflation jumped to levels not seen for 40 years in the EU. Our study aims to use artificial intelligence to forecast inflation. We also use artificial intelligence to forecast stock index changes. Based on the forecasts, we propose portfolio reallocation decisions to protect against inflation. The forecasting literature does not address the importance of structural breaks in the time series, which, among other things, can affect both the pattern recognition and prediction capabilities of various machine learning models. The novelty of our study is that we used the Zivot–Andrews unit root test to determine the breakpoints and partitioned the time series into training and testing datasets along these points. We then examined which database partition gives the most accurate prediction. This information can be used to re-balance the portfolio. Two different AI-based prediction algorithms were used (GRU and LSTM), and a hybrid model (LSTM–GRU) was also included to investigate the predictability of inflation. Our results suggest that the average error of the inflation forecast is a quarter of that of the stock market index forecast. Inflation developments have a fundamental impact on equity and government bond returns. If we obtain a reliable estimate of the inflation forecast, we have time to rebalance the portfolio until the inflation shock is incorporated into government bond returns. Our results not only support investment decisions at the national economy level but are also useful in the process of rebalancing international portfolios.","https://www.proquest.com/docview/3003396005?accountid=12870&bdid=124553&_bd=fh4TX8vc7WS2XCnQ0A7t5F1iRDI%3D","https://doi.org/10.3390/risks12030046"
"Sentiment lost: the effect of projecting the pricing kernel onto a smaller filtration set","","Sala, Carlo; Barone-Adesi, Giovanni","Stochastic Analysis and Applications","Scholarly Journals","","38","4","2020-01-01","2020","686","707","686-707","07362994","","","ENG","This paper provides a theoretical analysis on the impacts of using a suboptimal information set for the estimation of the pricing kernel and, more in general, for the validity of the fundamental theorems of asset pricing. While inferring the risk-neutral measure from options data provides a naturally forward-looking estimate, extracting the real world measure from historical returns is only partially informative, thus suboptimal with respect to investors’ future beliefs. As a consequence of this disalignment, the two measures no longer share the same nullset, thus distorting the investors’ risk premium and the validity of the pricing measure. From a probabilistic viewpoint, the missing beliefs are totally unaccessible stopping times on the coarser filtration set, so that an absolutely continuous strict local martingale, once projected on it, becomes continuous with jumps. Some empirical examples complete the paper.","https://www.proquest.com/docview/2416042835?accountid=12870&bdid=124553&_bd=EEmmiF9cL6pjaS8sYhY7mm0KA1E%3D","https://doi.org/10.1080/07362994.2019.1711119"
"A Hybrid Vector Autoregressive Model for Accurate Macroeconomic Forecasting: An Application to the U.S. Economy","","Khan Faridoon; Hasnain, Iftikhar; Khan, Imran; Rodrigues, Paulo Canas; Alharbi, Abdulmajeed Atiah; Jeza, Allohibi","Mathematics","Scholarly Journals","","13","11","2025-01-01","2025","1706","","","22277390","","","ENG","Forecasting macroeconomic variables is essential to macroeconomics, financial economics, and monetary policy analysis. Due to the high dimensionality of the macroeconomic dataset, it is challenging to forecast efficiently and accurately. Thus, this study provides a comprehensive analysis of predicting macroeconomic variables by comparing various vector autoregressive models followed by different estimation techniques. To address this, this paper proposes a novel hybrid model based on a smoothly clipped absolute deviation estimation method and a vector autoregression model that combats the curse of dimensionality and simultaneously produces reliable forecasts. The proposed hybrid model is applied to the U.S. quarterly macroeconomic data from the first quarter of 1959 to the fourth quarter of 2023, yielding multi-step-ahead forecasts (one-, three-, and six-step ahead). The multi-step-ahead out-of-sample forecast results (root mean square error and mean absolute error) for the considered data suggest that the proposed hybrid model yields a highly accurate and efficient gain. Additionally, it is demonstrated that the proposed models outperform the baseline models. Finally, the authors believe the proposed hybrid model may be expanded to other countries to assess its efficacy and accuracy.","https://www.proquest.com/docview/3217737749?accountid=12870&bdid=124553&_bd=WrfhJ0lYoX9nHnTmnqwOkeu35Fw%3D","https://doi.org/10.3390/math13111706"
"Are Government Deficits the Prime Cause of Inflation?","","Kohli, Ulrich R; McKibbin, Warwick J","Journal of Policy Modeling","Scholarly Journals","","4","3","1982-11-01","Nov 1982","279","","279","01618938","","","ENG","Wide acceptance of monetarist policy prescriptions has been accompanied by increasing attention to the behavior of monetary aggregates, and it has been accepted that inflation can only be brought under control through stricter control on the rate of monetary expansion.  This analysis hypothesizes that, if government bonds are counted as part of private wealth, government budget deficits are a major cause of inflation.  In that case, the method selected to finance the deficits (monetary expansion or borrowing) is of secondary importance.  As an illustration of the hypothesis, a simple portfolio model is described and incorporated into a model of the Australian economy.  The full model is specified in continuous time, and the full information maximum likelihood method (FIML) is utilized to estimate it.  The model is then used to estimate a number of fiscal shocks.","https://www.proquest.com/docview/196932307?accountid=12870&bdid=124553&_bd=SBH9ePQ6SX0SCpxpXRmD7t0YXGE%3D",""
"Returns to Speculators and the Theory of Normal Backwardation","","Chang, Eric C","The Journal of Finance","Scholarly Journals","","40","1","1985-03-01","Mar 1985","193","","193","00221082","","","ENG","Keynes (1930), in his theory of normal backwardation, argues that hedgers use the futures market to avoid risks, and that they pay a substantial premium to speculators for this insurance.  A nonparametric statistical procedure, adapted from a procedure developed by Merton (1981) and Henriksson and Merton (1981), is used to examine the existence of a positive profit to speculators in wheat, corn, and soybean futures markets.  Attention is focused on the form in which such profits are rewarded.  For all contracts, semimonthly price quotations on the Chicago Board of Trade were collected for the period July 15, 1951-June 30, 1972.  Monthly quotations were obtained for December 31, 1972-December 31, 1980.  The results provide support for the theory of backwardation.  It is shown that the validity of the theory seems to be in different degrees in different markets and in different periods.  The presence of such risk premiums appears to be more prominent in recent years than in earlier years.  The results are inconsistent with the hypothesis that commodity futures prices are unbiased estimates of the corresponding future spot prices.","https://www.proquest.com/docview/194705386?accountid=12870&bdid=124553&_bd=IGyHiTkebh4PmlyFZtyZ1%2FAC6A0%3D",""
"Prediction of US 30‐years‐treasury‐bonds movement and trading entry point using the robust 1DCNN‐BiLSTM‐XGBoost algorithm","","El Zaar, Abdellah; Benaya, Nabil; Bakir, Toufik; Mansouri, Amine; El Allati, Abderrahim","Expert Systems","Scholarly Journals","","41","1","2024-01-01","Jan 2024","","","","02664720","","","ENG","This article presents a novel algorithm that accurately predicts market trends and identifies trading entry points for US 30‐year Treasury bonds. The proposed method employs a hybrid approach, integrating a 1‐dimensional convolutional neural network (1DCNN), long‐short term memory (LSTM), and XGBoost algorithms. The 1DCNN is used to learn local and short‐term patterns, while LSTM is employed to capture both short and long‐term dependencies. Furthermore, we have implemented an algorithm that utilizes hull moving average (HMA) and simple moving average (SMA) crossover data to detect trading entry points and major trends in the market. The combination of the SMA–HMA crossover algorithm and predictions provided by the 1DCNN‐BiLSTM‐XGBoost algorithm yields exceptional results in terms of prediction accuracy and profitability. Additionally, these integrated techniques effectively filter out noise and mitigate false breakouts, which are often observed with US 30‐year Treasury bonds. In the field of financial time series prediction, the effectiveness of 1DCNN and LSTM in identifying trading entry points and market perturbations has not been comprehensively studied. Therefore, our work fills this gap by demonstrating through experiments that the proposed 1DCNN‐BiLSTM‐XGBoost algorithm, in combination with moving average crossovers, effectively reduces noise and market perturbations. This leads to the precise identification of trading entry points and accurate recognition of trend signals for US 30‐year Treasury bonds. We demonstrate through experiments that our proposed approach achieves an average root mean squared error of 0.0001 and an R‐square value of 0.9999, highlighting its promise as a method for predicting market trends and trading entry points for US 30‐year Treasury bonds.","https://www.proquest.com/docview/2898698604?accountid=12870&bdid=124553&_bd=hBMMCyI0%2Btq0B6CQkQd8e88q%2F7U%3D","https://doi.org/10.1111/exsy.13459"
"Valuing GM technologies using real options: the case of drought tolerant wheat in Australia","","Wynn, Katherine; Spangenberg, German; Smith, Kevin F; Wilson, William","Technology Analysis & Strategic Management","Scholarly Journals","","30","12","2018-12-01","Dec 2018","1470","","1470-1482","09537325","","","ENG","In this article we seek to estimate the value of a partially-developed crop technology from the perspective of the firm developing the technology. Firms need this value estimation to decide whether their technology will earn a sufficient return in the market to justify investing in it. However, determining the (ex-ante) value of the technology before it is commercialised is challenging as the technology is not yet in the market and hence the demand function has not yet been defined. An alternative valuation method is required. We use risk premiums, Monte Carlo simulation and real options analysis and we demonstrate this combination of valuation tools on wheat that is currently being developed in Australia to be drought tolerant. The results indicate that this drought tolerant wheat variety is likely to be adopted by farmers in most regions and has a pre-commercialisation value that justifies continued investment in its development. We also identified South Australia as a region in which the new variety would not be sufficiently valuable to farmers to see them adopt it and we consider possible explanations for this outcome.","https://www.proquest.com/docview/2125134335?accountid=12870&bdid=124553&_bd=enPU50Vx8%2FASuctui%2FWxO%2BH7fH4%3D","https://doi.org/10.1080/09537325.2018.1474194"
"Hybrid LSTM–Transformer Architecture with Multi-Scale Feature Fusion for High-Accuracy Gold Futures Price Forecasting","","Zhao, Yali; Guo Yingying; Wang, Xuecheng","Mathematics","Scholarly Journals","","13","10","2025-01-01","2025","1551","","","22277390","","","ENG","Amidst global economic fluctuations and escalating geopolitical risks, gold futures, as a pivotal safe-haven asset, demonstrate price dynamics that directly impact investor decision-making and risk mitigation effectiveness. Traditional forecasting models face significant limitations in capturing long-term trends, addressing abrupt volatility, and mitigating multi-source noise within complex market environments characterized by nonlinear interactions and extreme events. Current research predominantly focuses on single-model approaches (e.g., ARIMA or standalone neural networks), inadequately addressing the synergistic effects of multimodal market signals (e.g., cross-market index linkages, exchange rate fluctuations, and policy shifts) and lacking the systematic validation of model robustness under extreme events. Furthermore, feature selection often relies on empirical assumptions, failing to uncover non-explicit correlations between market factors and gold futures prices. A review of the global literature reveals three critical gaps: (1) the insufficient integration of temporal dependency and global attention mechanisms, leading to imbalanced predictions of long-term trends and short-term volatility; (2) the neglect of dynamic coupling effects among cross-market risk factors, such as energy ETF-metal market spillovers; and (3) the absence of hybrid architectures tailored for high-frequency noise environments, limiting predictive utility for decision support. This study proposes a three-stage LSTM–Transformer–XGBoost fusion framework. Firstly, XGBoost-based feature importance ranking identifies six key drivers from thirty-six candidate indicators: the NASDAQ Index, S&P 500 closing price, silver futures, USD/CNY exchange rate, China’s 1-year Treasury yield, and Guotai Zhongzheng Coal ETF. Second, a dual-channel deep learning architecture integrates LSTM for long-term temporal memory and Transformer with multi-head self-attention to decode implicit relationships in unstructured signals (e.g., market sentiment and climate policies). Third, rolling-window forecasting is conducted using daily gold futures prices from the Shanghai Futures Exchange (2015–2025). Key innovations include the following: (1) a bidirectional LSTM–Transformer interaction architecture employing cross-attention mechanisms to dynamically couple global market context with local temporal features, surpassing traditional linear combinations; (2) a Dynamic Hierarchical Partition Framework (DHPF) that stratifies data into four dimensions (price trends, volatility, external correlations, and event shocks) to address multi-driver complexity; (3) a dual-loop adaptive mechanism enabling endogenous parameter updates and exogenous environmental perception to minimize prediction error volatility. This research proposes innovative cross-modal fusion frameworks for gold futures forecasting, providing financial institutions with robust quantitative tools to enhance asset allocation optimization and strengthen risk hedging strategies. It also provides an interpretable hybrid framework for derivative pricing intelligence. Future applications could leverage high-frequency data sharing and cross-market risk contagion models to enhance China’s influence in global gold pricing governance.","https://www.proquest.com/docview/3212073334?accountid=12870&bdid=124553&_bd=IjdNoEGtyT2bXyhdBIEm0yWYH80%3D","https://doi.org/10.3390/math13101551"
"A machine learning based asset pricing factor model comparison on anomaly portfolios","","Fang, Ming; Taylor, Stephen","Economics Letters","Scholarly Journals","","204","","2021-07-01","Jul 2021","1","","","01651765","","","ENG","We frame asset pricing linear factor models in a machine learning context and consider related comparisons of their predictive performance against ordinary least squares linear regression over a dataset of anomaly portfolios. Specific regression models involved in the comparison include regularized linear, support vector machines, neural networks, and tree based models among others. Performance metrics are presented on a model, portfolio group, and sequential basis, and the strongest predictors are recommended as alternative techniques for the problem of excess return forecasting.","https://www.proquest.com/docview/2569691396?accountid=12870&bdid=124553&_bd=%2FLjZbYK47rrOPWaTyEjx7gth24k%3D","https://doi.org/10.1016/j.econlet.2021.109919"
"“Intelligent” finance and treasury management: what we can expect","","Polak Petr; Nelischer Christof; Guo Haochen; Robertson, David C","AI & Society","Scholarly Journals","","35","3","2020-09-01","Sep 2020","715","726","715-726","09515666","","","ENG","Artificial intelligence poses a particular challenge in its application to finance/treasury management because most treasury functions are no longer physical processes, but rather virtual processes that are increasingly highly automated. Most finance/treasury teams are knowledge workers who make decisions and conduct analytics within often dynamic frameworks that must incorporate environmental considerations (foreign exchange rates, GDP forecasts), internal considerations (growth needs, business trends), as well as the impact of any actions on related corporate decisions which are also highly complex (e.g., hedging, investing, capital structure, liquidity levels). Artificial intelligence in finance and treasury is thus most analogous to the complexity of a human nervous system as it encompasses far more than the automation of tasks. Similar to the human nervous system, AI systems in finance/treasury must manage data quickly and accurately, including the capture and classification of data and its integration into larger datasets. At present, the AI network neural system has been gradually improved and is widely used in many fields of treasury management, such as early warning of potential financial crisis, diagnosis of financial risk, control of financial information data quality and mining of hidden financial data, information, etc.","https://www.proquest.com/docview/2438552423?accountid=12870&bdid=124553&_bd=ZgJTL8SYFcurF%2F6yKbwYLINJhrs%3D","https://doi.org/10.1007/s00146-019-00919-6"
"Early warning strategies for corporate operational risk: A study by an improved random forest algorithm using FCM clustering","","Fang, Xini","PloS one","Undefined","","20","3","2025-01-01","Jan 2025","e0318491","","e0318491","1932-6203","","","ENG","To enhance the accuracy and response speed of the risk early warning system, this study develops a novel early warning system that combines the Fuzzy C-Means (FCM) clustering algorithm and the Random Forest (RF) model. Firstly, based on operational risk theory, market risk, research and development risk, financial risk, and human resource risk are selected as the primary indicators for enterprise risk assessment. Secondly, the Criteria Importance Through Intercriteria Correlation (CRITIC) weight method is employed to determine the importance of these risk indicators, thereby enhancing the model's prediction ability and stability. Following this, the FCM clustering algorithm is utilized for pre-processing sample data to improve the efficiency and accuracy of data classification. Finally, an improved RF model is constructed by optimizing the parameters of the RF algorithm. The data selected is mainly from RESSET/DB, covering the issuance, trading, and rating data of fixed-income products such as bonds, government bonds, and corporate bonds, and provides basic information, net value, position, and performance data of funds. The experimental results show that the model achieves an F1 score of 87.26%, an accuracy of 87.95%, an Area under the Curve (AUC) of 91.20%, a precision of 89.29%, and a recall of 87.48%. They are respectively 6.45%, 4.45%, 5.09%, 4.81%, and 3.83% higher than the traditional RF model. In this study, an improved RF model based on FCM clustering is successfully constructed, and the accuracy of risk early warning models and their ability to handle complex data are significantly improved.To enhance the accuracy and response speed of the risk early warning system, this study develops a novel early warning system that combines the Fuzzy C-Means (FCM) clustering algorithm and the Random Forest (RF) model. Firstly, based on operational risk theory, market risk, research and development risk, financial risk, and human resource risk are selected as the primary indicators for enterprise risk assessment. Secondly, the Criteria Importance Through Intercriteria Correlation (CRITIC) weight method is employed to determine the importance of these risk indicators, thereby enhancing the model's prediction ability and stability. Following this, the FCM clustering algorithm is utilized for pre-processing sample data to improve the efficiency and accuracy of data classification. Finally, an improved RF model is constructed by optimizing the parameters of the RF algorithm. The data selected is mainly from RESSET/DB, covering the issuance, trading, and rating data of fixed-income products such as bonds, government bonds, and corporate bonds, and provides basic information, net value, position, and performance data of funds. The experimental results show that the model achieves an F1 score of 87.26%, an accuracy of 87.95%, an Area under the Curve (AUC) of 91.20%, a precision of 89.29%, and a recall of 87.48%. They are respectively 6.45%, 4.45%, 5.09%, 4.81%, and 3.83% higher than the traditional RF model. In this study, an improved RF model based on FCM clustering is successfully constructed, and the accuracy of risk early warning models and their ability to handle complex data are significantly improved.","https://www.proquest.com/docview/3176342379?accountid=12870&bdid=124553&_bd=%2FkNFEH%2FrUkdt1yJPQhFIdZ%2B9tcA%3D","https://doi.org/10.1371/journal.pone.0318491"
"Navigating the Complexity of Money Laundering: Anti–money Laundering Advancements with AI/ML Insights","","Gandhi, Hitarth; Tandon, Kevin; Gite, Shilpa; Pradhan, Biswajeet; Alamri, Abdullah","International Journal on Smart Sensing and Intelligent Systems","Scholarly Journals","","","1","2024-01-01","2024","","","","11785608","","","ENG","This study explores the fusion of artificial intelligence (AI) and machine learning (ML) methods within anti–money laundering (AML) frameworks using data from the US Treasury’s Financial Crimes Enforcement Network (FinCEN). ML and deep learning (DL) algorithms—such as random forest classifier, elastic net regressor, least absolute shrinkage and selection operator (LASSO) regression, gradient boosting regressor, linear regression, multilayer perceptron (MLP) classifier, convolutional neural network (CNN), random forest regressor, and K-nearest neighbor (KNN)—were used to forecast variables such as state, year, and transaction types (credit card and debit card). Hyperparameter tuning through grid search and randomized search was used to optimize model performance. The results demonstrated the efficacy of AI/ML algorithms in predicting temporal, spatial, and industry-specific money-laundering patterns. The random forest classifier achieved 99.99% average accuracy in state prediction, while the gradient boosting regressor and random forest classifier excelled in predicting year and state simultaneously, and credit card transactions, respectively. MLP and CNN showed promise in the context of debit card transactions. The gradient boosting regressor performed competitively with low mean squared error (MSE) (2.9) and the highest R-squared (R2) value of 0.24, showcasing its pattern-capturing proficiency. Logistic regression and random forest classifier performed well in predicting credit card transactions, with area under the receiver operating characteristic curve (ROC_AUC) scores of 0.55 and 0.53, respectively. For debit card prediction, MLP achieved a precision of 0.55 and recall of 0.42, while CNN showed a precision of 0.6 and recall of 0.54, highlighting their effectiveness. The study recommends interpretability, hyperparameter optimization, specialized models, ensemble methods, data augmentation, and real-time monitoring for improved adaptability to evolving financial crime patterns. Future improvements could include exploring the integration of blockchain technology in AML.","https://www.proquest.com/docview/3134894425?accountid=12870&bdid=124553&_bd=4LVuFxf0t%2BODM%2FwHl2oGzdiTNEY%3D","https://doi.org/10.2478/ijssis-2024-0024"
"Technological bias at the exchange rate market","","Galeshchuk, Svitlana","Intelligent Systems in Accounting, Finance and Management","Scholarly Journals","","24","2-3","2017-04-01","Apr-Sep 2017","80","86","80-86","15501949","","","ENG","Prediction of exchange rates has been a topic for debate in economic literature since the late 1980s. The recent development of machine learning techniques has spurred a plethora of studies that further improves the prediction models for currency markets. This high‐tech progress may create challenges for market efficiency along with information asymmetry and irrationality of decision‐making. This technological bias emerges from the fact that recent innovative approaches have been used to solve trading tasks and to find the best trading strategies. This paper demonstrates that traders can leverage technological bias for financial market forecasting. Those traders who adapt faster to the changes in market innovations will get excess returns. To support this hypothesis we compare the performance of deep learning methods, shallow neural networks with baseline prediction methods and a random walk model using daily closing rate between three currency pairs: Euro and US Dollar (EUR/USD), British Pound and US Dollar (GBP/USD), and US Dollar and Japanese Yen (USD/JPY). The results demonstrate that deep learning achieves higher accuracy than alternate methods. The shallow neural network outperforms the random walk model, but cannot surpass ARIMA accuracy significantly. The paper discusses possible outcomes of the technological shift for financial market development and accounting conforming also to adaptive market hypothesis.","https://www.proquest.com/docview/1942987580?accountid=12870&bdid=124553&_bd=6MQmbh03cnS0F7P6kd55ZOiqT5Q%3D","https://doi.org/10.1002/isaf.1408"
"The real effects of public investment on private investment","","Erenburg, S J","Applied Economics","Scholarly Journals","","25","6","1993-06-01","Jun 1993","831","","831","00036846","","","ENG","A 2-equation system, estimated using a full-information maximum-likelihood statistical technique with nonlinear parameter restrictions, is presented to determine separate effects of past government investment spending and past government deficit spending on private investment spending.  The empirical results indicate that there is a positive, statistically significant relationship between private and public sector investment spendng, and suggest that government expenditures on public capital should be explicitly taken into account when examining aggregate effects of fiscal policy.  In addition, combined federal, state, and local deficit spending reveals no statistically significant effect on private capital investment spending.","https://www.proquest.com/docview/212702720?accountid=12870&bdid=124553&_bd=PktdJcmGdSlxY%2BLrPvWZNxjEg8A%3D",""
"Implementation Tests of Financial Market Analysis by Text Mining","","Izumi, Kiyoshi; Goto, Takashi; Matsui, Tohgoroh","Transactions of the Japanese Society for Artificial Intelligence","Undefined","The Japanese Society for Artificial Intelligence","26","2","2011-01-01","2011","313","317","313-317","1346-8030","1346-8030","","ENG","In this study, we propose a new text-mining method for long-term market analysis. Using our method, we performe out-of-sample tests using monthly price data of financial markets; Japanese government bond market, Japanese stock market, and the yen-dollar market. First we extract feature vectors from monthly reports of Bank of Japan. Then, trends of each market are estimated by regression analysis using the feature vectors. As a result of comparison with support vector regression, the proposal method could forecast in higher accuracy about both the level and direction of long-term market trends. Moreover, our method showed high returns with annual rate averages as a result of the implementation test.","https://www.proquest.com/docview/1671223829?accountid=12870&bdid=124553&_bd=r56CIofT4%2Fy0h6HjyaUxYd4rkCg%3D","https://doi.org/10.1527/tjsai.26.313"
"Benchmark bonds interactions under regime shifts","","Georgoutsos, Dimitris A; Migiakis, Petros M","European financial management","Undefined","","18","3","2012-06-01","Jun 2012","389","409","389-409","1354-7798","1354-7798","","ENG","In the present paper we examine the interactions among five benchmark ten year government bonds, namely those of the USA, Germany, France, Italy and the Netherlands. Our aim is to illustrate empirically a net of interactions existing among the major bond markets of Europe and the US market taking into account shifts in the underlying stochastic processes. For this purpose, differing from the rest of the relevant empirical literature, after specifying the long run equilibrium relations, we estimate the linkages between the bond markets as subject to hidden Markov chains, by applying the Markov Switching Vector Error Correction framework (MS-VECM). This formulation is found to efficiently reflect the shifts brought about by significant economic events, such as the European monetary unification. As a result we illustrate different short-run relations referring to the periods before and after the monetary union. Overall, our empirical results indicate that stronger interactions among the markets of the system exist in the period after the EMU. Also, by means of a variance decomposition analysis we assess leader-follower relations which indicate that the benchmark status of bonds has changed since the introduction of the common monetary policy framework in Europe. Reprinted by permission of Blackwell Publishers","https://www.proquest.com/docview/1082144533?accountid=12870&bdid=124553&_bd=9rJGGm0dZMzBvpWuMGWM5NKdWHQ%3D","https://doi.org/10.1111/j.1468-036X.2009.00535.x"
"Dissecting climate change risk and financial market instability: Implications for ecological risk management","","Ma, Feng; Cao, Jiawei; Wang, Yizhi; Vigne, Samuel A; Dong, Dayong","Risk analysis : an official publication of the Society for Risk Analysis","Undefined","","45","3","2025-03-01","Mar 2025","496","","496-522","1539-6924","","","ENG","This research investigates the impact of climate challenges on financial markets by introducing an innovative approach to measure climate risk, specifically the aggregate climate change concern (ACCC) index. The study aims to assess and quantify the potential influence of climate change and risk-related factors on the performance and dynamics of financial markets. In this paper, concern is defined as the attention paid to the risk of climate change and the associated negative consequences. The findings demonstrate that the aggregate index exhibits robust predictability of market risk premiums, both within the sample and out-of-sample. By comparison, the index contains additional information beyond 14 economic predictors and 12 risk/uncertainty indexes in forecasting stock market return. In addition, the index proves valuable for mean-variance investors in asset allocation, leading to significant economic gains. The study identifies the index's ability to capture the reversal of temporary price crashes caused by overreactions to climate change risk. Furthermore, it exhibits stronger return forecasting capability for green stocks, non-state-owned enterprise (non-SOE) stocks, and stocks in regions with low air pollution. Particularly during periods of low air pollution and relaxed regulation, the index displays an enhanced ability to forecast returns. The study's findings provide valuable insights for policymakers and financial institutions as they address 21st-century environmental challenges. Moreover, these findings can inform the design of adaptive measures and interventions aimed at mitigating ecological risks and promoting sustainable economic growth.This research investigates the impact of climate challenges on financial markets by introducing an innovative approach to measure climate risk, specifically the aggregate climate change concern (ACCC) index. The study aims to assess and quantify the potential influence of climate change and risk-related factors on the performance and dynamics of financial markets. In this paper, concern is defined as the attention paid to the risk of climate change and the associated negative consequences. The findings demonstrate that the aggregate index exhibits robust predictability of market risk premiums, both within the sample and out-of-sample. By comparison, the index contains additional information beyond 14 economic predictors and 12 risk/uncertainty indexes in forecasting stock market return. In addition, the index proves valuable for mean-variance investors in asset allocation, leading to significant economic gains. The study identifies the index's ability to capture the reversal of temporary price crashes caused by overreactions to climate change risk. Furthermore, it exhibits stronger return forecasting capability for green stocks, non-state-owned enterprise (non-SOE) stocks, and stocks in regions with low air pollution. Particularly during periods of low air pollution and relaxed regulation, the index displays an enhanced ability to forecast returns. The study's findings provide valuable insights for policymakers and financial institutions as they address 21st-century environmental challenges. Moreover, these findings can inform the design of adaptive measures and interventions aimed at mitigating ecological risks and promoting sustainable economic growth.","https://www.proquest.com/docview/2909085232?accountid=12870&bdid=124553&_bd=Img4pkKD71TJ8pPSin2tcX86h5U%3D","https://doi.org/10.1111/risa.14265"
"Optimal supplier testing and tolerance strategies for genetically modified (GM) wheat","","Wilson, William W; Dahl, Bruce L; Jabs, Eric","Agricultural Economics","Undefined","Elsevier Science, P.O. Box 211","36","1","2007-01-01","Jan 2007","39","48","39-48","0169-5150","1574-0862","","ENG","AbstractA stochastic optimization model was developed to determine optimal testing strategies, costs, and risks for dual marketing of genetically modified (GM) and non-GM wheat in an export supply chain. The optimal testing strategy is derived that minimizes disutility of additional system costs due to testing and quality loss. Cost components were estimated including those related to testing, quality loss, and a risk premium to induce shippers to undertake dual marketing as opposed to handling only non-GM crops. Uncertainties were incorporated for adventitious presence and commingling, variety declaration, and test accuracy. Sensitivities were performed for effects of variety risks and declaration, penalty differentials, buyer tolerances, risk aversion, and GM adoption. Results indicate testing and segregation can be performed at a relatively low cost and risk to buyers.","https://www.proquest.com/docview/20433972?accountid=12870&bdid=124553&_bd=hH3%2BSjvnV2PLD6aaLXta8WLwqhw%3D","https://doi.org/10.1111/j.1574-0862.2007.00175.x"
"A Stock Market Decision-Making Framework Based on CMR-DQN","","Chen, Xun; Wang, Qin; Hu, Chao; Hu, Chao; Wang, Chengqi","Applied Sciences","Scholarly Journals","","14","16","2024-01-01","2024","6881","","","20763417","","","ENG","In the dynamic and uncertain stock market, precise forecasting and decision-making are crucial for profitability. Traditional deep neural networks (DNN) often struggle with capturing long-term dependencies and multi-scale features in complex financial time series data. To address these challenges, we introduce CMR-DQN, an innovative framework that integrates discrete wavelet transform (DWT) for multi-scale data analysis, temporal convolutional network (TCN) for extracting deep temporal features, and a GRU–LSTM–Attention mechanism to enhance the model’s focus and memory. Additionally, CMR-DQN employs the Rainbow DQN reinforcement learning strategy to learn optimal trading strategies in a simulated environment. CMR-DQN significantly improved the total return rate on six selected stocks, with increases ranging from 20.37% to 55.32%. It also demonstrated substantial improvements over the baseline model in terms of Sharpe ratio and maximum drawdown, indicating increased excess returns per unit of total risk and reduced investment risk. These results underscore the efficiency and effectiveness of CMR-DQN in handling multi-scale time series data and optimizing stock market decisions.","https://www.proquest.com/docview/3097818737?accountid=12870&bdid=124553&_bd=tPGcDToGq0jbFYr1c3VxzQCdAT8%3D","https://doi.org/10.3390/app14166881"
"Forecasting CDS Term Structure Based on Nelson–Siegel Model and Machine Learning","","Kim, Won Joong; Jung, Gunho; Sun-Yong, Choi","Complexity","Scholarly Journals","","2020","","2020-01-01","2020","","","","1076-2787","1099-0526","","ENG","In this study, we analyze the term structure of credit default swaps (CDSs) and predict future term structures using the Nelson–Siegel model, recurrent neural network (RNN), support vector regression (SVR), long short-term memory (LSTM), and group method of data handling (GMDH) using CDS term structure data from 2008 to 2019. Furthermore, we evaluate the change in the forecasting performance of the models through a subperiod analysis. According to the empirical results, we confirm that the Nelson–Siegel model can be used to predict not only the interest rate term structure but also the CDS term structure. Additionally, we demonstrate that machine-learning models, namely, SVR, RNN, LSTM, and GMDH, outperform the model-driven methods (in this case, the Nelson–Siegel model). Among the machine learning approaches, GMDH demonstrates the best performance in forecasting the CDS term structure. According to the subperiod analysis, the performance of all models was inconsistent with the data period. All the models were less predictable in highly volatile data periods than in less volatile periods. This study will enable traders and policymakers to invest efficiently and make policy decisions based on the current and future risk factors of a company or country.","https://www.proquest.com/docview/2427219290?accountid=12870&bdid=124553&_bd=jVeBBU5ZYBPGMc963IGPOYpXhpQ%3D","https://doi.org/10.1155/2020/2518283"
"Bank risks, capital and loan supply: evidence from Sierra Leone","","Osei-Assibey, Eric; Bockarie, Baimba Augustine","Journal of Financial Economic Policy","Undefined","Emerald Group Publishing Ltd., Bingley, UK","5","3","2013-01-01","0, 2013","256","271","256-271","1757-6385","1757-6385","","ENG","Purpose -- The study aims to investigate the factors that influence banks' loan supply in Sierra Leone. More specifically, it seeks to look into the effects of risk premium, leverage ratio and credit risk on banks' loan supply in Sierra Leone. Design/methodology/approach -- Using annual bank level data on an unbalanced panel of 13 commercial banks data observed over a period of ten years (2002 to 2011), the study employs time and bank-specific fixed effects model for estimation. Findings -- The findings indicate that risk premium, the share of non-performing loans in the banks' loan portfolio, tier 1 capital ratio (leverage ratio) and local currency deposit levels positively and significantly affect the share of loan supply to the private sector in banks' earning assets. On the other hand, advances to local currency deposit ratio and bank size have significant negative effects on the share of loans in banks assets. The study also finds bank type and the growth rate of real GDP (a proxy for economic activity) to be important determinants of the share of loans in banks' earning assets. Practical implications -- The study recommends that the monetary authorities, banking practitioners and the government should pay keen attention to the key risk factors such as non-performing loans and risk premium in the operation of the banking sector to boost commercial banks' loan supply. Originality/value -- Sierra Leone's banking sector presents a unique opportunity to study bank loan supply in relation to bank-specific features in the context of post-war financial reconstruction. Adapted from the source document.","https://www.proquest.com/docview/1550997323?accountid=12870&bdid=124553&_bd=Vfe2b2YJRkbgNc8TzqYbt7S9jTA%3D","https://doi.org/10.1108/JFEP-09-2012-0041"
"Stochastic interest rates in the analysis of energy investments: Implications on economic performance and sustainability","","Tolis, Athanasios; Doukelis, Aggelos; Tatsiopoulos, Ilias","Applied Energy","Undefined","Elsevier Science, The Boulevard Kidlington Oxford OX5 1GB UK","87","8","2010-08-01","Aug 2010","2479","2490","2479-2490","0306-2619","0306-2619","","ENG","A systematic impact assessment of stochastic interest and inflation rates on the analysis of energy investments is presented. A real-options algorithm has been created for this task. Constant interest rates incorporating high risk premium have been extensively used for economic calculations, within the framework of traditional direct cash flow methods, thus favouring immediate, irreversible investments in the expense of, sometimes, insubstantially low anticipated yields. In this article, not only incomes and expenses but also interest and inflation rates are considered stochastically evolving according to specific probabilistic models. The numerical experiments indicated that the stochastic interest rate forecasts fluctuate in such low levels that may signal delayed investment entry in favour of higher expected yields. The implementation of stochastically evolving interest rates in energy investment analysis may have a controversial effect on sustainability. Displacements of inefficient plants may be significantly delayed, thus prolonging high CO sub(2) emission rates. Under the current CO sub(2) allowance prices or their medium-term forecasts, this situation may not be improved and flexible policy interventions may be necessitated.","https://www.proquest.com/docview/753670431?accountid=12870&bdid=124553&_bd=pcLIPJnc1BsW7QMWv9nmWUA4JG8%3D","https://doi.org/10.1016/j.apenergy.2009.11.033"
"Reducing the cost of capital to finance the energy transition in developing countries","","Calcaterra, M.; Aleluia Reis, L.; Fragkos, P.; Briera, T.; de Boer, H. S.; Egli, F.; Emmerling, J.; Iyer, G.; Mittal, S.; Polzin, F. H. J.; Sanders, M. W. J. L.; Schmidt, T. S.; Serebriakova, A.; Steffen, B.; van de Ven, D. J.; van Vuuren, D. P.; Waidelich, P.; Tavoni, M.","Nature Energy","Scholarly Journals","","9","10","2024-10-01","Oct 2024","1241","1251","1241-1251","20587546","","","ENG","Climate stabilization requires the mobilization of substantial investments in low- and zero-carbon technologies, especially in emerging and developing economies. However, access to stable and affordable finance varies dramatically across countries. Models used to evaluate the energy transition do not differentiate regional financing costs and therefore cannot study risk-sharing mechanisms for renewable electricity generation. In this study, we incorporated the empirically estimated cost of capital differentiated by country and technology into an ensemble of five climate–energy–economy models. We quantified the additional financing cost of decarbonization borne by developing regions and explored policies of risk premium convergence across countries. We found that alleviating financial constraints benefits both climate and equity as a result of more renewable and affordable energy in the developing world. This highlights the importance of fair finance for energy availability, affordability and sustainability, as well as the need to include financial considerations in model-based assessments.Fair finance in the energy sector is modelled in five climate–energy–economy models. The results show that convergence costs of capital could improve energy availability, affordability and sustainability in developing countries, thereby increasing the international equity of the energy transition.","https://www.proquest.com/docview/3119343186?accountid=12870&bdid=124553&_bd=KcWCKzwRlMA3FSHkHhWuSfyRTrw%3D","https://doi.org/10.1038/s41560-024-01606-7"
"Sign realized jump risk and the cross-section of stock returns: Evidence from China's stock market","","Chao, Youcong; Liu, Xiaoqun; Guo, Shijun","PloS one","Undefined","","12","8","2017-01-01","Jan 2017","e0181990","","e0181990","1932-6203","","","ENG","Using 5-minute high frequency data from the Chinese stock market, we employ a non-parametric method to estimate Fama-French portfolio realized jumps and investigate whether the estimated positive, negative and sign realized jumps could forecast or explain the cross-sectional stock returns. The Fama-MacBeth regression results show that not only have the realized jump components and the continuous volatility been compensated with risk premium, but also that the negative jump risk, the positive jump risk and the sign jump risk, to some extent, could explain the return of the stock portfolios. Therefore, we should pay high attention to the downside tail risk and the upside tail risk.Using 5-minute high frequency data from the Chinese stock market, we employ a non-parametric method to estimate Fama-French portfolio realized jumps and investigate whether the estimated positive, negative and sign realized jumps could forecast or explain the cross-sectional stock returns. The Fama-MacBeth regression results show that not only have the realized jump components and the continuous volatility been compensated with risk premium, but also that the negative jump risk, the positive jump risk and the sign jump risk, to some extent, could explain the return of the stock portfolios. Therefore, we should pay high attention to the downside tail risk and the upside tail risk.","https://www.proquest.com/docview/1926679549?accountid=12870&bdid=124553&_bd=NwC9NhkDBnvUHH03KXSEb1nBX8U%3D","https://doi.org/10.1371/journal.pone.0181990"
"Statistical actuarial estimation of the Capitation Payment Unit from copula functions and deep learning: historical comparability analysis for the Colombian health system, 2015-2021","","Espinosa, Oscar; Bejarano, Valeria; Ramos, Jeferson; Martínez, Boris","Health economics review","Undefined","","13","1","2023-02-24","Feb 24, 2023","15","","15","2191-1991","2191-1991","","ENG","The Capitation Payment Unit (CPU) financing mechanism constitutes more than 70% of health spending in Colombia, with a budget allocation of close to 60 trillion Colombian pesos for the year 2022 (approximately 15.7 billion US dollars). This article estimates actuarially, using modern techniques, the CPU for the contributory regime of the General System of Social Security in Health in Colombia, and compares it with what is estimated by the Ministry of Health and Social Protection. Using freely available information systems, by means of statistical copulas functions and artificial neural networks, pure risk premiums are calculated between 2015 and 2021. The study concludes that the weights by risk category are systematically different, showing historical pure premiums surpluses in the group of 0-1 years and deficits (for the regions normal and cities) in the groups over 54 years of age.The Capitation Payment Unit (CPU) financing mechanism constitutes more than 70% of health spending in Colombia, with a budget allocation of close to 60 trillion Colombian pesos for the year 2022 (approximately 15.7 billion US dollars). This article estimates actuarially, using modern techniques, the CPU for the contributory regime of the General System of Social Security in Health in Colombia, and compares it with what is estimated by the Ministry of Health and Social Protection. Using freely available information systems, by means of statistical copulas functions and artificial neural networks, pure risk premiums are calculated between 2015 and 2021. The study concludes that the weights by risk category are systematically different, showing historical pure premiums surpluses in the group of 0-1 years and deficits (for the regions normal and cities) in the groups over 54 years of age.","https://www.proquest.com/docview/2780069426?accountid=12870&bdid=124553&_bd=Jd%2FDIDVysyeU4Y7hMxlxLNF1S98%3D","https://doi.org/10.1186/s13561-022-00416-5"
"Predictability of sugar futures: evidence from the Indian commodity market","","Misra, Prabhati Kumari; Goswami, Kishor","Agricultural Finance Review","Scholarly Journals","","75","4","2015-10-01","2015","552","","n/a","00021466","","","ENG","Purpose- The forecasting power of commodity futures is a matter of intensive research as evidenced by a number of related publications. The purpose of this paper is to illustrate how advanced forecasting techniques improve the predictability of sugar futures in the Indian commodity market.Design/methodology/approach- The forward premium is estimated using ordinary least square regression technique. Different linear and nonlinear models are used to forecast the sugar future spot prices from the futures prices. The forecasting accuracy of each pair of models is then compared by estimating the corresponding Diebold-Mariano test statistics.Findings- From the estimated forward premiums, it is found that there is more volatility toward the date of maturity for a three-month horizon compared to six-month, and 12-month horizons. It is established that the futures prices of sugar, when used in a model, are able to generate better forecasts for the future spot prices. Moreover, the forecasting accuracy is found to be better for a shorter futures horizon.Research limitations/implications- The present study is restricted only to sugar. If sufficient data are available, the same study could be extended to other commodities as well. The findings imply that technical traders would benefit by using advanced forecasting techniques along with futures prices of sugar to determine the expected future spot prices.Practical implications- The findings in this paper suggest that though simple statistical models may be adopted to relate future spot prices to futures prices, more accurate prediction of the price behavior is possible with advanced forecasting methods like the artificial neural network.Social implications- The findings will help market participants such as traders to be better informed about the future spot prices and hence get a better deal.Originality/value- This is one of the first investigations to assess the predictability of commodity futures by employing advanced forecasting techniques.","https://www.proquest.com/docview/1724852654?accountid=12870&bdid=124553&_bd=UWGEyEA%2FufOHGO4i1Vn8uu8z90c%3D","https://doi.org/10.1108/AFR-02-2014-0002"
"Interest Rate Based on The Lie Group SO(3) in the Evidence of Chaos","","Bildirici, Melike; Ucan, Yasemen; Lousada, Sérgio; Lousada, Sérgio","Mathematics","Scholarly Journals","","10","21","2022-01-01","2022","3998","","","22277390","","","ENG","This paper aims to test the structure of interest rates during the period from 1 September 1981 to 28 December 2020 by using Lie algebras and groups. The selected period experienced substantial events impacting interest rates, such as the economic crisis, the military intervention of the USA in Iraq, and the COVID-19 pandemic, in which economies were in lockdown. These conditions caused the interest rate to have a nonlinear structure, chaotic behavior, and outliers. Under these conditions, an alternative method is proposed to test the random and nonlinear structure of interest rates to be evolved by a stochastic differential equation captured on a curved state space based on Lie algebras and group. Then, parameter estimates of this equation were obtained by OLS, NLS, and GMM estimators (hereafter, LieNLS, LieOLS, and LieGMM, respectively). Therefore, the interest rates that possess nonlinear structures and/or chaotic behaviors or outliers were tested with LieNLS, LieOLS, and LieGMM. We compared our LieNLS, LieOLS, and LieGMM results with the traditional OLS, NLS, and GMM methods, and the results favor the improvement achieved by the proposed LieNLS, LieOLS, and LieGMM in terms of the RMSE and MAE in the out-of-sample forecasts. Lastly, the Lie algebras with NLS estimators exhibited the lowest RMSE and MAE followed by the Lie algebras with GMM, and the Lie algebras with OLS, respectively.","https://www.proquest.com/docview/2734653947?accountid=12870&bdid=124553&_bd=PsFOAV4gj374WpiCt0W51S6aShU%3D","https://doi.org/10.3390/math10213998"
"Impact of China’s Provincial Government Debt on Economic Growth and Sustainable Development","","Yang, Wanping; Zhang, Zhenya; Zhang, Zhenya; Wang, Yajuan; Wang, Yajuan; Deng, Peidong; Guo, Luyao","Sustainability","Scholarly Journals","","14","3","2022-01-01","2022","1474","","","20711050","","","ENG","Macroeconomic stability is the core concept of sustainable development. However, the coronavirus disease (COVID-19) pandemic has caused government debt problems worldwide. In this context, it is of practical significance to study the impact of government debt on economic growth and fluctuations. Based on panel data of 30 provinces in China from 2012 to 2019, we used the Mann–Kendall method and Kernel Density estimation to analyze the temporal and spatial evolution of China’s provincial government debt ratio and adopted a panel model and HP filtering method to study the impact of provincial government debt on economic growth and fluctuation. Our findings indicate that, during the sample period, China’s provincial government debt promoted economic growth and the regression coefficient (0.024) was significant. From different regional perspectives, the promotion effect of the central region (0.027) is higher than that of the eastern (0.020) and western regions (0.023). There is a nonlinear relationship between China’s provincial government debt and economic growth, showing an inverted “U-shaped” curve. Fluctuations in government debt aggravate economic volatility, with a coefficient of 0.009; tax burden fluctuation and population growth rate aggravate economic changes. In contrast, the optimization of the province’s industrial structure and the improvement of the opening level of provinces slow down economic fluctuations.","https://www.proquest.com/docview/2627846493?accountid=12870&bdid=124553&_bd=8FJ0Rz52XW14mO4XKe7qxMvrWjc%3D","https://doi.org/10.3390/su14031474"
"Investigation of the Financial Stability of S&P 500 Using Realized Volatility and Stock Returns Distribution","","Akter, Nahida; Nobi, Ashadun","Journal of Risk and Financial Management","Scholarly Journals","","11","2","2018-06-01","Jun 2018","n/a","","","19118066","","","ENG","In this work, the financial data of 377 stocks of Standard & Poor’s 500 Index (S&P 500) from the years 1998–2012 with a 250-day time window were investigated by measuring realized stock returns and realized volatility. We examined the normal distribution and frequency distribution for both daily stock returns and volatility. We also determined the beta-coefficient and correlation among the stocks for 15 years and found that, during the crisis period, the beta-coefficient between the market index and stock’s prices and correlation among stock’s prices increased remarkably and decreased during the non-crisis period. We compared the stock volatility and stock returns for specific time periods i.e., non-crisis, before crisis and during crisis year in detail and found that the distribution behaviors of stock return prices has a better long-term effect that allows predictions of near-future market behavior than realized volatility of stock returns. Our detailed statistical analysis provides a valuable guideline for both researchers and market participants because it provides a significantly clearer comparison of the strengths and weaknesses of the two methods.","https://www.proquest.com/docview/2124659932?accountid=12870&bdid=124553&_bd=j7npgt%2BXJTRXOaP%2FhzaXDeW3OWs%3D","https://doi.org/10.3390/jrfm11020022"
"Investor Attention and Stock Returns","","Chen, Jian; Tang, Guohao; Yao, Jiaquan; Zhou, Guofu","Journal of Financial and Quantitative Analysis","Scholarly Journals","","57","2","2022-03-01","Mar 2022","455","","","00221090","","","ENG","We propose an investor attention index based on proxies in the literature and find that it predicts the stock market risk premium significantly, both in sample and out of sample, whereas every proxy individually has little predictive power. The index is extracted using partial least squares, but the results are similar by the scaled principal component analysis. Moreover, the index can deliver sizable economic gains for mean-variance investors in asset allocation. The predictive power of the investor attention index stems primarily from the reversal of temporary price pressure and from the stronger forecasting ability for high-variance stocks.","https://www.proquest.com/docview/2627993529?accountid=12870&bdid=124553&_bd=icgWutDc798Qv6DzCnjIY5%2BxfvI%3D","https://doi.org/10.1017/S0022109021000090"
"Inference in asset pricing models with a low-variance factor","","Shang, H","Journal of banking and finance","Undefined","","37","3","2013-03-01","Mar 2013","1046","1060","1046-1060","0378-4266","0378-4266","","ENG","This paper concerns with the effects of including a low-variance factor in an asset pricing model. When a low-variance factor is present, the commonly applied Fama-MacBeth two-pass regression procedure is very likely to yield misleading results. Local asymptotic analysis and simulation evidence indicate that the risk premiums corresponding to all factors are very likely to be unreliably estimated. Moreover, t- and F-statistics are less likely to detect whether the risk premiums are significantly different from zero. We recommend Kleibergen's (2009)FAR statistic when there is a low-variance factor included in an asset pricing model. All rights reserved, Elsevier","https://www.proquest.com/docview/1285625103?accountid=12870&bdid=124553&_bd=Deh5Cn7qdw%2FudY10LgEF2Fj%2B8lw%3D","https://doi.org/10.1016/j.jbankfin.2012.11.007"
"Evolutionary-based return forecasting with nonlinear STAR models: evidence from the Eurozone peripheral stock markets","","Avdoulas Christos; Bekiros Stelios; Sabri, Boubaker","Annals of Operations Research","Scholarly Journals","","262","2","2018-03-01","Mar 2018","307","333","307-333","02545330","","","ENG","Traditional linear regression and time-series models often fail to produce accurate forecasts due to inherent nonlinearities and structural instabilities, which characterize financial markets and challenge the Efficient Market Hypothesis. Machine learning techniques are becoming widespread tools for return forecasting as they are capable of dealing efficiently with nonlinear modeling. An evolutionary programming approach based on genetic algorithms is introduced in order to estimate and fine-tune the parameters of the STAR-class models, as opposed to conventional techniques. Using a hybrid method we employ trading rules that generate excess returns for the Eurozone southern periphery stock markets, over a long out-of-sample period after the introduction of the Euro common currency. Our results may have important implications for market efficiency and predictability. Investment or trading strategies based on the proposed approach may allow market agents to earn higher returns.","https://www.proquest.com/docview/2511602644?accountid=12870&bdid=124553&_bd=N9QMp8pevLIjeZ0EmoEXTs2HpiM%3D","https://doi.org/10.1007/s10479-015-2078-z"
"The impact of variability and correlation of selected geological parameters on the economic assessment of bituminous coal deposits with use of non-parametric bootstrap and copula-based Monte Carlo simulation","","Kopacz, Michal; Sobczyk, Eugeniusz J; Galica, Dominik","Resources Policy","Scholarly Journals","","55","","2018-03-01","Mar 2018","171","","","0301-4207","","","ENG","This paper presents an assessment of the impact of variability and interdependencies of selected deposit parameters on the net present value (NPV) and internal rate of return (IRR). The subjects of the analyses were three economically viable seams at one of the bituminous coal deposits in Poland. The source of information was the geological model and operational data of the mine “X”. The simulation was developed based on non-parametric bootstrapping, where the influence of coal quality parameters, seam thickness, spatial density of coal, and waste rock derived from coal partings, floor cutting and dinting, and roof falls, was tested. The interdependencies of geological and mining parameters were replicated in a simulation model using Gaussian and empirical copulas. In the model, the relationship between the amount of total waste rock and operating costs was associated with the use of elaborate mathematical formulas. Economic appraisal was based on an income approach, using the free cash flow for the firm (FCFF) analysis and discounting process. Based on the Gaussian copula, in the X-1 and X-2 seams, the average NPV differences achieved were a maximum of 39%. In the case of IRR, the mean difference did not exceed 3.6% points (pp). The quantified spread between the correlated and uncorrelated average values of NPV was at most 45% and 4.8 pp for IRR. Empirical copula limits the range of variation of input and output parameters, resulting in different values for the average NPV, at a maximum of 11.8%, and IRR, 2.4 pp. If the IRR reflects the level of expected return of investment, it can be stated that the additional risk premium resulting from the volatility and correlation of analysed deposits parameters of bituminous coal should be relatively low and less than 2.4 pp in similar cases. The analyses also revealed that the amount of available geological information is of secondary importance in the valuation process, as it does not negatively affect the regularity and symmetry of predicted outcomes.","https://www.proquest.com/docview/2056033591?accountid=12870&bdid=124553&_bd=rgOlz7z9CvOnwUWC4%2F%2Bp66ccPyI%3D",""
"A Model of Time-on-Market and Real Estate Price Under Sequential Search with Recall","","Cheng, Ping; Lin, Zhenguo; Liu, Yingchun","Real Estate Economics","Scholarly Journals","","36","4","2008-12-01","Winter 2008","813","","","10808620","","","ENG","This article develops a model and provides a closed-form formula to uncover the theoretical relationship between real estate price and time on market (TOM). Our model shows a nonlinear positive price-TOM relationship, and it identifies three economic factors that affect the impact of TOM on sale price. We demonstrate that conventional metrics for real estate return and risk, which are borrowed in a naive fashion from finance theory, do not account for marketing period risk and tend to overestimate real estate returns and underestimate real estate risks. Our model provides a simple way to correct such bias. This theory helps to explain the apparent ""risk-premium puzzle"" in real estate. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/870324813?accountid=12870&bdid=124553&_bd=Bzzm0CBcC3lIurST%2B5yQz4yKbHY%3D",""
"Financial markets","","","Bank of Finland Bulletin","Undefined","","79","1","2005-12-01","December 2005","9","21","9-21","0784-6509","1456-5870","","ENG","An examination of world financial markets notes that low short-term interest rates combined with a positive outlook for the world economy has increased higher-risk investments which in turn has raised share prices and narrowed the interest rate spread between corporate and government bonds. The growth rate of the world economy is forecast to remain around 4 percent in 2005-2007. Assumptions underlying the forecast are described; along with the pattern of interest rates in the Euro area, the US, and Japan between 1998 and 2005; and such exchange rate developments as depreciation of the US dollar and a rise in the value of the euro. Low interest rates, strong financial results in the corporate sector, and a healthy US economy have all contributed to a favorable trend in stock markets. There has also been growth in bank loans and deposits; however, there is a degree of uncertainty surrounding development on the loans market related to a possible rise in interest rates. Special attention is given to the status of housing loans in Finland.","https://www.proquest.com/docview/58852552?accountid=12870&bdid=124553&_bd=7Tdf8vkgZg%2B6NqQu2KZ1cPY08zo%3D",""
"Development of a Machine Learning Model Using Multiple, Heterogeneous Data Sources to Estimate Weekly US Suicide Fatalities","","Choi, Daejin; Sumner, Steven A; Holland, Kristin M; Draper, John; Murphy, Sean; Bowen, Daniel A; Zwald, Marissa; Wang, Jing; Law, Royal; Taylor, Jordan; Konjeti, Chaitanya; De Choudhury, Munmun","JAMA Network Open","Scholarly Journals","","3","12","2020-01-01","2020","e2030932","","","25743805","","","ENG","ImportanceSuicide is a leading cause of death in the US. However, official national statistics on suicide rates are delayed by 1 to 2 years, hampering evidence-based public health planning and decision-making.ObjectiveTo estimate weekly suicide fatalities in the US in near real time.Design, Setting, and ParticipantsThis cross-sectional national study used a machine learning pipeline to combine signals from several streams of real-time information to estimate weekly suicide fatalities in the US in near real time. This 2-phase approach first fits optimal machine learning models to each individual data stream and subsequently combines predictions made from each data stream via an artificial neural network. National-level US administrative data on suicide deaths, health services, and economic, meteorological, and online data were variously obtained from 2014 to 2017. Data were analyzed from January 1, 2014, to December 31, 2017.ExposuresLongitudinal data on suicide-related exposures were obtained from multiple, heterogeneous streams: emergency department visits for suicide ideation and attempts collected via the National Syndromic Surveillance Program (2015-2017); calls to the National Suicide Prevention Lifeline (2014-2017); calls to US poison control centers for intentional self-harm (2014-2017); consumer price index and seasonality-adjusted unemployment rate, hourly earnings, home price index, and 3-month and 10-year yield curves from the Federal Reserve Economic Data (2014-2017); weekly daylight hours (2014-2017); Google and YouTube search trends related to suicide (2014-2017); and public posts on suicide on Reddit (2 314 533 posts), Twitter (9 327 472 tweets; 2015-2017), and Tumblr (1 670 378 posts; 2014-2017).Main Outcomes and MeasuresWeekly estimates of suicide fatalities in the US were obtained through a machine learning pipeline that integrated the above data sources. Estimates were compared statistically with actual fatalities recorded by the National Vital Statistics System.ResultsCombining information from multiple data streams, the machine learning method yielded estimates of weekly suicide deaths with high correlation to actual counts and trends (Pearson correlation, 0.811;P < .001), while estimating annual suicide rates with low error (0.55%).Conclusions and RelevanceThe proposed ensemble machine learning framework reduces the error for annual suicide rate estimation to less than one-tenth of that of current forecasting approaches that use only historical information on suicide deaths. These findings establish a novel approach for tracking suicide fatalities in near real time and provide the potential for an effective public health response such as supporting budgetary decisions or deploying interventions.","https://www.proquest.com/docview/2667884008?accountid=12870&bdid=124553&_bd=ccv3IxwqPH7TKWrp%2FwcAIYrSWqc%3D","https://doi.org/10.1001/jamanetworkopen.2020.30932"
"A Nonlinear Factor Analysis of S&P 500 Index Option Returns","","Jones, Christopher S","Journal of Finance","Undefined","Blackwell Publishing Ltd., 9600 Garsington Road Oxford OX4 2DQ UK, [URL:http://www.blackwellpublishing.com]","61","5","2006-10-01","Oct 2006","2325","2363","2325-2363","0022-1082","1540-6261","","ENG","Growing evidence suggests that extraordinary average returns may be obtained by trading equity index options, and that at least part of this abnormal performance is attributable to volatility and jump risk premia. This paper asks whether such priced risk factors are alone sufficient to explain these average returns. To provide an answer in as general as possible a setting, I estimate a flexible class of nonlinear models using all S&P 500 Index futures options traded between 1986 and 2000. The results show that priced factors contribute to these expected returns but are insufficient to explain their magnitudes, particularly for short-term out-of-the-money puts.","https://www.proquest.com/docview/19450661?accountid=12870&bdid=124553&_bd=9KDRRPo1zRIN1jm2a4Kx9JyB508%3D","https://doi.org/10.1111/j.1540-6261.2006.01059.x"
"'The effect of country default risk on foreign direct investment'","","Clark, E; Kassimatis, K","Economia internazionale","Undefined","","LXII","3","2009-08-01","Aug 2009","341","361","341-361","0012-981X","0012-981X","","ENG","ABSTRACT IN ENGLISH: In this paper we use the structural credit risk methodology of Merton (1974) to estimate country default risk as the country financial risk premium for eight of the largest Latin American economies - Argentina, Bolivia, Brazil, Chile, Colombia, Mexico, Peru and Venezuela - from 1986 to 2000. We test whether and to what extent it affects the amount of foreign direct investment (FDI). We find that the lagged second difference of the financial risk premium is a significant explanatory variable that is robust with respect to the other explanatory variables, including a standard measure of country/political risk, as well as with respect to the individual countries.    // ABSTRACT IN ITALIAN: In questo studio si utilizza il modello strutturale per il calcolo del credit risk di Merton (1974) per stimare il default risk come premio per il rischio finanziario del paese relativamente a otto tra le maggiori economie dell'America Latina - Argentina, Bolivia, Brasile, Cile, Colombia, Messico, Perù e Venezuela - sui dati del periodo 1986-2000. Si esamina se e quanto ciò influisce sugli investimenti diretti esteri. I risultati indicano che la seconda differenza intervallata del risk premium finanziario è una variabile significativa ed esplicativa, robusta rispetto alle altre, ivi compresa la misura standard di rischio politico/economico, ed anche rispetto ai singoli paesi.","https://www.proquest.com/docview/743787381?accountid=12870&bdid=124553&_bd=l9%2Bs41eUK0KYk%2FWM1DvZlXO07p4%3D",""
"The Information in Long-Maturity Forward Rates","","Fama, Eugene F; Bliss, Robert R","The American Economic Review","Scholarly Journals","","77","4","1987-09-01","Sep 1987","680","","680","00028282","","","ENG","Attention is focused on the information in forward rates about future interest rates and current expected returns for annual US Treasury maturities to 5 years.  Estimates of the term-premium regression allow the inference that one-year expected returns for US Treasury maturities to 5 years, measured net of the interest rate on a one-year bond, vary through time.  Furthermore, at least during the 1964-1985 period, this variation of expected term premiums appears to be related to the business cycle.  Evidence suggests that the ordering of risks and rewards changes with the business cycle.  This behavior of expected returns is not consistent with simple term structure models in which expected returns increase with maturity.  Little evidence is found that forward rates can forecast near-term changes in interest rates.  However, when the forecast horizon is extended, forecast power improves, and one-year forward rates forecast changes in the one-year spot rate some 2-4 years ahead.  It is concluded that this forecast power reflects a slow mean-reverting tendency of interest rates.","https://www.proquest.com/docview/233026032?accountid=12870&bdid=124553&_bd=z3GMWUarTpZAYMstTYyiaQkPjSY%3D",""
"New results on the predictive value of crude oil for US stock returns","","Brigida, Matt","Studies in Economics and Finance","Scholarly Journals","","35","1","2018-01-01","2018","97","","97-108","10867376","","","ENG","PurposeThe purpose of this study is to clarify the nature of the predictive relationship between crude oil and the US stock market, with particular attention to whether this relationship is driven by time-varying risk premia.Design/methodology/approachThe authors formulate the predictive regression as a state-space model and estimate the time-varying coefficients via the Kalman filter and prediction-error decomposition.FindingsThe authors find that the nature of the predictive relationship between crude oil and the US stock market changed in the latter half of 2008. After mid-2008, the predictive relationship switched signs and exhibited characteristics which make it much more likely that the predictive relationship is due to time-varying risk premia rather than a market inefficiency.Originality/valueThe authors apply a state-space approach to modeling the predictive relationship. This allows one to watch the evolution of the predictive relationship over time. In particular, the authors identify a dramatic shift in the relationship around August 2008. Prior research has not been able to identify shifts in the relationship.","https://www.proquest.com/docview/2021248320?accountid=12870&bdid=124553&_bd=%2BWk4CJQBFY5OxiOrORmt8jN3bqY%3D","https://doi.org/10.1108/SEF-01-2017-0020"
"Evaluating credit rating prediction by using the KMV model and random forest","","Hsu-Che, Wu; Yu-Ting, Wu","Kybernetes","Scholarly Journals","","45","10","2016-11-30","2016","1637","1651","1637-1651","0368492X","","","ENG","PurposeAn increasing number of investors have begun using financial data to develop optimal investment portfolios; therefore, the public financial data shared in the capital market plays a critical role in credit ratings. These data enable investors to understand the credit levels of debtors from a bank perspective; this facilitates predicting the debtor default rate to efficiently evaluate investment risks. The paper aims to discuss these issues.Design/methodology/approachA credit rating model can be developed to reduce the risk of adverse selection and moral hazard caused by information asymmetry in the loan market. In this study, a random forest (RF) was used to evaluate financial variables and construct credit rating prediction models. Data-mining techniques, including an RF, decision tree, neural networks, and support vector machine, were used to search for suitable credit rating forecasting methods. The distance to default from the KMV model was then incorporated into the credit rating model as a research variable to increase predictive power of various data-mining techniques. In addition, four-level and nine-level classification were set to investigate the accuracy rates of various models.FindingsThe experimental results indicated that applying the RF in the variable feature selection process and developing a forecasting model was the most effective method of predicting credit ratings; the four-level and nine-level feature-selection settings achieved 95.5 and 87.8 percent accuracy rates, respectively, indicating that RF demonstrated outstanding feature selection and forecasting capacity.Research limitations/implicationsThe experimental cases were based on financial data from public companies in North America.Practical implicationsPractical implication of this study indicates the most effective financial variables were dividends common/ordinary, cash dividends, volatility assumption, and risk-free rate assumption.Originality/valueThe RF model can be used to perform feature selection and efficiently filter numerous financial variables to obtain crediting rating information instantly.","https://www.proquest.com/docview/2398020836?accountid=12870&bdid=124553&_bd=Qdl48bphGrHBImtVLSyHAsKQf3Q%3D","https://doi.org/10.1108/K-12-2014-0285"
"Kriging of financial term-structures","","Cousin, Areski; Maatoukb, Hassan; Rullierea, Didier","European Journal of Operational Research","Undefined","Elsevier B.V., Radarweg 29 Amsterdam 1043 NX Netherlands","255","2","2016-12-01","December 1, 2016","631","648","631-648","0377-2217","0377-2217","","ENG","Due to the lack of reliable market information, building financial term-structures may be associated with a significant degree of uncertainty. In this paper, we propose a new term-structure interpolation method that extends classical spline techniques by additionally allowing for quantification of uncertainty. The proposed method is based on a generalization of kriging models with linear equality constraints (market-fit conditions) and shape-preserving conditions such as monotonicity or positivity (no-arbitrage conditions). We define the most likely curve and show how to build confidence bands. The Gaussian process covariance hyper-parameters under the construction constraints are estimated using cross-validation techniques. Based on observed market quotes at different dates, we demonstrate the efficiency of the method by building curves together with confidence intervals for term-structures of OIS discount rates, of zero-coupon swaps rates and of CDS implied default probabilities. We also show how to construct interest-rate surfaces or default probability surfaces by considering time (quotation dates) as an additional dimension.","https://www.proquest.com/docview/1835568943?accountid=12870&bdid=124553&_bd=eOp3BdR%2FDTbsqpjsOPQ6%2F8hgnPs%3D","https://doi.org/10.1016/j.ejor.2016.05.057"
"A non-Gaussian Ornstein-Uhlenbeck model for pricing wind power futures","","Benth, Fred Espen; Pircalabu, Anca","Applied Mathematical Finance","Scholarly Journals","","25","1","2018-03-01","Mar 2018","36","","36-65","1350486X","","","ENG","The recent introduction of wind power futures written on the German wind power production index has brought with it new interesting challenges in terms of modelling and pricing. Some particularities of this product are the strong seasonal component embedded in the underlying, the fact that the wind index is bounded from both above and below and also that the futures are settled against a synthetically generated spot index. Here, we consider the non-Gaussian Ornstein-Uhlenbeck type processes proposed by Barndorff-Nielsen and Shephard in the context of modelling the wind power production index. We discuss the properties of the model and estimation of the model parameters. Further, the model allows for an analytical formula for pricing wind power futures. We provide an empirical study, where the model is calibrated to 37 years of German wind power production index that is synthetically generated assuming a constant level of installed capacity. Also, based on 1 year of observed prices for wind power futures with different delivery periods, we study the market price of risk. Generally, we find a negative risk premium whose magnitude decreases as the length of the delivery period increases. To further demonstrate the benefits of our proposed model, we address the pricing of European options written on wind power futures, which can be achieved through Fourier techniques.","https://www.proquest.com/docview/2084638706?accountid=12870&bdid=124553&_bd=VrnXI%2BmNuttP%2B0B2NBKvWix7Uk8%3D","https://doi.org/10.1080/1350486X.2018.1438904"
"Unconventional Monetary Policy in the Euro Zone","","Driffill, John","Open economies review","Undefined","","27","2","2016-04-01","April 2016","387","404","387-404","0923-7992","0923-7992","","ENG","The European Central Bank adopted a policy of quantitative easing early in 2015, long after the US and UK, and after implementing a succession of measures to increase liquidity in the Euro zone financial markets, none of which proved sufficient eventually. The paper draws out lessons for the Euro zone from US and UK experience. Numerous event studies have been undertaken to uncover the effects of QE on yields on and prices of financial assets. Estimated effects on long-term government bond yields are then converted into the size of the cut in the policy rate that would normally have been needed to produce them. From these implicit cuts in policy rates, estimates of the effect on GDP and inflation are generated. Euro zone QE appears to have had a much smaller effect on bond yields for the core members states than did QE in the US or UK. Therefore its effects on output and inflation are likely to be proportionately smaller. Its effects on long-term government bond yields in periphery members are greater. QE is compressing interest differential among Euro zone member states. The dangers of QE to which various commentators draw attention, that it creates a danger of inflation in the future, that it creates asset price bubbles, that it allows zombie firms and banks to survive, slowing down the process of adjustment, seem remote. Meanwhile it makes a useful contribution to cutting the costs of debt service and allowing member states more fiscal room for maneouvre. Reprinted by permission of Springer","https://www.proquest.com/docview/1878795891?accountid=12870&bdid=124553&_bd=VWi7Li3H3xpypIu2Ifr%2FCIeSBpI%3D",""
"The Stochastic Stationary Root Model","","Hetland, Andreas","Econometrics","Scholarly Journals","","6","3","2018-09-01","Sep 2018","n/a","","","22251146","","","ENG","We propose and study the stochastic stationary root model. The model resembles the cointegrated VAR model but is novel in that: (i) the stationary relations follow a random coefficient autoregressive process, i.e., exhibhits heavy-tailed dynamics, and (ii) the system is observed with measurement error. Unlike the cointegrated VAR model, estimation and inference for the SSR model is complicated by a lack of closed-form expressions for the likelihood function and its derivatives. To overcome this, we introduce particle filter-based approximations of the log-likelihood function, sample score, and observed Information matrix. These enable us to approximate the ML estimator via stochastic approximation and to conduct inference via the approximated observed Information matrix. We conjecture the asymptotic properties of the ML estimator and conduct a simulation study to investigate the validity of the conjecture. Model diagnostics to assess model fit are considered. Finally, we present an empirical application to the 10-year government bond rates in Germany and Greece during the period from January 1999 to February 2018.","https://www.proquest.com/docview/2125323080?accountid=12870&bdid=124553&_bd=NQJx4aGZ%2Bd8zObTe6MMJC%2FtclsQ%3D","https://doi.org/10.3390/econometrics6030039"
"Characterizing Predictable Components in Excess Returns on Equity and Foreign Exchange Markets","","Bekaert, Geert; Hodrick, Robert J","The Journal of Finance","Scholarly Journals","","47","2","1992-06-01","Jun 1992","467","","467","00221082","","","ENG","The predictable components in excess rates of returns on major equity and foreign exchange markets are characterized using lagged excess returns, dividend yields, and forward premiums as instruments.  The equity and foreign exchange excess returns are investigated using vector autoregressive techniques.  Variables known to predict excess equity returns, such as dividend yields, are demonstrated to have predictive power for excess returns in the foreign exchange market.  Similarly, variables known to predict excess returns in the foreign exchange market, such as forward premiums, are demonstrated to have predictive power for excess equity returns.  It is also shown that bounds on the nominal dollar IMRS derived from considering US investments jointly with foreign money market and stock market investments with appropriate conditioning information are considerably higher than those obtained when attention is restricted only to the US excess equity return.","https://www.proquest.com/docview/194707771?accountid=12870&bdid=124553&_bd=63y11oIWMP%2BLNiWvFYus495b2h8%3D",""
"Building Risk into the Mitigation/Adaptation Decisions simulated by Integrated Assessment Models","","Markandya, Anil; De Cian, Enrica; Drouet, Laurent; Polanco-Martínez, Josué M; Bosello, Francesco https://orcid.org/0000-0001-8492-219X","Environmental and resource economics","Undefined","Springer Netherlands","74","4 p.1687-1721","2019-12-01","Dec 2019","1687","1721","p. 1687-1721","0924-6460","0924-6460","","ENG","This paper proposes an operationally simple and easily generalizable methodology to incorporate climate change damage uncertainty into Integrated Assessment Models (IAMs). First uncertainty is transformed into a risk measure by extracting damage distribution means and variances from an ensemble of socio economic and climate change scenarios. Then a risk premium is computed under different degrees of risk aversion, quantifying what society would be willing to pay to insure against the uncertainty of the damages. Our estimates show that the premium for the risk is a potentially significant addition to the “standard average damage”, but highly sensitive to the attitudes toward risk. In the last research phase, the risk premium is incorporated into the climate change damage function of a widely used IAM which shows, consequently, a substantial increase in both mitigation and adaptation efforts, reflecting a more precautionary attitude by the social planner. Interestingly, adaptation is stimulated more than mitigation in the first half of this century, while the situation reverses afterwards.","https://www.proquest.com/docview/2431855040?accountid=12870&bdid=124553&_bd=TxQ7UiUBKM5rd6HfEzxw9XUN89Q%3D","https://doi.org/10.1007/s10640-019-00384-1"
"Probability and statistics applied to the practice of financial risk management: The case of J.P. Morgan's RiskMetrics","","Phelan, Michael J","Journal of Financial Services Research","Scholarly Journals","","12","2,3","1997-10-01","Oct/Dec 1997","175","","175-200","09208550","","","ENG","Applications of probability and statistics in RiskMetrics, J.P.  Morgan's methodology for quantifying market risk, are described.  The methodology implements an analytical approach to financial risk in trading, arbitrage, and investment based on the statistics of market moves in equities, bonds, currencies, and commodities.  The public unveiling of RiskMetrics in October 1994 attracted widespread interest among regulators, competing financial institutions, investment managers, and corporate treasurers, while the available technical documentation offers a unique opportunity for informed statistical research on the theory and practice of financial risk management.  There are 5 applications of statistics in RiskMetrics, ranging from data analysis of daily returns and locally Gaussian processes to stochastic volatility models and Ito processes for the term structure of interest rates.  One of the critical features of RiskMetrics is the practice of single exponential smoothing of the (squared) market innovations for estimating volatilities and correlations from historical returns.","https://www.proquest.com/docview/220922748?accountid=12870&bdid=124553&_bd=ftts5SCVY1E6jrmDu6bXGVbQ%2FEI%3D",""
"A machine learning based asset pricing factor model comparison on anomaly portfolios","","Fang, Ming; Taylor, Stephen","Economics letters","Undefined","Elsevier B.V.","204 p.109919-","","2021-07-01","Jul 2021","","","","0165-1765","0165-1765","","ENG","We frame asset pricing linear factor models in a machine learning context and consider related comparisons of their predictive performance against ordinary least squares linear regression over a dataset of anomaly portfolios. Specific regression models involved in the comparison include regularized linear, support vector machines, neural networks, and tree based models among others. Performance metrics are presented on a model, portfolio group, and sequential basis, and the strongest predictors are recommended as alternative techniques for the problem of excess return forecasting.","https://www.proquest.com/docview/2574341827?accountid=12870&bdid=124553&_bd=WICRkyBG%2B%2FZ78j96Kr9pDpwzudA%3D","https://doi.org/10.1016/j.econlet.2021.109919"
"Tracking market and non-traditional sources of risks in procyclical and countercyclical hedge fund strategies under extreme scenarios: a nonlinear VAR approach","","Racicot, François-Éric; Théoret, Raymond","Financial innovation","Undefined","","8","1","2022-01-01","Jan 2022","24","","24","2199-4730","","","ENG","The subprime crisis was quite damaging for hedge funds. Using the local projection method (Jordà 2004, 2005, 2009), we forecast the dynamic responses of the betas of hedge fund strategies to macroeconomic and financial shocks-especially volatility and illiquidity shocks-over the subprime crisis in order to investigate their market timing activities. In a robustness check, using TVAR (Balke 2000), we simulate the reaction of hedge fund strategies' betas in extreme scenarios allowing moderate and strong adverse shocks. Our results show that the behavior of hedge fund strategies regarding the monitoring of systematic risk is highly nonlinear in extreme scenarios-especially during the subprime crisis. We find that countercyclical strategies have an investment technology which differs from procyclical ones. During crises, the former seek to capture non-traditional risk premia by deliberately increasing their systematic risk while the later focus more on minimizing risk. Our results suggest that the hedge fund strategies' betas respond more to illiquidity uncertainty than to illiquidity risk during crises. We find that illiquidity and VIX shocks are the major drivers of systemic risk in the hedge fund industry.The subprime crisis was quite damaging for hedge funds. Using the local projection method (Jordà 2004, 2005, 2009), we forecast the dynamic responses of the betas of hedge fund strategies to macroeconomic and financial shocks-especially volatility and illiquidity shocks-over the subprime crisis in order to investigate their market timing activities. In a robustness check, using TVAR (Balke 2000), we simulate the reaction of hedge fund strategies' betas in extreme scenarios allowing moderate and strong adverse shocks. Our results show that the behavior of hedge fund strategies regarding the monitoring of systematic risk is highly nonlinear in extreme scenarios-especially during the subprime crisis. We find that countercyclical strategies have an investment technology which differs from procyclical ones. During crises, the former seek to capture non-traditional risk premia by deliberately increasing their systematic risk while the later focus more on minimizing risk. Our results suggest that the hedge fund strategies' betas respond more to illiquidity uncertainty than to illiquidity risk during crises. We find that illiquidity and VIX shocks are the major drivers of systemic risk in the hedge fund industry.","https://www.proquest.com/docview/2638945529?accountid=12870&bdid=124553&_bd=VEulNqetH5TcENP3CxOVoAhOKMg%3D","https://doi.org/10.1186/s40854-021-00316-3"
"Bank risks, capital and loan supply: evidence from Sierra Leone","","Osei-Assibey, Eric; Bockarie, Baimba Augustine","Journal of financial economic policy","Undefined","","5","3","2013-01-01","2013","256","271","256-271","1757-6385","1757-6385","","ENG","Purpose - The study aims to investigate the factors that influence banks' loan supply in Sierra Leone. More specifically, it seeks to look into the effects of risk premium, leverage ratio and credit risk on banks' loan supply in Sierra Leone. Design/methodology/approach - Using annual bank level data on an unbalanced panel of 13 commercial banks data observed over a period of ten years (2002 to 2011), the study employs time and bank-specific fixed effects model for estimation. Findings - The findings indicate that risk premium, the share of non-performing loans in the banks' loan portfolio, tier 1 capital ratio (leverage ratio) and local currency deposit levels positively and significantly affect the share of loan supply to the private sector in banks' earning assets. On the other hand, advances to local currency deposit ratio and bank size have significant negative effects on the share of loans in banks assets. The study also finds bank type and the growth rate of real GDP (a proxy for economic activity) to be important determinants of the share of loans in banks' earning assets. Practical implications - The study recommends that the monetary authorities, banking practitioners and the government should pay keen attention to the key risk factors such as non-performing loans and risk premium in the operation of the banking sector to boost commercial banks' loan supply. Originality/value - Sierra Leone's banking sector presents a unique opportunity to study bank loan supply in relation to bank-specific features in the context of post-war financial reconstruction.","https://www.proquest.com/docview/1552593878?accountid=12870&bdid=124553&_bd=gmr7c%2BCsTnP9qhcbnolR3AU4i44%3D",""
"Monetary policy document analysis for prediction of monetary policy board decision","","Kim, Misuk; Cho, Sungzoon","Heliyon","Undefined","","9","10","2023-10-01","Oct 2023","e20696","","e20696","2405-8440","2405-8440","","ENG","In terms of market capitalization, the bond market is larger than the stock market, and the bond market is affected by macroeconomic indicators. Despite this, there has been relatively little research, making it a good candidate for the use of data mining techniques. In this paper, a novel approach designed to predict the vote results of the Korean Monetary Policy Committee regarding the base interest rate was proposed. To predict sentence sentiment, prior monetary policy decision text was used as input for classification models. The sentence sentiment prediction model showed 83.7% performance when using a support vector machine. In addition, it was observed that the bigrams extracted from documents provided important descriptions of the Korean economy at the time. Finally, the document sentiment of monetary policy decision was calculated using aggregating sentence sentiment, and the vote results were predicted using this sentiment. As a result, when using the support vector machine to predict the Monetary Policy Committee vote results, the performance improved by 29.5% over the baseline model. Statistical tests confirmed whether there is a difference in document sentiments between unanimous and non-unanimous, and the null hypothesis was rejected at a significance level of 5%.In terms of market capitalization, the bond market is larger than the stock market, and the bond market is affected by macroeconomic indicators. Despite this, there has been relatively little research, making it a good candidate for the use of data mining techniques. In this paper, a novel approach designed to predict the vote results of the Korean Monetary Policy Committee regarding the base interest rate was proposed. To predict sentence sentiment, prior monetary policy decision text was used as input for classification models. The sentence sentiment prediction model showed 83.7% performance when using a support vector machine. In addition, it was observed that the bigrams extracted from documents provided important descriptions of the Korean economy at the time. Finally, the document sentiment of monetary policy decision was calculated using aggregating sentence sentiment, and the vote results were predicted using this sentiment. As a result, when using the support vector machine to predict the Monetary Policy Committee vote results, the performance improved by 29.5% over the baseline model. Statistical tests confirmed whether there is a difference in document sentiments between unanimous and non-unanimous, and the null hypothesis was rejected at a significance level of 5%.","https://www.proquest.com/docview/2881712223?accountid=12870&bdid=124553&_bd=pUy3Hwn6DLwKMgwtKIcBCRhh7IQ%3D","https://doi.org/10.1016/j.heliyon.2023.e20696"
"Testing different forms of efficiency for Dhaka Stock Exchange","","Arefin, Jarka; Rahman, Rashedur M","International Journal of Financial Services Management","Undefined","Inderscience Publishers Ltd., PO Box 735 Olney Bucks MK46 5WB UK","5","1","2011-01-01","2011","1","20","1-20","1460-6712","1741-8062","","ENG","The Efficient-Market Hypothesis (EMH) asserts that efficient markets are informationally efficient or all information (market, public or private) should reflect on stock prices. No one could earn excess profit using any kind of information in efficient market. There are three forms of efficiency in markets: strong, semi-strong and weak. We tested EMH for Dhaka Stock Exchange (DSE) for the period 2003 2005. We used the excess return market model to test the semi-strong form efficiency of DSE. Two forecasting techniques, Autoregressive Integrated Moving Average (ARIMA) and neural network, are used to test the weak form efficiency of DSE. We get excess return for many stocks listed in DSE, demonstrating that DSE is not an efficient market in semi-strong form. Besides, the DSE market index is not random and the trend could be captured by ARIMA and neural network techniques. Therefore, the DSE is also not an efficient market in weak form.","https://www.proquest.com/docview/861560500?accountid=12870&bdid=124553&_bd=Vnvukddnk%2B6v9d8jlW%2FE7pkLoH8%3D","https://doi.org/10.1504/IJFSM.2011.038325"
"Incorporating Research Reports and Market Sentiment for Stock Excess Return Prediction: A Case of Mainland China","","Song, Huilin; Peng, Diyun; Huang, Xin","Scientific Programming","Scholarly Journals","","2020","","2020-01-01","2020","","","","1058-9244","1875-919X","","ENG","The prediction of stock excess returns is an important research topic for quantitative trading, and stock price prediction based on machine learning is receiving more and more attention. This article takes the data of Chinese A-shares from July 2014 to September 2017 as the research object, and proposes a method of stock excess return forecasting that combines research reports and investor sentiment. The proposed method measures individual stocks released by analysts, separates the two indicators of research report attention and rating sentiment, calculates investor sentiment based on external market factors, and uses the LSTM model to represent the time series characteristics of stocks. The results show that (1) the accuracy and F1 evaluation indicators are used, and the proposed algorithm is better than the benchmark algorithm. (2) The performance of deep learning LSTM algorithm is better than traditional machine learning algorithm SVM. (3) Investor sentiment as the initial hidden state of the model can improve the accuracy of the algorithm. (4) The attention of the split research report takes the two indicators of investor sentiment and price as the input of the model, which can effectively improve the performance of the model.","https://www.proquest.com/docview/2412814037?accountid=12870&bdid=124553&_bd=M00k4EM1Ufj%2BE%2FIxIjXDEtAcVpQ%3D","https://doi.org/10.1155/2020/8894757"
"The decoupling between public debt fundamentals and bond spreads after the European sovereign debt crisis","","Guirola, Luis; Pérez, Javier J","Applied Economics","Scholarly Journals","","55","34","2023-07-01","Jul 2023","3971","3979","3971-3979","00036846","","","ENG","We contribute to the literature that documents empirically that the relationship between public debt fundamentals and sovereign bond spreads in Spain, France, and Italy (versus Germany) weakened after the 2010–2012 episode of sovereign debt markets’ significant distress. To construct our measure of public debt fundamentals, we build on the literature that combines the Value at Risk approach with the estimation of the correlation pattern of public debt dynamics’ macroeconomic determinants via Vector Auto Regressions (VARs) to estimate the probability distribution of alternative debt trajectories. Since we incorporate in the VAR new information in a sequential manner, we are able to retrieve time-varying probabilities that characterize the expected behaviour of debt at a given point in time in the future. We then empirically confront such probabilistic indicators with market-derived sovereign bond spreads.","https://www.proquest.com/docview/2821134014?accountid=12870&bdid=124553&_bd=%2FTH6%2BjW9iWC2nndb819xYbXqLcE%3D","https://doi.org/10.1080/00036846.2022.2120959"
"Simplicity and Risk","","Puri, Indira","The Journal of Finance","Scholarly Journals","","80","2","2025-04-01","Apr 2025","1029","1080","1029-1080","00221082","","","ENG","I introduce and test for preference for simplicity in choice under risk. I characterize the theory axiomatically, and derive its properties and unique predictions relative to canonical models. By designing and running theoretically motivated experiments, I document that people value simplicity in ways not fully captured by existing models that study risk premia in financial markets. Participants' risk premia increase as complexity increases, holding moments fixed; their dominance violations increase in complexity; their behavior is predicted by simplicity's characterizing axiom; and their complexity aversion is heterogeneous in cognitive ability. None of expected utility theory, cumulative prospect theory, prospect theory, rational inattention, sparsity, salience, or probability weighting that differs by number of outcomes fully capture the experimental findings. I generalize the underlying theory to additionally capture broader measures of complexity, including obfuscation, computation, and language effects.","https://www.proquest.com/docview/3178050568?accountid=12870&bdid=124553&_bd=KS8f6QfbsiV1Aft7mV%2BBShK8MlM%3D","https://doi.org/10.1111/jofi.13417"
"LSTM Framework Design and Volatility Research on Intelligent Forecasting Model for Solving the Parallel Dislocation Problem","","Weng, Yiran; Wang, Zhiyi; Zhou, Longzhen","Journal of Physics: Conference Series","Scholarly Journals","","1982","1","2021-07-01","Jul 2021","","","","17426588","","","ENG","The yield of treasury bonds is the benchmark interest rate in the financial market which is worth predicting and judging. Based on the Long Short-Term Memory (LSTM) neural network model in deep learning, combined with the vector autoregression method (VAR), this paper creatively constructs the VAR-LSTM framework and uses the predicted values of macroeconomic variables and lagged value of the time sequence as input factors to solve the problem of “parallel dislocation” of the fitting results of the traditional LSTM model which significantly improves the prediction accuracy. In order to meet the requirements of active quantitative investment for high precision prediction of stock market index, adaptive noise complete ensemble empirical mode decomposition (EMD) is introduced into the modeling of stock market index prediction. Combined with the efficient modeling ability of long-term and short-term memory network for medium- and long-term dependence of complex series, using the idea of “decomposition-reorganization-prediction-integration”, an integrated prediction method of stock market index CEEMDAN-LSTM is proposed. CEEMDAN is used to decompose and reconstruct the index to obtain its high and low frequency components and trend items. The LSTM prediction models of each component are constructed respectively and the IMF reorganization mode of high frequency subseries is optimized. Then the overall predicted value of the index is obtained by adding and integrating the predicted values of each component. Taking five representative stock market indexes as test data, the prediction results of CEEMDAN-LSTM and mainstream financial time series machine learning modeling methods are compared systematically. The results show that for treasury bond yield series, the prediction accuracy of ARIMA model is higher than that of general LSTM method, while VAR-LSTM model is better than ARIMA model. The prediction error in the training set and the test set is reduced by about 55% and 50% respectively, and the prediction accuracy of the change direction is improved by about 5% and 8% respectively, which has higher application value. The prediction performance of CEEMDAN-LSTM is consistently better than that of existing modeling methods, and has less prediction error and lower lag.","https://www.proquest.com/docview/2557523318?accountid=12870&bdid=124553&_bd=FOPMyiziLU%2FdwqCyQJMKErcu4Oc%3D","https://doi.org/10.1088/1742-6596/1982/1/012028"
"The value premium and uncertainty: An approach by support vector regression algorithm","","Bui Thanh Khoa; Huynh, Tran Trong","Cogent Economics & Finance","Scholarly Journals","","11","1","2023-01-01","Jan 2023","","","","23322039","","","ENG","Risk premium plays an important role in stock investing. Experiments have shown that value stocks typically have a higher average return than growth stocks; however, this effect persists indefinitely, even disappearing in some stages. Some studies suggested high volatility in the series of returns, broken structures, market volatility, or the impact of financial crises. This study aimed to build the uncertainty index and control it in the regression analysis model to solve the limitations above. The empirical analysis in Ho Chi Minh Stock Exchange (HOSE) showed that a value premium exists, and value stocks have a higher average return than growth stocks due to the higher overall risk. Furthermore, this study combined the Support Vector Regression (SVR) algorithm with the risk premium theoretical framework for the forecasting model; consequently, it is the most efficient model.","https://www.proquest.com/docview/2829591289?accountid=12870&bdid=124553&_bd=G1yjfES9wZ0xnhJGA0p7v0DA99k%3D","https://doi.org/10.1080/23322039.2023.2191459"
"A long-short dual-mode knowledge distillation framework for empirical asset pricing models in digital financial networks","","Yi, Yuanyuan; Cui, Kai; Xu, Minghua; Yi, Lingzhi; Yi, Kun; Zhou, Xinlei; Liu, Shenghao; Zhou, Gefei","Connection Science","Scholarly Journals","","36","1","2024-12-01","Dec 2024","","","","09540091","","","ENG","The continuous combination of digital network technology and traditional financial services has given birth to digital financial networks, which explore massive economic data under the AI-driven models to achieve intelligent connections among financial institutions, markets, transactions, and instruments. Empirical asset pricing is a challenging task in financial analysis, which has attracted research attention. However, existing studies only focus on tackling the challenges of equity risk premium in the single stock market. Considering multiple economic linkages between the two countries, the transaction history of the US stock market as empirical knowledge is a powerful supplement to improve the prediction of equity risk premium in the China market. In this paper, we aim to fully leverage the prior information in two stock markets for empirical asset pricing models. Due to the rich financial domain knowledge, there may be various characteristic signals that partially overlap in different periods. To address these issues, we propose a framework based on long-short dual-mode knowledge distillation, termed as LSDM-KD, which incorporates US and China stock market models, and a shared characteristic signals model. The method effectively understands the relationships between assets and market behaviour, reducing reliance on expensive correlation databases and professional knowledge. Extensive experiments conducted on US and China stock market datasets demonstrate that our LSDM-KD can significantly improve the performance of empirical asset pricing.","https://www.proquest.com/docview/3145983394?accountid=12870&bdid=124553&_bd=IKTMV4e9eAGEh3u6yjlbY7GjYH0%3D","https://doi.org/10.1080/09540091.2024.2306970"
"Reducing the cost of capital to finance the energy transition in developing countries","","Calcaterra, M; Aleluia Reis, L; Fragkos, P; Briera, T; de Boer, H S; Egli, F; Emmerling, J; Iyer, G; Mittal, S; Polzin, F H J; Sanders, M W J L; Schmidt, T S; Serebriakova, A; Steffen, B; van de Ven, D J; van Vuuren, D P; Waidelich, P; Tavoni, M","Nature energy","Undefined","","9","10","2024-01-01","Jan 2024","1241","","1241-1251","2058-7546","","","ENG","Climate stabilization requires the mobilization of substantial investments in low- and zero-carbon technologies, especially in emerging and developing economies. However, access to stable and affordable finance varies dramatically across countries. Models used to evaluate the energy transition do not differentiate regional financing costs and therefore cannot study risk-sharing mechanisms for renewable electricity generation. In this study, we incorporated the empirically estimated cost of capital differentiated by country and technology into an ensemble of five climate-energy-economy models. We quantified the additional financing cost of decarbonization borne by developing regions and explored policies of risk premium convergence across countries. We found that alleviating financial constraints benefits both climate and equity as a result of more renewable and affordable energy in the developing world. This highlights the importance of fair finance for energy availability, affordability and sustainability, as well as the need to include financial considerations in model-based assessments.Climate stabilization requires the mobilization of substantial investments in low- and zero-carbon technologies, especially in emerging and developing economies. However, access to stable and affordable finance varies dramatically across countries. Models used to evaluate the energy transition do not differentiate regional financing costs and therefore cannot study risk-sharing mechanisms for renewable electricity generation. In this study, we incorporated the empirically estimated cost of capital differentiated by country and technology into an ensemble of five climate-energy-economy models. We quantified the additional financing cost of decarbonization borne by developing regions and explored policies of risk premium convergence across countries. We found that alleviating financial constraints benefits both climate and equity as a result of more renewable and affordable energy in the developing world. This highlights the importance of fair finance for energy availability, affordability and sustainability, as well as the need to include financial considerations in model-based assessments.","https://www.proquest.com/docview/3120594874?accountid=12870&bdid=124553&_bd=ombiNz%2FWt%2BF8EyD044NGmkpkYmE%3D","https://doi.org/10.1038/s41560-024-01606-7"
"Fiscal determinants of government borrowing costs: do we have only ourselves to blame?","","Bobetko, Alan; Dumicic, Mirna; Funda, Josip","Financial theory and practice","Undefined","","37","2","2013-01-01","2013","135","160","135-160","1846-887X","1846-887X","","ENG","The global financial crisis and the problems in peripheral EU countries resulted in increased attention to fiscal developments and their impact on borrowing costs for both public and private sector. Existing theoretical literature suggests that worsening of current and expected budget balances as well as an increase of public debt lead to a rise in short and long term interest rates for sovereign debtors. However, empirical results are inconclusive, especially for emerging market countries. This paper analyzes the factors that determine the dynamics of government bond spreads, with special emphasis on fiscal indicators. The survey covered 17 European countries, of which 9 are developed and 8 are emerging market economies, all of them members of the EU except Croatia. The empirical part of the paper employs dynamic panel data method and uses the Arellano and Bond estimator to get consistent estimates of parameters of interest. The results show that in the period 2004-2011 fiscal balance and public debt projections had a significant impact on the differences in government bond yields for emerging market countries, with the effect being much stronger during the period after the onset of financial crises. On the other hand, it seems that sovereign spread dynamics in developed countries is driven mostly by the global market sentiment.","https://www.proquest.com/docview/1418119831?accountid=12870&bdid=124553&_bd=7EBXf2so4sKakyNcqRAZ7vd89h8%3D",""
"Expected Stock Returns and Volatility","","French, Kenneth R; Schwert, G William; Stambaugh, Robert F","Journal of Financial Economics","Scholarly Journals","","19","1","1987-09-01","Sep 1987","3","","3","0304405X","","","ENG","Attention is focused on whether the expected market risk premium, defined as the expected return on a stock market portfolio minus the risk-free interest rate, is positively related to risk as measured by the volatility of the stock market.  Daily returns are used to compute estimates of monthly volatility, and these estimates are decomposed into predictable and unpredictable components using univariate autoregressive integrated moving average (ARIMA) models.  Regressions of monthly excess holding period returns on the predictable component offer little evidence of a positive relation between ex ante volatility and expected risk premiums.  However, a strong negative relation is found between excess holding period returns and the unpredictable component of volatility -- providing indirect evidence of a positive ex ante relation.  Daily returns also are used to estimate ex ante measures of volatility with a generalized autoregressive conditional heteroskedasticity (GARCH) model.  The results support the interpretation of the ARIMA results.","https://www.proquest.com/docview/231747615?accountid=12870&bdid=124553&_bd=04ibmy2LrU%2FSRyDLtx3roNbETC4%3D",""
"Deep Learning Model for Stock Excess Return Prediction Based on Nonlinear Random Matrix and Esg Factor","","Meng, Tiantian; Yahya, M H; Chai, Jingmin","Mathematical Problems in Engineering","Scholarly Journals","","2022","","2022-01-01","2022","","","","1024-123X","1563-5147","","ENG","Aiming at the problem that the traditional model has low accuracy in describing stock excess return, in order to further analyze the change law of stock excess, based on the nonlinear random matrix and esg factor theory, the traditional learning model is analyzed, and the corresponding optimized deep learning model is obtained by introducing the single ring theorem and statistical data. Through the analysis and research of related indexes, the change rules of different indexes are obtained, and the optimization model is used to calculate and forecast the excess return of stocks. The results show that the statistics and spectral radius show typical local linear variation with the increase of eigenvalue. The corresponding statistics show a trend of gradual increase. The corresponding spectral radius has a decreasing variation law, and the two curves have obvious symmetry at some eigenvalues. It can be seen from the change curves under different factors that the change trend of the yield curve is mainly affected by the investment factor, while the change rule of the specific value of the yield curve is controlled by the profit factor. This shows that the two factors have the same influence on the stock excess return. The influence of optimized deep learning model on stock excess index has typical linear characteristics, which can be divided into linear increase and linear decline according to different change rules. The basic type has the greatest influence, while the corresponding pattern analysis type has the least influence. Finally, the method of experimental verification is used to verify the stock excess data, and the results show that the optimized deep learning model can better characterize the experimental results. Therefore, the optimized deep learning model based on nonlinear random matrix and esg factor can carry out targeted analysis of different types of stock returns, thus improving research ideas and calculation methods for the application of deep learning model in different fields.","https://www.proquest.com/docview/2717516891?accountid=12870&bdid=124553&_bd=oSEtQztUKR7X0s3y3lhe1m2IY5Q%3D","https://doi.org/10.1155/2022/5239493"
"Forecasting cryptocurrencies returns: Do macroeconomic and financial variables improve tail expectation predictions?","","Lawuobahsumo, Kokulo K.; Algieri, Bernardina; Leccadito, Arturo","Quality and Quantity","Scholarly Journals","","58","3","2024-06-01","Jun 2024","2647","2675","2647-2675","00335177","","","ENG","This study aims to jointly predict conditional quantiles and tail expectations for the returns of the most popular cryptocurrencies (Bitcoin, Ethereum, Ripple, Dogecoin and Litecoin) using financial and macroeconomic indicators as explanatory variables. We adopt a Monotone Composite Quantile Regression Neural Network (MCQRNN) model to make one- and five-steps-ahead predictions of Value-at-Risk (VaR) and Expected Shortfall (ES) based on a rolling window and compare the performance of our model against the Historical simulation and the standard ARMA(1,1)-GARCH(1,1) model used as benchmarks. The superior set of models is then chosen by backtesting VaR and ES using a Model Confidence Set procedure. Our results show that the MCQRNN performs better than both benchmark models for jointly predicting VaR and ES when considering daily data. Models with the implied volatility index, treasury yield spread and inflation expectations sharpen the extreme return predictions. The results are consistent for the two risk measures at the 1% and 5% level both, in the case of a long and short position and for all cryptocurrencies.","https://www.proquest.com/docview/3046124028?accountid=12870&bdid=124553&_bd=j0RER7N6J9AVB2XCfHc5UINBF70%3D","https://doi.org/10.1007/s11135-023-01761-1"
"A Synthetic Data Generation Technique for Enhancement of Prediction Accuracy of Electric Vehicles Demand","","Chatterjee, Subhajit; Yung-Cheol Byun; Yung-Cheol Byun","Sensors","Scholarly Journals","","23","2","2023-01-01","2023","594","","","14248220","","","ENG","In terms of electric vehicles (EVs), electric kickboards are crucial elements of smart transportation networks for short-distance travel that is risk-free, economical, and environmentally friendly. Forecasting the daily demand can improve the local service provider’s access to information and help them manage their short-term supply more effectively. This study developed the forecasting model using real-time data and weather information from Jeju Island, South Korea. Cluster analysis under the rental pattern of the electric kickboard is a component of the forecasting processes. We cannot achieve noticeable results at first because of the low amount of training data. We require a lot of data to produce a solid prediction result. For the sake of the subsequent experimental procedure, we created synthetic time-series data using a generative adversarial networks (GAN) approach and combined the synthetic data with the original data. The outcomes have shown how the GAN-based synthetic data generation approach has the potential to enhance prediction accuracy. We employ an ensemble model to improve prediction results that cannot be achieved using a single regressor model. It is a weighted combination of several base regression models to one meta-regressor. To anticipate the daily demand in this study, we create an ensemble model by merging three separate base machine learning algorithms, namely CatBoost, Random Forest (RF), and Extreme Gradient Boosting (XGBoost). The effectiveness of the suggested strategies was assessed using some evaluation indicators. The forecasting outcomes demonstrate that mixing synthetic data with original data improves the robustness of daily demand forecasting and outperforms other models by generating more agreeable values for suggested assessment measures. The outcomes further show that applying ensemble techniques can reasonably increase the forecasting model’s accuracy for daily electric kickboard demand.","https://www.proquest.com/docview/2767294696?accountid=12870&bdid=124553&_bd=xxR2FkpsTQzsiSxD%2FDcKWv%2F5hwk%3D","https://doi.org/10.3390/s23020594"
"Estimating the risk-return profile of new venture investments using a risk-neutral framework and 'thick' models","","Reber, Beat","The European Journal of Finance","Scholarly Journals","","20","4","2014-04-01","2014","341","","","1351847X","","","ENG","This study proposes cascade neural networks to estimate the model parameters of the Cox-Ross-Rubinstein risk-neutral approach, which, in turn, explain the risk-return profile of firms at venture capital and initial public offering (IPO) financing rounds. Combining the two methods provides better estimation accuracy than risk-adjusted valuation approaches, conventional neural networks, and linear benchmark models. The findings are persistent across in-sample and out-of-sample tests using 3,926 venture capital and 1360 US IPO financing rounds between January 1989 and December 2008. More accurate estimates of the risk-return profile are due to less heterogeneous risk-free rates of return from the risk-neutral framework. Cascade neural networks nest both the linear and nonlinear functional estimation form in addition to taking account of variable interaction effects. Better estimation accuracy of the risk-return profile is desirable for investors so they can make a more informed judgement before committing capital at different stages of development and various financing rounds. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/1493890402?accountid=12870&bdid=124553&_bd=GUud3t%2FKkPtzcEBbldCGGOxPGNY%3D",""
"A hybrid novel framework for flood disaster risk control in developing countries based on smart prediction systems and prioritized scenarios","","Akbarian, Hadi; Gheibi, Mohammad; Hajiaghaei-Keshteli, Mostafa; Rahmani, Mojtaba","Journal of environmental management","Undefined","","312","","2022-06-15","Jun 15, 2022","114939","","114939","1095-8630","","","ENG","A Decision Support System (DSS) is a highly efficient concept for managing complex objects in nature or human-made phenomena. The main purpose of the present study is related to designing and implementation of real-time monitoring, prediction, and control system for flood disaster management as a DSS. Likewise, the problem of statement in the research is correlated to implementation of a system for different climates of Iran as a unique flood control system. For the first time, this study coupled hydrological data mining, Machine Learning (ML), and Multi-Criteria Decision Making (MCDM) as smart alarm and prevention systems. Likewise, it created the platform for conditional management of floods in Iran's different clusters of climates. According to the KMeans clustering system, which determines homogeneity of the hydrology of a specific region, Iran's rainfall is heterogeneous with 0.61 score, which is approved high efficiency of clustering in a vast country such as Iran with four seasons and different climates. In contrast, the relation of rainfall and flood disaster is evaluated by Nearest Neighbors Classification (NNC), Stochastic Gradient Descent (SGD), Gaussian Process Classifier (GPC), and Neural Network (NN) algorithms which have an acceptable correlation coefficient with a mean of 0.7. The machine learning outputs demonstrated that based on valid data existence problems in developing countries, just with verified precipitation records, the flood disaster can be estimated with high efficiency. In the following, Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) method as a Game Theory (GT) technique ranked the preventive flood damages strategies through three social (Se 1), environmental (Se 2), and economic (Se 3) crises scenarios. The solutions of flood disaster management are collected from literature review, and the opinion approves them of 9 senior experts who are retired from a high level of water resource management positions of Iran. The outcomes of the TOPSIS method proved that National announcement for public-institutional participation for rapid response and funding (G1-2), Establishment of delay structures to increase flood focus time to give the animals in the ecosystem the opportunity to escape to the upstream points and to preserve the habitat (G 2-8), and Granting free national financial resources by government agencies in order to rebuild sensitive infrastructure such as railways, hospitals, schools, etc. to the provincial treasury (G3-10) are selected as the best solution of flood management in Social, Environmental, and Economic crises, respectively. Finally, the collected data are categorized in Social, Environmental, and Economic aspects as three dimensions of Sustainable Development Goals (SDGs) and ranked based on the opinion of 32 experts in the five provinces of present case studies.A Decision Support System (DSS) is a highly efficient concept for managing complex objects in nature or human-made phenomena. The main purpose of the present study is related to designing and implementation of real-time monitoring, prediction, and control system for flood disaster management as a DSS. Likewise, the problem of statement in the research is correlated to implementation of a system for different climates of Iran as a unique flood control system. For the first time, this study coupled hydrological data mining, Machine Learning (ML), and Multi-Criteria Decision Making (MCDM) as smart alarm and prevention systems. Likewise, it created the platform for conditional management of floods in Iran's different clusters of climates. According to the KMeans clustering system, which determines homogeneity of the hydrology of a specific region, Iran's rainfall is heterogeneous with 0.61 score, which is approved high efficiency of clustering in a vast country such as Iran with four seasons and different climates. In contrast, the relation of rainfall and flood disaster is evaluated by Nearest Neighbors Classification (NNC), Stochastic Gradient Descent (SGD), Gaussian Process Classifier (GPC), and Neural Network (NN) algorithms which have an acceptable correlation coefficient with a mean of 0.7. The machine learning outputs demonstrated that based on valid data existence problems in developing countries, just with verified precipitation records, the flood disaster can be estimated with high efficiency. In the following, Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) method as a Game Theory (GT) technique ranked the preventive flood damages strategies through three social (Se 1), environmental (Se 2), and economic (Se 3) crises scenarios. The solutions of flood disaster management are collected from literature review, and the opinion approves them of 9 senior experts who are retired from a high level of water resource management positions of Iran. The outcomes of the TOPSIS method proved that National announcement for public-institutional participation for rapid response and funding (G1-2), Establishment of delay structures to increase flood focus time to give the animals in the ecosystem the opportunity to escape to the upstream points and to preserve the habitat (G 2-8), and Granting free national financial resources by government agencies in order to rebuild sensitive infrastructure such as railways, hospitals, schools, etc. to the provincial treasury (G3-10) are selected as the best solution of flood management in Social, Environmental, and Economic crises, respectively. Finally, the collected data are categorized in Social, Environmental, and Economic aspects as three dimensions of Sustainable Development Goals (SDGs) and ranked based on the opinion of 32 experts in the five provinces of present case studies.","https://www.proquest.com/docview/2644011034?accountid=12870&bdid=124553&_bd=6SB3U7Qak11pNpBUkesl5cy9v%2B8%3D","https://doi.org/10.1016/j.jenvman.2022.114939"
"Evaluating the Impact of Risk on Contractor's Tender Figure in Public Buildings Projects in Northern Nigeria","","Oyewobi, L O; Ibrahim, A D; Ganiyu, B O","Journal of Engineering, Project, and Production Management","Undefined","Association of Engineering, Project, and Production Management","2","1","2012-01-01","2012","2","13","2-13","2221-6529","2223-8379","","ENG","It has become almost impossible to have projects completed within the initial cost and time in Nigeria; this is as a result of many factors the construction industry is being plagued with ranging from estimating risk to time and cost overruns. The construction industry is widely associated with a high degree of risk and uncertainty due to the nature of its operating heterogeneous environment. The paper aimed at evaluating the impact of estimating risk on contractor's tender sum with a view of ensuring efficient delivery of projects in the Northern part of Nigeria. A survey was conducted using questionnaire and a total of four headings of risk factors were identified. Research findings showed defects in design, inflation, contractor's competence and political uncertainty as well as changes in government had greatest impact on contractor's tender figure whereas likely trend in wages rates over the period, excessive approval procedure in administration government department, unavailability of sufficient amount of unskilled labor and technical manpower and resources of the company were the most significant factors to be considered by contractors when estimating the pricing risk. The paper recommends that construction professionals should identify and adequately quantify project estimating risk factors. Adding a risk premium to quotation and time estimation has to be supported by governmental owner organizations and other agencies in the local construction sector. Competent contractors should be allowed to tender so as to see the incidence of these estimating risks as an important aspect that requires attention while evaluating contractor's tender sum.","https://www.proquest.com/docview/1031298752?accountid=12870&bdid=124553&_bd=rgfiLBLu4xR2fJQLtwCMg1BlsiI%3D",""
"Predictable variation and profitable trading of US equities: a trading simulation using neural networks","","Motiwalla, Luvai; Wahab, Mahmoud","Computers & Operations Research","Undefined","Elsevier Science BV, P.O. Box 211, Amsterdam, 1000 AE, Netherlands, [mailto:w.tukker@elsevier.nl], [URL:http://www.elsevier.com]","27","11","2000-01-01","2000","1111","1129","1111-1129","0305-0548","0305-0548","","ENG","A switching rule conditioned on out-of-sample one-step-ahead predictions of returns is used to establish investment positions in either stocks or Treasury bills. The economic significance of any discernible patterns of predictability is assessed by incorporating transaction costs in the simulated trading strategies. We find that ANN models produce switching signals that could have been exploited by investors in an out-of-sample context to achieve superior cumulative and risk-adjusted returns when compared to either regression or a simple buy-and-hold strategy in the market indices. The robustness of these results across a large number of stock market indices is encouraging.","https://www.proquest.com/docview/27651367?accountid=12870&bdid=124553&_bd=coPmkgI13dWiy4iwWB8g%2B8WiaJw%3D",""
"A hybrid approach for portfolio construction: Combing two‐stage ensemble forecasting model with portfolio optimization","","Chen, Wei; Liu, Zinuo; Jia, Lifen","Computational Intelligence","Scholarly Journals","","40","2","2024-04-01","Apr 2024","","","","08247935","","","ENG","Combining the stock prediction with portfolio optimization can improve the performance of the portfolio construction. In this article, we propose a novel portfolio construction approach by utilizing a two‐stage ensemble model to forecast stock prices and combining the forecasting results with the portfolio optimization. To be specific, there are two phases in the approach: stock prediction and portfolio optimization. The stock prediction has two stages. In the first stage, three neural networks, that is, multilayer perceptron (MLP), gated recurrent unit (GRU), and long short‐term memory (LSTM) are used to integrate the forecasting results of four individual models, that is, LSTM, GRU, deep multilayer perceptron (DMLP), and random forest (RF). In the second stage, the time‐varying weight ordinary least square model (OLS) is utilized to combine the first‐stage forecasting results to obtain the ultimate forecasting results, and then the stocks having a better potential return on investment are chosen. In the portfolio optimization, a diversified mean‐variance with forecasting model named DMVF is proposed, in which an average predictive error term is considered to obtain excess returns, and a 2‐norm cost function is introduced to diversify the portfolio. Using the historical data from the Shanghai stock exchange as the study sample, the results of the experiments indicate the DMVF model with two‐stage ensemble prediction outperforms benchmarks in terms of return and return‐risk characteristics.","https://www.proquest.com/docview/3044657538?accountid=12870&bdid=124553&_bd=6xBUtkW2V4OE0re7n0Fsv35vBBU%3D","https://doi.org/10.1111/coin.12617"
"Heterogeneous Demand and Supply for an Insurance‐linked Credit Product in Kenya: A Stated Choice Experiment Approach","","Shee, Apurba; Turvey, Calum G; Marr, Ana","Journal of Agricultural Economics","Scholarly Journals","","72","1","2021-02-01","Feb 2021","244","267","244-267","0021857X","","","ENG","We employ a discrete choice experiment to elicit demand and supply side preferences for insurance‐linked credit, a promising market‐based tool for managing agricultural weather risks and providing access to credit for farmers. We estimate preference heterogeneity using primary data from smallholder farmers and managers of lenders/insurers combined with household socio‐economic survey data in Kenya. We analyse the choice data using maximum simulated likelihood and Hierarchical Bayes estimation of a mixed logit model. Although there are some similarities, we find that there is conflicting demand and supply side preferences for credit terms, collateral requirements, and loan use flexibility. We also analyse willingness to buy and willingness to offer for farmers and suppliers, respectively, for the risk premium for different attributes and their levels. Identifying the preferred attributes and levels for both farmers and financial institutions can guide optimal packaging of insurance and credit providing market participation and adoption motivation for insurance‐bundled credit product.","https://www.proquest.com/docview/2475287969?accountid=12870&bdid=124553&_bd=A670LxNB06B5bwP5OycMi2VbFEY%3D","https://doi.org/10.1111/1477-9552.12401"
"Forecasting stock prices changes using long-short term memory neural network with symbolic genetic programming","","Li, Qi; Kamaruddin, Norshaliza; Yuhaniz, Siti Sophiayati; Al-Jaifi, Hamdan Amer Ali","Scientific reports","Undefined","","14","1","2024-01-03","Jan 3, 2024","422","","422","2045-2322","","","ENG","This study introduces an augmented Long-Short Term Memory (LSTM) neural network architecture, integrating Symbolic Genetic Programming (SGP), with the objective of forecasting cross-sectional price returns across a comprehensive dataset comprising 4500 listed stocks in the Chinese market over the period from 2014 to 2022. Using the S&P Alpha Pool Dataset for China as basic input, this architecture incorporates data augmentation and feature extraction techniques. The result of this study demonstrates significant improvements in Rank Information coefficient (Rank IC) and IC information ratio (ICIR) by 1128% and 5360% respectively when it is applied to fundamental indicators. For technical indicators, the hybrid model achieves a 206% increase in Rank IC and an impressive surge of 2752% in ICIR. Furthermore, the proposed hybrid SGP-LSTM model outperforms major Chinese stock indexes, generating average annualized excess returns of 31.00%, 24.48%, and 16.38% compared to the CSI 300 index, CSI 500 index, and the average portfolio, respectively. These findings highlight the effectiveness of SGP-LSTM model in improving the accuracy of cross-sectional stock return predictions and provide valuable insights for fund managers, traders, and financial analysts.This study introduces an augmented Long-Short Term Memory (LSTM) neural network architecture, integrating Symbolic Genetic Programming (SGP), with the objective of forecasting cross-sectional price returns across a comprehensive dataset comprising 4500 listed stocks in the Chinese market over the period from 2014 to 2022. Using the S&P Alpha Pool Dataset for China as basic input, this architecture incorporates data augmentation and feature extraction techniques. The result of this study demonstrates significant improvements in Rank Information coefficient (Rank IC) and IC information ratio (ICIR) by 1128% and 5360% respectively when it is applied to fundamental indicators. For technical indicators, the hybrid model achieves a 206% increase in Rank IC and an impressive surge of 2752% in ICIR. Furthermore, the proposed hybrid SGP-LSTM model outperforms major Chinese stock indexes, generating average annualized excess returns of 31.00%, 24.48%, and 16.38% compared to the CSI 300 index, CSI 500 index, and the average portfolio, respectively. These findings highlight the effectiveness of SGP-LSTM model in improving the accuracy of cross-sectional stock return predictions and provide valuable insights for fund managers, traders, and financial analysts.","https://www.proquest.com/docview/2910191689?accountid=12870&bdid=124553&_bd=Rd2KtYrPyVZIRUeiDrmGQ20bOYU%3D","https://doi.org/10.1038/s41598-023-50783-0"
"A model-selection approach to assessing the information in the term structure using linear models and artificial neural networks","","Swanson, Norman R; White, Halbert","Journal of business & economic statistics","Undefined","","13","3","1995-07-01","Jul 1995","265","276","265-276","0735-0015","0735-0015","","ENG","","https://www.proquest.com/docview/38763842?accountid=12870&bdid=124553&_bd=Z1FMY7dyShC8qLDezToNynH4eCA%3D",""
"Research on the Risks of Financial Informatization Construction in Colleges and Universities, Its Prevention and Control and Path Optimization","","Lv, Xin","Applied Mathematics and Nonlinear Sciences","Scholarly Journals","","10","1","2025-01-01","2025","","","","24448656","","","ENG","With the rapid growth of the demand for college and university funding, the financial management of colleges and universities from the traditional meaning of the risk-free state to the risky mode of change, for the college and university financial risk of accurate and reasonable prevention and control has become an important issue that needs to be resolved at this stage. This paper selects a university finance as the research object, designs 12 financial indicators as sample data, processes the financial risk indicator system through principal component analysis, and obtains 8 principal factor components as the input data of the risk prediction model. Then the particle swarm algorithm is combined with BP neural network to overcome the defects of BP neural network as a way to strengthen its prediction accuracy of financial risk. Through simulation experiments, comparative analysis of prediction rates of different models, it is found that the PSO-BP prediction model achieves an identification accuracy of 91.7% for 60 test samples, which improves the identification correctness by 23.7% and 8.4% compared with the traditional BP model and GA-BP model, respectively. It confirms that the PSO-BP neural network model has a higher prediction rate and is effective in introducing university finance for risk prediction. Finally, the article proposes an optimization strategy for the path of university finance information technology construction, in order to improve the effectiveness of university finance information technology construction.","https://www.proquest.com/docview/3254257496?accountid=12870&bdid=124553&_bd=8ZqetLzA6dwZjviZvlsGVtbzi6M%3D","https://doi.org/10.2478/amns-2025-1039"
"Unconventional monetary policy in a nonlinear quadratic model","","Faulwasser, Timm; Gross, Marco; Semmler, Willi; Loungani, Prakash","Studies in Nonlinear Dynamics and Econometrics","Scholarly Journals","","24","5","2020-12-01","Dec 2020","","","","1081-1826","","","ENG","After the financial market meltdown and the Great Recession of the years 2007–9, the financial market-macro link has become an important issue in monetary policy modeling. We develop a dynamic model that contains a nonlinear Phillips curve, a dynamic output equation, and a nonlinear credit flow equation – capturing the importance of credit cycles, risk premia, and credit spreads. Our Nonlinear Quadratic Model (NLQ) model has three dynamic state equations and a quadratic objective function. It can be used to evaluate the response of central banks to the Great Recession in moving from conventional to unconventional monetary policy. We solve the model with a new numerical procedure using estimated parameters for the euro area. We conduct simulations to explore the (de)stabilizing effects of the nonlinearities in the model. We demonstrate that credit flows, risk premia, and credit spreads play an important role as an amplification mechanism and in affecting the transmission of monetary policy. We thereby highlight the importance of the natural rate of interest as an anchor for a central bank target and the weight it places on the credit flows for the effectiveness of unconventional monetary policy. Our model is similar in structure compared to larger scale macro-econometric models which many central banks employ.","https://www.proquest.com/docview/2483641831?accountid=12870&bdid=124553&_bd=ucbidJg6sNDS7NqIWI14TfO7Ln0%3D","https://doi.org/10.1515/snde-2019-0099"
"Do local and global factors impact the emerging markets' sovereign yield curves? Evidence from a data‐rich environment","","Cepni, Oguzhan; Ibrahim, Ethem Guney; Kucuksarac, Doruk; Yilmaz, M Hasan","Journal of Forecasting","Scholarly Journals","","40","7","2021-11-01","Nov 2021","1214","1229","1214-1229","02776693","","","ENG","This paper investigates the relation between yield curve and macroeconomic factors for 10 emerging sovereign bond markets using the sample from January 2006 to April 2019. To this end, the diffusion indices obtained under four categories (global variables, inflation, domestic financial variables, and economic activity) are incorporated by estimating dynamic panel data regressions together with the yield curve factors. Besides, in order to capture dynamic interaction between yield curve and macroeconomic/financial factors, a panel vector autoregressive (VAR) analysis based on the system generalized method of moments (GMM) approach is utilized. Empirical results suggest that the level factor responds to shocks originated from inflation, domestic financial variables, and global variables. Furthermore, the slope factor is affected by shocks in global variables, and the curvature factor appears to be influenced by domestic financial variables. We also show that macroeconomic/financial factors captures significant predictive information over yield curve factors by running individual country factor‐augmented predictive regressions and variable selection algorithms such ridge regression, least absolute shrinkage operator (LASSO), and Elastic Net. Our findings have important implications for policymakers and fund managers by explaining the underlying forces of movements in the yield curve and forecasting accurately dynamics of yield curve factors.","https://www.proquest.com/docview/2578915422?accountid=12870&bdid=124553&_bd=yG6fsfUAXziTk0q%2BmukxJSiCVDY%3D","https://doi.org/10.1002/for.2763"
"Early warning strategies for corporate operational risk: A study by an improved random forest algorithm using FCM clustering","","Fang, Xini","PLoS One","Scholarly Journals","","20","3","2025-03-01","Mar 2025","e0318491","","","19326203","","","ENG","To enhance the accuracy and response speed of the risk early warning system, this study develops a novel early warning system that combines the Fuzzy C-Means (FCM) clustering algorithm and the Random Forest (RF) model. Firstly, based on operational risk theory, market risk, research and development risk, financial risk, and human resource risk are selected as the primary indicators for enterprise risk assessment. Secondly, the Criteria Importance Through Intercriteria Correlation (CRITIC) weight method is employed to determine the importance of these risk indicators, thereby enhancing the model’s prediction ability and stability. Following this, the FCM clustering algorithm is utilized for pre-processing sample data to improve the efficiency and accuracy of data classification. Finally, an improved RF model is constructed by optimizing the parameters of the RF algorithm. The data selected is mainly from RESSET/DB, covering the issuance, trading, and rating data of fixed-income products such as bonds, government bonds, and corporate bonds, and provides basic information, net value, position, and performance data of funds. The experimental results show that the model achieves an F1 score of 87.26%, an accuracy of 87.95%, an Area under the Curve (AUC) of 91.20%, a precision of 89.29%, and a recall of 87.48%. They are respectively 6.45%, 4.45%, 5.09%, 4.81%, and 3.83% higher than the traditional RF model. In this study, an improved RF model based on FCM clustering is successfully constructed, and the accuracy of risk early warning models and their ability to handle complex data are significantly improved.","https://www.proquest.com/docview/3176284910?accountid=12870&bdid=124553&_bd=IlcGd4iZoyO35MpQykmIGuCYzls%3D","https://doi.org/10.1371/journal.pone.0318491"
"Cost-benefit analysis in a climate of change: setting social discount rates in the case of Ireland","","O'Mahony, Tadhg","Green Finance","Scholarly Journals","","3","2","2021-01-01","2021","175","","175-197","26431092","","","ENG","The global practice of Cost-Benefit Analysis (CBA), to analyse the welfare impacts of public investments, has undergone profound changes in recent years. The reforms in general practice have primarily been driven by the discussions of the implications of climate change and environmental degradation. Central to the discussion has been the social discount rate, used to value future costs and benefits in the present, and also the dual discount rates for ""environmental goods"", as goods that are of no, or of risky substitution. Official rates, in many nations, are calculated using the ""Ramsey"" formula. The literature has explored the relevant factors in this formula, but with less attention paid to the selection of the rate of future growth in consumption, or to the setting of dual discount rates in national practice guidance. Through considering the case of Ireland, this study demonstrates that the selection of growth rates in consumption, in the context of future uncertainty, requires the use of plausible scenarios, rather than historical trends or forecasts. By employing economic scenarios, alongside established values for the other factors, the main discount rate for Ireland is calculated in a range of 1.7 to 2.8 per cent. Seperately, a dual discount rate, for capital that cannot be replaced, is estimated at ≤1.3 per cent. The main discount rate is validated by comparison against discount rates found in the literature, applied in other comparable nations, and by the rate estimated from the real yield on government bonds. All four independent lines of evidence support the range estimated. This demonstrates that the Irish government's estimated discount rate, of 4.0 per cent, is not credible, and needs reduction, alongside introduction of dual discounting.","https://www.proquest.com/docview/3147490787?accountid=12870&bdid=124553&_bd=w1S2ncYp1J9SmYl5PeSHB5YP5MQ%3D","https://doi.org/10.3934/GF.2021010"
"Are quantitative easing effects transitory? Evidence from out-of-sample forecasts","","Kirikos, Dimitris G","Journal of Financial Economic Policy","Scholarly Journals","","14","6","2022-11-01","2022","811","822","811-822","17576385","","","ENG","Purpose>Advocates of quantitative easing (QE) policies have emphasized some evidence that structural models do not predict long-term asset yields as well as naive forecasts, implying that predictions of price reversals cannot be profitable and that QE effects are not transitory. The purpose of this study is to reconsider the out-of-sample forecasting performance of structural time series processes relative to that of a random walk with or without drift.Design/methodology/approach>This study uses bivariate vector autoregression and Markov switching representations to generate out-of-sample forecasts of ten-year sovereign bond yields, when the information set is augmented by including the growth rate of the monetary base, and the estimation relies on monthly data from countries that have pursued unconventional policies over the last decade.Findings>The results show that naive forecasts are not better than those of structural time series models, based on root mean squared errors, while the Markov model provides additional information on price reversals, through probabilistic inferences regarding policy regime switches, which can induce agents to counteract QE interventions and reduce their effectiveness.Originality/value>The novel features of this work are the use of a large information set including the instrument of unconventional monetary policy, the use of a structural model (Markov process) that can really inform about potential asset price reversals and the use of a large sample over which QE policies have been pursued.","https://www.proquest.com/docview/2728402466?accountid=12870&bdid=124553&_bd=ZS6I3wq0IlF%2Bkqq%2BuDvjY2Z7lao%3D","https://doi.org/10.1108/JFEP-04-2022-0099"
"Sign realized jump risk and the cross-section of stock returns: Evidence from China's stock market","","Chao, Youcong; Liu, Xiaoqun; Guo, Shijun","PLoS One","Scholarly Journals","","12","8","2017-08-01","Aug 2017","e0181990","","","19326203","","","ENG","Using 5-minute high frequency data from the Chinese stock market, we employ a non-parametric method to estimate Fama-French portfolio realized jumps and investigate whether the estimated positive, negative and sign realized jumps could forecast or explain the cross-sectional stock returns. The Fama-MacBeth regression results show that not only have the realized jump components and the continuous volatility been compensated with risk premium, but also that the negative jump risk, the positive jump risk and the sign jump risk, to some extent, could explain the return of the stock portfolios. Therefore, we should pay high attention to the downside tail risk and the upside tail risk.","https://www.proquest.com/docview/1925832808?accountid=12870&bdid=124553&_bd=MbQOSy5fHx%2FmUyIXzhm2hECwheQ%3D","https://doi.org/10.1371/journal.pone.0181990"
"Complex systems and ‘‘Spatio ‐Temporal Anti‐Compliance Coordination’’ In cyber‐physical networks: A critique of the Hipster Effect, bankruptcy prediction and alternative risk premia","","Nwogugu, Michael I. C.","Journal of Cell Communication and Signaling","Scholarly Journals","","3","3","2021-09-01","Sep 1, 2021","253","262","253-262","18739601","","","ENG","The Hipster Effect is a group of evolutionary ‘‘Diffusive Learning’’ processes of networks of individuals and groups (and their communication devices) that form Cyber‐Physical Systems; and the Hipster Effect theory has potential applications in many fields of research. This study addresses decision‐making parameters in machine‐learning algorithms, and more specifically, critiques the explanations for the Hipster Effect, and discusses the implications for portfolio management and corporate bankruptcy prediction (two areas where AI has been used extensively). The methodological approach in this study is entirely theoretical analysis. The main findings are as follows: (i) the Hipster Effect theory and associated mathematical models are flawed; (ii) some decision‐making and learning models in machine‐learning algorithms are flawed; (iii) but regardless of whether or not the Hipster Effect theory is correct, it can be used to develop portfolio management models, some of which are summarised herein; (iv) the [1] corporate bankruptcy prediction model can also be used for portfolio‐selection (stocks and bonds).","https://www.proquest.com/docview/3091974902?accountid=12870&bdid=124553&_bd=WBw34Hit2nVnrKJdzLh9BjI7U9Y%3D","https://doi.org/10.1049/ccs2.12029"
"Foreign exchange risk and risk exposure in the Japanese stock market","","Tai, Chu-Sheng","Managerial Finance","Undefined","Emerald Group Publishing Limited, 60-62 Toller Lane Bradford West Yorkshire BD8 9BY UK","36","6","2010-01-01","2010","511","524","511-524","0307-4358","0307-4358","","ENG","Purpose - Whether stock returns are linked to exchange rate changes and whether foreign exchange risk is priced in a domestic context are less conclusive and thus still subject to a great debate. The purpose of this paper is to provide new empirical evidence on these two inter-related issues, which are critical to investors and corporate risk management. Design/methodology/approach - This paper applies two different econometric approaches: Nonlinear Seemingly Unrelated Regression (NLSUR) via Hansen's Generalized Method of Moment (GMM) and multivariate GARCH in mean (MGARCH-M) to examine the exchange rate exposure and its pricing. Findings - Using industry data for Japan, similar to previous studies, foreign exchange risk is not priced based on the test of an unconditional two-factor asset pricing model. However, strong evidence of time-varying foreign exchange risk premium and significant exchange rate betas are obtained based on the tests of conditional asset pricing models using MGARCH-M approach where both conditional first and second moments of industry returns and risk factors are estimated simultaneously. Research limitations/implications - The strong empirical evidence found in this study implies that corporate currency hedging not only results in more stable cash flows for a firm, but also reduces its cost of capital, and hence is justifiable. Originality/value - This paper conducts an in-depth investigation regarding the exchange rate exposure and its pricing by utilizing two different econometric approaches: NLSUR via Hansen's GMM and MGARCH-M. In doing so, a more reliable conclusion about the exchange rate exposure and its pricing can be drawn.","https://www.proquest.com/docview/746224064?accountid=12870&bdid=124553&_bd=wFcez7kWF9wL9VxLUPGYDM%2B3ZgA%3D","https://doi.org/10.1108/03074351011042991"
"The Pruned State-Space System for Non-Linear DSGE Models: Theory and Empirical Applications","","Andreasen, Martin M","The Review of Economic Studies","Scholarly Journals","","85","1","2018-01-01","Jan 2018","1","49","1-49","00346527","","","ENG","This article studies the pruned state-space system for higher-order perturbation approximations to dynamic stochastic general equilibrium (DSGE) models. We show the stability of the pruned approximation up to third order and provide closed-form expressions for first and second unconditional moments and impulse response functions. Our results introduce generalized method of moments (GMM) estimation and impulse-response matching for DSGE models approximated up to third order and provide a foundation for indirect inference and simulated method of moments (SMM). As an application,we consider a New Keynesian model with Epstein–Zin preferences and two novel feedback effects from long-term bonds to the real economy, allowing us to match the level and variability of the $10$-year term premium in the U.S. with a low relative risk aversion of $5$.","https://www.proquest.com/docview/3244133988?accountid=12870&bdid=124553&_bd=hpRQHuKGi2qWlEtGooBDPklbhwg%3D","https://doi.org/10.1093/restud/rdx037"
"Does extreme climate concern drive equity premiums? Evidence from China","","Xu, Yongan; Liang, Chao","Humanities & Social Sciences Communications","Scholarly Journals","","11","1","2024-12-01","Dec 2024","1187","","1187","2662-9992","","","ENG","We construct an extreme climate concern indicator (ECC) on the basis of the coverage of the extreme climate news reports. First, ECC significantly negatively forecasts stock market returns in subsequent months. The predictability of ECC returns outperforms alternative confidence indicators and economic predictors over both in-sample and out-of-sample periods. Second, relative to before the Paris Agreement entered into force, extreme climate concerns prominently enhanced the forecasting capabilities after the signing of the Paris Agreement. Third, the return prediction accuracy of ECC in periods of low climate concern is significantly greater than that in periods of high climate concern, which is also consistent with the limited attention of investors. Finally, ECC substantially brings appreciable economic gains to investors, and the relevant empirical results pass a series of robustness tests.","https://www.proquest.com/docview/3103060202?accountid=12870&bdid=124553&_bd=8ak74dDy0kcZFDAPtWSGyPT6M1s%3D","https://doi.org/10.1057/s41599-024-03705-y"
"Investor attention using the Google search volume index – impact on stock returns","","Swamy, Vighneswara; Munusamy Dharani","Review of Behavioral Finance","Scholarly Journals","","11","1","2019-01-01","2019","56","70","56-70","19405979","","","ENG","PurposeThe purpose of this paper is to investigate whether the investor attention using the Google search volume index (GSVI) can be used to forecast stock returns. The authors also find the answer to whether the “price pressure hypothesis” would hold true for the Indian stock market.Design/methodology/approachThe authors employ a more recent fully balanced panel data for the period from July 2012 to Jun 2017 (260 weeks) of observations for companies of NIFTY 50 of the National Stock Exchange in the Indian stock market. The authors are motivated by Tetlock (2007) and Bijl et al. (2016) to employ regression approach of econometric estimation.FindingsThe authors find that high Google search volumes lead to positive returns. More precisely, the high Google search volumes predict positive and significant returns in the subsequent fourth and fifth weeks. The GSVI performs as an useful predictor of the direction as well as the magnitude of the excess returns. The higher quantiles of the GSVI have corresponding higher excess returns. The authors notice that the domestic investor searches are correlated with higher excess returns than the worldwide investor searches. The findings imply that the signals from the search volume data could be of help in the construction of profitable trading strategies.Originality/valueTo the best of the authors knowledge, no paper has examined the relationship between Google search intensity and stock-trading behavior in the Indian stock market. The authors use a more recent data for the period from 2012 to 2017 to investigate whether search query data on company names can be used to predict weekly stock returns for individual firms. This study complements the prior studies by investigating the relationship between search intensity and stock-trading behavior in the Indian stock market.","https://www.proquest.com/docview/2229579655?accountid=12870&bdid=124553&_bd=mbGLv1XBGOLto4tnv9X61wJCCwg%3D","https://doi.org/10.1108/RBF-04-2018-0033"
"Elliptical Capital Asset Pricing Models: Formulation, Diagnostics, Case Study with Chilean Data, and Economic Rationale","","Leal, Danilo; Jiménez, Rodrigo; Riquelme, Marco; Leiva, Víctor; Leiva, Víctor","Mathematics","Scholarly Journals","","11","6","2023-01-01","2023","1394","","","22277390","","","ENG","The capital asset pricing model (CAPM) is often based on the Gaussianity or normality assumption. However, such an assumption is frequently violated in practical situations. In this paper, we introduce the symmetric CAPM considering distributions with lighter or heavier tails than the normal distribution. These distributions are symmetric and belong to the family of elliptical distributions. We pay special attention to the family members related to the normal, power-exponential, and Student-t cases, with the power-exponential distribution being particularly considered, as it has not been explored widely. Based on these cases, the expectation-maximization algorithm can be used to facilitate the estimation of model parameters utilizing the maximum likelihood method. In addition, we derive the leverage and local influence methods to carry out diagnostics in the symmetric CAPM. We conduct a detailed case study to apply the obtained results estimating the systematic risk of the financial assets of a Chilean company with real data. We employ the Akaike information criterion to conclude that the studied models provide better results than the CAPM under Gaussianity.","https://www.proquest.com/docview/2791670629?accountid=12870&bdid=124553&_bd=t7LlUFjqv7Oe2yjn9emEK6neSew%3D","https://doi.org/10.3390/math11061394"
"Investor attention and stock market volatility","","Andrei, Daniel; Hasler, Michael","Review of financial studies","Undefined","","28","1","2015-01-01","Jan 2015","33","72","33-72","0893-9454","0893-9454","","ENG","We investigate, in a theoretical framework, the joint role played by investors' attention to news and learning uncertainty in determining asset prices. The model provides two main predictions. First, stock return variance and risk premia increase with both attention and uncertainty. Second, this increasing relationship is quadratic. We empirically test these two predictions, and we show that the data lend support to the increasing relationship. The evidence for a quadratic relationship is mixed. Overall, our study shows theoretically and empirically that both attention and uncertainty are key determinants of asset prices. Reprinted by permission of Oxford University Press","https://www.proquest.com/docview/1646697003?accountid=12870&bdid=124553&_bd=G1yl8wbLNq%2BADNMcsr91yWHXhOo%3D",""
"Yield and Risk - The Basic Coordinates of Socio-Economic Development Programs","","Stoica, Emilia Cornelia; Sudacevschi, Mihaela","Global Economic Observer","Scholarly Journals","","7","1","2019-01-01","2019","146","151","146-151","23439742","","","ENG","Public policies are implemented through larger and smaller public programs and projects that have to comply with very strict governance conditions. Evaluating the net benefits generated by public programs or projects allows for the identification of the cost-effective ones in order to select them. For this purpose, a lot of indicators, mainly the Net Present Value (NPV), both in financial and socio-economic terms, as well as the recovery period, are being constructed, the probabilistic modeling of which provides the information needed to determine the public spending performance, public expendityres financing the national economy development. Development and implementation of the public programs are faced with risks, their prediction being a complex approach. For the identification of risks, a wide range of values of indicators involved in risky actions is assigned so that probability appraisal of the occurrence of those risks can be made, including their impact upon environment and / or community. The mix of the probability of producing the risk and its impact leads to the identification of most of its manifestations, so that we can retain to evaluate the program only the significant risks. The paper also presents the most important criteria for the selection of the development programs /projects, focusing on addressing economic and social benefits, expressed in monetary terms. The cost-benefit analysis that must accompany any public project proposal will identify both its utility for the intended community and externalities, positive and / or negative, that will be a factor of impact upon the NPV.","https://www.proquest.com/docview/2242029715?accountid=12870&bdid=124553&_bd=pmCIq1kRZd6f49SSE3a9BGImE4Y%3D",""
"Weight of the Default Component of CDS Spreads: Avoiding Procyclicality in Credit Loss Provisioning Framework","","Gubareva, Mariya","Complexity","Scholarly Journals","","2019","","2019-01-01","2019","","","","1076-2787","1099-0526","","ENG","The current expected loss calculations have recently attracted considerable attention in the research on credit risk modeling, impairment provisioning, and financial networks’ stability. A new CDS-based approach to estimate current expected credit loss is proposed for low default portfolios, containing credit exposures to corporate issuers covered by publicly traded CDS contracts. First, a fraction of CDS spread related to a pure default compensation for different CDS maturities is assessed. Our results contrast with previous research. Second, based on the obtained historical weights of the default risk premium, a forward-looking term structure of the probabilities of default implied by the current CDS quotes is derived. The proposed approach covers both investment and noninvestment grade debt. The resulting framework is applied to a sample of corporate bonds. The developed methodology provides a useful tool, on one hand, for credit risk managers and balance-sheet preparers and, on the other hand, for regulators of financial markets as it sheds light on how procyclicality could be avoided in provisions.","https://www.proquest.com/docview/2257544369?accountid=12870&bdid=124553&_bd=OZaIAuGU5Hswu%2BnA8Y5y82YBFVM%3D","https://doi.org/10.1155/2019/7820618"
"Bayesian factor-adjusted sparse regression","","Fan, Jianqing; Jiang, Bai; Sun, Qiang","Journal of Econometrics","Scholarly Journals","","230","1","2022-09-01","Sep 2022","3","","","03044076","","","ENG","Many sparse regression methods rely on an assumption that the covariates are weakly correlated, which hardly holds in many economic and financial datasets. To relax this assumption, we model the strongly correlated covariates by a factor structure: strong correlations among covariates are modeled by common factors, while the remaining variations of covariates are modeled as idiosyncratic components. We then propose a factor-adjusted sparse regression model and develop a semi-Bayesian estimation method for it. Posterior contraction rate and model selection consistency are established by a non-asymptotic analysis. Experimental studies show that the proposed method outperforms its Lasso analogue, manifests insensitivity to overestimates of the number of common factors, pays a negligible price when covariates are uncorrelated, scales up well with increasing sample size, dimensionality and sparsity, and converges fast to the posterior distribution. An application to the U.S. bond risk premia lends further support to the proposed model and method.","https://www.proquest.com/docview/2712275938?accountid=12870&bdid=124553&_bd=vxKbOrqNUMKTgkxxvFePk%2BQv0kE%3D","https://doi.org/10.1016/j.jeconom.2020.06.012"
"Government Deficits and the Term Structure of Interest Rates","","Lee, Bong-Soo","Journal of Monetary Economics","Scholarly Journals","","27","3","1991-06-01","Jun 1991","425","","425","03043932","","","ENG","The effects of government deficits on interest rates with different terms to maturities are investigated.  A nonlinear term structure model with a time-varying term premium in which the Ricardian equivalence hypothesis (REH) holds is developed and estimated allowing for conditional heteroskedasticity and serial correlation in the disturbance terms.  The model is found to be compatible with postwar US data.  An alternative non-Ricardian model allowing for a wealth effect is also developed and estimated.  It does not show any evidence of a significant wealth effect.  The findings suggest that the government's financing decision for a given time path of government expenditure did not have any significant effect on bond markets.  An appropriate econometric treatment that captures the conditional heteroskedasticity does not reveal, with respect to various interest rates, any strong evidence against either the REH or the term structure model.","https://www.proquest.com/docview/205785202?accountid=12870&bdid=124553&_bd=NSdwDgaQ405K10jbo6ajelwV5lk%3D",""
"Financial Stock Investment Management Using Deep Learning Algorithm in the Internet of Things","","Fan, Jianjuan; Peng, Shen","Computational intelligence and neuroscience","Undefined","","2022","","2022-01-01","Jan 2022","4514300","","4514300","1687-5273","","","ENG","This paper aims to explore a new model to study financial stock investment management (SIM) and obtain excess returns. Consequently, it proposes a financial SIM model using deep Q network (DQN) as reinforcement earning (RL) algorithm and Long Short-Term Memory (LSTM) as deep neural network (DNN). Then, after training and optimization, the proposed model is back-tested. The research findings are as follows: the LSTM neural network (NN)-based model will import the observation of the market at each time and the change of transaction information over time. The LSTM network can find and learn the potential relationship between time series data. There are two hidden layers and one output layer in the model. The hidden layer is an LSTM structure and the output layer is the fully connected NN. DQN algorithm first stores the experience sample data of the agent-environment interaction into the experience pool. It then randomly selects a small batch of data from the experience pool to train the network. Doing so removes the correlation and dependence between samples so that the DNN model can better learn the value function in the RL task. The model can predict the future state according to historical information and decide which actions to take in the next step. Meanwhile, five stocks of Chinese A-shares are selected to form an asset pool. The initial 500,000 amount of the account is divided into five equal shares, which are invested and traded. Overall, the model account's rate of return (RoR) during the back-test is 32.12%. The Shanghai Stock Exchange (SSI) has risen by 19.157% in the same period. Thus, the model's performance has exceeded the SSI's in the same period. E stock has the maximum RoR of 78.984%. The RoR of A, B, and C stocks is 54.129%, 11.594%, and 9.815%, respectively. B stock presents a minimum RoR of 6.084%. All these stocks have got positive returns. Therefore, the proposed financial SIM based on the DL algorithm is scientific and feasible. The research content has certain significant reference for the DL-based financial SIM.This paper aims to explore a new model to study financial stock investment management (SIM) and obtain excess returns. Consequently, it proposes a financial SIM model using deep Q network (DQN) as reinforcement earning (RL) algorithm and Long Short-Term Memory (LSTM) as deep neural network (DNN). Then, after training and optimization, the proposed model is back-tested. The research findings are as follows: the LSTM neural network (NN)-based model will import the observation of the market at each time and the change of transaction information over time. The LSTM network can find and learn the potential relationship between time series data. There are two hidden layers and one output layer in the model. The hidden layer is an LSTM structure and the output layer is the fully connected NN. DQN algorithm first stores the experience sample data of the agent-environment interaction into the experience pool. It then randomly selects a small batch of data from the experience pool to train the network. Doing so removes the correlation and dependence between samples so that the DNN model can better learn the value function in the RL task. The model can predict the future state according to historical information and decide which actions to take in the next step. Meanwhile, five stocks of Chinese A-shares are selected to form an asset pool. The initial 500,000 amount of the account is divided into five equal shares, which are invested and traded. Overall, the model account's rate of return (RoR) during the back-test is 32.12%. The Shanghai Stock Exchange (SSI) has risen by 19.157% in the same period. Thus, the model's performance has exceeded the SSI's in the same period. E stock has the maximum RoR of 78.984%. The RoR of A, B, and C stocks is 54.129%, 11.594%, and 9.815%, respectively. B stock presents a minimum RoR of 6.084%. All these stocks have got positive returns. Therefore, the proposed financial SIM based on the DL algorithm is scientific and feasible. The research content has certain significant reference for the DL-based financial SIM.","https://www.proquest.com/docview/2694959931?accountid=12870&bdid=124553&_bd=rGMqI7MZe9bifkbD8B6AqEY5Zzg%3D","https://doi.org/10.1155/2022/4514300"
"Bayesian inference for long memory term structure models","","Valente, Fernanda; Laurini, Márcio","Journal of Statistical Computation and Simulation","Scholarly Journals","","94","8","2024-05-01","May 2024","1735","1759","1735-1759","00949655","","","ENG","In this study, we propose a novel adaptation of the Dynamic Nelson–Siegel term structure model, incorporating long memory properties to enhance its forecasting accuracy. Our approach involves modelling the evolution of latent factors using fractional Gaussian noise processes, approximated by a weighted sum of independent first-order autoregressive components. The resulting formulation allows for a Gaussian Markov Random Field representation, facilitating the application of computationally efficient Bayesian techniques through Integrated Nested Laplace Approximations. Extensive simulation and empirical analysis demonstrate that integrating long memory significantly improves the model's forecasting performance, particularly for longer time horizons. By shedding light on the potential benefits of incorporating long memory concepts into traditional term structure models, our research highlights its utility in capturing intricate temporal dependencies and enhancing prediction precision.","https://www.proquest.com/docview/3072935909?accountid=12870&bdid=124553&_bd=AfOqUN13yT%2BLlrSUl2MUQBybqO4%3D","https://doi.org/10.1080/00949655.2023.2299938"
"Risk, Return and Volatility Feedback: A Bayesian Nonparametric Analysis","","Jensen, Mark J; Maheu, John M","Journal of Risk and Financial Management","Scholarly Journals","","11","3","2018-09-01","Sep 2018","n/a","","","19118066","","","ENG","In this paper, we let the data speak for itself about the existence of volatility feedback and the often debated risk–return relationship. We do this by modeling the contemporaneous relationship between market excess returns and log-realized variances with a nonparametric, infinitely-ordered, mixture representation of the observables’ joint distribution. Our nonparametric estimator allows for deviation from conditional Gaussianity through non-zero, higher ordered, moments, like asymmetric, fat-tailed behavior, along with smooth, nonlinear, risk–return relationships. We use the parsimonious and relatively uninformative Bayesian Dirichlet process prior to overcoming the problem of having too many unknowns and not enough observations. Applying our Bayesian nonparametric model to more than a century’s worth of monthly US stock market returns and realized variances, we find strong, robust evidence of volatility feedback. Once volatility feedback is accounted for, we find an unambiguous positive, nonlinear, relationship between expected excess returns and expected log-realized variance. In addition to the conditional mean, volatility feedback impacts the entire joint distribution.","https://www.proquest.com/docview/2121708686?accountid=12870&bdid=124553&_bd=4XPoJxzjWArVqCBPiCZY6HRI1ZI%3D","https://doi.org/10.3390/jrfm11030052"
"Oil price dynamics and speculation: A multivariate financial approach","","Cifarelli, Giulio; Paladino, Giovanna","Energy Economics","Undefined","Elsevier Ltd, Amsterdam The Netherlands","32","2","2010-03-01","March 2010","363","372","363-372","0140-9883","0140-9883","","ENG","This paper assesses empirically whether speculation affects oil price dynamics. The growing presence of financial operators in the oil markets has led to the diffusion of trading techniques based on extrapolative expectations. Strategies of this kind foster feedback trading that may cause considerable departures of prices from their fundamental values. We investigate this hypothesis using a modified CAPM following Shiller (1984) and Sentana and Wadhwani (1992). First, a univariate GARCH(1,1)-M is estimated assuming the risk premium to be a function of the conditional oil price volatility. The single factor model, however, is outperformed by the multifactor ICAPM (Merton, 1973), which takes into account a larger investment opportunity set. Analysis is then carried out using a trivariate CCC GARCH-M model with complex nonlinear conditional mean equations where oil price dynamics are associated with both stock market and exchange rate behavior. We find strong evidence that oil price shifts are negatively related to stock price and exchange rate changes and that a complex web of time-varying first and second order conditional moment interactions affects both the CAPM and feedback trading components of the model. Despite the difficulties, we identify a significant role played by speculation in the oil market, which is consistent with the observed large daily upward and downward shifts in prices - a clear evidence that it is not a fundamental-driven market. Thus, from a policy point of view - given the impact of volatile oil prices on global inflation and growth - actions that monitor speculative activities on commodity markets more effectively are to be welcomed. [Copyright Elsevier B.V.]","https://www.proquest.com/docview/58837340?accountid=12870&bdid=124553&_bd=SlpjPq5mNq6NHF1shd6zGVFgPAE%3D","https://doi.org/10.1016/j.eneco.2009.08.014"
"Oil volatility risk and stock market volatility predictability: Evidence from G7 countries","","Feng, Jiabao; Wang, Yudong; Yin, Libo","Energy Economics","Scholarly Journals","","68","","2017-10-01","Oct 2017","240","","","01409883","","","ENG","Academic research relies extensively on stock market information to forecast oil volatility, with relatively little attention paid to the reverse evidence. Our paper fills this gap by investigating the predictive ability of oil volatility risk to forecast stock market volatility. Using oil volatility risk premium (oil VRP) as the predictor, we find that oil VRP does exhibit statistically and economically significant in-sample and out-of-sample forecasting power for G7 countries, even controlling for some popular macroeconomic variables. These findings are robust when using alternative proxies for volatilities of stock and oil. Furthermore, the strength of the predictive evidence is substantial during relatively high and low level of stock market, while is substantially higher for recessions vis-á-vis expansions. Oil VRP can also contains additional information for predicting a series of macroeconomic variables, which serves as an available explanation for its forecasting ability.","https://www.proquest.com/docview/1999637270?accountid=12870&bdid=124553&_bd=hdsMbjUmcdDZrxWjqPwCNsm3CIM%3D",""
"Indicator variables for inflation expectations in the Euro area","","Masten, Igor; Maver, Vida","International Journal of Sustainable Economy","Scholarly Journals","","13","2","2021-01-01","2021","107","125","107-125","17565804","","","ENG","In this paper, we model the Euro area market-based inflation expectations extracted from the inflation-linked swaps, and study the macroeconomic information embedded in expected inflation. First, we estimate the Gaussian affine term structure model to decompose the forward ILS-implied inflation rate into inflation expectations and inflation risk premium at one-, two- and three-year horizons. Secondly, from a large panel of macroeconomic series we identify the most significant indicator variables for inflation expectations using the elastic net modification of the LASSO regression. Finally, we measure partial contributions of individual indicator variables to the changes in inflation expectations. Our findings reveal that across horizons considered inflation expectations are correlated to the measures of current inflation of the overall price level and price level of services, the unemployment rate, and the Euro exchange rate. The identified indicators provide a useful information about the evolution of inflation expectations with different intensities at different horizons.","https://www.proquest.com/docview/2519181086?accountid=12870&bdid=124553&_bd=HOsWTdBazKF81DMX9ftlvycDJYE%3D","https://doi.org/10.1504/IJSE.2021.114615"
"Robust term structure estimation in developed and emerging markets","","Ahi, Emrah; Akgiray, Vedat; Sener, Emrah","Annals of Operations Research","Scholarly Journals","","260","1-2","2018-01-01","Jan 2018","23","49","23-49","02545330","","","ENG","Despite powerful advances in interest rate curve modeling for data-rich countries in the last 30 years, comparatively little attention has been paid to the key practical problem of estimation of the term structure of interest rates for emerging markets. This may be partly due to limited data availability. However, emerging bond markets are becoming increasingly important and liquid. It is, therefore, important to be understand whether conclusions drawn from developed countries carry over to emerging markets. We estimate model parameters of fully flexible Nelson–Siegel–Svensson term structures model which has become one of the most popular term structure model among academics, practitioners, and central bankers. We investigate four sets of bond data: U.S. Treasuries, and three major emerging market government bond data-sets (Brazil, Mexico and Turkey). By including both the very dense U.S. data and the comparatively sparse emerging market data, we ensure that are results are not specific to a particular data-set. We find that gradient and direct search methods perform poorly in estimating term structures of interest rates, while global optimization methods, particularly the hybrid particle swarm optimization introduced in this paper, do well. Our results are consistent across four countries, both in- and out-of-sample, and for perturbations in prices and starting values. For academics and practitioners interested in optimization methods, this study provides clear evidence of the practical importance of choice of optimization method and validates a method that works well for the NSS model.","https://www.proquest.com/docview/1983621774?accountid=12870&bdid=124553&_bd=bZLsQY%2BwNjQt20W7jjmknLAB1ec%3D","https://doi.org/10.1007/s10479-016-2282-5"
"Risk aversion and the yield of corporate debt","","Wu, Chunchi; Yu, Chih-Hsien","Journal of Banking and Finance","Undefined","","20","2","1996-01-01","1996","267","281","267-281","0378-4266","0378-4266","","ENG","This paper develops a model to estimate the implied default probability of corporate bonds. The model explicitly considers the risk averse behavior of investors to provide a more precise framework for estimating the implied default probability. A Kalman filter method is used to estimate time-varying risk premium associated with the investor's risk aversion. The results of nonlinear regressions indicate that previous risk-neutrality models consistently overestimate the implied default rates of corporate bonds. The results also suggest that investors may have been adequately compensated for investment in risky bonds.","https://www.proquest.com/docview/15856561?accountid=12870&bdid=124553&_bd=j%2FMEXg3CiU3uTgxRIDMd7Ryhxxg%3D",""
"Equity securities analysis in the U.S.","","Muller, Frederick L","Financial Analysts Journal","Scholarly Journals","","50","1","1994-01-01","Jan-Feb 1994","6","","6","0015198X","","","ENG","An overview of the development of securities analysis in the US is presented.  The first coherent framework for analyzing securities came in 1934 with the publication of Security Analysis, by Benjamin Graham and David Dodd.  Security Analysis offered a rigorous approach to determining the fundamental worth of a company's balance sheet and earning power.  In the 1970s, three powerful forces converged to change the way long-term capital is invested.  1.  The ideas of Modern Portfolio Theory were increasingly disseminated.  2.  The amount of assets flowing to professional investment institutions exploded, fueled by ERISA.  3.  After the bear market of 1970 and the devastation of wealth in 1973 and 1974, skepticism about the ability of investment managers to earn excess returns beame pervasive.  Today, passive management appears to have peaked but will remain important.  The CAPM is also under seige, but the evidence against it is not yet convincing.  The future likely holds advances in fundamental analysis and nonlinear systems.","https://www.proquest.com/docview/219233447?accountid=12870&bdid=124553&_bd=dKwdTlFW%2BwHLwY0AEteJGU6LQIQ%3D",""
"On LASSO for predictive regression","","Lee, Ji Hyung; Shi, Zhentao; Gao, Zhan","Journal of Econometrics","Scholarly Journals","","229","2","2022-08-01","Aug 2022","322","","","03044076","","","ENG","Explanatory variables in a predictive regression typically exhibit low signal strength and various degrees of persistence. Variable selection in such a context is of great importance. In this paper, we explore the pitfalls and possibilities of the LASSO methods in this predictive regression framework. In the presence of stationary, local unit root, and cointegrated predictors, we show that the adaptive LASSO cannot asymptotically eliminate all cointegrating variables with zero regression coefficients. This new finding motivates a novel post-selection adaptive LASSO, which we call the twin adaptive LASSO (TAlasso), to restore variable selection consistency. Accommodating the system of heterogeneous regressors, TAlasso achieves the well-known oracle property. In contrast, conventional LASSO fails to attain coefficient estimation consistency and variable screening in all components simultaneously. We apply these LASSO methods to evaluate the short- and long-horizon predictability of S&P 500 excess returns.","https://www.proquest.com/docview/2727703194?accountid=12870&bdid=124553&_bd=RW4Us41Ldzd7bTKYZRrEOO44gFM%3D","https://doi.org/10.1016/j.jeconom.2021.02.002"
"An Evaluation of Machine Learning Models for Forecasting Short-Term U.S. Treasury Yields","","Yi-Fan, Wang; Wang, Max Yue-Feng; Li-Ying, Tu","Applied Sciences","Scholarly Journals","","15","12","2025-01-01","2025","6903","","","20763417","","","ENG","This study explores the historical evolution and short-term predictive modeling of the U.S. 10-year Treasury bond yield, a critical indicator in global financial markets. Recognizing its sensitivity to macroeconomic conditions, the research integrates economic variables, including the federal funds rate, core Consumer Price Index (CPI), real Gross Domestic Product (GDP) growth rate, and the U.S. federal debt growth rate, to assess their influence on yield movements. Four forecasting models are employed for comparative analysis: linear regression (LR), decision tree (DT), random forest (RF), and multilayer perceptron (MLP) neural networks. Using historical data from the Federal Reserve Economic Data (FRED), this study finds that the RF model offers the most accurate short-term predictions, achieving the lowest mean squared error (MSE) and mean absolute error (MAE), with an R2 value of 0.5760. The results highlight the superiority of ensemble-based nonlinear models in capturing complex interactions between economic indicators and yield dynamics. This research not only provides empirical support for using machine learning in economic forecasting but also offers practical implications for bond traders, system developers, and financial institutions aiming to enhance predictive accuracy and risk management.","https://www.proquest.com/docview/3223875273?accountid=12870&bdid=124553&_bd=KVZLqM5Ka5Da6wwHlAN58CimMn4%3D","https://doi.org/10.3390/app15126903"
"Can climate change attention predict energy stock returns?","","Jia, Shanghui; Liu, Yingke; Jin, Jiayu","Environmental Science and Pollution Research","Scholarly Journals","","30","38","2023-08-01","Aug 2023","89253","89269","89253-89269","09441344","","","ENG","We propose a climate change attention (CCA) index based on Google search volume index (GSVI) from 2004 to 2021 and show that it is an economically and statistically significant negative predictor for next month’s energy stock returns. The index is extracted using principal component analysis (PCA), but the results are similar by using the equal-weighted average method. Compared with 14 traditional macroeconomic predictors, CCA performs the best and provides complementary information when added into bivariate and multivariate macro predictive models. When further considering the effect of CCA’s forecasting power over different periods, strong evidence is shown that this outperformance is especially prominent in economic depressions and down market conditions. From the asset allocation perspective, CCA can provide a mean-variance investor with significant economic gains under alternative risk aversions. Our empirical results prove that investors’ attention to climate change contains predictive information for excess returns of global traditional energy stock index.","https://www.proquest.com/docview/2848014306?accountid=12870&bdid=124553&_bd=3fYiTvDTkwF6z4cTeppKlapWRgs%3D","https://doi.org/10.1007/s11356-023-28731-2"
"Maximum likelihood estimation of non-affine volatility processes","","Chourdakis, K; Dotsis, G","Journal of empirical finance","Undefined","","18","3","2011-06-01","Jun 2011","533","545","533-545","0927-5398","0927-5398","","ENG","In this paper we develop a new estimation method for extracting non-affine latent stochastic volatility and risk premia from measures of model-free realized and risk-neutral integrated volatility. We estimate non-affine models with nonlinear drift and constant elasticity of variance and we compare them to the popular square-root stochastic volatility model. Our empirical findings are: (1) the square-root model is misspecified; (2) the inclusion of constant elasticity of variance and nonlinear drift captures stylized facts of volatility dynamics and (3) the square-root stochastic volatility model is explosive under the risk-neutral probability measure. All rights reserved, Elsevier","https://www.proquest.com/docview/873846255?accountid=12870&bdid=124553&_bd=b%2BJ4WPig1AHb2l2a0zVcgEvMH8w%3D","https://doi.org/10.1016/j.jempfin.2010.10.006"
"Oil price dynamics and speculation","","Cifarelli, G; Paladino, Giovanna","Energy economics","Undefined","","32","2","2010-03-01","Mar 2010","363","372","363-372","0140-9883","0140-9883","","ENG","This paper assesses empirically whether speculation affects oil price dynamics. The growing presence of financial operators in the oil markets has led to the diffusion of trading techniques based on extrapolative expectations. Strategies of this kind foster feedback trading that may cause considerable departures of prices from their fundamental values. We investigate this hypothesis using a modified CAPM following Shiller (1984) and Sentana and Wadhwani (1992). First, a univariate GARCH(1,1)-M is estimated assuming the risk premium to be a function of the conditional oil price volatility. The single factor model, however, is outperformed by the multifactor ICAPM (Merton, 1973), which takes into account a larger investment opportunity set. Analysis is then carried out using a trivariate CCC GARCH-M model with complex nonlinear conditional mean equations where oil price dynamics are associated with both stock market and exchange rate behavior. We find strong evidence that oil price shifts are negatively related to stock price and exchange rate changes and that a complex web of time-varying first and second order conditional moment interactions affects both the CAPM and feedback trading components of the model. Despite the difficulties, we identify a significant role played by speculation in the oil market, which is consistent with the observed large daily upward and downward shifts in prices - a clear evidence that it is not a fundamental-driven market. Thus, from a policy point of view - given the impact of volatile oil prices on global inflation and growth - actions that monitor speculative activities on commodity markets more effectively are to be welcomed. All rights reserved, Elsevier","https://www.proquest.com/docview/37268225?accountid=12870&bdid=124553&_bd=1dD%2FSyfZZ9LEPoI3aPVQD3rxUYs%3D","https://doi.org/10.1016/j.eneco.2009.08.014"
"Stochastic interest rates in the analysis of energy investments: Implications on economic performance and sustainability","","Tolis, Athanasios; Doukelis, Aggelos; Tatsiopoulos, Ilias","Applied Energy","Undefined","Elsevier Science, The Boulevard Kidlington Oxford OX5 1GB United Kingdom","87","8","2010-08-01","Aug 2010","2479","2490","2479-2490","0306-2619","0306-2619","","ENG","A systematic impact assessment of stochastic interest and inflation rates on the analysis of energy investments is presented. A real-options algorithm has been created for this task. Constant interest rates incorporating high risk premium have been extensively used for economic calculations, within the framework of traditional direct cash flow methods, thus favouring immediate, irreversible investments in the expense of, sometimes, insubstantially low anticipated yields. In this article, not only incomes and expenses but also interest and inflation rates are considered stochastically evolving according to specific probabilistic models. The numerical experiments indicated that the stochastic interest rate forecasts fluctuate in such low levels that may signal delayed investment entry in favour of higher expected yields. The implementation of stochastically evolving interest rates in energy investment analysis may have a controversial effect on sustainability. Displacements of inefficient plants may be significantly delayed, thus prolonging high CO sub(2) emission rates. Under the current CO sub(2) allowance prices or their medium-term forecasts, this situation may not be improved and flexible policy interventions may be necessitated.","https://www.proquest.com/docview/1671296851?accountid=12870&bdid=124553&_bd=lFBg89HsqueV3cvNv9uwPsdjqVA%3D","https://doi.org/10.1016/j.apenergy.2009.11.033"
"Anomalies and the Expected Market Return","","Dong, Xi; Li, Yan; Rapach, David E; Zhou, Guofu","The Journal of Finance","Scholarly Journals","","77","1","2022-02-01","Feb 2022","639","681","639-681","00221082","","","ENG","We provide the first systematic evidence on the link between long‐short anomaly portfolio returns—a cornerstone of the cross‐sectional literature—and the time‐series predictability of the aggregate market excess return. Using 100 representative anomalies from the literature, we employ a variety of shrinkage techniques (including machine learning, forecast combination, and dimension reduction) to efficiently extract predictive signals in a high‐dimensional setting. We find that long‐short anomaly portfolio returns evince statistically and economically significant out‐of‐sample predictive ability for the market excess return. The predictive ability of anomaly portfolio returns appears to stem from asymmetric limits of arbitrage and overpricing correction persistence.","https://www.proquest.com/docview/2616565886?accountid=12870&bdid=124553&_bd=pmpe3gMBuWKeJH3W9IWPTE4AVG0%3D","https://doi.org/10.1111/jofi.13099"
"Rating Crop Insurance Contracts with Nonparametric Bayesian Model Averaging","","Liu, Yong; Ker, Alan P","Journal of Agricultural and Resource Economics","Scholarly Journals","","45","2","2020-05-01","May 2020","244","264","244-264","10685502","","","ENG","Crop insurance is plagued by relatively little historical information but significant spatial information. We investigate the efficacy of using nonparametric Bayesian model averaging (BMA) to incorporate extraneous information into the estimated premium rates. Nonparametric BMA is particularly suited to this application because it does not make any assumptions about parametric form or the extent to which yields are similar. We evaluate the proposed estimator under small-to-medium sample sizes and various geographical restrictions on the distance of spatial smoothing for policy relevance. The nonparametric BMA consistently decreases error and enables statistically significant and economically important rents to be captured.","https://www.proquest.com/docview/2427312064?accountid=12870&bdid=124553&_bd=CbHe37Of1CE%2BC0nZQRDr4tsLivc%3D","https://doi.org/10.22004/ag.econ.302453"
"The maturity premium","","Chaderina, Maria; Weiss, Patrick; Zechner, Josef","Journal of Financial Economics","Scholarly Journals","","144","2","2022-05-01","May 2022","670","","","0304405X","","","ENG","We show that firms with longer debt maturities earn risk premia not explained by unconditional factors. Embedding dynamic capital structure choices in an asset-pricing framework where the market price of risk evolves with the business cycle, we find that firms with long-term debt exhibit more countercyclical leverage. The induced covariance between betas and the market price of risk generates a maturity premium similar in size to our empirical estimate of 0.21% per month. We also provide direct evidence for the model mechanism and confirm that the maturity premium is consistent with observed leverage dynamics of long- and short-maturity firms.","https://www.proquest.com/docview/2662023440?accountid=12870&bdid=124553&_bd=Q9zkLcEKHyqmNeGTREAVTfS8Lw0%3D","https://doi.org/10.1016/j.jfineco.2021.07.008"
"Short term forecasting with support vector machines and application to stock price prediction","","Ince, Huseyin; Trafalis, Theodore B","International Journal of General Systems","Undefined","Taylor & Francis Ltd , 11 New Fetter Lane, London, EC4P 4EE, UK, [URL:http://www.tandf.co.uk]","37","6","2008-12-01","Dec. 2008","677","687","677-687","0308-1079","0308-1079","","ENG","Forecasting a stock price movement is one of the most difficult problems in finance. The reason is that financial time series are complex, non stationary. Furthermore, it is also very difficult to predict this movement with parametric models. Instead of parametric models, we propose two techniques, which are data driven and non parametric. Based on the idea that excess returns would be possible with publicly available information, we developed two models in order to forecast the short term price movements by using technical indicators. Our assumption is that the future value of a stock price depends on the financial indicators although there is no parametric model to explain this relationship. This relationship comes from the technical analysis. Comparison shows that support vector regression (SVR) out performs the multi layer perceptron (MLP) networks for a short term prediction in terms of the mean square error. If the risk premium is used as a comparison criterion, then the SVR technique is as good as the MLP method or better.","https://www.proquest.com/docview/35642830?accountid=12870&bdid=124553&_bd=DUvz%2Fn6w6tQApuIyOHQdCc%2FCMNk%3D","https://doi.org/10.1080/03081070601068595"
"Fluctuations in economic and activity and stabilization policies in the CIS","","Kiani, Khurshid M","Computational economics","Undefined","","37","2","2011-02-01","Feb 2011","193","220","193-220","0927-7099","0927-7099","","ENG","In this study, a highly flexible form of nonlinear time series models called artificial neural networks (ANNs) are employed to predict fluctuations in economic activity in selected members (Armenia, Azerbaijan, Georgia, Kazakhstan, and Kyrgyzstan) of the Commonwealth of Independent States (CIS) using macroeconomic time series [treasury bill rate (T-bill), long term bond rate (BondLT), money supply (MS), industrial production (IP), spread (10-year treasury bond rate less 3-month treasury bill rate), BRTB (bank rate less 3-month treasury bill rate), and GDP growth rate]. Forecasting recessions being very important though challenging, recessions in the selected countries are modeled recursively 1-10 quarters ahead out-of-sample using ANNs in conjunction with macroeconomic time series for all the countries. The out-of-sample forecast results show that in general no single macroeconomic variable employed appears to be useful for predicting recessions in any of the series. However, for Armenia, the treasury bill rate, industrial production, money supply, and the spread (the yield curve) are candidate variables for predicting recessions 1-10 quarters ahead. For Georgia, Kazakhstan, and Kyrgyzstan, the treasury bill rate and money supply series are candidate variables for predicting recessions 1-10 quarters ahead. Reprinted by permission of Springer","https://www.proquest.com/docview/853212355?accountid=12870&bdid=124553&_bd=dxyBdHITjDd4jaMbmWYLr2r3jQs%3D","https://doi.org/10.1007/s10614-010-9233-z"
"Measuring the Financial Value of Marketing Strategy with Excess Stock Market Return","","Lane, Vicki","International Journal of Risk and Contingency Management","Scholarly Journals","","3","4","2014-01-01","2014","1","16","1-16","21609624","","","ENG","This paper proposes excess stock market return as a way to measure the impact of marketing strategy on firm value. First, it provides an overview of event study method. An event study examines the excess return to a firm's stock price after the release of information that is relevant to the firm's financial success. Second, it shows how excess return captures a marketing strategy's impact on firm value. It presents a model that illustrates how a marketing strategy impacts consumers, future cash flows, firm value, investor's expectations, and excess return. Third, a comparison shows that excess return stacks up well against standard marketing metrics. Excess return yields unbiased estimates, allows direct causal inference, is future oriented, includes all cash flows, accounts for opportunity costs, factors in risk, and takes into account the time value of money.","https://www.proquest.com/docview/2932402876?accountid=12870&bdid=124553&_bd=xJ3ELb0CI68iP9JUhWqwhfHOCdk%3D","https://doi.org/10.4018/ijrcm.2014100101"
"A nonlinear factor analysis of S&P 500 index option returns","","Jones, Christopher S","Journal of finance","Undefined","","61","5","2006-10-01","Oct 2006","2325","2364","2325-2364","0022-1082","0022-1082","","ENG","Growing evidence suggests that extraordinary average returns may be obtained by trading equity index options, and that at least part of this abnormal performance is attributable to volatility and jump risk premia. This paper asks whether such priced risk factors are alone sufficient to explain these average returns. To provide an answer in as general as possible a setting, I estimate a flexible class of nonlinear models using all S&P 500 Index futures options traded between 1986 and 2000. The results show that priced factors contribute to these expected returns but are insufficient to explain their magnitudes, particularly for short-term out-of-the-money puts. Reprinted by permission of Blackwell Publishing","https://www.proquest.com/docview/36525587?accountid=12870&bdid=124553&_bd=Ej9SvP9IjAANYIA5V75rWqUjey4%3D",""
"Oil price dynamics and speculation: A multivariate financial approach","","Cifarelli, Giulio; Paladino, Giovanna","Energy Economics","Undefined","Elsevier B.V., The Boulevard Kidlington Oxford OX5 1GB United Kingdom","32","2","2010-03-01","Mar 1, 2010","363","372","363-372","0140-9883","0140-9883","","ENG","This paper assesses empirically whether speculation affects oil price dynamics. The growing presence of financial operators in the oil markets has led to the diffusion of trading techniques based on extrapolative expectations. Strategies of this kind foster feedback trading that may cause considerable departures of prices from their fundamental values. We investigate this hypothesis using a modified CAPM following Shiller (1984) and Sentana and Wadhwani (1992). First, a univariate GARCH(1,1)-M is estimated assuming the risk premium to be a function of the conditional oil price volatility. The single factor model, however, is outperformed by the multifactor ICAPM (Merton, 1973), which takes into account a larger investment opportunity set. Analysis is then carried out using a trivariate CCC GARCH-M model with complex nonlinear conditional mean equations where oil price dynamics are associated with both stock market and exchange rate behavior. We find strong evidence that oil price shifts are negatively related to stock price and exchange rate changes and that a complex web of time-varying first and second order conditional moment interactions affects both the CAPM and feedback trading components of the model. Despite the difficulties, we identify a significant role played by speculation in the oil market, which is consistent with the observed large daily upward and downward shifts in prices - a clear evidence that it is not a fundamental-driven market. Thus, from a policy point of view - given the impact of volatile oil prices on global inflation and growth - actions that monitor speculative activities on commodity markets more effectively are to be welcomed.","https://www.proquest.com/docview/1125230825?accountid=12870&bdid=124553&_bd=fEc7OqBQyJgUwQOe7owon%2BeHMmc%3D","https://doi.org/10.1016/j.eneco.2009.08.014"
"Forecasting time series subject to multiple structural breaks","","Pesaran, M Hashem; Pettenuzzo, Davide; Timmermann, Allan","Review of economic studies","Undefined","","73(4)","257","2006-10-01","Oct 2006","1057","1084","1057-1084","0034-6527","0034-6527","","ENG","This paper provides a new approach to forecasting time series that are subject to discrete structural breaks. We propose a Bayesian estimation and prediction procedure that allows for the possibility of new breaks occurring over the forecast horizon, taking account of the size and duration of past breaks (if any) by means of a hierarchical hidden Markov chain model. Predictions are formed by integrating over the parameters from the meta-distribution that characterizes the stochastic break-point process. In an application to U.S. Treasury bill rates, we find that the method leads to better out-of-sample forecasts than a range of alternative methods. Reprinted by permission of Blackwell Publishers","https://www.proquest.com/docview/36509894?accountid=12870&bdid=124553&_bd=iWrPUW6VuBY8XHcEQmQA4EoQifY%3D",""
"The Pruned State-Space System for Non-Linear DSGE Models: Theory and Empirical Applications","","Andreasen, Martin M; Fernández-Villaverde, Jesús; Rubio-Ramírez, Juan F","The Review of Economic Studies","Scholarly Journals","","85","1","2018-01-01","Jan 2018","1","","","00346527","","","ENG","This article studies the pruned state-space system for higher-order perturbation approximations to dynamic stochastic general equilibrium (DSGE) models. We show the stability of the pruned approximation up to third order and provide closed-form expressions for first and second unconditional moments and impulse response functions. Our results introduce generalized method of moments (GMM) estimation and impulse-response matching for DSGE models approximated up to third order and provide a foundation for indirect inference and simulated method of moments (SMM). As an application,we consider a New Keynesian model with Epstein-Zin preferences and two novel feedback effects from long-term bonds to the real economy, allowing us to match the level and variability of the 10-year term premium in the U.S. with a low relative risk aversion of 5. [web URL: https://academic.oup.com/restud/article/85/1/1/3897018]","https://www.proquest.com/docview/2001315937?accountid=12870&bdid=124553&_bd=owwHi0rnN0iwpXilctuoNmCZ2nE%3D",""
"Endogenous parameter time series estimation of the Ohlson model: linear and nonlinear analyses","","Morel, Mindy","Journal of business finance and accounting","Undefined","","30","9-10","2003-11-01","Nov 2003","1341","1362","1341-1362","0306-686X","0306-686X","","ENG","This paper tests the empirical validity of the Ohlson (1995) model on a firm-level time series basis. The coefficients of the earnings dynamic and valuation equations are first estimated by OLS. Next, recognizing the nonlinear relationships among the parameters, each equation is estimated by nonlinear Least Squares. Lastly, the model is estimated as a restricted system by nonlinear Least Squares and nonlinear SUR. In all cases, parameters are endogenously estimated. Irrespective of the estimation method, the Ohlson model often yields inconsistent or insignificant parameter estimates. Nevertheless, point estimates of equity risk premia are similar to those obtained from alternative methodologies. Reprinted by permission of Blackwell Publishers","https://www.proquest.com/docview/37848099?accountid=12870&bdid=124553&_bd=cy1kKZMGeUETy64qie%2BmN0gRMxQ%3D",""
"Event-based approach for probabilistic agricultural drought risk assessment under rainfed conditions","","Quijano, Juan A; Jaimes, Miguel A; Torres, Marco A; Reinoso, Eduardo; Castellanos, Luisarturo; Escamilla, Jesus; Ordaz, Mario","Natural Hazards","Undefined","Springer Science+Business Media, Van Godewijckstraat 30 Dordrecht 3311 GX Netherlands","76","2","2015-03-01","March 2015","1297","1318","1297-1318","0921-030X","1573-0840","","ENG","An event-based approach for the probabilistic risk assessment of agricultural drought under rainfed conditions to estimate the economic impact is proposed. The risk parameters are evaluated in an event-based probabilistic framework for a set of hazard events; these results are probabilistically integrated including, in a formal way, all uncertainties related to every part of the process. The hazard is defined as a stochastic or historic set of events, collectively exhaustive and mutually exclusive, that describes the spatial distribution, the annual frequency, and the randomness of the hazard intensity. The risk is expressed in different economic terms: the average annual loss (or pure risk premium) and the loss exceedance curve; these metrics are of particular importance for risk retention (financing) schemes or risk transfer instruments. As an illustrative example, this approach is applied to probabilistic drought risk assessment of maize under rainfed conditions in Mexico. These results are the base of further studies in defining strategies for financial protection against agricultural losses and disasters.","https://www.proquest.com/docview/1677928600?accountid=12870&bdid=124553&_bd=JzpEVvI2R8Uo8zYxkS3X34Xgynk%3D","https://doi.org/10.1007/s11069-014-1550-4"
"Investor attention and FX market volatility","","Goddard, John; Kita, Arben; Wang, Qingwei","Journal of international financial markets, institutions and money","Undefined","","38","","2015-09-01","Sep 2015","79","96","79-96","1042-4431","1042-4431","","ENG","We study the relationship between investors' active attention, measured by a Google search volume index (SVI), and the dynamics of currency prices. Investor attention is correlated with the trading activities of large FX market participants. Investor attention comoves with contemporaneous FX market volatility and predicts subsequent FX market volatility, after controlling for macroeconomic fundamentals. In addition, investor attention is related to the currency risk premium. Our results suggest that investor attention is a priced source of risk in FX markets.","https://www.proquest.com/docview/1721357705?accountid=12870&bdid=124553&_bd=HGO1nWhXP%2Fxv7YAlBv%2Bn58p0rXk%3D",""
"Asset market equilibrium under rational inattention","","Miao, Jianjun; Su, Dongling","Economic Theory","Scholarly Journals","","75","1","2023-01-01","Jan 2023","1","30","1-30","09382259","","","ENG","We propose a noisy rational expectations equilibrium model of asset markets with rationally inattentive investors. We incorporate any finite number of assets with arbitrary correlation. We also do not restrict the signal form and show that investors optimally choose a single signal, which is a noisy linear combination of all risky assets. This generates comovement of asset prices and contagion of shocks, even when asset payoffs are negatively correlated. The model also provides testable predictions of the impact of risk aversion, aggregate risk, and information capacity on the security market line, the portfolio dispersion, and the abnormal return.","https://www.proquest.com/docview/2761428805?accountid=12870&bdid=124553&_bd=N%2BO%2B%2FZ5mN4SjaAytbfzuBApNiVA%3D","https://doi.org/10.1007/s00199-021-01396-z"
"A sparse enhanced indexation model with chance and cardinality constraints","","Xu, Fengmin; Wang, Meihua; Yu-Hong, Dai; Xu, Dachuan","Journal of Global Optimization","Scholarly Journals","","70","1","2018-01-01","Jan 2018","5","25","5-25","09255001","","","ENG","Enhanced indexation aims to construct a portfolio to track and outperform the performance of a stock market index by employing both passive and active fund management strategies. This paper presents a novel sparse enhanced indexation model with chance and cardinality constraints. Its goal is to maximize the excess return that can be attained with a high probability, while the model allows a fund manger to limit the number of stocks in the portfolio and specify the maximum tolerable relative market risk. In particular, we model the asset returns as random variables and estimate their probability distributions by the Capital Asset Pricing Model or Fama-French 3-factor model, and measure the relative market risk with the coherent semideviation risk function. We deal with the chance constraint via distributionally robust approach and present a second-order cone programming and a semidefinite programming safe approximation for the model under different sets of potential distribution functions. A hybrid genetic algorithm is applied to solve the NP-hard problem. Numerical tests are conducted on the real data sets from major international stock markets, including USA, UK, Germany and China. The results demonstrate that the proposed model and the method can efficiently solve the enhanced indexation problem and our approach can generally achieve sparse tracking portfolios with good out-of-sample excess returns and high robustness.","https://www.proquest.com/docview/1992793726?accountid=12870&bdid=124553&_bd=t1S%2BxCnHrUQG2gVNXJqwGW1YRFQ%3D","https://doi.org/10.1007/s10898-017-0513-1"
"Investor Flows and the 2008 Boom/Bust in Oil Prices","","Singleton, Kenneth J","Management Science","Scholarly Journals","","60","2","2014-02-01","Feb 2014","300","","300-318","00251909","","","ENG","This paper explores the impact of investor flows and financial market conditions on returns in crude oil futures markets. I argue that informational frictions and the associated speculative activity may induce prices to drift away from ""fundamental"" values, and may result in price booms and busts. Particular attention is given to the interplay between imperfect information about real economic activity, including supply, demand, and inventory accumulation, and speculative activity in oil markets. Furthermore, I present new evidence that there were economically and statistically significant effects of investor flows on futures prices, after controlling for returns in the United States and emerging-economy stock markets, a measure of the balance sheet flexibility of large financial institutions, open interest, the futures/spot basis, and lagged returns on oil futures. The largest impacts on futures prices were from intermediate-term growth rates of index positions and managed-money spread positions. Moreover, my findings suggest that these effects were through risk or informational channels distinct from changes in convenience yield. Finally, the evidence suggests that hedge fund trading in spread positions in futures impacted the shape of term structure of oil futures prices. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/1503663915?accountid=12870&bdid=124553&_bd=wRfviGPh%2BsNn4V0NNeBbtRfDXmU%3D",""
"Two-Stage Classification Method for Individual Workout Status Prediction with Machine Learning Approach","","Noh, Yoonjae; Yoon, YoonIl; Kim, Sangjin","Measurement: Interdisciplinary Research and Perspectives","Undefined","Routledge","22","1","2024-01-01","2024","121","129","121-129","1536-6367","1536-6367","","ENG","The default risk, one of the main risk factors for bonds, should be measured and reflected in the bond yield. Particularly, in the case of financial companies that treat bonds as a major product, failure to properly identify and filter customers' workout status adversely affects returns. This study proposes a two-stage classification algorithm for workout prediction based on the history data of individual customers such as transaction details of financial companies secured after loans, which is collected over 10 years. The first stage is to rank variables that are closely related to the workout application based on feature selection. In the second step, the first to nth cumulative variables input to each machine learning method generate n candidate classifiers, respectively. Among the total candidates, the model with the highest classification accuracy was selected as the optimal one, which is the Gradient Boost combined with F-score-based feature selection.","https://www.proquest.com/docview/3040247096?accountid=12870&bdid=124553&_bd=PpDvXhZbHAdvKPXVgYvKq4oAjC0%3D","https://doi.org/10.1080/15366367.2023.2246109"
"The disappearance of style in the US equity market","","Hwang, S; Satchell, S E","Applied financial economics","Undefined","","17","7-9","2007-04-01","Apr 2007","597","613","597-613","0960-3107","0960-3107","","ENG","This article investigates the modelling of style returns in the United States and the returns to style 'tilts' based on forecasts of enhanced future style returns. We use hidden Markov model to build our forecasts for data from 1975 to 1998. We do not include more recent observations as the subsequent trend and volatility sways the analysis. Our finding that style returns are less forecastible in the late 1990s is consistent with the hypothesis that style returns are the result of anomalies rather than risk premia. The erosion of anomalous returns as public awareness of their presence is translated into strategies that arbitrage away the excess returns seems to be a hypothesis consistent with our modelling results. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/36819681?accountid=12870&bdid=124553&_bd=pVKo0IPfmLATPY6Zn8dh7pTkACQ%3D","https://doi.org/10.1080/09603100701217978"
"Distributional modeling and forecasting of natural gas prices","","Berrisch, Jonathan; Ziel, Florian","Journal of Forecasting","Scholarly Journals","","41","6","2022-09-01","Sep 2022","1065","1086","1065-1086","02776693","","","ENG","We examine the problem of modeling and forecasting European day‐ahead and month‐ahead natural gas prices. For this, we propose two distinct probabilistic models that can be utilized in risk and portfolio management. We use daily pricing data ranging from 2011 to 2020. Extensive descriptive data analysis shows that both time series feature heavy tails and conditional heteroscedasticity and show asymmetric behavior in their differences. We propose state‐space time series models under skewed, heavy‐tailed distributions to capture all stylized facts of the data. They include the impact of autocorrelation, seasonality, risk premia, temperature, storage levels, the price of European Emission Allowances, and related fuel prices of oil, coal, and electricity. We provide rigorous model diagnostics and interpret all model components in detail. Additionally, we conduct a probabilistic forecasting study with significance tests and compare the predictive performance against literature benchmarks. The proposed day‐ahead (month‐ahead) model leads to a 13% (9%) reduction in out‐of‐sample continuous ranked probability score (CRPS) compared with the best performing benchmark model, mainly due to adequate modeling of the volatility and heavy tails.","https://www.proquest.com/docview/2697530944?accountid=12870&bdid=124553&_bd=cXLJWZ0%2BBFleqNF1oz8edpGO3Ek%3D","https://doi.org/10.1002/for.2853"
"The causality link between political risk and stock prices","A counterfactual study in an emerging market","Wang, Huiqiang","Journal of Financial Economic Policy","Scholarly Journals","","11","3","2019-07-01","2019","338","367","338-367","17576385","","","ENG","PurposePrior studies have paid close attention to the impact of political risk on financial markets. Following this strand of literature, this paper aims to focus on the causality link between political shocks and their impacts on emerging stock markets.Design/methodology/approachThis paper highlights an innovative counterfactual model for political risk assessment. Based on a natural experiment, i.e. the Taiwan Strait Crisis in 1995-1996, this study utilizes one data-driven approach, e.g. the synthetic control methods (SCMs), to estimate causal impact of this political shock on Taiwan’s stock market.FindingsMajor findings in this study are consistent with existing literature on the price of political risk, e.g. political uncertainty commands a risk premium. The SCM estimations suggest that Taiwan’s stock prices dramatically underperformed its newly industrialized peers and other developed markets during the crisis. The SCM results are statistically significant and robust to various cross-validation tests.Research limitations/implicationsFindings in this study indicate that political risks could generate enormous impacts on emerging financial markets. In particular, political uncertainty following new geopolitical dynamics requires proper identification and assessment.Originality/valueTo the author’s knowledge, this paper is the first rigorous counterfactual study to the causality relationship between political uncertainty and stock prices in emerging markets. This paper is distinct from previous studies in applying a data-driven approach to combine the features of learning from others (cross-sectional) and learning from the past (time series).","https://www.proquest.com/docview/2268784942?accountid=12870&bdid=124553&_bd=lgx3xABNThKgqjl953f%2B08jaaJ8%3D","https://doi.org/10.1108/JFEP-07-2018-0106"
"A tale of two coffees? Analysing interaction and futures market efficiency","","Holmes, Mark J; Otero, Jesús","Studies in Economics and Finance","Scholarly Journals","","37","1","2020-01-01","2020","89","109","89-109","10867376","","","ENG","PurposeThe purpose of this paper is to assess the informational efficiency of Arabica (other milds) and Robusta coffee futures markets in terms of predicting future coffee spot prices.Design/methodology/approachFutures market efficiency is associated with the existence of a long-run equilibrium relationship between spot and future prices such that coffee futures prices are unbiased predictors of future spot prices. This study applies unit root testing to daily data for futures-spot price differentials. A range of maturities for futures contracts are considered, and the study also uses a recursive approach to consider time variation in futures market efficiency.FindingsThe other milds and Robusta futures prices tend to be unbiased predictors for their own respective spot prices. The paper further finds that other milds and Robusta futures prices are unbiased predictors of the respective Robusta and other milds spot prices. Recursive estimation suggests that the futures market efficiency associated with these cross cases has increased, though with no clear link to the implementation of the 2007 International Coffee Agreement.Originality/valueThe paper draws new insights into futures market efficiency by examining the two key types of coffee and analyses the potential interactions between them. Hitherto, no attention has been paid to futures contracts of the Robusta variety. The employment of unit root testing of spot futures coffee price differentials can be viewed as more stringent than an approach based on non-cointegration testing.","https://www.proquest.com/docview/2361957379?accountid=12870&bdid=124553&_bd=X3iCGipRddtz13fAP2VQlb0zIpE%3D","https://doi.org/10.1108/SEF-09-2019-0356"
"Economic costs of Fusarium Head Blight, scab and deoxynivalenol","","Wilson, W; Dahl, B; Nganje, W","World Mycotoxin Journal","Scholarly Journals","","11","2","2018-01-01","2018","291","","291-302","18750710","","","ENG","Fusarium Head Blight (FHB) has led to major economic costs for wheat and barley producers. Grain products and feed grain contaminated with deoxynivalenol (DON) (commonly known as vomitoxin) are subject to Food and Drug Administration advisory limits and as a result end-users place restrictions on their use. This has led to steep price discounts, as well as higher risks for producers and grain merchandisers. Varietal research has led to development of varieties that are resistant or moderately resistant to FHB. Studies indicate combinations of genetic resistance, fungicides and some management practices (combine settings, tillage practices, etc.) can be used to decrease economic costs due to FHB. The purpose of this study was to estimate the economic costs of scab. To do so we developed several economic models, analysed extensive data and conducted surveys of wheat flour millers, barley maltsters, and grain handlers. A detailed assessment of costs indicates the most important costs accrued by the wheat and barley industries were the risk premium paid to induce adoption of DON reducing technologies and the value of yield forgone. These were followed by the direct costs of fungicide, added shipping costs, testing and segregation and discounts.","https://www.proquest.com/docview/2030210955?accountid=12870&bdid=124553&_bd=ebGwfvAJqJIqQujtuOK8Jz7uhMw%3D","https://doi.org/10.3920/WMJ2017.2204"
"Can climate change attention predict energy stock returns?","","Jia, Shanghui; Liu, Yingke; Jin, Jiayu","Environmental science and pollution research international","Undefined","","30","38","2023-08-01","Aug 2023","89253","","89253-89269","1614-7499","","","ENG","We propose a climate change attention (CCA) index based on Google search volume index (GSVI) from 2004 to 2021 and show that it is an economically and statistically significant negative predictor for next month's energy stock returns. The index is extracted using principal component analysis (PCA), but the results are similar by using the equal-weighted average method. Compared with 14 traditional macroeconomic predictors, CCA performs the best and provides complementary information when added into bivariate and multivariate macro predictive models. When further considering the effect of CCA's forecasting power over different periods, strong evidence is shown that this outperformance is especially prominent in economic depressions and down market conditions. From the asset allocation perspective, CCA can provide a mean-variance investor with significant economic gains under alternative risk aversions. Our empirical results prove that investors' attention to climate change contains predictive information for excess returns of global traditional energy stock index.We propose a climate change attention (CCA) index based on Google search volume index (GSVI) from 2004 to 2021 and show that it is an economically and statistically significant negative predictor for next month's energy stock returns. The index is extracted using principal component analysis (PCA), but the results are similar by using the equal-weighted average method. Compared with 14 traditional macroeconomic predictors, CCA performs the best and provides complementary information when added into bivariate and multivariate macro predictive models. When further considering the effect of CCA's forecasting power over different periods, strong evidence is shown that this outperformance is especially prominent in economic depressions and down market conditions. From the asset allocation perspective, CCA can provide a mean-variance investor with significant economic gains under alternative risk aversions. Our empirical results prove that investors' attention to climate change contains predictive information for excess returns of global traditional energy stock index.","https://www.proquest.com/docview/2838250599?accountid=12870&bdid=124553&_bd=REpkPiEPfMKfIsSnz93tF%2BfwL9I%3D","https://doi.org/10.1007/s11356-023-28731-2"
"Research on Financial Stock Market Prediction Based on the Hidden Quantum Markov Model","","Song Xingyao; Chen, Wenyu; Lu, Junyi","Mathematics","Scholarly Journals","","13","15","2025-01-01","2025","2505","","","22277390","","","ENG","Quantum finance, as a key application scenario of quantum computing, showcases multiple significant advantages of quantum machine learning over traditional machine learning methods. This paper first aims to overcome the limitations of the hidden quantum Markov model (HQMM) in handling continuous data and proposes an innovative method to convert continuous data into discrete-time sequence data. Second, a hybrid quantum computing model is developed to forecast stock market trends. The model was used to predict 15 stock indices from the Shanghai and Shenzhen Stock Exchanges between June 2018 and June 2021. Experimental results demonstrate that the proposed quantum model outperforms classical algorithmic models in handling higher complexity, achieving improved efficiency, reduced computation time, and superior predictive performance. This validation of quantum advantage in financial forecasting enables the practical deployment of quantum-inspired prediction models by investors and institutions in trading environments. This quantum-enhanced model empowers investors to predict market regimes (bullish/bearish/range-bound) using real-time data, enabling dynamic portfolio adjustments, optimized risk controls, and data-driven allocation shifts.","https://www.proquest.com/docview/3239074475?accountid=12870&bdid=124553&_bd=dX2TsP7ula6Z7eG2ICupOlhqjvE%3D","https://doi.org/10.3390/math13152505"
"A Synthetic Data Generation Technique for Enhancement of Prediction Accuracy of Electric Vehicles Demand","","Chatterjee, Subhajit; Byun, Yung-Cheol","Sensors (Basel, Switzerland)","Undefined","","23","2","2023-01-04","Jan 4, 2023","","","","1424-8220","","","ENG","In terms of electric vehicles (EVs), electric kickboards are crucial elements of smart transportation networks for short-distance travel that is risk-free, economical, and environmentally friendly. Forecasting the daily demand can improve the local service provider's access to information and help them manage their short-term supply more effectively. This study developed the forecasting model using real-time data and weather information from Jeju Island, South Korea. Cluster analysis under the rental pattern of the electric kickboard is a component of the forecasting processes. We cannot achieve noticeable results at first because of the low amount of training data. We require a lot of data to produce a solid prediction result. For the sake of the subsequent experimental procedure, we created synthetic time-series data using a generative adversarial networks (GAN) approach and combined the synthetic data with the original data. The outcomes have shown how the GAN-based synthetic data generation approach has the potential to enhance prediction accuracy. We employ an ensemble model to improve prediction results that cannot be achieved using a single regressor model. It is a weighted combination of several base regression models to one meta-regressor. To anticipate the daily demand in this study, we create an ensemble model by merging three separate base machine learning algorithms, namely CatBoost, Random Forest (RF), and Extreme Gradient Boosting (XGBoost). The effectiveness of the suggested strategies was assessed using some evaluation indicators. The forecasting outcomes demonstrate that mixing synthetic data with original data improves the robustness of daily demand forecasting and outperforms other models by generating more agreeable values for suggested assessment measures. The outcomes further show that applying ensemble techniques can reasonably increase the forecasting model's accuracy for daily electric kickboard demand.In terms of electric vehicles (EVs), electric kickboards are crucial elements of smart transportation networks for short-distance travel that is risk-free, economical, and environmentally friendly. Forecasting the daily demand can improve the local service provider's access to information and help them manage their short-term supply more effectively. This study developed the forecasting model using real-time data and weather information from Jeju Island, South Korea. Cluster analysis under the rental pattern of the electric kickboard is a component of the forecasting processes. We cannot achieve noticeable results at first because of the low amount of training data. We require a lot of data to produce a solid prediction result. For the sake of the subsequent experimental procedure, we created synthetic time-series data using a generative adversarial networks (GAN) approach and combined the synthetic data with the original data. The outcomes have shown how the GAN-based synthetic data generation approach has the potential to enhance prediction accuracy. We employ an ensemble model to improve prediction results that cannot be achieved using a single regressor model. It is a weighted combination of several base regression models to one meta-regressor. To anticipate the daily demand in this study, we create an ensemble model by merging three separate base machine learning algorithms, namely CatBoost, Random Forest (RF), and Extreme Gradient Boosting (XGBoost). The effectiveness of the suggested strategies was assessed using some evaluation indicators. The forecasting outcomes demonstrate that mixing synthetic data with original data improves the robustness of daily demand forecasting and outperforms other models by generating more agreeable values for suggested assessment measures. The outcomes further show that applying ensemble techniques can reasonably increase the forecasting model's accuracy for daily electric kickboard demand.","https://www.proquest.com/docview/2768228843?accountid=12870&bdid=124553&_bd=QOUKTZyUncue1y8GWXIhhovwADU%3D","https://doi.org/10.3390/s23020594"
"Testing the efficiency of the aluminium market: evidence from London Metal Exchange","","Arouri, Mohamed El Hedi; Jawadi, Fredj; Mouak, Prosper","Applied financial economics","Undefined","","23","6","2013-03-01","Mar 2013","483","493","483-493","0960-3107","0960-3107","","ENG","This article studies the efficiency of the aluminium market based on contracts traded on the London Metal Exchange (LME) over the last 3 decades. We test for both short- and long-run efficiency using nonlinear cointegration and Error Correction Models (ECM). Our findings suggest the following points. First, futures aluminium prices are found to be cointegrated with spot prices, but they do not constitute unbiased predictors of future spot prices. Second, the hypothesis of risk neutrality is rejected, but there is no evidence in favour of a time-varying risk premia. Finally, using past futures price returns improves the modelling and forecast of future spot price returns and the short-run efficiency hypothesis is rejected by regime, in particular when the disequilibrium size between spot and futures prices is high. Our findings have important implications for producers, arbitrageurs, speculators as well as policymakers. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/1267026190?accountid=12870&bdid=124553&_bd=wj7o96ytxLaEyx%2B4nHtwwnabxw8%3D",""
"LSTM-GARCH Hybrid Model for the Prediction of Volatility in Cryptocurrency Portfolios","","García-Medina, Andrés; Aguayo-Moreno, Ester","Computational economics","Undefined","","","","2023-03-14","Mar 14, 2023","1","","1-32","1572-9974","","","ENG","In the present work, the volatility of the leading cryptocurrencies is predicted through generalised autoregressive conditional heteroskedasticity (GARCH) models, multilayer perceptron (MLP), long short-term memory (LSTM), and hybrid models of the type LSTM and GARCH, where parameters of the GARCH family are included as features of LSTM models. The study period covered the scenario of the World Health Organization pandemic declaration around March 2020 at hourly frequency. We have found that the different variants of deep neural network models outperform those of the GARCH family in the sense of the hetorerocedastic error, and absolute and squared error (HSE). Under the sharpe ratio, the volatility forecasting of a uniform portfolio at long horizons systematically outperforms the stablecoin Tether, which is considered here as the risk-free asset. Also, including transaction volume helps reduce the value at risk or loss probability for the uniform portfolio. Moreover, in a minimum variance portfolio, it is observed that before the pandemic declaration, a large proportion of the capital was allocated to bitcoin (BTC). In contrast, after March 2020, the portfolio is more diversified with short positions for BTC. Moreover, the MLP models give the best predictive results, although not statistically different in accuracy compared to the LSTM and LSTM-GARCH versions under the Diebold-Mariano test. In sum, MLP models outperform most stylised financial models and are less computationally expensive than more complex neural networks. Therefore, simple learning models are suggested in highly non-linear time series volatility forecasts as it is the cryptocurrency market.In the present work, the volatility of the leading cryptocurrencies is predicted through generalised autoregressive conditional heteroskedasticity (GARCH) models, multilayer perceptron (MLP), long short-term memory (LSTM), and hybrid models of the type LSTM and GARCH, where parameters of the GARCH family are included as features of LSTM models. The study period covered the scenario of the World Health Organization pandemic declaration around March 2020 at hourly frequency. We have found that the different variants of deep neural network models outperform those of the GARCH family in the sense of the hetorerocedastic error, and absolute and squared error (HSE). Under the sharpe ratio, the volatility forecasting of a uniform portfolio at long horizons systematically outperforms the stablecoin Tether, which is considered here as the risk-free asset. Also, including transaction volume helps reduce the value at risk or loss probability for the uniform portfolio. Moreover, in a minimum variance portfolio, it is observed that before the pandemic declaration, a large proportion of the capital was allocated to bitcoin (BTC). In contrast, after March 2020, the portfolio is more diversified with short positions for BTC. Moreover, the MLP models give the best predictive results, although not statistically different in accuracy compared to the LSTM and LSTM-GARCH versions under the Diebold-Mariano test. In sum, MLP models outperform most stylised financial models and are less computationally expensive than more complex neural networks. Therefore, simple learning models are suggested in highly non-linear time series volatility forecasts as it is the cryptocurrency market.","https://www.proquest.com/docview/2830218947?accountid=12870&bdid=124553&_bd=UEmuR5gn7Yv25j4%2F6AF41I16uBE%3D","https://doi.org/10.1007/s10614-023-10373-8"
"A Hybrid Methodology Using Machine Learning Techniques and Feature Engineering Applied to Time Series for Medium- and Long-Term Energy Market Price Forecasting","","Flávia Pessoa Monteiro; Flávia Pessoa Monteiro; Monteiro, Suzane; Rodrigues, Carlos; Reis, Josivan; Bezerra, Ubiratan; Tostes, Maria Emília; Almeida, Frederico A F","Energies","Scholarly Journals","","18","6","2025-01-01","2025","1387","","","19961073","","","ENG","In the electricity market, the issue of contract negotiation prices between generators/traders and buyers is of particular relevance, as an accurate contract modeling leads to increased financial returns and business sustainability for the various participating agents, encouraging investments in specialized sectors for price forecasting and risk analysis. This paper presents a methodology applied in experiments on energy forward curve scenarios using a set of techniques, including Long Short-Term Memory (LSTM), Extreme Gradient Boosting (XGBoost), Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors (SARIMAX), and Feature Engineering to generate a 10-year projection of the Conventional Long-Term Price. The model validation proved to be effective, with errors of only 4.5% by Root Mean Square Error (RMSE) and slightly less than 2% by Mean Absolute Error (MAE), for a time series spanning from 7 January 2012 to 31 August 2024, in the Brazilian energy market.","https://www.proquest.com/docview/3181471566?accountid=12870&bdid=124553&_bd=D5TCGS8WLoFlV%2BXCRS1gzUk9%2FQo%3D","https://doi.org/10.3390/en18061387"
"Rewards available to currency futures speculators: Compensation for risk or evidence of inefficient pricing?","","Taylor, Stephen J","Economic Record","Scholarly Journals","","","","1992-01-01","1992","105","","105","00130249","","","ENG","Filter, channel, and moving-average trading rules are compared with rules which use ARIMA price forecasts, by evaluating their ex ante performance for currency futures transactions from December 1981 to November 1987.  All of the trading rules are profitable.  An investment in a portfolio made up of the 16 combinations of 4 adaptive systems applied to 4 currencies would have returned, on average, over 7% per annum more than the risk-free rate, with positive excess returns in every 12-month period from December to the following November.  The question of why simple technical trading rules have outperformed sophisticated rules based upon ARIMA forecasts can be answered either by drawing attention to the lack of significant differences between the performances of the rules, or by casting doubts on the accuracy of the time-series models used to motivate the sophisticated rules, or by noting that the simple rules, especially the channel rule, obtain good results in the Monte Carlo study.  These results strongly suggest that the trading profits are too large to be explained by the elusive, time-varying risk premium sought in forward market literature.","https://www.proquest.com/docview/219659444?accountid=12870&bdid=124553&_bd=mrgayXFHSuICWQJwOUXQj7%2F1Y%2BE%3D",""
"A Structural Credit Risk Model with Jumps Based on Uncertainty Theory","","Huang, Hong; Huang, Hong; Jiang, Meihua; Yufu Ning; Wang, Shuai","Mathematics","Scholarly Journals","","13","6","2025-01-01","2025","897","","","22277390","","","ENG","This study, within the framework of uncertainty theory, employs an uncertain differential equation with jumps to model the asset value process of a company, establishing a structured model of uncertain credit risk that incorporates jumps. This model is applied to the pricing of two types of credit derivatives, yielding pricing formulas for corporate zero-coupon bonds and Credit Default Swap (CDS). Through numerical analysis, we examine the impact of asset value volatility and jump magnitude on corporate default uncertainty, as well as the influence of jump magnitude on the pricing of zero-coupon bonds and CDS. The results indicate that an increase in volatility levels significantly enhances default uncertainty, and an expansion in the magnitude of negative jumps not only directly elevates default risk but also leads to a significant increase in the value of zero-coupon bonds and the price of CDS through a risk premium adjustment mechanism. Therefore, when assessing corporate default risk and pricing credit derivatives, the disturbance of asset value jumps must be considered a crucial factor.","https://www.proquest.com/docview/3181587830?accountid=12870&bdid=124553&_bd=Zrco%2F7oxSOXvQBQIlvOgtpmlxzg%3D","https://doi.org/10.3390/math13060897"
"Predicting bank inactivity: A comparative analysis of machine learning techniques for imbalanced data","","Mrad, Ali Ben; Lahiani, Amine; Mefteh-Wali, Salma; Mselmi, Nada","Annals of Operations Research","Scholarly Journals","","351","1","2025-08-01","Aug 2025","937","963","937-963","02545330","","","ENG","This study compares the predictive accuracy of a set of machine learning models coupled with three resampling techniques (Random Undersampling, Random Oversampling, and Synthetic Minority Oversampling Technique) in predicting bank inactivity. Our sample includes listed banks in EU-28 member states between 2011 and 2019. We employed 23 financial ratios comprising capital adequacy, asset quality, management capability, earnings, liquidity, and sensitivity indicators. The empirical findings established that XGBoost performs exceptionally well as a classifier in predicting bank inactivity, particularly when considering a one-year time frame before the event. Furthermore, our findings indicate that random forest with Synthetic Minority Oversampling Technique demonstrates the highest predictive accuracy two years prior to inactivity, while XGBoost with Random Oversampling outperforms other methods three years in advance. Furthermore, the empirical results emphasize the significance of management capability and loan quality ratios as key factors in predicting bank inactivity. Our findings present important policy implications.HighlightsBank inactivity predictive accuracy of machine learning techniques with resampling techniques is analyzed.Data on banks in the EU-28 member states between 2011 and 2019 are used.XGBoost performs exceptionally well one year before inactivity.Random Forest with Synthetic Minority Oversampling is the best classifier two years before inactivity.XGBoost with Random Oversampling outperforms other methods three years before inactivity.","https://www.proquest.com/docview/3235126946?accountid=12870&bdid=124553&_bd=m0NC7eq8vUOPaEsh3R7nQh%2FJ6%2BU%3D","https://doi.org/10.1007/s10479-024-06018-0"
"The Effect of Risk Factor Disclosures on the Pricing of Credit Default Swaps","","Tzu‐Ting Chiu; Guan, Yuyan; Jeong‐Bon Kim","Contemporary Accounting Research","Scholarly Journals","","35","4","2018-12-01","Winter 2018","2191","2224","2191-2224","08239150","","","ENG","This study examines the relation between narrative risk disclosures in mandatory reports and the pricing of credit risk. In particular, we investigate whether and how the Securities and Exchange Commission (SEC) mandate of risk factor disclosures (RFDs) affects credit default swap (CDS) spreads. Based on the theory of Duffie and Lando (2001), we predict and find that CDS spreads decrease significantly after RFDs are made available in 10‐K/10‐Q filings. These results suggest that RFDs improve information transparency about the firm's underlying risk, thereby reducing the information risk premium in CDS spreads. The content analysis further reveals that disclosures pertinent to financial and idiosyncratic risk are especially relevant to credit investors. In cross‐sectional analyses, we document that RFDs are more useful for evaluating the business prospects and default risk of firms with greater information uncertainty/asymmetry. Overall, our findings imply that the SEC requirement for adding a risk factor section to periodic reports enhances the transparency of firm risk and facilitates credit investors in evaluating the credit quality of the firm.","https://www.proquest.com/docview/2154986458?accountid=12870&bdid=124553&_bd=gq%2F1H1Bu0ybhTpMV8wOfCrisUyY%3D","https://doi.org/10.1111/1911-3846.12362"
"In honor of Berç Rustem","","Kontoghiorghes, Erricos John; Chiarella, Carl; Tô, Thuy-Duong; Sirakaya, S; Turnovsky, Stephen; Alemdar, M Nedim; Gilli, Manfred; Këllezi, Evis; Hallett, Andrew Hughes; Richter, Christian; Kendrick, David A; Mercado, P Ruben; Amman, Hans M; Kim, Dukwon; Pan, Xinyan; Pardalos, Panos M; Kozicki, Sharon; Tinsley, P A; Andreou, Panayiotis C; Charalambous, Chris; Martzoukos, Spiros H; Nagurney, Anna; Wakolbinger, Tina; Zhao, Li; Meij, S; Pau, L F","Computational economics","Undefined","","27","2-3","2006-04-01","Apr 2006","161","430","161-430","0927-7099","0927-7099","","ENG","","https://www.proquest.com/docview/36551156?accountid=12870&bdid=124553&_bd=E8EbrhqtwXGYYyt%2Bu0rbmqkbsoQ%3D",""
"Estimating Latent Factors Based on Statistical Data Analysis","","Xu, Guoqing; Yang, Guoxiao","Journal of Physics: Conference Series","Scholarly Journals","","1995","1","2021-08-01","Aug 2021","","","","17426588","","","ENG","In recent years, statistical methods have been widely used to estimate latent risk factors that affect the prices of financial assets. This paper develops new estimators for asset pricing factors by introducing dependence measure--distance covariance, that can identify nonlinear dependence. We combined distance covariance with Principal Component Analysis (PCA) and Risk-Premium PCA (RPPCA) and made contrast analysis based on Chinese market data. RPPCA, as a new method, shows strong applicability and detects factors with high Sharpe-ratio efficiently. Moreover, distance covariance produces better performance than covariance in PCA as a factor estimator, which illustrates the superiority of the distance covariance. Finally, the most striking results revealed by the study is that RPPCA including distance covariance of residuals outperforms others with a smaller pricing error and a significantly large Sharpe-ratio.","https://www.proquest.com/docview/2561945077?accountid=12870&bdid=124553&_bd=2P4xbds5v4%2FxVQkQ94WL9qEv3zA%3D","https://doi.org/10.1088/1742-6596/1995/1/012065"
"A Quantitative Investment Model Based on Random Forest and Sentiment Analysis","","Chen, Mingqin; Zhang, Zhenhua; Shen, Jiawen; Deng, Zhijian; He, Jiaxing; Huang, Shiting","Journal of Physics: Conference Series","Scholarly Journals","","1575","1","2020-06-01","Jun 2020","","","","17426588","","","ENG","In recent years, under the influence of economic globalization and anti-globalization, the stock market has experienced great fluctuations in China. Quantitative investment has attracted a lot of attention because of its characteristics of maintaining stable returns. Existing research is unilaterally based on quantitative data or qualitative data for analysis to construct a quantitative investment model. This paper considers both quantitative and qualitative data to construct a more comprehensive model than that in the past. Based on the optimized database, we present a combinational model named RF-SA, which is composed of random forest and sentiment analysis model. First of all, this paper uses the SBS algorithm to select the characteristics of stock transaction historical data, optimizes the prediction database, reduces data redundancy, and improves the accuracy of the model. Secondly, we analyze the characteristics of the Chinese stock market and study the advantages and disadvantages of many data mining algorithms, and select random forest model, the most suitable model, to build the first step of stock selection model. Then, through the analysis of public opinion, the confidence index of the stockholders is calculated; on this basis, the results of the RF model and the confidence index are combined to make a second choice for the stock, and the quantitative investment portfolio is obtained, and excess returns can be obtained. The results of empirical data show that, the RF-SA model obtains a higher rate of return than the investment model of the Shanghai Stock Index.","https://www.proquest.com/docview/2570386330?accountid=12870&bdid=124553&_bd=30U%2BdTJbQfemnpUNkUHgeFm0BsY%3D","https://doi.org/10.1088/1742-6596/1575/1/012083"
"Modelling Electricity Swaps with Stochastic Forward Premium Models","","Blanco, Iván; Peña, Juan Ignacio; Rodríguez, Rosa","The Energy Journal","Scholarly Journals","","39","2","2018-03-01","Mar 2018","1","34","1-34","01956574","","","ENG","We present a new model for pricing electricity swaps. Two general factors affect contracts but unique risk elements affect each contract. General factors are average swap prices and deterministic trend-seasonal components, and unique elements are forward premiums. Innovations follow MNIG distributions. We estimate the model with data from the European Energy Exchange. The model outperforms four competitors, both in in-sample valuation and in out-of-sample forecasting, and in fitting the term structure of volatilities by market segments. Competitor models are (i) diffusion spot prices, (ii) jump-diffusion spot prices with time dependent volatility, (iii) HJM-based and (iv) Levy multifactor model with NIG distributions. Value-at-Risk measures based on normality strongly underestimate tail risk but our model gives estimates that are more exact.Keywords: Electricity swaps; Stochastic forward premium; Multivariate Normal Inverse Gaussian distribution; Levy processes","https://www.proquest.com/docview/3098710236?accountid=12870&bdid=124553&_bd=WYfvF%2F0NZ1e0cOQJULKkopo6t0M%3D","https://doi.org/10.5547/01956574.39.2.ibla"
"Nonlinear trading models through Sharpe Ratio maximization","","Choey, M; Weigend, A S","International journal of neural systems","Undefined","","8","4","1997-08-01","Aug 1997","417","","417-31","0129-0657","0129-0657","","ENG","While many trading strategies are based on price prediction, traders in financial markets are typically interested in optimizing risk-adjusted performance such as the Sharpe Ratio, rather than the price predictions themselves. This paper introduces an approach which generates a nonlinear strategy that explicitly maximizes the Sharpe Ratio. It is expressed as a neural network model whose output is the position size between a risky and a risk-free asset. The iterative parameter update rules are derived and compared to alternative approaches. The resulting trading strategy is evaluated and analyzed on both computer-generated data and real world data (DAX, the daily German equity index). Trading based on Sharpe Ratio maximization compares favorably to both profit optimization and probability matching (through cross-entropy optimization). The results show that the goal of optimizing out-of-sample risk-adjusted profit can indeed be achieved with this nonlinear approach.While many trading strategies are based on price prediction, traders in financial markets are typically interested in optimizing risk-adjusted performance such as the Sharpe Ratio, rather than the price predictions themselves. This paper introduces an approach which generates a nonlinear strategy that explicitly maximizes the Sharpe Ratio. It is expressed as a neural network model whose output is the position size between a risky and a risk-free asset. The iterative parameter update rules are derived and compared to alternative approaches. The resulting trading strategy is evaluated and analyzed on both computer-generated data and real world data (DAX, the daily German equity index). Trading based on Sharpe Ratio maximization compares favorably to both profit optimization and probability matching (through cross-entropy optimization). The results show that the goal of optimizing out-of-sample risk-adjusted profit can indeed be achieved with this nonlinear approach.","https://www.proquest.com/docview/79638683?accountid=12870&bdid=124553&_bd=3Qp3SFgRTFdyZiCiJMh5ksdk7Gg%3D","https://doi.org/10.1142/s0129065797000410"
"On Crop Biodiversity, Risk Exposure, and Food Security in the Highlands of Ethiopia","","Di Falco, Salvatore; Chavas, Jean‐Paul","American journal of agricultural economics","Undefined","Oxford University Press","91","3 p.599-611","2009-08-01","Aug 2009","599","611","p. 599-611","0002-9092","0002-9092","","ENG","This paper investigates the effects of crop genetic diversity on farm productivity and production risk in the highlands of Ethiopia. Using a moment‐based approach, the analysis uses a stochastic production function capturing mean, variance, and skewness effects. Welfare implications of diversity are evaluated using a certainty equivalent, measured as expected income minus a risk premium (reflecting the cost of risk). We find that the effect of diversity on skewness dominates its effect on variance, meaning that diversity reduces the cost of risk. The analysis also shows that the beneficial effects of diversity become of greater value in degraded land.","https://www.proquest.com/docview/46341958?accountid=12870&bdid=124553&_bd=vOjRK%2BOT97ioXx6FF10rSLHQjeo%3D","https://doi.org/10.1111/j.1467-8276.2009.01265.x"
"Calendar anomolies and stock market volatility in selected Arab stock exchanges","","Kamaly, A; Tooma, E A","Applied Financial Economics","Undefined","","19","11","2009-01-01","2009","881","892","881-892","0960-3107","0960-3107","","ENG","While seasonal effects for both advanced and emerging markets have been investigated extensively in mean and variance equations, Arab region asset markets have received much less attention. The objective of this article is to fill this gap in the literature by investigating the day-of-the-week effect in 12 major Arab stock markets using Arab Monetary Fund (AMF) daily index returns from May 2002 to December 2005. Our estimation strategy utilizes Autoregressive (AR) and Generalized Autoregressive Conditional Heteroscedastic (GARCH)-type specifications to allow for a time-varying variance. Among the most important results of this article are, first, is one-third of these markets exhibit significant day-of-the-week effect in returns. Second, two-third of these markets exhibit significant day-of-the-week effect on volatility. Third, most of these day-of-the-week effects are focused within the beginning and the end of the trading week. Finally, the existence of a significant risk premium was confirmed in five of the 12 studied markets.","https://www.proquest.com/docview/745639882?accountid=12870&bdid=124553&_bd=DcugTt%2FAMEM5ozh5msi1AGap7UM%3D","https://doi.org/10.1080/09603100802359976"
"Fluoride-treated water and the problem of merit goods","","Roger Lee Mendoza","Water Policy","Scholarly Journals","","13","1","2011-02-01","Feb 2011","38","","38-52","13667017","","","ENG","This paper inquires into the fluoride treatment of community water in the United States to determine why and how conflicts in the production, consumption, and distribution of merit goods arise and are resolved. Primary and secondary data were employed to analyze statewide and municipality-level fluoridation initiatives in one key “battleground” state. We find that obstacles to successful fluoridation include a unidimensional policy space, high risk premia assigned by the affected population to health and environmental hazards, concerns over government interference with personal health choices, perceived adequacy of fluoride sources, “customer bundling,” and lack of a critical middle ground for consensus-building. The accessibility and social desirability of merit goods, like fluoridated water, cannot therefore be considered as value-free choices. How consumer demand is expressed, how fluoridation costs and benefits are estimated, how conflicts over its provision and production are resolved, and how the merits of science-based policies can be equally recast in terms of their presumed demerits require serious attention on the part of decision-makers in formulating and implementing health promotion policies.","https://www.proquest.com/docview/1943075320?accountid=12870&bdid=124553&_bd=D9eL24oUt6tUVqYQ7oNdbyvn244%3D","https://doi.org/10.2166/wp.2010.127"
"Modeling Health Data Using Machine Learning Techniques Applied to Financial Management Predictions","","Rafael Leon Sanz; Rafael Leon Sanz; Leon-Sanz, Pilar","Applied Sciences","Scholarly Journals","","12","23","2022-01-01","2022","12148","","","20763417","","","ENG","Health management has steadily improved in performance and accuracy using IT technology. Hospitals and health institutions hold an enormous number of data in their software applications, which can be used with Big Data methodologies to extract useful information. One of the most challenging aspects of health institutional management is financial management; billing prediction is a key aspect to maintain a predictable service level for patients, avoiding unpleasant surprises and anticipating treasury management. Using patient data from public patient databases and applying a machine learning approach, this article offers a model that helps to make more precise and detailed financial plans.","https://www.proquest.com/docview/2748520474?accountid=12870&bdid=124553&_bd=FLbQh%2Fe7T%2B5p3h8jlg1q92wmPok%3D","https://doi.org/10.3390/app122312148"
"Equity Return Dispersion and Stock Market Volatility: Evidence from Multivariate Linear and Nonlinear Causality Tests","","Demirer, Riza; Gupta, Rangan; Lv, Zhihui; Wing-Keung Wong","Sustainability","Scholarly Journals","","11","2","2019-01-01","2019","351","","","20711050","","","ENG","We employ bivariate and multivariate nonlinear causality tests to document causality from equity return dispersion to stock market volatility and excess returns, even after controlling for the state of the economy. Expansionary (contractionary) market states are associated with a low (high) level of equity return dispersion, indicating asymmetries in the relationship between return dispersion and economic conditions. Our findings indicate that both return dispersion and business conditions are valid joint forecasters of stock market volatility and excess returns and that return dispersion possesses incremental information regarding future stock return dynamics beyond that which can be explained by the state of the economy.","https://www.proquest.com/docview/2574327922?accountid=12870&bdid=124553&_bd=tY6nIAb6lvcfM8aKuxByMhbydPk%3D","https://doi.org/10.3390/su11020351"
"Can google search volume index predict the returns and trading volumes of stocks in a retail investor dominant market","","Lai, Huei-Hwa; Chang, Tzu-Pu; Cheng-Han, Hu; Po-Ching Chou","Cogent Economics & Finance","Scholarly Journals","","10","1","2022-01-01","Jan 2022","","","","23322039","","","ENG","This research examines whether Google search volume index (GSVI), a proxy of investor attention, can predict the excess returns and abnormal trading volumes of TPEx 50 index constituents. It also explores the motive underlying GSVI based on positive or negative shocks to stock prices. The empirical data include 48 companies from TPEx 50 index constituents and cover a period from 1 September 2016 to 31 August 2019. The empirical results present that (1) lagged GSVI negatively affects current excess returns, perhaps due to the characteristics of TPEx, in which there are a higher proportion of retail investors, smaller listed companies, and a higher information asymmetry problem. (2) Lagged GSVI can positively affect abnormal current trading volumes. (3) If GSVI is driven by positive shocks, then it can predict excess returns and abnormal trading volumes positively.","https://www.proquest.com/docview/2770809975?accountid=12870&bdid=124553&_bd=xFmF1GihJH%2BYsjlYbk9aFpkwSqQ%3D","https://doi.org/10.1080/23322039.2021.2014640"
"Do asymmetric and nonlinear adjustments explain the forward premium anomaly?","","Baillie, R T; Kiliç, R","Journal of international money and finance","Undefined","","25","1","2006-02-01","Feb 2006","22","47","22-47","0261-5606","0261-5606","","ENG","This paper explores some of the asymmetries and nonlinearities in an attempt to throw light on the forward premium anomaly, where spot exchange rate returns are typically found to be negatively correlated with the lagged interest rate differential and lead to an apparent rejection of Uncovered Interest Parity (UIP). The approach in this paper is motivated by some recent theoretical literature on the limits to speculation and hysteresis. The paper estimates Logistic Smooth Transition Dynamic Regression (LSTR) models with a variety of transition variables, including the lagged forward premium, monetary and income fundamentals and also variables associated with time varying risk premium, including the conditional variances of some fundamentals. Results are reported for nine different currencies. Many of the estimated LSTR models provide evidence for the existence of an outer regime that is consistent with UIP. Estimation of the standard forward premium regression on observations falling in these regimes across the sample is moderately supportive of UIP holding in the outer regime. A simulation experiment also suggests that an LSTR dgp can produce data consistent with the anomaly. However, parameter estimation issues leads to considerable uncertainty with the estimated transition functions and hence imprecise definitions of regimes. The results are an interesting step in the direction of understanding the nonlinear dimension of the problem without fully resolving the anomaly.","https://www.proquest.com/docview/38211479?accountid=12870&bdid=124553&_bd=mrI3V64K2%2BlwUzPfpxglrMiqwO8%3D","https://doi.org/10.1016/j.jimonfin.2005.10.002"
"Heartbeat classification based on single lead-II ECG using deep learning","","Issa, Mohamed F; Yousry, Ahmed; Tuboly, Gergely; Juhasz, Zoltan; AbuEl-Atta, Ahmed H; Selim, Mazen M","Heliyon","Undefined","","9","7","2023-07-01","Jul 2023","e17974","","e17974","2405-8440","2405-8440","","ENG","The analysis and processing of electrocardiogram (ECG) signals is a vital step in the diagnosis of cardiovascular disease. ECG offers a non-invasive and risk-free method for monitoring the electrical activity of the heart that can assist in predicting and diagnosing heart diseases. The manual interpretation of the ECG signals, however, can be challenging and time-consuming even for experts. Machine learning techniques are increasingly being utilized to support the research and development of automatic ECG classification, which has emerged as a prominent area of study. In this paper, we propose a deep neural network model with residual blocks (DNN-RB) to classify cardiac cycles into six ECG beat classes. The MIT-BIH dataset was used to validate the model resulting in a test accuracy of 99.51%, average sensitivity of 99.7%, and average specificity of 98.2%. The DNN-RB method has achieved higher accuracy than other state-of-the-art algorithms tested on the same dataset. The proposed method is effective in the automatic classification of ECG signals and can be used for both clinical and out-of-hospital monitoring and classification combined with a single-lead mobile ECG device. The method has also been integrated into a web application designed to accept digital ECG beats as input for analyses and to display diagnostic results.The analysis and processing of electrocardiogram (ECG) signals is a vital step in the diagnosis of cardiovascular disease. ECG offers a non-invasive and risk-free method for monitoring the electrical activity of the heart that can assist in predicting and diagnosing heart diseases. The manual interpretation of the ECG signals, however, can be challenging and time-consuming even for experts. Machine learning techniques are increasingly being utilized to support the research and development of automatic ECG classification, which has emerged as a prominent area of study. In this paper, we propose a deep neural network model with residual blocks (DNN-RB) to classify cardiac cycles into six ECG beat classes. The MIT-BIH dataset was used to validate the model resulting in a test accuracy of 99.51%, average sensitivity of 99.7%, and average specificity of 98.2%. The DNN-RB method has achieved higher accuracy than other state-of-the-art algorithms tested on the same dataset. The proposed method is effective in the automatic classification of ECG signals and can be used for both clinical and out-of-hospital monitoring and classification combined with a single-lead mobile ECG device. The method has also been integrated into a web application designed to accept digital ECG beats as input for analyses and to display diagnostic results.","https://www.proquest.com/docview/2846928415?accountid=12870&bdid=124553&_bd=ykzuk0vjQSE0q6jToP85NEMwn%2BQ%3D","https://doi.org/10.1016/j.heliyon.2023.e17974"
"Climate-sensitive hydrological drought insurance for irrigated agriculture under deep uncertainty. Insightful results from the Cega River Basin in Spain","","Agudo-Domínguez, Alberto; Pérez-Blanco, C Dionisio; Gil-García, Laura; Ortega, José Antonio; Dasgupta, Shouro","Agricultural water management","Undefined","Elsevier B.V.","274 p.107938-","","2022-12-01","Dec 1, 2022","","","","0378-3774","0378-3774","","ENG","This paper assesses the feasibility and robustness of an index-based insurance scheme against hydrological droughts under climate change. To this end, we develop a grand ensemble that samples both modeling and scenario uncertainty in the estimation of the insurance risk premium, so to reveal potential unfavorable surprises and minimize regret in the design of the proposed insurance scheme. The grand ensemble combines four microeconomic models and seven GAMLSS models, which are run for three alternative climate change scenarios: stationary climate/no climate change, RCP 2.6, and RCP 8.5. Methods are illustrated with an application to the Cega River Sub-basin (CRS) in central Spain. Results indicate that for a conventional deductible of 30%, the proposed index-based insurance scheme would be actuarially feasible and affordable under all models for the stationary climate scenario (i.e., robust). For climate change scenarios RCP 2.6 and 8.5 and a 30% deductible, the suggested index-based insurance would be actuarially feasible under most models, albeit some outliers point towards potential unfavorable surprises. Lower deductibles decrease feasibility, particularly for deductibles <10%.","https://www.proquest.com/docview/2723105266?accountid=12870&bdid=124553&_bd=o4bMfZXiWiGMoxJT%2FufWva0n%2BwM%3D","https://doi.org/10.1016/j.agwat.2022.107938"
"Optimal supplier testing and tolerance strategies for genetically modified (GM) wheat","","Wilson, William W; Dahl, Bruce L; Jabs, Eric","Agricultural economics","Undefined","Blackwell Publishing Inc","36","1 p.39-48","2007-01-01","Jan 2007","39","48","p. 39-48","0169-5150","0169-5150","","ENG","A stochastic optimization model was developed to determine optimal testing strategies, costs, and risks for dual marketing of genetically modified (GM) and non-GM wheat in an export supply chain. The optimal testing strategy is derived that minimizes disutility of additional system costs due to testing and quality loss. Cost components were estimated including those related to testing, quality loss, and a risk premium to induce shippers to undertake dual marketing as opposed to handling only non-GM crops. Uncertainties were incorporated for adventitious presence and commingling, variety declaration, and test accuracy. Sensitivities were performed for effects of variety risks and declaration, penalty differentials, buyer tolerances, risk aversion, and GM adoption. Results indicate testing and segregation can be performed at a relatively low cost and risk to buyers.","https://www.proquest.com/docview/47597336?accountid=12870&bdid=124553&_bd=b1Ap7rPWHgDVCaWhivCpokkpGUY%3D","https://doi.org/10.1111/j.1574-0862.2007.00175.x"
"Bond return predictability: Macro factors and machine learning methods","","Jiang, Ying; Liu, Xiaoquan; Liu, Yirong; Zhu, Fumin","European Financial Management","Scholarly Journals","","30","5","2024-11-01","Nov 2024","2596","2627","2596-2627","13547798","","","ENG","We investigate the impact of macroeconomic variables on bond risk premia prediction via machine learning techniques. On the basis of Chinese treasury bonds from March 2006 to December 2022, we show that adding macroeconomic factors improves bond return forecasts and generates higher economic benefits to investors. This is achieved when the nonlinear relationship between macroeconomic variables and bond returns is modelled via machine learning methods. Furthermore, the importance of macroeconomic determinants changes along the yield curve. Our study sheds new light on the information contained in macroeconomic variables for treasury bond valuation and highlights the importance of utilizing appropriate machine learning methods.","https://www.proquest.com/docview/3124278826?accountid=12870&bdid=124553&_bd=S3k3fNmyASuCmoVqMG2KR7TSE7U%3D","https://doi.org/10.1111/eufm.12483"
"Investor attention and FX market volatility","","Goddard, John; Kita, Arben; Wang, Qingwei","Journal of international financial markets, institutions and money","Undefined","","38","","2015-09-01","Sep 2015","79","96","79-96","1042-4431","1042-4431","","ENG","We study the relationship between investors' active attention, measured by a Google search volume index (SVI), and the dynamics of currency prices. Investor attention is correlated with the trading activities of large FX market participants. Investor attention comoves with contemporaneous FX market volatility and predicts subsequent FX market volatility, after controlling for macroeconomic fundamentals. In addition, investor attention is related to the currency risk premium. Our results suggest that investor attention is a priced source of risk in FX markets.","https://www.proquest.com/docview/1718086725?accountid=12870&bdid=124553&_bd=YDtSlOwKxGKCBRo1F2Oec1Byfys%3D",""
"Hierarchical Bayesian collective risk model: an application to health insurance","","Migon, H S; Moura, FAS","Insurance Mathematics & Economics","Undefined","","36","2","2005-04-01","Apr 2005","119","135","119-135","0167-6687","0167-6687","","ENG","This paper deals with the main statistical steps involved in building an insurance plan, with special emphasis on an application to health insurance. The pure premium is predicted based on the available past information concerning the number and the amount of losses, and also the population exposed to risk. Both the size and the number of losses are treated in a stochastic manner. The claims are assumed to follow a Poisson process and the claim sizes are independent and identically distributed non-negative random variables. The model proposed is a generalization of the collective risk model, usually applied in practice. The evolution of the population at risk is also stochastically described via a nonlinear hierarchical growth model. Furthermore, a theoretical decision framework is adopted for evaluating the premium. Model selection and premium calculation are obtained from the predictive distribution, incorporating all the uncertainties involved.","https://www.proquest.com/docview/17847431?accountid=12870&bdid=124553&_bd=aweLgflBZMqJ0pyMwp1qOIxwKh0%3D","https://doi.org/10.1016/j.insmatheco.2004.11.006"
"How good are analyst forecasts of oil prices?","","Cortazar, Gonzalo; Ortega, Hector; Valencia, Consuelo","Energy Economics","Scholarly Journals","","102","","2021-10-01","Oct 2021","1","","","01409883","","","ENG","Even though there is a wide consensus that having good oil price forecasts is very valuable for many agents in the economy, results have not been fully satisfactory and there is an ongoing effort to improve their accuracy. Research has explored many different modeling approaches including time series, regressions, and artificial intelligence, among others. Also, many different sources of input data have been used like spot and futures prices, product spreads, and micro and macro variables. This paper explores how useful analyst expected price data are for forecasting when appropriate measures are taken to account for their sparse nature and high volatility. It proposes a multifactor stochastic pricing model, with time-varying risk premiums calibrated with filtered futures and analyst forecasts using a Kalman Filter. The forecasting model is applied to ten years of oil prices and analyst forecasts, from NYMEX and Bloomberg, respectively. Results are very encouraging showing that the model forecasts are much better than the no-change forecasts, commonly used as a benchmark, and better than those from the widely used Bloomberg's Consensus Expected Price Model. We conclude that analyst forecasts are a valuable source of input data that should be considered in future forecasting models.","https://www.proquest.com/docview/2599116135?accountid=12870&bdid=124553&_bd=7x1ZFzzJ1ZT9REuOPKlQPyaKpnE%3D","https://doi.org/10.1016/j.eneco.2021.105500"
"Use of (Time-Domain) Vector Autoregressions to Test Uncovered Interest Parity","","Ito, Takatoshi","The Review of Economics and Statistics","Scholarly Journals","","70","2","1988-05-01","May 1988","296","","296","00346535","","","ENG","A vector autoregression (VAR) model is developed in order to test uncovered interest parity (UIP) in the foreign exchange market.  The VAR system with the spot yen-dollar exchange rate, the Japanese domestic interest rate, and the Eurodollar interest rate describes the interdependence of domestic and world financial markets.  The VAR model will generate the expected future spot exchange rate as a k-step ahead prediction.  Therefore, the null hypothesis, UIP, is stated as nonlinear cross-equational restrictions for the 3-variable VAR model and can be tested using the Wald test.  Uncovered interest parity is tested in the proposed model.  UIP is rejected for the period of strict capital controls (1973-1977) and accepted for the period of free capital mobility (1981-1985).  Thus, the analysis suggests that, because few controls are left on capital flows between Tokyo and Euro-markets, the yen-dollar foreign exchange market is efficient (without risk premium) in the 1980s.","https://www.proquest.com/docview/194677630?accountid=12870&bdid=124553&_bd=CkT0XO7Sli3n0jhIfWevzRSC1Mg%3D",""
"Business performance assessment of small and medium-sized enterprises: Evidence from the Czech Republic","","Stehel, Vojtech; Horak, Jakub; Krulicky, Tomas","Problems and Perspectives in Management","Scholarly Journals","","19","3","2021-01-01","2021","430","","430-439","17277051","","","ENG","Business performance assessment is one of the basic tasks of management. Business performance can be assessed using a number of methods. The basic ones include financial analysis, Balanced Scorecard or Economic Value Added (EVA). The paper is focused on SME business performance assessment based on Economic Value Added, calculated using the INFA build-up model. According to this method, companies were divided into four categories. The first category included companies with a positive EVA value. The second category included companies with negative EVA, but with the economic result above the risk-free rate. The third category included companies with a positive economic result above the risk-free rate. The fourth category included companies with a negative economic result. The model did not include companies with negative equity. The input represented 15 predictors based on their financial statements. The data were normalized and all extreme values, likely caused by a data rewriting error, were removed. Company performance is visualized by comparing Principal Component Analysis and Kohonen neural networks. Compared to similar research, the methods are compared using the data that analyzes the performance of companies. Both methods made it possible to visualize the given task. With regard to the purpose of facilitating the interpretation of the results, for the given case, the use of PC seems to be more appropriate.","https://www.proquest.com/docview/3102484161?accountid=12870&bdid=124553&_bd=71kOTmWtLnauhA74dlMZnvB%2B0fU%3D","https://doi.org/10.21511/ppm.19(3).2021.35"
"Monte Carlo Simulations for Resolving Verifiability Paradoxes in Forecast Risk Management and Corporate Treasury Applications","","Pavlik, Martin; Michalski Grzegorz","International Journal of Financial Studies","Scholarly Journals","","13","2","2025-04-01","2025","49","","","22277072","","","ENG","Forecast risk management is central to the financial management process. This study aims to apply Monte Carlo simulation to solve three classic probabilistic paradoxes and discuss their implementation in corporate financial management. The article presents Monte Carlo simulation as an advanced tool for risk management in financial management processes. This method allows for a comprehensive risk analysis of financial forecasts, making it possible to assess potential errors in cash flow forecasts and predict the value of corporate treasury growth under various future scenarios. In the investment decision-making process, Monte Carlo simulation supports the evaluation of the effectiveness of financial projects by calculating the expected net value and identifying the risks associated with investments, allowing more informed decisions to be made in project implementation. The method is used in reducing cash flow volatility, which contributes to lowering the cost of capital and increasing the value of a company. Simulation also enables more accurate liquidity planning, including forecasting cash availability and determining appropriate financial reserves based on probability distributions. Monte Carlo also supports the management of credit and interest rate risk, enabling the simulation of the impact of various economic scenarios on a company’s financial obligations. In the context of strategic planning, the method is an extension of decision tree analysis, where subsequent decisions are made based on the results of earlier ones. Creating probabilistic models based on Monte Carlo simulations makes it possible to take into account random variables and their impact on key financial management indicators, such as free cash flow (FCF). Compared to traditional methods, Monte Carlo simulation offers a more detailed and precise approach to risk analysis and decision-making, providing companies with vital information for financial management under uncertainty. This article emphasizes that the use of Monte Carlo simulation in financial management not only enhances the effectiveness of risk management, but also supports the long-term growth of corporate value. The entire process of financial management is able to move into the future based on predicting future free cash flows discounted at the cost of capital. We used both numerical and analytical methods to solve veridical paradoxes. Veridical paradoxes are a type of paradox in which the result of the analysis is counterintuitive, but turns out to be true after careful examination. This means that although the initial reasoning may lead to a wrong conclusion, a correct mathematical or logical analysis confirms the correctness of the results. An example is Monty Hall’s problem, where the intuitive answer suggests an equal probability of success, while probabilistic analysis shows that changing the decision increases the chances of winning. We used Monte Carlo simulation as the numerical method. The following analytical methods were used: conditional probability, Bayes’ rule and Bayes’ rule with multiple conditions. We solved truth-type paradoxes and discovered why the Monty Hall problem was so widely discussed in the 1990s. We differentiated Monty Hall problems using different numbers of doors and prizes.","https://www.proquest.com/docview/3223908513?accountid=12870&bdid=124553&_bd=DSW6I44sWuqVAOVPjhuXP8ar4Gs%3D","https://doi.org/10.3390/ijfs13020049"
"A Comparative Analysis of the Choice of Mother Wavelet Functions Affecting the Accuracy of Forecasts of Daily Balances in the Treasury Single Account","","Karaev, Alan K; Gorlova, Oksana S; Ponkratov, Vadim V; Sedova, Marina L; Shmigol, Nataliya S; Vasyunina, Margarita L","Economies","Scholarly Journals","","10","9","2022-01-01","2022","213","","","22277099","","","ENG","Improving the accuracy of cash flow forecasting in the TSA is key to fulfilling government payment obligations, minimizing the cost of maintaining the cash reserve, providing the absence of outstanding debt accumulation and ensuring investment in financial instruments to obtain additional income. This study aims to improve the accuracy of traditional methods of forecasting the time series compiled from the daily remaining balances in the TSAbased on prior decomposition using a discrete wavelet transform. The paper compares the influence of selecting a mother wavelet out of 570 mother wavelet functions belonging to 10 wavelet families (Haar;Dabeshies; Symlet; Coiflet; Biorthogonal Spline; Reverse Biorthogonal Spline; Meyer; Shannon; Battle-Lemarie; and Cohen–Daubechies–Feauveau) and the decomposition level (from 1 to 8) on the forecast accuracy of time series compiled from the daily remaining balances in the TSA in comparison with the traditional forecasting method without prior timeseries decomposition. The model with prior time series decomposition based on the Reverse Biorthogonal Spline Wavelet [5.5] mother wavelet function, upon the eighth iteration, features the highest accuracy, significantly higher than that of the traditional forecasting models. The choice of the mother wavelet and the decomposition level play an important role in increasing the accuracy of forecasting the daily remaining balances in the TSA.","https://www.proquest.com/docview/2716517146?accountid=12870&bdid=124553&_bd=jWwP6AuWPYOWeiwoAXs9DjC86GM%3D","https://doi.org/10.3390/economies10090213"
"Removing Bias in Estimating Financial Contagion: An Empirical Analysis Based on European Economies","","Du, Wenti; Pentecost, Eric; Bird, Graham","Open Economies Review","Scholarly Journals","","36","4","2025-09-01","Sep 2025","1081","1096","1081-1096","09237992","","","ENG","The degree of contagion is frequently measured by the size and significance of linear correlation coefficients. In this paper, we show that such linear measures are inappropriate for three reasons: contagion is likely to be nonlinear, the structural contagion model is unknown, and the contagion itself will be time-varying. Instead, we use a time-varying coefficient method to give a time-varying, unbiased measure of bilateral contagion between two countries, which shows that simple correlation measures over-estimate the average contagion from the source country and how the degree of contagion varies over the sample period. To illustrate, we use Greece as an exemplar source country and Belgium, France, Italy, Ireland, Netherlands, Portugal, and Spain as recipient countries over the period 2009 to 2022.","https://www.proquest.com/docview/3241055797?accountid=12870&bdid=124553&_bd=yUzR2GqF7z7GKmeWvIDwN9vQi40%3D","https://doi.org/10.1007/s11079-024-09788-z"
"Bayesian factor-adjusted sparse regression","","Fan, Jianqing; Jiang, Bai; Sun, Qiang","Journal of Econometrics","Undefined","Elsevier B.V.","230","1 p.3-19","2022-09-01","Sep 2022","3","19","p. 3-19","0304-4076","0304-4076","","ENG","Many sparse regression methods rely on an assumption that the covariates are weakly correlated, which hardly holds in many economic and financial datasets. To relax this assumption, we model the strongly correlated covariates by a factor structure: strong correlations among covariates are modeled by common factors, while the remaining variations of covariates are modeled as idiosyncratic components. We then propose a factor-adjusted sparse regression model and develop a semi-Bayesian estimation method for it. Posterior contraction rate and model selection consistency are established by a non-asymptotic analysis. Experimental studies show that the proposed method outperforms its Lasso analogue, manifests insensitivity to overestimates of the number of common factors, pays a negligible price when covariates are uncorrelated, scales up well with increasing sample size, dimensionality and sparsity, and converges fast to the posterior distribution. An application to the U.S. bond risk premia lends further support to the proposed model and method.","https://www.proquest.com/docview/2636599470?accountid=12870&bdid=124553&_bd=oNNu9o%2FgGqdCp2snXUITs7NbbOw%3D","https://doi.org/10.1016/j.jeconom.2020.06.012"
"Blockchain Innovation for Sustainability: Unraveling Its Market Impact Through Public Attention and Financial Performance","","Celina Toscano Hernandez; Appio, Francesco Paolo; Platania, Federico","IEEE Transactions on Engineering Management","Scholarly Journals","","72","","2025-01-01","2025","3688","3703","3688-3703","00189391","","","ENG","This study investigates the dynamic interplay between blockchain innovation, public attention, and financial performance, with a focus on sustainability applications. Using a state-space model and the Kalman filter, it analyzes data from blockchain-related patents and Google Trends to assess their influence on the excess returns of blockchain-focused exchange-traded funds (ETFs). The findings highlight that innovation activity significantly enhances financial performance, underscoring blockchain’s role as a general-purpose technology with transformative sustainability potential. Public attention, measured through search interest, independently drives investor sentiment and market outcomes, while the interaction between innovation and public attention does not exhibit significant synergistic effects, suggesting distinct channels of influence. This study contributes to the growing stream of literature in sustainable finance, innovation management, and behavioral finance by introducing a real-time measure of blockchain innovation for sustainability into an asset pricing model, by showing that patent activity and public attention operate as separate predictors of financial returns, and by advancing methodological practice through the use of a state-space approach to capture latent innovation dynamics. The findings suggest actionable strategies: investors can track patent-based innovation and search trends as early signals of thematic-ETF performance; industry leaders can align blockchain projects with sustainability goals to unlock valuation gains; and policymakers can foster environmental, social, and governance innovation ecosystems by encouraging transparent patent disclosure and public awareness.","https://www.proquest.com/docview/3247523347?accountid=12870&bdid=124553&_bd=Mb4WS2HZ6Gev%2BdwWfRCa8EtvdbM%3D","https://doi.org/10.1109/TEM.2025.3598382"
"ChatGPT and Commodity Return","","Gao, Shen; Wang, Shijie; Wang, Yuanzhi; Zhang, Qunzi","The Journal of Futures Markets","Scholarly Journals","","45","3","2025-03-01","Mar 2025","161","175","161-175","02707314","","","ENG","This paper investigates the ability of a ChatGPT‐based indicator to forecast excess returns of the commodity futures index. Using ChatGPT to extract information from over 2.5 million articles from nine international newspapers, we demonstrate that our constructed commodity news ratio index significantly predicts future commodity returns, both in‐sample and out‐of‐sample. Furthermore, it outperforms traditional textual analysis methods, including Bidirectional Encoder Representations from Transformers (BERT) and Bag‐of‐Words (BoW), while indicating economic significance within an asset allocation framework. The results highlight the critical role of ChatGPT in forecasting commodity market dynamics and provide valuable insights for both financial market participants and researchers.","https://www.proquest.com/docview/3165735434?accountid=12870&bdid=124553&_bd=vx8X3JfFUzbZQv9xkbYmidVpZME%3D","https://doi.org/10.1002/fut.22568"
"SCORING: FAILURE RISK MANAGEMENT TOOL FOR SMES IN ALGERIA","","Tarhlissia, Lamine","Scientific Bulletin - Nicolae Balcescu Land Forces Academy","Scholarly Journals","","29","1","2024-01-01","2024","169","178","169-178","2451-3148","","","ENG","Algerian public banks need to implement credit risk management techniques tailored to the specific characteristics of SMEs to prevent the deterioration of the banks' solvency due to the degradation of the quality of their SME portfolios. In this regard, our main objective is to highlight the interest that credit risk management will have within the People's Credit of Algeria by developing a Credit Scoring model based on the logistic regression technique, using a sample of 226 SMEs. The study results demonstrate the importance of the logistic regression model in classifying companies and its predictive ability for default, with a good classification rate of 91.2%.","https://www.proquest.com/docview/3068463166?accountid=12870&bdid=124553&_bd=LYgCSY%2FzGEPOf%2BmyBV%2F1yE1oMuA%3D","https://doi.org/10.2478/bsaft-2024-0018"
"An interval constraint-based trading strategy with social sentiment for the stock market","","Li, Mingchen; Yang, Kun; Lin, Wencan; Wei, Yunjie; Wang, Shouyang","Financial Innovation","Scholarly Journals","","10","1","2024-12-01","Dec 2024","56","","56","21994730","","","ENG","Developing effective strategies to earn excess returns in the stock market is a cutting-edge topic in the field of economics. At the same time, stock price forecasting that supports trading strategies is considered one of the most challenging tasks. Therefore, this study analyzes and extracts news media data, expert comments, social opinion data, and pandemic text data using natural language processing, and then combines the data with a deep learning model to forecast future stock price patterns based on historical stock prices. An interval constraint-based trading strategy is constructed. Using data from several typical stocks in the Chinese stock market during the COVID-19 period, the empirical studies and trading simulations show, first, that the sentiment composite index and the deep learning model can improve the accuracy of stock price forecasting. Second, the interval constraint-based trading strategy based on the proposed approach can effectively enhance returns and thus, can assist investors in decision-making.","https://www.proquest.com/docview/2924112716?accountid=12870&bdid=124553&_bd=nUNrqssHWXo58GQoiYC6awsoSOw%3D","https://doi.org/10.1186/s40854-023-00567-2"
"Exchange rate parities and Taylor rule deviations","","Anderl, Christina; Caporale, Guglielmo Maria","Empirical Economics","Scholarly Journals","","63","4","2022-10-01","Oct 2022","1809","1835","1809-1835","03777332","","","ENG","This paper investigates the PPP and UIP conditions by taking into account possible nonlinearities as well as the role of Taylor rule deviations under alternative monetary policy frameworks. The analysis is conducted using monthly data from January 1993 to December 2020 for five inflation-targeting countries (the UK, Canada, Australia, New Zealand and Sweden) and three non-targeting ones (the USA, the Euro Area and Switzerland). Both a benchmark linear VECM and a nonlinear Threshold VECM are estimated; the latter includes Taylor rule deviations as the threshold variable. The results can be summarized as follows. First, the nonlinear specification provides much stronger evidence for the PPP and UIP conditions, the estimated adjustment speed towards equilibrium being twice as fast. Second, Taylor rule deviations play an important role: the adjustment speed is twice as fast when deviations are small and the credibility of the central bank is higher. Third, inflation targeting tends to generate a higher degree of credibility for the monetary authorities, thereby reducing deviations of the exchange rate from the PPP- and UIP-implied equilibrium.","https://www.proquest.com/docview/2717354601?accountid=12870&bdid=124553&_bd=quA%2B4kAy7YENwFSQtEm6Jvrc2h8%3D","https://doi.org/10.1007/s00181-021-02192-3"
"Robust optimal decisions with stochastic nonlinear economic systems","","Becker, R; Hall, S; Rustem, B","Journal of Economic Dynamics & Control","Scholarly Journals","","18","1","1994-01-01","Jan 1994","125","","125","01651889","","","ENG","Optimal decisions for nonlinear systems are usually computed on the basis that certainty-equivalent decisions are sufficiently accurate.  This premise is tested using an approach that evaluates, using Monte Carlo simulations, any expectations bias that nonlinearities may introduce.  Optimal decisions are determined by incorporating this bias with a robust decision formulation.  The expected value of the policy objective function is optimized simultaneously with the sensitivity of the problem to given sources of uncertainty in the model.  Numerical results, based on the National Institute of Economic and Social Research model of the UK economy, are used to highlight 2 specific points.  The first is that robust decision performs better than simple certainty-equivalent deterministic decision and that increased robustness makes the policy more risk-averse.  The 2nd point is that the bias due to the nonlinearity of the model is significant in terms of the policy and the endogenous variables.","https://www.proquest.com/docview/196704816?accountid=12870&bdid=124553&_bd=tlm0qhRmu8pyg7I4%2BTYgBrsVO58%3D",""
"Calendar anomolies and stock market volatility in selected Arab stock exchanges","","Kamaly, Ahmed; Tooma, Eskandar","Applied financial economics","Undefined","","19","11","2009-06-01","Jun 2009","881","892","881-892","0960-3107","0960-3107","","ENG","While seasonal effects for both advanced and emerging markets have been investigated extensively in mean and variance equations, Arab region asset markets have received much less attention. The objective of this article is to fill this gap in the literature by investigating the day-of-the-week effect in 12 major Arab stock markets using Arab Monetary Fund (AMF) daily index returns from May 2002 to December 2005. Our estimation strategy utilizes Autoregressive (AR) and Generalized Autoregressive Conditional Heteroscedastic (GARCH)-type specifications to allow for a time-varying variance. Among the most important results of this article are, first, is one-third of these markets exhibit significant day-of-the-week effect in returns. Second, two-third of these markets exhibit significant day-of-the-week effect on volatility. Third, most of these day-of-the-week effects are focused within the beginning and the end of the trading week. Finally, the existence of a significant risk premium was confirmed in five of the 12 studied markets. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/37106642?accountid=12870&bdid=124553&_bd=UPPQCye0UYiEdax4mRcXbwvXVAk%3D","https://doi.org/10.1080/09603100802359976"
"Dopamine D2 −141C Ins/Del and Taq1A polymorphisms, body mass index, and prediction error brain response","","Frank, Guido K W; Shott, Megan E; DeGuzman, Marisa C; Smolen, Andrew","Translational Psychiatry","Scholarly Journals","","8","","2018-05-01","May 2018","1","7","1-7","21583188","","","ENG","The prediction error model is a widely used paradigm that is conceptually based on neuronal dopamine function. However, whether dopamine receptor gene alleles contribute to human neuroimaging prediction error results is uncertain. Recent research implicated the dopamine D2 receptor in behavior response during a prediction error paradigm and we expected that polymorphisms of that receptor would contribute to prediction error brain response. In this study, healthy female participants in the early follicular phase of the menstrual cycle underwent a taste prediction error paradigm during functional magnetic resonance imaging. Participants were also genotyped for dopamine receptor polymorphisms. Our data suggest that the dopamine D2 receptor −141C Ins/Del and Taq1A polymorphisms together with body mass index selectively explain putamen prediction error response. This was true using a region of interest analysis as well as for a whole-brain analysis (FWE corrected). Polymorphisms for dopamine D1 or D4 receptors, dopamine transporter, or COMT did not significantly contribute to prediction error activation. The prediction error model is a computational reward-learning paradigm that is important in psychiatric research and has been associated with dopamine. The results from this study indicate that dopamine D2 receptor polymorphisms together with body mass index are important determinants to include in research that tests prediction error response of the brain. Psychiatric disorders are frequently associated with elevated or reduced body weight. Adding BMI to genetic information in brain-imaging studies that use reward and the prediction error paradigm may be important to increase validity and reliability of results.","https://www.proquest.com/docview/2043151605?accountid=12870&bdid=124553&_bd=4Zn682te6i%2FfMq0K3lCOh5SuFDo%3D","https://doi.org/10.1038/s41398-018-0147-1"
"Capital accumulation, external indebtedness, and macroeconomic performance of emerging countries","","Rocha, Marcos; Oreiro, José Luis","Journal of post Keynesian economics","Undefined","","35","4","2013-06-01","Jun 2013","599","620","599-620","0160-3477","0160-3477","","ENG","This paper aims at presenting a nonlinear post Keynesian growth model to evaluate at the theoretical and empirical levels the relationship between external indebtedness and economic growth in emerging countries. To this end, a post Keynesian endogenous growth model is presented, in which: (1) the desired rate of capital accumulation is assumed to be a nonlinear function of external indebtedness as a share of capital stock; (2) an endogenous country risk premium is assumed to be an increasing (linear) function of external indebtedness (as a share of capital stock); (3) there is a fixed exchange rate regime and perfect capital mobility in the sense of Mundell and Fleming. The main theoretical result of the model is the existence of two long-run equilibrium positions, one of which has a high level of external indebtedness (as a ratio of capital stock) and a low profit rate and the other has a low level of external indebtedness and a high profit rate. This means that 'excessive' external indebtedness can result in stagnant growth due to its negative effect on the rate of profit. To test the effects of external indebtedness on the rate of economic growth in emerging economies, a dynamic panel is estimated to evaluate whether external debt has an effective negative influence on economic growth in emerging countries. An empirical test of demand-led growth equations with a dynamic panel for fifty-five emerging countries confirms the potential negative effects of external debt on long-term growth rates in the sample countries. [PUBLICATION ABSTRACT] Reprinted by permission of M.E. Sharpe, Inc.","https://www.proquest.com/docview/1426224381?accountid=12870&bdid=124553&_bd=IJto4VBcDF%2FC61vzM1o9PrlA%2BAc%3D",""
"Artificial Intelligence and Firm Performance: Does Machine Intelligence Shield Firms from Risks?","","Linh Tu Ho; Linh Tu Ho; Gan, Christopher; Jin, Shan; Le, Bryan","Journal of Risk and Financial Management","Scholarly Journals","","15","7","2022-01-01","2022","302","","","19118066","","","ENG","We estimate and compare the impact of the coronavirus pandemic (COVID-19) on the performance of Artificial Intelligence (AI) and conventional listed firms using stock market indices. The single-group and multiple-group Interrupted Time-Series Analyses (ITSA) with panel data were used with four interventions: when the news of COVID-19 spread and the pandemic entered the first, second, third, and fourth months (24 February 2020, 23 March 2020, 20 April 2020, and 18 May 2020, respectively). The results show that the negative impact of COVID-19 on the AI stock market was less severe than on the conventional stock market in the first month of the pandemic. The performance of the AI stock market recovered quicker than the conventional stock market when the pandemic went into its third month. The results suggest that the AI stocks were more resilient than conventional stocks when the financial market was exposed to uncertainty caused by the COVID-19 pandemic. The deployment of AI in firms serves as a resilient, crucial driver for sustainable performance in challenging environments. Observing the performance of AI-adopted firms is an interesting direction for technical and fundamental analysts. Investors and portfolio managers should consider an AI market index to minimize risk or invest in stocks of AI-adopted listed firms to maximize excess returns.","https://www.proquest.com/docview/2693975247?accountid=12870&bdid=124553&_bd=uU5srLhV2JDkNUVbDvQpOi7RnGg%3D","https://doi.org/10.3390/jrfm15070302"
"Equity Return Dispersion and Stock Market Volatility: Evidence from Multivariate Linear and Nonlinear Causality Tests","","Demirer, Riza; Gupta, Rangan; Lv, Zhihui; Wong, Wing-Keung","Sustainability","Undefined","Multidisciplinary Digital Publishing Institute","11","2","2019-01-11","Jan 11, 2019","","","","2071-1050","2071-1050","","ENG","We employ bivariate and multivariate nonlinear causality tests to document causality from equity return dispersion to stock market volatility and excess returns, even after controlling for the state of the economy. Expansionary (contractionary) market states are associated with a low (high) level of equity return dispersion, indicating asymmetries in the relationship between return dispersion and economic conditions. Our findings indicate that both return dispersion and business conditions are valid joint forecasters of stock market volatility and excess returns and that return dispersion possesses incremental information regarding future stock return dynamics beyond that which can be explained by the state of the economy.","https://www.proquest.com/docview/2374196267?accountid=12870&bdid=124553&_bd=gCsnxwaFtsevUJexL8G6tXfl0G0%3D","https://doi.org/10.3390/su11020351"
"Estimating the risk-return profile of new venture investments using a risk-neutral framework and 'thick' models","","Reber, Beat","European journal of finance","Undefined","","20","4","2014-04-01","Apr 2014","341","360","341-360","1351-847X","1351-847X","","ENG","This study proposes cascade neural networks to estimate the model parameters of the Cox-Ross-Rubinstein risk-neutral approach, which, in turn, explain the risk-return profile of firms at venture capital and initial public offering (IPO)financing rounds. Combining the two methods provides better estimation accuracy than risk-adjusted valuation approaches, conventional neural networks, and linear benchmark models. The findings are persistent across in-sample and out-of-sample tests using 3926 venture capital and 1360 US IPO financing rounds between January 1989 and December 2008. More accurate estimates of the risk-return profile are due to less heterogeneous risk-free rates of return from the risk-neutral framework. Cascade neural networks nest both the linear and nonlinear functional estimation form in addition to taking account of variable interaction effects. Better estimation accuracy of the risk-return profile is desirable for investors so they can make a more informed judgement before committing capital at different stages of development and various financing rounds. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/1504157242?accountid=12870&bdid=124553&_bd=SAcfj1XzqKW2xFPPMgKxYMQiNAE%3D","https://doi.org/10.1080/1351847X.2012.708471"
"Market Efficiency and the Returns to Simple Technical Trading Rules: New Evidence from U.S. Equity Market and Chinese Equity Markets","","Tian, Gary Gang; Wan, Guang Hua; Guo, Mingyuan","Asia - Pacific Financial Markets","Scholarly Journals","","9","3-4","2002-09-01","Sep 2002","241","","241-258","13872834","","","ENG","Numerous studies in the finance literature have investigated technical analysis to determine its validity as an investment tool. This study is an attempt to explore whether some forms of technical analysis can predict stock price movement and make excess profits based on certain trading rules in markets with different efficiency level. To avoid using arbitrarily selected 26 trading rules as did by Brock, Lakonishok and LeBaron (1992) and later by Bessembinder and Chan (1998), this paper examines predictive power and profitability of simple trading rules by expanding their universe of 26 rules to 412 rules. In order to find out the relationship between market efficiency and excess return by applying trading rules, we examine excess return over periods in U.S. markets and also compare the excess returns between U.S. market and Chinese markets. Our results found that there is no evidence at all supporting technical forecast power by these trading rules in U.S. equity index after 1975. During the 1990s break-even costs turned to be negative, -0.06%, even failing to beat a buy-holding strategy in U.S. equity market. In comparison, our results provide support for the technical strategies even in the presence of trading cost in Chinese stock markets. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/215209510?accountid=12870&bdid=124553&_bd=0OVoPvZwHr2VaYBNn4TpVRur%2FL0%3D",""
"Dissecting climate change risk and financial market instability: Implications for ecological risk management","","Ma, Feng; Cao, Jiawei; Wang, Yizhi; Vigne, Samuel A; Dong, Dayong","Risk Analysis","Scholarly Journals","","45","3","2025-03-01","Mar 2025","496","522","496-522","02724332","","","ENG","This research investigates the impact of climate challenges on financial markets by introducing an innovative approach to measure climate risk, specifically the aggregate climate change concern (ACCC) index. The study aims to assess and quantify the potential influence of climate change and risk‐related factors on the performance and dynamics of financial markets. In this paper, concern is defined as the attention paid to the risk of climate change and the associated negative consequences. The findings demonstrate that the aggregate index exhibits robust predictability of market risk premiums, both within the sample and out‐of‐sample. By comparison, the index contains additional information beyond 14 economic predictors and 12 risk/uncertainty indexes in forecasting stock market return. In addition, the index proves valuable for mean–variance investors in asset allocation, leading to significant economic gains. The study identifies the index's ability to capture the reversal of temporary price crashes caused by overreactions to climate change risk. Furthermore, it exhibits stronger return forecasting capability for green stocks, non‐state‐owned enterprise (non‐SOE) stocks, and stocks in regions with low air pollution. Particularly during periods of low air pollution and relaxed regulation, the index displays an enhanced ability to forecast returns. The study's findings provide valuable insights for policymakers and financial institutions as they address 21st‐century environmental challenges. Moreover, these findings can inform the design of adaptive measures and interventions aimed at mitigating ecological risks and promoting sustainable economic growth.","https://www.proquest.com/docview/3182921366?accountid=12870&bdid=124553&_bd=d0%2FbT9XVnCSffHYUM6SLiMZPYk8%3D","https://doi.org/10.1111/risa.14265"
"How to Rate the Financial Performance of Private Companies? A Tailored Integrated Rating Methodology Applied to North-Eastern Italian Districts","","Mantovani, Guido Max; Mantovani, Guido Max; Gadzinski, Gregory","Journal of Risk and Financial Management","Scholarly Journals","","15","11","2022-01-01","2022","493","","","19118066","","","ENG","This paper contributes to solving the puzzle of assessing the financial performance of private/unlisted companies. The inner characteristics of these companies make the adoption of traditional best practices in estimating risk premia difficult or impossible. Moreover, the lack of market data and comparable information biases the perception of corporate performance and generates the misallocation of credit fundings (both quantities and pricing). Hence, in this paper, we develop an Integrated Rating Methodology (IRM) to estimate a more efficient corporate “return-to-risk” measure. Our IRM is rooted in the seminal “certainty equivalent” model as developed by Lintner in 1965, but we modify it using a shortfall approach, and then compute a “confident equivalent” that is compliant with Fischer Black’s zero-beta model as well as the Basel agreements. An empirical application of the approach is conducted with a sample of 13,583 non-financial SMEs in the north-east regions of Italy, where there is evidence of inefficient bank financing. We back-test our IRM by rating these companies using corporate financial data during the period 2007–2014, which encompasses both the Great Financial Crisis and the European sovereign debt crisis. Our empirical results depict a clear crowding-out effect of credit allocations when we compare our IRM scoring measure with the actual raising ability and the cost of capital relating to these firms. We find that 36% of companies are underfunded, even if they have a superior IRM score, while 27% of them are funded without merit. Interestingly, this last figure is in line with the average non-performing loan ratio provided by official Italian statistics from 2015 to 2020. Therefore, we conclude that our IRM methodology is promising and may be better at estimating risk financing in small private companies (including start-ups) than internal banking models. These initial results will drive our forthcoming research towards creating an IRM 2.0.","https://www.proquest.com/docview/2734630370?accountid=12870&bdid=124553&_bd=BN3h8fAx5%2BEi%2BAT%2FrecRtgVuodA%3D","https://doi.org/10.3390/jrfm15110493"
"The cost of carbon capture and storage for natural gas combined cycle power plants","","Rubin, Edward S; Zhai, Haibo","Environmental science & technology","Undefined","","46","6","2012-03-20","Mar 20, 2012","3076","","3076-84","1520-5851","","","ENG","This paper examines the cost of CO(2) capture and storage (CCS) for natural gas combined cycle (NGCC) power plants. Existing studies employ a broad range of assumptions and lack a consistent costing method. This study takes a more systematic approach to analyze plants with an amine-based postcombustion CCS system with 90% CO(2) capture. We employ sensitivity analyses together with a probabilistic analysis to quantify costs for plants with and without CCS under uncertainty or variability in key parameters. Results for new baseload plants indicate a likely increase in levelized cost of electricity (LCOE) of $20-32/MWh (constant 2007$) or $22-40/MWh in current dollars. A risk premium for plants with CCS increases these ranges to $23-39/MWh and $25-46/MWh, respectively. Based on current cost estimates, our analysis further shows that a policy to encourage CCS at new NGCC plants via an emission tax or carbon price requires (at 95% confidence) a price of at least $125/t CO(2) to ensure NGCC-CCS is cheaper than a plant without CCS. Higher costs are found for nonbaseload plants and CCS retrofits.This paper examines the cost of CO(2) capture and storage (CCS) for natural gas combined cycle (NGCC) power plants. Existing studies employ a broad range of assumptions and lack a consistent costing method. This study takes a more systematic approach to analyze plants with an amine-based postcombustion CCS system with 90% CO(2) capture. We employ sensitivity analyses together with a probabilistic analysis to quantify costs for plants with and without CCS under uncertainty or variability in key parameters. Results for new baseload plants indicate a likely increase in levelized cost of electricity (LCOE) of $20-32/MWh (constant 2007$) or $22-40/MWh in current dollars. A risk premium for plants with CCS increases these ranges to $23-39/MWh and $25-46/MWh, respectively. Based on current cost estimates, our analysis further shows that a policy to encourage CCS at new NGCC plants via an emission tax or carbon price requires (at 95% confidence) a price of at least $125/t CO(2) to ensure NGCC-CCS is cheaper than a plant without CCS. Higher costs are found for nonbaseload plants and CCS retrofits.","https://www.proquest.com/docview/929505009?accountid=12870&bdid=124553&_bd=SC7c6ui0Ja0tLgRhUWbIGMVLEBw%3D","https://doi.org/10.1021/es204514f"
"Is technical analysis in the foreign exchange market profitable? A genetic programming approach","","Neely, Christopher; Weller, Paul; Dittmar, Rob","Journal of Financial and Quantitative Analysis","Scholarly Journals","","32","4","1997-12-01","Dec 1997","405","","405-426","00221090","","","ENG","Using genetic programming techniques to find technical trading rules, a study finds strong evidence of economically significant out-of-sample excess returns to those rules for each of 6 exchange rates over the period 1981-1995.  Furthermore, when the dollar/Deutsche mark rules are allowed to determine trades in the other markets, there is significant improvement in performance in all cases, except for the Deutsche mark/yen.  Betas calculated for the returns according to various benchmark portfolios provide no evidence that the returns to these rules are compensation for bearing systematic risk.  Bootstrapping results on the dollar/Deutsche market indicate that the trading rules detect patterns in the data that are not captured by standard statistical models.","https://www.proquest.com/docview/211951424?accountid=12870&bdid=124553&_bd=YJ%2FZ1ho8YZKsdBu52a29sNHDu5g%3D",""
"Gold Price Prediction Using Two-layer Decomposition and XGboost Optimized by the Whale Optimization Algorithm","","Guo, Yibin; Li, Chen; Wang, Xiang; Duan, Yonghui","Computational Economics","Scholarly Journals","","66","2","2025-08-01","Aug 2025","1157","1189","1157-1189","09277099","","","ENG","Gold price prediction is of great importance in big data computing and economic sphere. This paper aims to contribute to the study of hybrid models that can be used to forecast the price of gold. In this study, The Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) is employed to decompose a residual term containing complex information following the variational modal decomposition (VMD) and an extreme gradient boosting tree (XGBoost) optimized by the Whale Optimization Algorithm (WOA) is combined to construct the VMD-RES.-CEEMDAN-WOA-XGBoost model. The closing price data of COMEX gold futures from 1 October 2018 to 20 November 2023 were selected as examples of gold futures price. A variety of factors that can affect the price of gold are considered in the research. This study indicates that the combined forecasting model proposed in this paper has superior performance when compared to the other comparison forecasting models evaluated. Furthermore, it has been found through SHAP analysis that the Nasdaq index, silver price, and the yield of US 10-year Treasury bonds are most closely related to the prediction of gold price.","https://www.proquest.com/docview/3240553918?accountid=12870&bdid=124553&_bd=%2FLRE5w63FOCE8J808x%2F7e0Hwdag%3D","https://doi.org/10.1007/s10614-024-10736-9"
"QuantFactor REINFORCE: Mining Steady Formulaic Alpha Factors With Variance-Bounded REINFORCE","","Zhao, Junjie; Zhang, Chengxi; Qin, Min; Yang, Peng","IEEE Transactions on Signal Processing","Scholarly Journals","","73","","2025-01-01","2025","2448","2463","2448-2463","1053587X","","","ENG","Alpha factor mining aims to discover investment signals from the historical financial market data, which can be used to predict asset returns and gain excess profits. Powerful deep learning methods for alpha factor mining lack interpretability, making them unacceptable in the risk-sensitive real markets. Formulaic alpha factors are preferred for their interpretability, while the search space is complex and powerful explorative methods are urged. Recently, a promising framework is proposed for generating formulaic alpha factors using deep reinforcement learning, and quickly gained research focuses from both academia and industries. This paper first argues that the originally employed policy training method, i.e., Proximal Policy Optimization (PPO), faces several important issues in the context of alpha factors mining. Herein, a novel reinforcement learning algorithm based on the well-known REINFORCE algorithm is proposed. REINFORCE employs Monte Carlo sampling to estimate the policy gradient—yielding unbiased but high variance estimates. The minimal environmental variability inherent in the underlying state transition function, which adheres to the Dirac distribution, can help alleviate this high variance issue, making REINFORCE algorithm more appropriate than PPO. A new dedicated baseline is designed to theoretically reduce the commonly suffered high variance of REINFORCE. Moreover, the information ratio is introduced as a reward shaping mechanism to encourage the generation of steady alpha factors that can better adapt to changes in market volatility. Evaluations on real assets data indicate the proposed algorithm boosts correlation with returns by 3.83%, and a stronger ability to obtain excess returns compared to the latest alpha factors mining methods, which meets the theoretical results well.","https://www.proquest.com/docview/3227093066?accountid=12870&bdid=124553&_bd=KURsm2ylQgId6yNc%2BzIfw3c3Hkg%3D","https://doi.org/10.1109/TSP.2025.3576781"
"OP73 Human and financial costs of six early years disadvantages in the UK and Bradford: a birth cohort microsimulation study","","Shrathinth, Venkatesh; Skarda Ieva; Villadsen Aase; Warburton, Matthew; Mansukoski Liina; Miqdad, Asaria; Williams, Mark Mon; Cookson, Richard","Journal of Epidemiology and Community Health","Scholarly Journals","","79","Suppl 1","2025-08-01","Aug 2025","A36","A36","A36-A36","0143005X","","","ENG","BackgroundEarly childhood disadvantages (up to age 5) can have life-long effects on health and wellbeing. Methods of birth cohort microsimulation can capture these long-term effects and the associated public cost savings, which are hard to estimate using conventional methods (e.g. trials) because the effects may take decades to manifest. We aimed to quantify the long-term effects and public costs of six different early years disadvantages up to age 17 in the UK and Bradford, a multi-ethnic deprived local authority, using a microsimulation model based on the UK Millennium Cohort Study.MethodsUsing a cohort of 15,380 children from the Millenium Cohort Study (MCS) we model early years risk factors (conception to age 5) and subsequent outcomes up to age 17. We choose six risk factors: having a teenage mother, preterm birth, low birthweight (for gestational age), low height (age 5); disability (age 5), and school readiness (age 5). The causal effect parameters used in our microsimulation model are estimated using regressions based on Directed Acyclic Graphs (DAGs) which clearly set out our causal inference assumptions. We quantify a set of policy-relevant outcomes and their annual public costs for the UK and calibrate to Bradford based on local prevalence and population data. We assess the robustness of our findings to alternative assumptions and measures.ResultsThe public cost up to age 17 ranged between £86,058 [44,114–128,002] per 1,000 children for having a teenage mother, or £58,544 for each annual Bradford cohort to £432,920 [263,733–600,108] for school readiness or £1,872,265 for each Bradford cohort. The wellbeing impact ranged from 21 [-37–78] WELLBYs per 1,000 children for low birth weight or 20 per Bradford cohort, to 268 [245–290] for school readiness or 1,160 per Bradford cohort. Each WELLBY is valued by the UK Treasury at £13,000.ConclusionImproving school readiness yielded a larger wellbeing gain and public cost savings per child beneficiary than eliminating any of the other disadvantages we examined, but less than reducing early childhood poverty by moving families from the bottom income quintile to the next. When combined with evidence on short term effects of interventions, comparative long-term estimates of this kind may help policymakers prioritise and justify early years investments.We will report full results for the Uk and Bradford at the meeting, including a ready reckoner table of the long-term benefits and costs of reducing each childhood disadvantage.","https://www.proquest.com/docview/3243664230?accountid=12870&bdid=124553&_bd=AjfQeHoS34s2kL9Nj7k5%2BkvXkfs%3D","https://doi.org/10.1136/jech-2025-SSMabstracts.73"
"Can climate change attention predict energy stock returns?","","JiaShanghui; Liu, Yingke; Jin, Jiayu","Environ Sci Pollut Res","Undefined","Springer Berlin Heidelberg","30","38 p.89253-89269","2023-08-01","Aug 2023","89253","89269","p. 89253-89269","1614-7499","1614-7499","","ENG","We propose a climate change attention (CCA) index based on Google search volume index (GSVI) from 2004 to 2021 and show that it is an economically and statistically significant negative predictor for next month’s energy stock returns. The index is extracted using principal component analysis (PCA), but the results are similar by using the equal-weighted average method. Compared with 14 traditional macroeconomic predictors, CCA performs the best and provides complementary information when added into bivariate and multivariate macro predictive models. When further considering the effect of CCA’s forecasting power over different periods, strong evidence is shown that this outperformance is especially prominent in economic depressions and down market conditions. From the asset allocation perspective, CCA can provide a mean-variance investor with significant economic gains under alternative risk aversions. Our empirical results prove that investors’ attention to climate change contains predictive information for excess returns of global traditional energy stock index.","https://www.proquest.com/docview/3153179478?accountid=12870&bdid=124553&_bd=xTZrOOCTP%2BxlPlv1H440njfm8so%3D","https://doi.org/10.1007/s11356-023-28731-2"
"Accounting-based probabilistic prediction of ROE, the residual income valuation model and the assessment of mispricing in the Swedish stock market","","Skogsvik, Kenth; Skogsvik, Stina","Abacus","Undefined","","46","4","2010-12-01","Dec 2010","387","418","387-418","0001-3072","0001-3072","","ENG","Using Swedish stock market data, this study investigates whether an investment strategy based on publicly available accounting information can generate abnormal investment returns. The strategy involves two steps. First, an accounting-based probabilistic prediction model of changes in the medium-term book return on owners' equity (ROE) is estimated. Second, market expectations of changes in medium-term ROE are assessed through observed stock prices and the residual income valuation model. Stock market positions over thirty-six-month holding periods are taken when the accounting-based predictions of ROE and the market expectations differ. Over the period 1983-2003, the investment strategy generated values of Jensen's alpha corresponding to an average monthly excess return for a hedge position of up to 0.8% for a sample of manufacturing companies. In the main this hedge return was caused by strong positive returns to the long positions, and additional analyses show that the returns appear to have been affected by a positive market sentiment bias (i.e. positive ROE surprises being associated with stronger price reactions than negative ROE surprises) making out-of-sample inferences somewhat dubious. Furthermore, most of the investment returns accrued over holding periods up to around 1995, with no indications of market mispricing over the last third (1995-2003) of the investment period. The empirical results are consistent with market investors having become more sophisticated in their use of publicly available accounting information over time. Reprinted by permission of Blackwell Publishers","https://www.proquest.com/docview/916507975?accountid=12870&bdid=124553&_bd=YLivBXzI1STREUOhCwFfuJ1uA20%3D","https://doi.org/10.1111/j.1467-6281.2010.00325.x"
"Investor attention and cryptocurrency: Evidence from the Bitcoin market","","Zhu, Panpan; Zhang, Xing; Wu, You; Zheng, Hao; Zhang, Yinpeng","PLoS One","Scholarly Journals","","16","2","2021-02-01","Feb 2021","e0246331","","","19326203","","","ENG","[...]investor attention had been applied in traditional financial markets, i.e., stock market and FX market, and proved to be an influential factor in certain markets.The empirical results may shed lights on investors in Bitcoin market to focus more on the variations in behavioral variable; Second, existing studies mainly focused on the linear connections between Bitcoin market and investor attention, failing to comprehensively explore the non-linear connections between the two.[...]current research may be incomplete in explaining the relationships between investor attention and Bitcoin market.The results for out-of-sample predictions further illustrate the importance of investor attention in Bitcoin market and will surely guide the investors to forecast the Bitcoin return with the investor attention.[...]the empirical results add evidence on the in-sample and out-of-sample analysis; Fourth, based on the empirical results of out-of-sample predictions for Bitcoin return, we construct several simple portfolios including Bitcoin asset and risk-free asset to further explore the usefulness of investor attention in Bitcoin portfolio management based on the framework of asset allocation.[...]Neves [42] suggested that investment attractiveness had a prominent role in Bitcoin price formation, while other researchers [3, 34, 43, 44] argued the stock market, exchange rate, gold, oil, Economic Policy Uncertainty (EPU), and the Geopolitical Risk Index, etc.","https://www.proquest.com/docview/2484876872?accountid=12870&bdid=124553&_bd=GqcGnCkWJXvbgiVyPb0DnDgczSg%3D","https://doi.org/10.1371/journal.pone.0246331"
"A stock selection algorithm hybridizing grey wolf optimizer and support vector regression","","Liu, Meng; Luo, Kaiping; Zhang, Junhuan; Chen, Shengli","Expert Systems with Applications","Scholarly Journals","","179","","2021-10-01","Oct 1, 2021","1","","","0957-4174","","","ENG","Artificial intelligence remarkably facilitates quantitative investment. A latest intelligent search algorithm, grey wolf optimizer, is well integrated with support vector regression machine to obtain the optimal portfolio. The performance of the hybrid algorithm is empirically investigated through transactional and financial data from stock markets of America and China. The experimental results indicate that (i) the proposed algorithm is able to stably achieve excess returns; (ii) compared with genetic algorithm, particle swarm optimization, gravitational search algorithm and harmony search, the enhanced grey wolf optimizer significantly boots the predictive performance of support vector regression machine; (iii) the proposed algorithm can achieve the better profitability and the higher reliability in Chinese A-share market.","https://www.proquest.com/docview/2550536255?accountid=12870&bdid=124553&_bd=s7xneNs6Ps3bfcMBaxNYMAWhb7M%3D","https://doi.org/10.1016/j.eswa.2021.115078"
"Comparison of the Short Term Interest Rate Models: Parametric versus Non parametric Approach","","Mouna Ben Salah","Journal of Finance and Investment Analysis","Scholarly Journals","","4","2","2015-01-01","2015","n/a","","","22410988","","","ENG","This article attempts to identify the best features the short term interest rates stochastic process. We studied nine different linear models of short term interest rates. The choice of these models was the aim of analyzing the relevance of certain specifications of the short term interest rate stochastic process, the effect of mean reversion and the sensitivity of the volatility to the level of interest rate. We studied also the relevance of the Ait-Sahalia (1996b) nonlinear interest rate model. To further study the accurate parametric specification of the interest rate stochastic process we used a nonparametric estimation of the drift and the diffusion functions.The yield on three months treasury bills is used as a proxy for the short term interest rates. The parameters of the different linear stochastic process are estimated using the generalized method of moments. A semi parametric approach is used to estimate the non linear Ait Sahalia model (1996b). The kernel regression is used as a nonparametric approach to estimate the interest rate process. The results show that the effect of mean reversion is not statistically significant and that volatility is highly sensitive to the level of interest rates. The results prove also that both the drift and the diffusion functions should be nonlinear and that the nonlinear specification proposed by Ait Sahalia (1996b) model is not accurate.","https://www.proquest.com/docview/2573396144?accountid=12870&bdid=124553&_bd=tKTYry7U3eBz53RxidIAPYgWVZI%3D",""
"Complexity, nonlinearity and high frequency financial data modeling: lessons from computational approaches","","Amman, Hans; Barnett, William A.; Jawadi, Fredj; Tucci, Marco","Annals of Operations Research","Scholarly Journals","","352","3","2025-09-01","Sep 2025","353","358","353-358","02545330","","","ENG","This editorial introduces the special issue Complexity, Nonlinearity and High Frequency Financial Data Modeling: Lessons from Computational Approaches in Annals of Operations Research, which brings together 19 contributions exploring advanced methods and applications in the analysis of financial markets. The collected works reflect the growing importance of complexity and nonlinear dynamics in understanding modern financial systems, marked by high volatility, interdependence, and structural shifts. The papers are organized thematically into five main areas: (i) complexity and nonlinearity in financial markets, (ii) advanced forecasting and econometric modeling, (iii) network theory, causality, and information flows, (iv) banking, credit risk, and economic growth, and (v) continuous-time and structural model reviews. There is an additional section on methodological innovations, which include time–frequency and multi-scale analysis, recent developments of nonlinear and regime-switching models, machine learning, and complex network approaches. A heartfelt tribute is dedicated to the late Marco Tucci, co-editor of this special issue, whose vision and scholarly contributions significantly shaped its content. Sadly, Marco passed away while we were in the process of compiling this special issue. The editorial concludes by highlighting common methodological threads, synthesizing key insights, and outlining promising avenues for future research in complexity-informed financial modeling.","https://www.proquest.com/docview/3253503199?accountid=12870&bdid=124553&_bd=qaaMr3v3%2Fuqt1WAMPWNTUZ0m8FY%3D","https://doi.org/10.1007/s10479-025-06809-z"
"Predicting Regional Recessions Via the Yield Spread","","Gauger, Jean; Schunk, Don","The Review of Regional Studies","Scholarly Journals","","32","2","2002-01-01","2002","151","","151-170","15530892","","","ENG","This paper examines the ability of the slope of the yield curve to serve as a predictor of regional recessions. The ability of interest rate spreads to predict recessions has received considerable attention at the aggregate level. This paper offers evidence on the usefulness of rate spreads in predicting economic downturns at the regional level. The evidence points to regional differences in the ability of the U.S. yield curve to predict regional recessions. These differences are highlighted in the context of differing regional economic structures.","https://www.proquest.com/docview/1690846083?accountid=12870&bdid=124553&_bd=OGpKnCS3kkOU4S6WH9AtR7%2F4DgI%3D",""
"Health and Quality Risk Assessment of Bottled Water","","Birzul, A N; Pitilyak, D A; Videnin, I I","IOP Conference Series. Earth and Environmental Science","Scholarly Journals","","272","2","2019-06-01","Jun 2019","","","","17551307","","","ENG","The risk and quality assessment paper is dedicated to estimation of impact (for human health) of bottled drinking-water package (especially PET one). The investigation is concentrated on using one integral method for different risk types (factors connected with potential carcinogenicity: concentrations of antimony, formaldehyde, diethylhexylphthalate; and organoleptic factors: turbidity, colour, and pH). We imply the nature of organoleptic (quality assessment) factors close to risk ones because their indirect influence on polluting power of chemicals can be amplifying. The acceptable risk levels for these types are fixed as 10-1 and 10-5 respectively. The research is based on Russian and International (principally, American) scientific researches and standards. The calculation of risk metric is proposed to be estimated in dimensionless number (hazard quotient – HQ). HQ can be transformed in probabilistic numbers in conversion to events per million (Risk Index – RI and risk of olfactory-reflectory impact factors, Integral Index of Water Risk). In the article we used the idea of “chronic daily intake” (CDI) as an acceptable risk-free measure of factors of potential carcinogenicity, which is an adequate evaluation of permissible concentration. 5 brands of Russian bottled water were analyzed, it turned out that one of them had an exceeded acceptable level of risk.","https://www.proquest.com/docview/2557750766?accountid=12870&bdid=124553&_bd=ex%2BPvEnF2cfG4PV2zjlGo8xtOvc%3D","https://doi.org/10.1088/1755-1315/272/2/022142"
"Price Forecast of Treasury Bond Market Yield: Optimize Method Based on Deep Learning Model","","Weiying Ping; Hu, Yuwen; Luo, Liangqing","IEEE Access","Scholarly Journals","","12","","2024-01-01","2024","194521","","194521-194539","21693536","","","ENG","Accurate forecasting of the treasury bond market is beneficial for financial institutions to formulate investment research strategies and for national managers to build a modern financial system. This paper integrates the ideas of improved multivariate time series sampling and deep learning prediction model structure optimization, and proposes an optimized deep learning model framework under the LASSO-SMLR-PCA machine learning method. Through the LASSO and SMLR methods, the multicollinearity of the multivariate time series is reduced and the variables with insignificant correlation coefficients are eliminated. Then, the PCA method is used for dimensionality reduction and reconstruction, and finally, the LSTM deep learning model with Bayesian optimized hyperparameters is used to achieve rolling time prediction of the treasury bond market yield price. The empirical results show that the optimized deep learning model performs excellently in terms of evaluation indicators for treasury bond yield price forecasting, with accurate curve fitting, efficient model structure, and stable and effective practical application.","https://www.proquest.com/docview/3149573678?accountid=12870&bdid=124553&_bd=NUyn%2F%2FCZU1HW0yRPLY5DP4AGn4Q%3D","https://doi.org/10.1109/ACCESS.2024.3519438"
"Can the Sharia-based Islamic Stock Market returns be forecasted using large number of predictors and models?","","Gupta, Rangan; Hammoudeh, Shawkat; Simo-Kengne, Beatrice D; Sarafrazi, Soodabeh","Applied financial economics","Undefined","","24","17","2014-09-01","Sep 2014","1147","1157","1147-1157","0960-3107","0960-3107","","ENG","This study employs 14 global economic and financial variables to predict the return of the Islamic stock market as identified by the Dow Jones Islamic Stock Market (DJIM). It implements alternative forecasting methods and allows for nonlinearity in the multivariate predictive regressions by estimating time-varying parameter models. All the methods fail to forecast the returns of the Sharia-based DJIM index over the out- of-sample period. The forecasts are weak at best, with only four predictors, the 3-month Treasury bill rate, inflation, oil price and return on the SandP500 Index, outperforming the benchmark autoregressive model of order one. The study suggests that the DJIM return is best predicted by an autocorrelation(1) model, and that future research should aim at analysing whether the performance of the linear autoregressive model can be improved by using nonlinear methods. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/1548778903?accountid=12870&bdid=124553&_bd=ECmmMO4Wv9h2HWiVSg51NE4kuqs%3D","https://doi.org/10.1080/09603107.2014.924296"
"Mortgage Selection Using a Decision Tree Approach","","Luna, Robert E; Reid, Richard A","Interfaces","Scholarly Journals","","16","3","1986-05-01","May-Jun 1986","73","","73","00922102","","","ENG","When people choose between mortgage alternatives, a major issue to be considered concerns the present and future interest rates.  The current interest rate is used to attract the borrower, but the evaluation of an adjustable rate mortgage (ARM) requires an estimate of future interest rates as well.  To aid in this analysis, a decision tree model was developed.  Initially, a forecast of the range over which future interest rates could vary was determined by examining the interest rates on 3- and 5-year Treasury bills for the past 30 years.  After the decision tree was constructed, 4 decision criteria were used to help assess the economic consequences of various mortgage alternatives: 1.  minimax, a conservative orientation toward the future, 2.  minimin, an optimistic attitude regarding future events, 3.  minimizing the maximum regret, and 4.  minimization of expected mortgage costs, which uses probabilities concerning future rates.","https://www.proquest.com/docview/217117584?accountid=12870&bdid=124553&_bd=fl8%2FOKX78CezDzpf74cFgXZH%2FtA%3D",""
"The Informational Content of the Term Spread in Forecasting the US Inflation Rate: A Nonlinear Approach","","Plakandaras, Vasilios; Gogas, Periklis; Papadimitriou, Theophilos; Gupta, Rangan","Journal of Forecasting","Scholarly Journals","","36","2","2017-03-01","Mar 2017","109","","109-121","02776693","","","ENG","The difficulty in modelling inflation and the significance in discovering the underlying data-generating process of inflation is expressed in an extensive literature regarding inflation forecasting. In this paper we evaluate nonlinear machine learning and econometric methodologies in forecasting US inflation based on autoregressive and structural models of the term structure. We employ two nonlinear methodologies: the econometric least absolute shrinkage and selection operator (LASSO) and the machine-learning support vector regression (SVR) method. The SVR has never been used before in inflation forecasting considering the term spread as a regressor. In doing so, we use a long monthly dataset spanning the period 1871:1-2015:3 that covers the entire history of inflation in the US economy. For comparison purposes we also use ordinary least squares regression models as a benchmark. In order to evaluate the contribution of the term spread in inflation forecasting in different time periods, we measure the out-of-sample forecasting performance of all models using rolling window regressions. Considering various forecasting horizons, the empirical evidence suggests that the structural models do not outperform the autoregressive ones, regardless of the model's method. Thus we conclude that the term spread models are not more accurate than autoregressive models in inflation forecasting. Copyright © 2016 John Wiley & Sons, Ltd.","https://www.proquest.com/docview/1865973582?accountid=12870&bdid=124553&_bd=kXWPqjvGaXCz3d2pMZB2PSsqCrg%3D","https://doi.org/10.1002/for.2417"
"Are bond returns predictable with real-time macro data?","","Huang, Dashan; Jiang, Fuwei; Li, Kunpeng; Tong, Guoshi; Zhou, Guofu","Journal of Econometrics","Undefined","Elsevier B.V.","237","2 p.105438-","2023-12-01","Dec 2023","","","","0304-4076","0304-4076","","ENG","We investigate the predictability of bond returns using real-time macro variables and consider the possibility of a nonlinear predictive relationship and the presence of weak factors. To address these issues, we propose a scaled sufficient forecasting (sSUFF) method and analyze its asymptotic properties. Using both the existing and the new method, we find empirically that real-time macro variables have significant forecasting power both in-sample and out-of-sample. Moreover, they generate sizable economic values, and their predictability is not spanned by the yield curve. We also observe that the forecasted bond returns are countercyclical, and the magnitude of predictability is stronger during economic recessions, which lends empirical support to well-known macro finance theories.","https://www.proquest.com/docview/2834220355?accountid=12870&bdid=124553&_bd=%2B6ZkXwq0%2FBpRe7PBmW2Zvuiv%2Bm0%3D","https://doi.org/10.1016/j.jeconom.2022.09.008"
"Multi-Country and Multi-Horizon GDP Forecasting Using Temporal Fusion Transformers","","Laborda, Juan; Laborda, Juan; Ruano, Sonia; Zamanillo, Ignacio","Mathematics","Scholarly Journals","","11","12","2023-01-01","2023","2625","","","22277390","","","ENG","This paper applies a new artificial intelligence architecture, the temporal fusion transformer (TFT), for the joint GDP forecasting of 25 OECD countries at different time horizons. This new attention-based architecture offers significant advantages over other deep learning methods. First, results are interpretable since the impact of each explanatory variable on each forecast can be calculated. Second, it allows for visualizing persistent temporal patterns and identifying significant events and different regimes. Third, it provides quantile regressions and permits training the model on multiple time series from different distributions. Results suggest that TFTs outperform regression models, especially in periods of turbulence such as the COVID-19 shock. Interesting economic interpretations are obtained depending on whether the country has domestic demand-led or export-led growth. In essence, TFT is revealed as a new tool that artificial intelligence provides to economists and policy makers, with enormous prospects for the future.","https://www.proquest.com/docview/2829843057?accountid=12870&bdid=124553&_bd=2aT45mfRPKico6HZyzLKkbIdiwg%3D","https://doi.org/10.3390/math11122625"
"Exploring the role of artificial intelligence in orthopedic medical education: A narrative review","","Das, Lakshmana S; Das, Deepanjan; Chandrakar, Denish; Bhavani, Prashant; Dubepuria, Amol; Barik, Sitanshu","Journal of clinical orthopaedics and trauma","Undefined","","69","","2025-10-01","Oct 2025","103100","","103100","0976-5662","0976-5662","","ENG","Artificial intelligence (AI) is transforming orthopedic medical education by enhancing diagnostic accuracy, surgical training, and personalized learning. This narrative review explores AI's applications, including machine learning (ML) and computer vision for interpreting imaging studies, virtual reality (VR) and augmented reality (AR) for immersive surgical simulations, and natural language processing (NLP) for streamlining clinical workflows. AI-powered tools offer objective feedback, adaptive learning modules, and risk-free environments for skill acquisition, bridging gaps in traditional training methods. However, challenges such as data privacy, algorithmic bias, and the need for robust validation remain. Ethical considerations, including patient trust and trainee over-reliance on AI, must also be addressed. Despite these barriers, AI democratizes access to high-quality education, particularly in resource-limited settings, through cloud-based platforms and mobile applications. The future of AI in orthopedics is promising, with advancements in predictive analytics, robotic-assisted surgery, and haptic feedback technologies poised to further revolutionize training. Collaborative efforts among educators, clinicians, and developers are essential to ensure responsible integration. This review highlights AI's potential to reshape orthopedic education while emphasizing the importance of preserving the mentor-trainee relationship and fostering evidence-based adoption.Artificial intelligence (AI) is transforming orthopedic medical education by enhancing diagnostic accuracy, surgical training, and personalized learning. This narrative review explores AI's applications, including machine learning (ML) and computer vision for interpreting imaging studies, virtual reality (VR) and augmented reality (AR) for immersive surgical simulations, and natural language processing (NLP) for streamlining clinical workflows. AI-powered tools offer objective feedback, adaptive learning modules, and risk-free environments for skill acquisition, bridging gaps in traditional training methods. However, challenges such as data privacy, algorithmic bias, and the need for robust validation remain. Ethical considerations, including patient trust and trainee over-reliance on AI, must also be addressed. Despite these barriers, AI democratizes access to high-quality education, particularly in resource-limited settings, through cloud-based platforms and mobile applications. The future of AI in orthopedics is promising, with advancements in predictive analytics, robotic-assisted surgery, and haptic feedback technologies poised to further revolutionize training. Collaborative efforts among educators, clinicians, and developers are essential to ensure responsible integration. This review highlights AI's potential to reshape orthopedic education while emphasizing the importance of preserving the mentor-trainee relationship and fostering evidence-based adoption.","https://www.proquest.com/docview/3227637315?accountid=12870&bdid=124553&_bd=FUNDu0%2BypgLb%2BOG4WXe2lDLw%2BnA%3D","https://doi.org/10.1016/j.jcot.2025.103100"
"SF-Transformer: A Mutual Information-Enhanced Transformer Model with Spot-Forward Parity for Forecasting Long-Term Chinese Stock Index Futures Prices","","Mao, Weifang; Liu, Pin; Huang, Jixian; Huang, Jixian","Entropy","Scholarly Journals","","26","6","2024-01-01","2024","478","","","10994300","","","ENG","The complexity in stock index futures markets, influenced by the intricate interplay of human behavior, is characterized as nonlinearity and dynamism, contributing to significant uncertainty in long-term price forecasting. While machine learning models have demonstrated their efficacy in stock price forecasting, they rely solely on historical price data, which, given the inherent volatility and dynamic nature of financial markets, are insufficient to address the complexity and uncertainty in long-term forecasting due to the limited connection between historical and forecasting prices. This paper introduces a pioneering approach that integrates financial theory with advanced deep learning methods to enhance predictive accuracy and risk management in China’s stock index futures market. The SF-Transformer model, combining spot-forward parity and the Transformer model, is proposed to improve forecasting accuracy across short and long-term horizons. Formulated upon the arbitrage-free futures pricing model, the spot-forward parity model offers variables such as stock index price, risk-free rate, and stock index dividend yield for forecasting. Our insight is that the mutual information generated by these variables has the potential to significantly reduce uncertainty in long-term forecasting. A case study on predicting major stock index futures prices in China demonstrates the superiority of the SF-Transformer model over models based on LSTM, MLP, and the stock index futures arbitrage-free pricing model, covering both short and long-term forecasting up to 28 days. Unlike existing machine learning models, the Transformer processes entire time series concurrently, leveraging its attention mechanism to discern intricate dependencies and capture long-range relationships, thereby offering a holistic understanding of time series data. An enhancement of mutual information is observed after introducing spot-forward parity in the forecasting. The variation of mutual information and ablation study results highlights the significant contributions of spot-forward parity, particularly to the long-term forecasting. Overall, these findings highlight the SF-Transformer model’s efficacy in leveraging spot-forward parity for reducing uncertainty and advancing robust and comprehensive approaches in long-term stock index futures price forecasting.","https://www.proquest.com/docview/3072320690?accountid=12870&bdid=124553&_bd=vStvXeyXx5ozTeGzYcL3ob4bmUM%3D","https://doi.org/10.3390/e26060478"
"TURNING POINT VS TREND","","Ryaboshlyk, Volodymyr","Journal of International Studies","Scholarly Journals","","4","1","2011-01-01","2011","n/a","","","20718330","","","ENG","At the beginning of the paper some shortcomings of the existing forecasting systems are demonstrated on examples of products of the EU forecasting service and of the Macroeconomic Prospect Team of the Treasury of the UK. And apart of it the smoothed lines of Nobel Prize winner of 2010 Professor Pissarides are considered in comparison with clear forecasts of turning points received by the author on the same time series. Then a description of forecasting of the recession of the early 1990s in the UK is given, as a part of forecasting of innovative growth. It is underlined that statistics must show explicitly ‘the height of technological leap’ and provide separate parameters of old and new technologies. And that the current focusing of attention on the most advanced technologies only should be broadened to all technologies which actually are being implementing in the economy. Comparison with the Cambridge Multisectoral Dynamic Model of the British Economy shows how peculiarities of reflection of new technologies could affect ability of seeing turning points. At the end some remarks are contributed to the current discussion between the competing schools. Positive aspects of the “Great Recession” of 2008 – 2010 are highlighted along with their similarity with previous crises. At that an attempt to restore the “shattered intellectual structure” of Alan Greenspan is made.","https://www.proquest.com/docview/2363766806?accountid=12870&bdid=124553&_bd=eyZr5ilJMkOjJ1UgFIGOJravTE0%3D",""
"Interest-Rate Volatility, Basis Risk and Heteroscedasticity in Hedging Mortgages","","Park, Hun Y; Bera, Anil K","AREUEA Journal","Scholarly Journals","","15","2","1987-07-01","Summer 1987","79","","79","02700484","","","ENG","Investigation is made of the validity of the ordinary least squares regression to estimate the hedge ratio for Government National Mortgage Association (GNMA) mortgages, and alternative methodologies are provided.  In particular, consideration is given to the variance structure (conditional and unconditional heteroscedasticities) and the misspecification (nonlinearities) of the simple linear regression model for direct as well as cross-hedging.  Employing data on spot prices of GNMA and futures prices of GNMAs and US Treasury bills for the period September 1979 to January 1985, it is demonstrated that there exists significant heteroscedasticity particularly for cross-hedging, and nonlinearity between cash and futures prices for direct as well as cross-hedging.  Alternative hedge ratio estimates are given using the Box-Cox transformation model and an autoregressive conditional heteroscedastic (ARCH) model.  Further research should be directed at combining the ARCH and nonlinear models to combine heteroscedasticity and nonlinearity in estimating hedge ratios.","https://www.proquest.com/docview/211162331?accountid=12870&bdid=124553&_bd=qba0cDz565Mm5b2RJYAmzs6%2F7JA%3D",""
"Can investor attention predict oil prices?","","Han, Liyan; Lv, Qiuna; Yin, Libo","Energy Economics","Scholarly Journals","","66","","2017-08-01","Aug 2017","547","","","01409883","","","ENG","This paper sets out to investigate the predictive power of investor attention onto oil prices. We firstly construct investor attention index by using the Google search volume index (SVI) based on a broad set of words related to oil-related variables and terms that are directly linked to real economy to measure investor attention. Then the empirical work is performed via a novel hybrid approach and WN model (Westerlund and Narayan, 2012, 2014) that account for characteristics of persistency, endogeneity, and heteroskedasticity. The empirical results show that investor attention does exhibit statistically and economically significant in-sample and out-of-sample forecasting power to directly forecast oil prices for both daily data and weekly data. In addition, the results exhibit the term structure character, which are helpful for understanding the financial phenomena that irrational attentions have more effect in short-term decision-making.","https://www.proquest.com/docview/1963430985?accountid=12870&bdid=124553&_bd=p1OcIZIboNiIuP8L%2FA54nzFK260%3D",""
"Multiplicative parameters and estimators: applications in economics and finance","","Jasiulewicz, Helena; Kordecki, Wojciech","Annals of Operations Research","Scholarly Journals","","238","1-2","2016-03-01","Mar 2016","299","","299-313","02545330","","","ENG","In this paper, we pay our attention to multiplicative parameters of random variables and their estimators. We study multiplicative properties of the multiplicative expectation and multiplicative variation as well as their estimators. For distributions having applications in finance and insurance we provide their multiplicative parameters and their properties. We consider, among others, heavy-tailed distributions such as lognormal and Pareto distributions, applied to the modelling of large losses. We discuss multiplicative models, in which the geometric mean and the geometric standard deviation are more natural than their arithmetic counterparts. We provide two examples from the Warsaw Stock Exchange in 1995-2009 and from a bid of 52-week treasury bills in 1992-2009 in Poland as an illustrative example.","https://www.proquest.com/docview/1771108572?accountid=12870&bdid=124553&_bd=MjIsVvwVxFPnEI51DeSfCIL07J8%3D","https://doi.org/10.1007/s10479-015-2035-x"
"Climate, race, and the cost of capital in the municipal bond market","","Smull, Erika; Kodra, Evan; Stern, Adam; Teras, Andrew; Bonanno, Michael; Doyle, Martin","PloS one","Undefined","","18","8","2023-01-01","Jan 2023","e0288979","","e0288979","1932-6203","","","ENG","Both climate risk and race are factors that may affect municipal bond yields, yet each has received relatively limited empirical research attention. We analyzed > 712,000 municipal bonds representing nearly 2 trillion USD in par outstanding, focusing on credit spread or the difference between a debt issuer's interest cost to borrow and a benchmark ""risk-free"" municipal rate. The relationship between credit spread and physical climate risk is significant and slightly positive, yet the coefficient indicates no meaningful spread penalty for increased physical climate risk. We also find that racial composition (the percent of a community that is Black) explains a statistically significant and meaningful portion of municipal credit spreads, even after controlling for a variety of variables in domains such as geographic location of issuer, bond structure (e.g., bond maturity), credit rating, and non-race economic variables (e.g., per capita income). Assuming 4 trillion USD in annual outstanding par across the entire municipal market, and weighting each issuer by its percent Black, an estimated 19 basis point (bp) penalty for Black Americans sums to approximately 900 million USD annually in aggregate. Our combined findings indicate a systemic mispricing of risk in the municipal bond market, where race impacts the cost of capital, and climate does not.Both climate risk and race are factors that may affect municipal bond yields, yet each has received relatively limited empirical research attention. We analyzed > 712,000 municipal bonds representing nearly 2 trillion USD in par outstanding, focusing on credit spread or the difference between a debt issuer's interest cost to borrow and a benchmark ""risk-free"" municipal rate. The relationship between credit spread and physical climate risk is significant and slightly positive, yet the coefficient indicates no meaningful spread penalty for increased physical climate risk. We also find that racial composition (the percent of a community that is Black) explains a statistically significant and meaningful portion of municipal credit spreads, even after controlling for a variety of variables in domains such as geographic location of issuer, bond structure (e.g., bond maturity), credit rating, and non-race economic variables (e.g., per capita income). Assuming 4 trillion USD in annual outstanding par across the entire municipal market, and weighting each issuer by its percent Black, an estimated 19 basis point (bp) penalty for Black Americans sums to approximately 900 million USD annually in aggregate. Our combined findings indicate a systemic mispricing of risk in the municipal bond market, where race impacts the cost of capital, and climate does not.","https://www.proquest.com/docview/2848842881?accountid=12870&bdid=124553&_bd=Lu2NHu0Mq1PuqQCJnOsn2bg%2F8ns%3D","https://doi.org/10.1371/journal.pone.0288979"
"Nonlinear mean reversion in stock prices","","Bali, Turan G; Demirtas, K O; Levy, H","Journal of banking and finance","Undefined","","32","5","2008-05-01","May 2008","767","782","767-782","0378-4266","0378-4266","","ENG","This paper provides new evidence on the time-series predictability of stock market returns by introducing a test of nonlinear mean reversion. The performance of extreme daily returns is evaluated in terms of their power to predict short- and long-horizon returns on various stock market indices and size portfolios. The paper shows that the speed of mean reversion is significantly higher during the large falls of the market. The parameter estimates indicate a negative and significant relation between the monthly portfolio returns and the extreme daily returns observed over the past one to eight months. Specifically, in a quarter in which the minimum daily return is -2% the expected excess return is 37 basis points higher than in a month in which the minimum return is only -1%. This result holds for the value-weighted and equal-weighted stock market indices and for each of the size decile portfolios. The findings are also robust to different sample periods, different indices, and investment horizons. All rights reserved, Elsevier","https://www.proquest.com/docview/36860006?accountid=12870&bdid=124553&_bd=7%2B6H%2BTfC97aGxOKS3A7r4Xt0bLM%3D","https://doi.org/10.1016/j.jbankfin.2007.05.013"
"Forecasting Chinese Stock Market Volatility With Volatilities in Bond Markets","","Likun Lei; He, Mengxi; Zhang, Yi; Zhang, Yaojie","Journal of Forecasting","Scholarly Journals","","44","2","2025-03-01","Mar 2025","547","555","547-555","02776693","","","ENG","In this paper, we investigate whether the bond markets contain important information that can improve the accuracy of stock market volatility forecasts in China. We use realized volatility (RV) implemented by different maturity treasury bond futures contracts to predict the Chinese stock market volatility. Our work is based on the heterogeneous autoregressive (HAR) framework. Empirical results show that the volatility of treasury bond contracts with longer maturities (especially 10 years) has the best effect on predicting the Chinese stock market volatility, both in sample and out of sample. Two machine learning methods, the scaled principal component analysis (SPCA) and the least absolute shrinkage and selection operator (lasso), are also more effective than the HAR benchmark model's prediction. Finally, mean–variance investors can achieve substantial economic gains by allocating their investment portfolios based on volatility forecasts after introducing treasury bond futures volatility.","https://www.proquest.com/docview/3163284294?accountid=12870&bdid=124553&_bd=q43FN8hx52rWsZ5FzV89gvix8iM%3D","https://doi.org/10.1002/for.3215"
"Forecasting stock market returns with a lottery index: Evidence from China","","Zhang, Yaojie; Han, Qingxiang; He, Mengxi","Journal of Forecasting","Scholarly Journals","","43","5","2024-08-01","Aug 2024","1595","1606","1595-1606","02776693","","","ENG","This study constructs a Chinese lottery index (LI) based on six popular lottery preference variables by using the partial least squares method and examines the relationship between the LI and future stock market returns during the period from January 2000 to December 2021. We find that the LI can negatively predict stock market excess returns in‐sample and out‐of‐sample. In addition, the LI can generate a large economic gain for a mean–variance investor. Finally, the predictive sources of the LI stem from a cash flow channel and can be explained by the positive volume–volatility relationship and investor attention.","https://www.proquest.com/docview/3074207209?accountid=12870&bdid=124553&_bd=JGLr7r4UbMKp%2FrG6g6I1tw5ktY0%3D","https://doi.org/10.1002/for.3100"
"The COVID-19 pandemic and Bitcoin: Perspective from investor attention","","Wan, Jieru; Wu, You; Zhu, Panpan","Frontiers in public health","Undefined","","11","","2023-01-01","Jan 2023","1147838","","1147838","2296-2565","","","ENG","The response of the Bitcoin market to the novel coronavirus (COVID-19) pandemic is an example of how a global public health crisis can cause drastic market adjustments or even a market crash. Investor attention on the COVID-19 pandemic is likely to play an important role in this response. Focusing on the Bitcoin futures market, this paper aims to investigate whether pandemic attention can explain and forecast the returns and volatility of Bitcoin futures. Using the daily Google search volume index for the ""coronavirus"" keyword from January 2020 to February 2022 to represent pandemic attention, this paper implements the Granger causality test, Vector Autoregression (VAR) analysis, and several linear effects analyses. The findings suggest that pandemic attention is a granger cause of Bitcoin returns and volatility. It appears that an increase in pandemic attention results in lower returns and excessive volatility in the Bitcoin futures market, even after taking into account the interactive effects and the influence of controlling other financial markets. In addition, this paper carries out the out-of-sample forecasts and finds that the predictive models with pandemic attention do improve the out-of-sample forecast performance, which is enhanced in the prediction of Bitcoin returns while diminished in the prediction of Bitcoin volatility as the forecast horizon is extended. Finally, the predictive models including pandemic attention can generate significant economic benefits by constructing portfolios among Bitcoin futures and risk-free assets. All the results demonstrate that pandemic attention plays an important and non-negligible role in the Bitcoin futures market. This paper can provide enlightens for subsequent research on Bitcoin based on investor attention sparked by public emergencies.The response of the Bitcoin market to the novel coronavirus (COVID-19) pandemic is an example of how a global public health crisis can cause drastic market adjustments or even a market crash. Investor attention on the COVID-19 pandemic is likely to play an important role in this response. Focusing on the Bitcoin futures market, this paper aims to investigate whether pandemic attention can explain and forecast the returns and volatility of Bitcoin futures. Using the daily Google search volume index for the ""coronavirus"" keyword from January 2020 to February 2022 to represent pandemic attention, this paper implements the Granger causality test, Vector Autoregression (VAR) analysis, and several linear effects analyses. The findings suggest that pandemic attention is a granger cause of Bitcoin returns and volatility. It appears that an increase in pandemic attention results in lower returns and excessive volatility in the Bitcoin futures market, even after taking into account the interactive effects and the influence of controlling other financial markets. In addition, this paper carries out the out-of-sample forecasts and finds that the predictive models with pandemic attention do improve the out-of-sample forecast performance, which is enhanced in the prediction of Bitcoin returns while diminished in the prediction of Bitcoin volatility as the forecast horizon is extended. Finally, the predictive models including pandemic attention can generate significant economic benefits by constructing portfolios among Bitcoin futures and risk-free assets. All the results demonstrate that pandemic attention plays an important and non-negligible role in the Bitcoin futures market. This paper can provide enlightens for subsequent research on Bitcoin based on investor attention sparked by public emergencies.","https://www.proquest.com/docview/2808213768?accountid=12870&bdid=124553&_bd=B8K%2FUBGV31KnBd9DzZJO0E84eG0%3D","https://doi.org/10.3389/fpubh.2023.1147838"
"An empirical investigation into the impact of US federal government budget deficits on the real interest rate yield on intermediate-term treasury issues, 1972-2012","","Cebula, Richard J","Applied economics","Undefined","","46","28","2014-10-01","Oct 2014","3483","3493","3483-3493","0003-6846","0003-6846","","ENG","This study provides new empirical evidence on the impact of the federal budget deficit on the real interest rate yields on intermediate-term debt issues of the US Treasury, represented herein by the ex post real interest rate yields on 3-year Treasury notes and 7-year Treasury notes, two interest rate measures that have received essentially no attention in the economics and finance literature in recent years. This study is couched within a loanable funds model that includes two ex post real interest rate yields, the monetary base as a per cent of GDP, the change in per capita real GDP, net financial capital inflows as a per cent of GDP and the budget deficit as a per cent of GDP. This study uses annual data for the study period 1972 to 2012, a time period that includes 'quantitative easing' monetary policies by the Federal Reserve. Two-stage least squares estimations reveal that the federal budget deficit, expressed as a per cent of GDP, exercised a positive and statistically significant impact on the ex post real interest rate yields on both 3-year and 7-year Treasury notes, even after allowing for quantitative easing and other factors. The study also considers the time period 1980 to 2012 and offers simple robustness testing. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/1552593548?accountid=12870&bdid=124553&_bd=HB9Lsoh%2FSckHpkHjVL9fuoiwRNM%3D","https://doi.org/10.1080/00036846.2014.932050"
"Forecasting benchmarks of long-term stock returns via machine learning","","Kyriakou, Ioannis; Mousavi, Parastoo; Nielsen, Jens Perch; Scholz, Michael","Annals of Operations Research","Scholarly Journals","","","","2019-07-01","Jul 2019","1","20","1-20","02545330","","","ENG","Recent advances in pension product development seem to favour alternatives to the risk free asset often used in the financial theory as a performance standard for measuring the value generated by an investment or a reference point for determining the value of a financial instrument. To this end, in this paper, we apply the simplest machine learning technique, namely, a fully nonparametric smoother with the covariates and the smoothing parameter chosen by cross-validation to forecast stock returns in excess of different benchmarks, including the short-term interest rate, long-term interest rate, earnings-by-price ratio, and the inflation. We find that, net-of-inflation, the combined earnings-by-price and long-short rate spread form our best-performing two-dimensional set of predictors for future annual stock returns. This is a crucial conclusion for actuarial applications that aim to provide real-income forecasts for pensioners.","https://www.proquest.com/docview/2263018588?accountid=12870&bdid=124553&_bd=ZvAfDw%2F99Sv%2FXtGqeYTZr19sffI%3D","https://doi.org/10.1007/s10479-019-03338-4"
"A Rational Theory of Mutual Funds' Attention Allocation","","Kacperczyk, Marcin; Vannieuwerburgh, Stijn; Veldkamp, Laura","Econometrica","Undefined","","84","2","2016-03-01","March 2016","571","571","571","0012-9682","0012-9682","","ENG","The question of whether and how mutual fund managers provide valuable services for their clients motivates one of the largest literatures in finance. One candidate explanation is that funds process information about future asset values and use that information to invest in high-valued assets. But formal theories are scarce because information choice models with many assets are difficult to solve as well as difficult to test. This paper tackles both problems by developing a new attention allocation model that uses the state of the business cycle to predict information choices, which in turn, predict observable patterns of portfolio investments and returns. The predictions about fund portfolios' covariance with payoff shocks, cross-fund portfolio and return dispersion, and their excess returns are all supported by the data. These findings offer new evidence that some investment managers have skill and that attention is allocated rationally. Reprinted by permission of the Econometric Society","https://www.proquest.com/docview/1811846304?accountid=12870&bdid=124553&_bd=OpEw3BJTHXe14yMe5m9WJw6Dn%2BQ%3D",""
"Using Particle Swarm Optimization Algorithm to Calibrate the Term Structure Model","","Zhou, Yanli; Liu, Shican; Tian, Tianhai; He, Qi; Ge, Xiangyu","Mathematical Problems in Engineering","Scholarly Journals","","2021","","2021-01-01","2021","","","","1024-123X","1563-5147","","ENG","One of the advantages of stochastic differential equations (SDE) is that they can follow a variety of different trends so that they can establish complex dynamic systems in the economic and financial fields. Although some estimation methods have been proposed to identify the unknown parameters in virtue of the results in the SDE model to speed up the process, these solutions only focus on using explicit approach to solve SDEs, and therefore they are not reliable to deal with data source merged being large and varied. Thus, this study makes progress in creating a new implicit way to fill in the gaps of accurately calibrating the unknown parameters in the SDE model. Essentially, the primary goal of the article is to generate rigid SDE simulation. Meanwhile, the particle swarm optimization method serves a purpose to search and simultaneously obtain the optimal estimation of the model unknown parameters in the complicated experiment of parameter space in an effective way. Finally, in an interest rate term structure model, it is verified that the method effectively deals with parameter estimation in the SDE model.","https://www.proquest.com/docview/2478359650?accountid=12870&bdid=124553&_bd=GCIAYQMVYj4zWsKMcHkp2imlIqQ%3D","https://doi.org/10.1155/2021/8893940"
"Psychological Pathways to Fraud: Understanding and Preventing Fraud in Organizations","","Murphy, Pamela R; Dacin, M Tina","Journal of Business Ethics","Scholarly Journals","","101","4","2011-07-01","Jul 2011","601","","601-618","01674544","","","ENG","In response to calls for more research on how to prevent or detect fraud (ACAP, Final Report of the Advisory Committee on the Auditing Profession, United States Department of the Treasury, Washington, DC, 2008; AICPA, SAS No. 99: Consideration of Fraud in a Financial Statement Audit, New York, NY, 2002; Carcello et al., Working Paper, University of Tennessee, Bentley University and Kennesaw State University, 2008; Wells, Journal of Accountancy, 2004), we develop a framework that identifies three psychological pathways to fraud, supported by multiple theories relating to moral intuition and disengagement, rationalization, and the role played by negative affect. The purpose of developing the framework is twofold: (1) to draw attention to important yet under-researched aspects of ethical decision-making, and (2) to increase our understanding of the psychology of committing fraud. Our framework builds on the existing fraud triangle (PCAOB, Consideration of fraud in a financial statement audit. AU Section 316, www.pcaobus.org, 2005) which is used by auditors to assess fraud risk. The fraud triangle is composed of three factors that, together, predict the likelihood of fraud within an organization: opportunity, incentive/pressure, and attitude/rationalization. We find that, when faced with the opportunity and incentive/pressure, there are three psychological pathways to fraud nestled within attitude/rationalization: (1) lack of awareness, (2) intuition coupled with rationalization, and (3) reasoning. These distinctions are important for fraud prevention because each of these paths is driven by a different psychological mechanism. This framework is useful in a number of ways. First, it identifies certain insidious situational factors in which individuals commit fraud without recognizing it. Second, it extends our knowledge of rationalization by theorizing that individuals use rationalization to avoid or reduce the negative affect that accompanies performing an unethical behavior. Negative affect is important because individuals wish to avoid it. Third, it identifies several other methods fraudsters use to reduce negative affect, each of which could serve as potential ""psychological red flags"" and helps predict future fraudulent behavior. Finally, our framework can be used as a theoretical foundation to explore several interventions designed to prevent fraud.[PUBLICATION ABSTRACT]","https://www.proquest.com/docview/880966227?accountid=12870&bdid=124553&_bd=Hgji8zG8nFSq%2BadNfTowe4Z5Fvw%3D","https://doi.org/10.1007/s10551-011-0741-0"
"The October 2014 United States Treasury bond flash crash and the contributory effect of mini flash crashes","","Levine, Zachary S; Hale, Scott A; Floridi, Luciano","PLoS One","Scholarly Journals","","12","11","2017-11-01","Nov 2017","e0186688","","","19326203","","","ENG","We investigate the causal uncertainty surrounding the flash crash in the U.S. Treasury bond market on October 15, 2014, and the unresolved concern that no clear link has been identified between the start of the flash crash at 9:33 and the opening of the U.S. equity market at 9:30. We consider the contributory effect of mini flash crashes in equity markets, and find that the number of equity mini flash crashes in the three-minute window between market open and the Treasury Flash Crash was 2.6 times larger than the number experienced in any other three-minute window in the prior ten weekdays. We argue that (a) this statistically significant finding suggests that mini flash crashes in equity markets both predicted and contributed to the October 2014 U.S. Treasury Bond Flash Crash, and (b) mini-flash crashes are important phenomena with negative externalities that deserve much greater scholarly attention.","https://www.proquest.com/docview/1958633367?accountid=12870&bdid=124553&_bd=KEjICbwMYz8Dvm4Y%2FZSWtCLAcmk%3D","https://doi.org/10.1371/journal.pone.0186688"
"A Nonlinear Equilibrium Model of the Term Structure of Interest Rates","","Longstaff, Francis A","Journal of Financial Economics","Scholarly Journals","","23","2","1989-08-01","Aug 1989","195","","195","0304405X","","","ENG","An alternative closed-form general equilibrium model of the term structure within the Cox, Ingersoll, and Ross (1985) theoretical framework in which yields are nonlinear functions of the risk-free rate is derived and tested.  It is shown that equilibrium bond prices and the risk-free rate are not always inversely related and that bond risk need not be strictly increasing in maturity.  Hansen's generalized method of moments is used to obtain parameter estimates.  This nonlinear model outperforms the Cox, Ingersoll, and Ross square root model in describing actual Treasury-bill yields for the period between 1964 and 1986.  Theoretical and empirical results suggest that term structure models that allow yield nonlinearity can help explain the behavior of equilibrium interest rates.","https://www.proquest.com/docview/231766731?accountid=12870&bdid=124553&_bd=%2BBQag8dZS1GnHVD3d4jY1VdibMI%3D",""
"A genetic algorithm estimation of the term structure of interest rates","","Gimeno, Ricardo; Nave, Juan M","Computational Statistics & Data Analysis","Undefined","Elsevier B.V., P.O. Box 211 Amsterdam 1000 AE Netherlands","53","6","2009-04-15","Apr 15, 2009","2236","2250","2236-2250","0167-9473","0167-9473","","ENG","The term structure of interest rates is a key instrument for financial research. It provides relevant information for pricing deterministic financial cash flows, it measures economic market expectations and it is extremely useful when assessing the effectiveness of monetary policy decisions. However, it is not directly observable and needs to be estimated by smoothing asset pricing data through statistical techniques. The most popular techniques adjust parsimonious functional forms based on bond yields to maturity. Unfortunately, these functions, which need to be optimised, are highly non-linear which make them very sensitive to the initial conditions. In this context, this paper proposes the use of genetic algorithms to find the values for the initial conditions and to reduce the risk of false convergence, showing that stable parameters are obtained without imposing arbitrary restrictions.","https://www.proquest.com/docview/907963265?accountid=12870&bdid=124553&_bd=SCsk9nsvG9pTw7QiAD9WviIOHb4%3D","https://doi.org/10.1016/j.csda.2008.10.030"
"The impact of oil price shocks on Turkish sovereign yield curve","","Çepni, Oğuzhan; Gül, Selçuk; Yılmaz, Muhammed Hasan; Lucey, Brian","International Journal of Emerging Markets","Scholarly Journals","","17","9","2022-09-01","2022","2258","2277","2258-2277","17468809","","","ENG","Purpose>This paper aims to investigate the impact of oil price shocks on the Turkish sovereign yield curve factors.Design/methodology/approach>To extract the latent factors (level, slope and curvature) of the Turkish sovereign yield curve, we estimate conventional Nelson and Siegel (1987) model with nonlinear least squares. Then, we decompose oil price shocks into supply, demand and risk shocks using structural VAR (structural VAR) models. After this separation, we apply Engle (2002) dynamic conditional correlation GARCH (DCC-GARCH (1,1)) method to investigate time-varying co-movements between yield curve factors and oil price shocks. Finally, using the LP (local projections) proposed by Jorda (2005), we estimate the impulse-response functions to examine the impact of different oil price shocks on yield curve factors.Findings>Our results demonstrate that the various oil price shocks influence the yield curve factors quite differently. A supply shock leads to a statistically significant increase in the level factor. This result shows that elevated oil prices due to supply disruptions are interpreted as a signal of a surge in inflation expectations since the cost channel prevails. Besides, unanticipated demand shocks have a positive impact on the slope factor as a result of the central bank policy response for offsetting the elevated inflation expectations. Finally, a risk shock is associated with a decrease in the curvature factor indicating that risk shocks influence the medium-term bonds due to the deflationary pressure resulting from depressed economic conditions.Practical implications>Our results provide new insights to understand the driving forces of yield curve movements induced by various oil shocks to formulate appropriate policy responses.Originality/value>The study contributes to the literature by two main dimensions. First, the recent oil shock identification scheme of Ready (2018) is modified using the “geopolitical oil price risk index” to capture the changes in the risk perceptions of oil markets driven by geopolitical tensions such as terrorism and conflicts and sanctions. The modified identification scheme attributes more power to demand shocks in explaining the variation of the oil price compared to that of the baseline scheme. Second, it provides recent evidence that distinguishes the impact of oil demand and supply shocks on Turkey's yield curve.","https://www.proquest.com/docview/2740362118?accountid=12870&bdid=124553&_bd=eO69W7uNkz5S%2FTciMjw5glRB8rA%3D","https://doi.org/10.1108/IJOEM-06-2020-0681"
"Medical Extended Reality for Radiology Education and Training","","Lang, Min; Ghandour, Samir; Rikard, Blaire; Balasalle, Eleni K; Rouhezamin, Mohammad R; Zhang, Haipeng; Uppot, Raul N","Journal of the American College of Radiology : JACR","Undefined","","21","10","2024-10-01","Oct 2024","1583","","1583-1594","1558-349X","","","ENG","Medical extended reality (MXR), encompassing augmented reality, virtual reality, and mixed reality (MR), presents a novel paradigm in radiology training by offering immersive, interactive, and realistic learning experiences in health care. Although traditional educational tools in the field of radiology are essential, it is necessary to capitalize on the innovative and emerging educational applications of extended reality (XR) technologies. At the most basic level of learning anatomy, XR has been extensively used with an emphasis on its superiority over conventional learning methods, especially in spatial understanding and recall. For imaging interpretation, XR has fostered the concepts of virtual reading rooms by enabling collaborative learning environments and enhancing image analysis and understanding. Moreover, image-guided interventions in interventional radiology have witnessed an uptick in XR utilization, illustrating its effectiveness in procedural training and skill acquisition for medical students and residents in a safe and risk-free environment. However, there remain several challenges and limitations for XR in radiology education, including technological, economic, and ergonomic challenges and and integration into existing curricula. This review explores the transformative potential of MXR in radiology education and training along with insights on the future of XR in radiology education, forecasting advancements in immersive simulations, artificial intelligence integration for personalized learning, and the potential of cloud-based XR platforms for remote and collaborative training. In summation, MXR's burgeoning role in reshaping radiology education offers a safer, scalable, and more efficient training model that aligns with the dynamic healthcare landscape.Medical extended reality (MXR), encompassing augmented reality, virtual reality, and mixed reality (MR), presents a novel paradigm in radiology training by offering immersive, interactive, and realistic learning experiences in health care. Although traditional educational tools in the field of radiology are essential, it is necessary to capitalize on the innovative and emerging educational applications of extended reality (XR) technologies. At the most basic level of learning anatomy, XR has been extensively used with an emphasis on its superiority over conventional learning methods, especially in spatial understanding and recall. For imaging interpretation, XR has fostered the concepts of virtual reading rooms by enabling collaborative learning environments and enhancing image analysis and understanding. Moreover, image-guided interventions in interventional radiology have witnessed an uptick in XR utilization, illustrating its effectiveness in procedural training and skill acquisition for medical students and residents in a safe and risk-free environment. However, there remain several challenges and limitations for XR in radiology education, including technological, economic, and ergonomic challenges and and integration into existing curricula. This review explores the transformative potential of MXR in radiology education and training along with insights on the future of XR in radiology education, forecasting advancements in immersive simulations, artificial intelligence integration for personalized learning, and the potential of cloud-based XR platforms for remote and collaborative training. In summation, MXR's burgeoning role in reshaping radiology education offers a safer, scalable, and more efficient training model that aligns with the dynamic healthcare landscape.","https://www.proquest.com/docview/3067915855?accountid=12870&bdid=124553&_bd=caofU9Zb0%2BeWKgsgXf7oC8VkZH4%3D","https://doi.org/10.1016/j.jacr.2024.05.006"
"Mind the gap: forecasting euro-area output gaps with machine learning","","Sofianos, Emmanouil; Gogas, Periklis; Papadimitriou, Theophilos","Applied Economics Letters","Scholarly Journals","","29","19","2022-11-01","Nov 2022","1824","1828","1824-1828","13504851","","","ENG","In this paper, we use the Eurozone yield curve in an effort to forecast the deviations of the euro-area output (IPI) from its long-run trend. We use various short- and long-term interest rates spanning the period from 2004:9 to 2020:6 in monthly frequency. The interest rates are fed to three machine learning methodologies: Decision Trees, Random Forests, and Support Vector Machines (SVM). These Machine Learning methodologies are then compared to an Elastic-Net Logistic Regression (Logit) model from the area of Econometrics. According to the results, the optimal SVM model coupled with the RBF kernel outperforms the competition reaching an in-sample accuracy of 85.29% and an out-of-sample accuracy of 94.74%.","https://www.proquest.com/docview/2722612634?accountid=12870&bdid=124553&_bd=kB8eYQJYbcEFGT7jyR6%2BR%2Bz350g%3D","https://doi.org/10.1080/13504851.2021.1963403"
"Nonlinear time-series analysis of stock volatilities","","Cao, C Q; Tsay, R S","Journal of Applied Econometrics","Scholarly Journals","","7","","1992-12-01","Dec 1992","S165","","S165","08837252","","","ENG","The absolute value of the mean-corrected excess return is used to measure the volatility of stock returns.  Various nonlinearity tests available were applied to show that such volatility series are strongly nonlinear.  The use of threshold autoregressive (TAR) models are explored in describing monthly volatility series.  The models built suggest that the volatility series exhibit significant lower order serial correlations when the volatility is large, indicating certain volatility clustering in stock returns.  Out-of-sample forecasts are used to compare the TAR models with linear ARMA models and nonlinear GARCH and EGARCH models.  Based on mean squared error and average absolute deviation, the comparisons show that: 1.  The TAR models consistently outperform the linear ARMA models in multi-step ahead forecasts for large stocks.  2.  The TAR models provide better forecasts than the GARCH and EGARCH models also for the volatilities of large stock returns.  3.  The EGARCH model gives the best long-horizon volatility forecasts for small stock returns.","https://www.proquest.com/docview/218750106?accountid=12870&bdid=124553&_bd=ebCKCkTZYn2rgQaQKvmUayXgTD0%3D",""
"Wasserstein barycenter regression for estimating the joint dynamics of renewable and fossil fuel energy indices","","De Giuli, Maria Elena; Spelta, Alessandro","Computational Management Science","Scholarly Journals","","20","1","2023-12-01","Dec 2023","1","","1","1619697X","","","ENG","In order to characterize non-linear system dynamics and to generate term structures of joint distributions, we propose a flexible and multidimensional approach, which exploits Wasserstein barycentric coordinates for histograms. We apply this methodology to study the relationships between the performance in the European market of the renewable energy sector and that of the fossil fuel energy one. Our methodology allows us to estimate the term structure of conditional joint distributions. This optimal barycentric interpolation can be interpreted as a posterior version of the joint distribution with respect to the prior contained in the past histograms history. Once the underlying dynamics mechanism among the set of variables are obtained as optimal Wasserstein barycentric coordinates, the learned dynamic rules can be used to generate term structures of joint distributions.","https://www.proquest.com/docview/2888460079?accountid=12870&bdid=124553&_bd=iy69zFPcnCis3U8tH%2FQCXwukJZY%3D","https://doi.org/10.1007/s10287-023-00436-4"
"Developing a Composite Measure to Represent Information Flows in Networks: Evidence from a Stock Market","","Shangguan, Wuyue(Phoebe); Leung, Alvin Chung Man; Agarwal, Ashish; Konana, Prabhudev; Chen, Xi","Information Systems Research","Scholarly Journals","","33","2","2022-06-01","Jun 2022","413","","","10477047","","","ENG","There is increasing interest in information systems research to model information flows from different sources (e.g., social media, news) associated with a network of assets (e.g., stocks, products) and to study the economic impact of such information flows. This paper employs a design science approach and proposes a new composite metric, eigen attention centrality (EAC), as a proxy for information flows associated with a node that considers both attention to a node and coattention with other nodes in a network. We apply the EAC metric in the context of financial market where nodes are individual stocks and edges are based on coattention relationships among stocks. Composite information from different channels is used to measure attention and coattention. To evaluate the effectiveness of the EAC metric on predicting outcomes, we conduct an in-depth performance evaluation of the EAC metric by (1) using multiple linear and nonlinear prediction methods and (2) comparing EAC with a benchmark model without EAC and models with a set of alternative network metrics. Our analysis shows that EAC significantly outperforms other measures in predicting the direction and magnitude of abnormal returns of stocks. Besides, our EAC specification has better predictive performance than alternative specifications, and EAC outperforms direct attention in predicting abnormal returns. Using the EAC metric, we derive a stock portfolio and develop a trading strategy that provides significant and positive excess returns. Lastly, we find that composite information has significantly better predictive performance than separate information sources, and such superior performance owes to information from social media instead of traditional media.","https://www.proquest.com/docview/2690251982?accountid=12870&bdid=124553&_bd=Lr13JMO6ZcTaXzY1nJsm8e3el8I%3D","https://doi.org/10.1287/isre.2021.1066"
"AI-Driven Dental Caries Management Strategies: From Clinical Practice to Professional Education and Public Self Care","","Liang, Yutong; Li, Dongling; Deng, Dongmei; Chu, Chun Hung; Mei, May Lei; Li, Yunpeng; Yu, Na; He, Jinzhi; Cheng, Lei","International dental journal","Undefined","","75","4","2025-08-01","Aug 2025","100827","","100827","1875-595X","","","ENG","Dental caries is one of the most prevalent chronic diseases among both children and adults, despite being largely preventable. This condition has significant negative impacts on human health and imposes a substantial economic burden. In recent years, scientists and dentists have increasingly started to utilize artificial intelligence (AI), particularly machine learning, to improve the efficiency of dental caries management. This study aims to provide an overview of the current knowledge about the AI-enabled approaches for dental caries management within the framework of personalized patient care. Generally, AI works as a promising tool that can be used by both dental professionals and patients. For dental professionals, it predicts the risk of dental caries by analyzing dental caries risk and protective factors, enabling to formulate personalized preventive measures. AI, especially those based on machine learning and deep learning, can also analyze images to detect signs of dental caries, assist in developing treatment plans, and help to make a risk assessment for pulp exposure during treatment. AI-powered tools can also be used to train dental students through simulations and virtual case studies, allowing them to practice and refine their clinical skills in a risk-free environment. Additionally, AI tracks brushing patterns and provides feedback to improve oral hygiene practices of the patients and the general population, thereby improving their understanding and compliance. This capability of AI can inform future research and the development of new strategies for dental caries management and control.Dental caries is one of the most prevalent chronic diseases among both children and adults, despite being largely preventable. This condition has significant negative impacts on human health and imposes a substantial economic burden. In recent years, scientists and dentists have increasingly started to utilize artificial intelligence (AI), particularly machine learning, to improve the efficiency of dental caries management. This study aims to provide an overview of the current knowledge about the AI-enabled approaches for dental caries management within the framework of personalized patient care. Generally, AI works as a promising tool that can be used by both dental professionals and patients. For dental professionals, it predicts the risk of dental caries by analyzing dental caries risk and protective factors, enabling to formulate personalized preventive measures. AI, especially those based on machine learning and deep learning, can also analyze images to detect signs of dental caries, assist in developing treatment plans, and help to make a risk assessment for pulp exposure during treatment. AI-powered tools can also be used to train dental students through simulations and virtual case studies, allowing them to practice and refine their clinical skills in a risk-free environment. Additionally, AI tracks brushing patterns and provides feedback to improve oral hygiene practices of the patients and the general population, thereby improving their understanding and compliance. This capability of AI can inform future research and the development of new strategies for dental caries management and control.","https://www.proquest.com/docview/3203305615?accountid=12870&bdid=124553&_bd=vsxi9R4AVLrdhIXueTX2FUDltME%3D","https://doi.org/10.1016/j.identj.2025.04.007"
"Simulation-based estimation of contingent-claims prices","","Phillips, Peter C.B.; Yu, Jun","Review of financial studies","Undefined","","22","9","2009-09-01","Sep 2009","3669","3706","3669-3706","0893-9454","0893-9454","","ENG","A new methodology is proposed to estimate theoretical prices of financial contingent claims whose values are dependent on some other underlying financial assets. In the literature, the preferred choice of estimator is usually maximum likelihood (ML). ML has strong asymptotic justification but is not necessarily the best method in finite samples. This paper proposes a simulation-based method. When it is used in connection with ML, it can improve the finite-sample performance of the ML estimator while maintaining its good asymptotic properties. The method is implemented and evaluated here in the Black-Scholes option pricing model and in the Vasicek bond and bond option pricing model. It is especially favored when the bias in ML is large due to strong persistence in the data or strong nonlinearity in pricing functions. Monte Carlo studies show that the proposed procedures achieve bias reductions over ML estimation in pricing contingent claims when ML is biased. The bias reductions are sometimes accompanied by reductions in variance. Empirical applications to U.S. Treasury bills highlight the differences between the bond prices implied by the simulation-based approach and those delivered by ML. Some consequences for the statistical testing of contingent-claim pricing models are discussed. Reprinted by permission of Oxford University Press","https://www.proquest.com/docview/757458320?accountid=12870&bdid=124553&_bd=o4gKvaBVe0qrU1k36Psg%2F2le48w%3D","https://doi.org/10.1093/rfs/hhp009"
"Investor Inattention and the Market Impact of Summary Statistics","","Gilbert, Thomas; Kogan, Shimon; Lochstoer, Lars; Ozyildirim, Ataman","Management Science","Scholarly Journals","","58","2","2012-02-01","Feb 2012","336","","336-350","00251909","","","ENG","We show that U.S. stock and Treasury futures prices respond sharply to recurring stale information releases. In particular, we identify a unique macroeconomic series-the U.S. Leading Economic Index® (LEI)-which is released monthly and constructed as a summary statistic of previously released inputs. We show that a front-running strategy that trades S&P 500 futures in the direction of the announcement a day before its release and then trades in the opposite direction of the announcement following its release generates an average annual return of close to 8%. These patterns are more pronounced for high beta stocks, for stocks that are more difficult to arbitrage, and during times when investors' sensitivity to firm-specific stale information is high. Treasury futures exhibit similar, albeit less pronounced, price patterns. Other measures of information arrival, such as price volatility and volume, spike following the release. These empirical findings suggest that some investors are inattentive to the stale nature of the information included in the LEI releases, instead interpreting it as new information, and thereby causing temporary yet significant mispricing. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/928760600?accountid=12870&bdid=124553&_bd=%2BASxGFHy%2FlHbHR2YkITDBdbAaFs%3D",""
"Modeling the density of US yield curve using Bayesian semiparametric dynamic Nelson-Siegel model","","Çakmakli, Cem","Econometric Reviews","Scholarly Journals","","39","1","2020-01-01","2020","71","","71-91","07474938","","","ENG","This paper proposes the Bayesian semiparametric dynamic Nelson-Siegel model for estimating the density of bond yields. Specifically, we model the distribution of the yield curve factors according to an infinite Markov mixture (iMM). The model allows for time variation in the mean and covariance matrix of factors in a discrete manner, as opposed to continuous changes in these parameters such as the Time Varying Parameter (TVP) models. Estimating the number of regimes using the iMM structure endogenously leads to an adaptive process that can generate newly emerging regimes over time in response to changing economic conditions in addition to existing regimes. The potential of the proposed framework is examined using US bond yields data. The semiparametric structure of the factors can handle various forms of non-normalities including fat tails and nonlinear dependence between factors using a unified approach by generating new clusters capturing these specific characteristics. We document that modeling parameter changes in a discrete manner increases the model fit as well as forecasting performance at both short and long horizons relative to models with fixed parameters as well as the TVP model with continuous parameter changes. This is mainly due to fact that the discrete changes in parameters suit the typical low frequency monthly bond yields data characteristics better.","https://www.proquest.com/docview/2328254222?accountid=12870&bdid=124553&_bd=3Iqo5%2Feld765yk5%2Bp3hiS5gPHrQ%3D","https://doi.org/10.1080/07474938.2019.1690191"
"A Public, Open, and Independently-Curated Database of Happiness Coefficients","","Barrington-Leigh, C. P.; Lemermeyer, Katja","Journal of Happiness Studies","Scholarly Journals","","24","4","2023-04-01","Apr 2023","1505","1531","1505-1531","13894978","","","ENG","We present a nascent database of happiness coefficients. This is a synthesis of evidence on the size of improvements to human life experience that can be expected from changing objective, policy-amenable circumstances. The wealth of data on people’s self-reported satisfaction with life in a wide variety of circumstances, from around the world, including respondents undergoing a diversity of changes and life events and subject to a variety of public policies and policy changes, has provided a rich base of knowledge about what makes life good. This growing research literature has in recent years been met with interest from central governments looking for accountable but more human-centred approaches to measuring progress, as well as for communicating objectives, making policy, and allocating resources. Meanwhile, frameworks for benefit-cost accounting using inference from life satisfaction data have been devised. In some cases central government finance departments and treasuries are incorporating this approach into their formal methodology for budgeting. The body of causal inference about these effects is still somewhat diffuse. Collating, reviewing, and synthesizing such evidence should be led initially by academia and ultimately by a broad academic, civil society, and government collaboration. We report on the assembly of a database of summary estimates for Canada, supplemented where needed by evidence from around the world. The categorized domains of individual experience and circumstances include Education, Environment, Work, Finances, Health, Social Capital, and Crime. The paper also explains the context for and limitations of the use of a database of happiness coefficients.","https://www.proquest.com/docview/2812890314?accountid=12870&bdid=124553&_bd=en73eW84ImfY0hFcIChG34oU%2BAs%3D","https://doi.org/10.1007/s10902-023-00652-4"
"The October 2014 United States Treasury bond flash crash and the contributory effect of mini flash crashes","","Levine, Zachary S; Hale, Scott A; Floridi, Luciano","PloS one","Undefined","","12","11","2017-01-01","Jan 2017","e0186688","","e0186688","1932-6203","","","ENG","We investigate the causal uncertainty surrounding the flash crash in the U.S. Treasury bond market on October 15, 2014, and the unresolved concern that no clear link has been identified between the start of the flash crash at 9:33 and the opening of the U.S. equity market at 9:30. We consider the contributory effect of mini flash crashes in equity markets, and find that the number of equity mini flash crashes in the three-minute window between market open and the Treasury Flash Crash was 2.6 times larger than the number experienced in any other three-minute window in the prior ten weekdays. We argue that (a) this statistically significant finding suggests that mini flash crashes in equity markets both predicted and contributed to the October 2014 U.S. Treasury Bond Flash Crash, and (b) mini-flash crashes are important phenomena with negative externalities that deserve much greater scholarly attention.We investigate the causal uncertainty surrounding the flash crash in the U.S. Treasury bond market on October 15, 2014, and the unresolved concern that no clear link has been identified between the start of the flash crash at 9:33 and the opening of the U.S. equity market at 9:30. We consider the contributory effect of mini flash crashes in equity markets, and find that the number of equity mini flash crashes in the three-minute window between market open and the Treasury Flash Crash was 2.6 times larger than the number experienced in any other three-minute window in the prior ten weekdays. We argue that (a) this statistically significant finding suggests that mini flash crashes in equity markets both predicted and contributed to the October 2014 U.S. Treasury Bond Flash Crash, and (b) mini-flash crashes are important phenomena with negative externalities that deserve much greater scholarly attention.","https://www.proquest.com/docview/1959325594?accountid=12870&bdid=124553&_bd=vn0sefcrn%2FCrt%2FmiaRPYFYERO5Q%3D","https://doi.org/10.1371/journal.pone.0186688"
"The Term Structure: A Test of the Segmented Markets Hypothesis","","Van Horne, James C","Southern Economic Journal","Scholarly Journals","","46","4","1980-04-01","Apr 1980","1129","","1129","00384038","","","ENG","The influence of market segmentation on the term structure of interest rates has received considerable attention in recent years.  However, an event gone unnoticed in this work is relaxation in the authority of the Treasury to issue long-term bonds apart from the 41/2% interest rate ceiling imposed by Congress.  A test is made of the effect of 1971 and 1976 changes in this authority which, in turn, affected the expected supply of long-term relative to short-term securities.Several widely used term structure models were used to predict long-term bond yields for time periods immediately following March of 1971 and February of 1976.  The discrepancy between actual long rates and predicted long rates, or the residual, was used as a measure of the impact of the new information.  Residuals were not found to be predominantly positive, but rather were mixed over time.  Expressed differently, there was no evidence that long-term rates rose relative to short-term rates after a change in the Treasury's authority to issue long-term bonds occurred.  Therefore, the results do not support a hypothesis of partial market segmentation in the Treasury security market.","https://www.proquest.com/docview/212134539?accountid=12870&bdid=124553&_bd=sErVxEF2aplp%2Ffu1f%2Fbr9F6oANA%3D",""
"The 'forward premium puzzle' and the sovereign default risk","","Coudert, Virginie; Mignon, Valérie","Journal of international money and finance","Undefined","","32","1","2013-02-01","Feb 2013","491","511","491-511","0261-5606","0261-5606","","ENG","Carry-trade strategies which consist of buying forward high-yield currencies tend to yield positive excess returns when global financial markets are booming, whereas they generate losses during crises. Firstly, we show that the sovereign default risk, which is taken on by investing in high-yield currencies, may increase the magnitude of the gains during the boom periods and the losses during crises. We empirically test for this hypothesis on a sample of 18 emerging currencies over the period from June 2005 to September 2010, the default risk being proxied by the sovereign credit default swap spread. Relying on smooth transition regression (STR) models, we show that default risk contributes to the carry-trade gains during booms, and worsens the losses during busts. Secondly, we turn to the 'Fama regression' linking the exchange-rate depreciation to the interest-rate differential. We propose a nonlinear estimation of this equation, explaining the puzzling evolution of its coefficient by the change in the market volatility along the financial cycle. Then, we introduce the default risk into this equation and show that the 'forward bias', usually evidenced by a coefficient smaller than unity in this regression, is somewhat alleviated, as the default risk is significant to explain the exchange-rate change. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/1317584908?accountid=12870&bdid=124553&_bd=gEaOEoY%2FR8XKeId1lIvZcPWkzKs%3D",""
"Prediction and Allocation of Stocks, Bonds, and REITs in the US Market","","","Computational Economics","Scholarly Journals","","65","3","2025-03-01","Mar 2025","1191","1230","1191-1230","09277099","","","ENG","This study employs dynamic model averaging and selection of Vector Autoregressive and Time-Varying Parameters Vector Autoregressive models to forecast out-of-sample monthly returns of US stocks, bonds, and Real Estate Investment Trusts (REITs) indexes from October 2006 to December 2021. The models were recursively estimated using 17 additional predictors chosen by a genetic algorithm applied to an initial list of 155 predictors. These forecasts were then used to dynamically choose portfolios formed by these assets and the riskless asset proxied by the 3-month US treasury bills. Although we did not find any predictability in the stock market, positive results were obtained for REITs and especially for bonds. The Bayesian-based approaches applied to just the returns of the three risky assets resulted in portfolios that remarkably outperform the portfolios based on the historical means and covariances and the equally weighted portfolio in terms of certainty equivalent return, Sharpe ratio, Sortino ratio and even Conditional Value-at-Risk at 5%. This study points out that Constant Relative Risk Averse investors should use Bayesian-based approaches to forecast and choose the investment portfolios, focusing their attention on different types of assets.","https://www.proquest.com/docview/3173580330?accountid=12870&bdid=124553&_bd=yGXT%2Fj3RCjzdph02945XiAKJ2n4%3D","https://doi.org/10.1007/s10614-024-10589-2"
"An Evaluation of the One-Time Capital Gains Exclusion for Older Homeowners","","Newman, Sandra; Reschovsky, James","AREUEA Journal","Scholarly Journals","","15","1","1987-04-01","Spring 1987","704","","704","02700484","","","ENG","An evaluation is provided of the one-time capital gains exclusion for older homeowners, a provision that was largely intended to prevent large capital gains tax liabilities from locking older households into current, and possibly inappropriate, housing.  The basic strategy is to estimate probabilistic models of residential mobility that include an explanatory variable measuring the potential tax benefits that eligible households would enjoy if they were to sell their homes and elect Section 121 of the Internal Revenue Code.  Data are from the Panel Study of Income Dynamics.  Cross-sectional data, weighted to be representative of the US population, are pooled for the years 1970-1981.  It is found that the exclusion facilitates a modest number of moves, though not entirely of the downscaling type intended by Congress.  Among beneficiaries, the distribution of benefits seems to be highly regressive.  Modest benefits also are found to be enjoyed by the real estate and mortgage industries.  Revenue losses are found to be significantly larger than estimates provided by the Treasury Department.","https://www.proquest.com/docview/211122053?accountid=12870&bdid=124553&_bd=Ws49kF6N6LZ2wPSCLL6R04ByDvM%3D",""
"Relationship Between Expected Treasury Bill and Eurodollar Interest Rates: A Fractional Cointegration Analysis","","Shrestha, Keshab; Welch, Robert L","Review of Quantitative Finance and Accounting","Scholarly Journals","","16","1","2001-01-01","Jan 2001","65","","65","0924865X","","","ENG","In this paper, we extend Booth and Tse's (BT) 1995 analysis of fractional cointegration between the expected Eurodollar and Treasury bill interest rates implied by their respective futures contracts. The definition of fractional cointegration suggested by Cheung and Lai (1993) and used by BT is refined so that it requires the cointegrating relationship to be stationary as well as mean-reverting. In addition to the Geweke and Porter-Hudak method used by  BT, a more efficient Maximum Likelihood (ML) method is used to estimate the cointegrating relationship. The LM (Engle (1982)) test indicates the possible existence of a heteroscedastic cointegrating relationship. Therefore, we use heteroscedastic models (GARCH and Exponential GARCH) to represent the cointegrating regression instead of the simple homoscedastic model used by BT. The empirical evidence cannot reject the null hypothesis of a stationary fractional cointegration relationship between the Eurodollar and Treasury bill interest rates. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/210347207?accountid=12870&bdid=124553&_bd=Qw%2F1cRjG6%2FaVOZMmg8wR6FHDS6w%3D",""
"Black-Scholes Fuzzy Numbers as Indexes of Performance","","Simonelli, M R","Applied Computational Intelligence and Soft Computing","Scholarly Journals","","2010","","2010-01-01","2010","n/a","","","16879724","","","ENG","We use the set of propositions of some previous papers to define a fuzzy version of the Black-Scholes value where the risk free instantaneous interest intensity, the volatility and the initial stock price are fuzzy numbers whose parameters are built with statistical financial data. With our Black-Scholes fuzzy numbers we define indexes of performance varing in time. As an example, with data of the Italian Stock Exchange on MIB30, we see that in 2004 and 2006 our indexes are negative, that is, they are indexes of the refuse to invest and this refuse increased. So, on November 11, 2006 we could forecast that the market will become with more risk: the risk of loss will increase. Now, on January 25, 2010, we know that this forecast has happened. Obviously, the parameters of our Black-Scholes fuzzy numbers can be valued also with incomplete, possibilistic data. With respect to the probabilistic one, our fuzzy method is more simple and immediate to have a forecast on the financial market.","https://www.proquest.com/docview/855274878?accountid=12870&bdid=124553&_bd=m8U9sd%2B0ILp9%2Fnw%2Ff4pjrxEydTY%3D","https://doi.org/10.1155/2010/607214"
"Nutritional value, elemental bioaccumulation and antioxidant activity of fruiting bodies and mycelial cultures of an unrecorded wild Lactarius hatsudake from Nanyue mountainous region in China","","Zhu, Hanyu; Chen, Zheng; Hu, Yujing; Li, Geqing; Yao, Xiaoqian; Cao, Limin","Food research international (Ottawa, Ont.)","Undefined","","173","Pt 1","2023-11-01","Nov 2023","113358","","113358","1873-7145","","","ENG","An unrecorded wild mushroom Lactarius hatsudake from Nanyue mountainous region in China was identified. Subsequently, comparative investigation on the nutritional value, elemental bioaccumulation, and antioxidant activity was performed in the fruiting body (FB) and mycelium (MY) samples of this species. It revealed that the contents of moisture (87.66 ± 0.16 g/100 g fw) and ash (6.97 ± 0.16 g/100 g dw) were significantly higher in FB, and the total carbohydrate, fat, and protein concentrations of FB were similar to those in MY. Among nutritionally important elements, FB possessed higher concentrations of potassium (37808.61 ± 1237.38 mg/kg dw), iron (470.69 ± 85.54 mg/kg dw), and zinc (136.13 ± 5.16 mg/kg dw), whereas MY was a better source of magnesium (1481.76 ± 18.03 mg/kg dw), calcium (2203.87 ± 69.61 mg/kg dw), and sodium (277.44 ± 22.93 mg/kg dw). According to the health risk estimation, FB might pose an aluminum-related health problem when a prolonged period of exposure, while MY was risk-free for consumers. The results of antioxidant capacity (1,1-diphenyl-2-picrylhydrazyl (DPPH) and 2,2'-Azino-bis (3-ethylbenzothiazoline-6-sulfonic acid) diammonium salt (ABTS) assays) in FB and MY were within the range of 104.19 ± 5.70 mg ascorbic acid equivalents (AAE)/g to 169.50 ± 4.94 mg AAE/g, and half maximal effective concentration EC50 values ranged from 0.23 ± 0.01 mg/mL to 0.62 ± 0.05 mg/mL. The aqueous extracts of MY demonstrated a strong ABTS radical scavenging capacity with the highest AAE value.An unrecorded wild mushroom Lactarius hatsudake from Nanyue mountainous region in China was identified. Subsequently, comparative investigation on the nutritional value, elemental bioaccumulation, and antioxidant activity was performed in the fruiting body (FB) and mycelium (MY) samples of this species. It revealed that the contents of moisture (87.66 ± 0.16 g/100 g fw) and ash (6.97 ± 0.16 g/100 g dw) were significantly higher in FB, and the total carbohydrate, fat, and protein concentrations of FB were similar to those in MY. Among nutritionally important elements, FB possessed higher concentrations of potassium (37808.61 ± 1237.38 mg/kg dw), iron (470.69 ± 85.54 mg/kg dw), and zinc (136.13 ± 5.16 mg/kg dw), whereas MY was a better source of magnesium (1481.76 ± 18.03 mg/kg dw), calcium (2203.87 ± 69.61 mg/kg dw), and sodium (277.44 ± 22.93 mg/kg dw). According to the health risk estimation, FB might pose an aluminum-related health problem when a prolonged period of exposure, while MY was risk-free for consumers. The results of antioxidant capacity (1,1-diphenyl-2-picrylhydrazyl (DPPH) and 2,2'-Azino-bis (3-ethylbenzothiazoline-6-sulfonic acid) diammonium salt (ABTS) assays) in FB and MY were within the range of 104.19 ± 5.70 mg ascorbic acid equivalents (AAE)/g to 169.50 ± 4.94 mg AAE/g, and half maximal effective concentration EC50 values ranged from 0.23 ± 0.01 mg/mL to 0.62 ± 0.05 mg/mL. The aqueous extracts of MY demonstrated a strong ABTS radical scavenging capacity with the highest AAE value.","https://www.proquest.com/docview/2874263834?accountid=12870&bdid=124553&_bd=vVxadpnL5tDmVECzvoYYOAeJS%2BU%3D","https://doi.org/10.1016/j.foodres.2023.113358"
"Testing the Optimality of Consumption Decisions of the Representative Household: Evidence from Brazil","","Costa, Marcos Gesteira; Carrasco-Gutierrez, Carlos Enrique","Revista Brasileira de Economia","Scholarly Journals","","69","3","2015-01-01","2015","373","","373-387","00347140","","","ENG","This paper investigates whether there is a fraction of consumers that do not behave as fully forward-looking optimal consumers in the Brazilian economy. The generalized method of moments technique was applied to nonlinear Euler equations of the consumption-based capital assets model contemplating utility functions with time separability and non-separability. The results show that when the household utility function was modeled as constant relative risk aversion, external habits and Kreps-Porteus, estimates of the fraction of rule-of-thumb households was, respectively, 89%, 78% and 22%. According to this, a portion of disposable income goes to households who consume their current incomes in violation of the permanent income hypothesis.","https://www.proquest.com/docview/1806798989?accountid=12870&bdid=124553&_bd=UH9N1valNydK8npMN%2F60oWps6PQ%3D",""
"ABS inflows to the United States and the global financial crisis","","Bertaut, C; DeMarco, L P; Kamin, S; Tryon, R","Journal of international economics","Undefined","","88","2","2012-11-01","Nov 2012","219","234","219-234","0022-1996","0022-1996","","ENG","Relative to the 'global savings glut' (GSG) hypothesis, we present a more complete picture of how capital flows contributed to the financial crisis, drawing attention to the sizable inflows from European investors into U.S. private-label asset-backed securities (ABS), including mortgage-backed securities and other structured investment products. The GSG hypothesis argues that the surge in capital inflows from emerging market economies to the United States led to significant declines in long-term interest rates in the United States and other industrial economies. In turn, these lower interest rates, when combined with both innovations and deficiencies of the U.S. credit market, are believed to have contributed to the U.S. housing bubble and to the buildup in financial vulnerabilities that led to the financial crisis. Because the GSG countries for the most part restricted their U.S. purchases to Treasuries and Agency debt, their provision of savings to ultimately risky subprime mortgage borrowers was necessarily indirect, pushing down yields on safe assets and increasing the appetite for alternative investments on the part of other investors. Foreign acquisitions of private-label ABS, primarily by Europeans, provided credit more directly and, by adding to domestic demand for these securities, contributed to the decline in their spreads over Treasury yields. Through a combination of empirical estimation and model simulation, we verify that both GSG inflows into Treasuries and Agencies, as well as European acquisitions of ABS, played a role in contributing to downward pressures on U.S. interest rates. All rights reserved, Elsevier","https://www.proquest.com/docview/1267028444?accountid=12870&bdid=124553&_bd=rKL4HWE1hTWLdr%2F2G1dYHC3V4VY%3D","https://doi.org/10.1016/j.jinteco.2012.04.001"
"Financial and Real Sector Leading Indicators of Recessions in Brazil Using Probabilistic Models","","Nascimento de Oliveira, Fernando; Nascimento de Oliveira, Fernando","Revista Brasileira de Economia","Scholarly Journals","","70","3","2016-01-01","2016","337","","337-355","00347140","","","ENG","We examine the usefulness of various financial and real sector variables to forecast recessions in Brazil between one and eight quarters ahead. We estimate probabilistic models of recession and select models based on their out-of-sample forecasts, using the Receiver Operating Characteristic (ROC) function. We find that the predictive out-of-sample ability of several models vary depending on the numbers of quarters ahead to forecast and on the number of regressors used in the model specification. The models selected seem to be relevant to give early warnings of recessions in Brazil.","https://www.proquest.com/docview/1843900890?accountid=12870&bdid=124553&_bd=dc1RlrtEus90uPZACKKWUuQGjpo%3D",""
"Air pollution, weather factors, and realized volatility forecasts of agricultural commodity futures","","Luo, Jiawen; Zhang, Qun","The Journal of Futures Markets","Scholarly Journals","","44","2","2024-02-01","Feb 2024","151","217","151-217","02707314","","","ENG","This study investigates the potential effects of environmental factors on fluctuations in agricultural commodity futures markets, by constructing a new category of daily exogenous predictors related to air pollution, weather, climate change, and investor attention. The empirical results from out‐of‐sample analyses suggest that the heterogeneous autoregressive (HAR) model incorporating all these exogenous predictors is more likely to outperform other HAR‐type models. Additionally, economic evaluations demonstrate the superior performance of models incorporating investors' attention to climate change or extreme weather as predictors. While not all exogenous predictors are equally important for volatility forecasts, adopting appropriate variable selection methods to handle different sets of exogenous predictors can lead to better performance than the HAR benchmark. With the inclusion of air pollution or weather factors in the HAR model, a portfolio with an annualized average excess return of 16.2068% or a Sharpe ratio of 10.0431 can be achieved for the wheat futures, respectively.","https://www.proquest.com/docview/2911091802?accountid=12870&bdid=124553&_bd=IDYLZB5tgzCSQl%2BoC0bUggIkK3w%3D","https://doi.org/10.1002/fut.22467"
"Economic Freedom, Budget Deficits, and Perceived Risk from Larger National Debt-to-GDP Ratios: An Exploratory Analysis of Their Real Interest Rate Effects","","Cebula, Richard J","Journal of Risk and Financial Management","Scholarly Journals","","17","10","2024-01-01","2024","469","","","19118066","","","ENG","Since the early 1980s, there have been a number of principally empirical studies of the impact of government budget deficits on interest rates that have typically tested the hypothesis that larger deficits raise interest rates. However, in more recent years, this topic has received far less attention. Accordingly, this study seeks to “update” the findings of such studies and to do so for the dominant North American economies of Canada and the U.S. Furthermore, in the pursuit of further insights into interest rates, the present study also investigates an effectively heretofore overlooked variable that arguably also might influence interest rates, namely, economic freedom. Finally, given the increased upward trend of government debt (relative to GDP) in recent years in Canada and the U.S., this study investigates the interest rate impact of rising national debt-to-GDP ratios. For the 1995–2024 period (and also in one estimate for the 1985–2001 period), this exploratory study finds compelling evidence (1) that the real interest rate yield on 10-year Treasuries in Canada and the real interest rate yield on 10-year U.S. Treasury notes are increasing functions of the central government budget deficits in both Canada and the U.S., respectively, and (2) the real interest rate yields on 10-year Treasuries in Canada and 10-year U.S. Treasury notes are both decreasing functions of economic freedom in Canada and the U.S., respectively. On the other hand, regarding the impact of a higher national debt-to-GDP ratio on the real ten-year Treasury yield, there is only very mixed support for an impact, with support for its impact coming from the Canadian estimates but no support whatsoever coming from the U.S. estimates.","https://www.proquest.com/docview/3120673771?accountid=12870&bdid=124553&_bd=kcAyTisI5OhzTqWUZSF2hwOoaqM%3D","https://doi.org/10.3390/jrfm17100469"
"FORECASTING THE DEMAND FOR MONEY UNDER CHANGING TERM STRUCTURE OF INTEREST RATES - AN APPLICATION OF RIDGE REGRESSION","","Watson, Dan E; White, Kenneth J","Southern Economic Journal","Scholarly Journals","","43","2","1976-10-01","OCT 1976","1096","","1096","00384038","","","ENG","AN APPLICATION OF RIDGE REGRESSION TO THE FORECASTING PROBLEM IS PRESENTED.  THE CONDITION IS THAT THE ECONOMETRICIAN SUSPECTS THAT THE ORIGINAL INTERCORRELATIONS AMONG INDEPENDENT VARIABLES HAVE CHANGED IN THE FORECAST PERIOD.  THIS IS A FREQUENT EVENT UNDER RAPIDLY CHANGING ECONOMIC CONDITIONS.  RIDGE REGRESSION MAY PROVE TO BE USEFUL IN ESTIMATING THE TERM STRUCTURE OF INTEREST RATES AND IN MANY APPLICATIONS OF LARGER SCALE ECONOMETRIC MODELS.  THE ESTIMATION PROCEDURE OF RIDGE REGRESSION IS USED TO APPROACH THE MULTICOLLINEARITY PROBLEM INTRODUCED BY THE INCLUSION OF MULTIPLE INTEREST RATES IN THE DEMAND FOR MONEY.  THE ESTIMATED COEFFICIENTS FROM RIDGE REGRESSION ARE BIASED BUT GENERALLY HAVE A LOWER VARIANCE.  THE RIDGE ESTIMATORS OFTEN HAVE A SMALLER MEAN SQUARE ERROR THAN THE ORDINARY LEAST SQUARES COUNTERPARTS WHEN A HIGH DEGREE OF MULTICOLLINEARITY IS PRESENT.  GRAPH.  TABLES.","https://www.proquest.com/docview/212137755?accountid=12870&bdid=124553&_bd=OYazoTOADg4njwDvOZLZUN8IXQ4%3D",""
"Fractional Black-Scholes option pricing, volatility calibration and implied Hurst exponents in South African context","","Flint, Emlyn; Maré, Eben","South African Journal of Economic and Management Sciences","Scholarly Journals","","20","1","2017-01-01","2017","n/a","","","10158812","","","ENG","Background: Contingent claims on underlying assets are typically priced under a framework that assumes, inter alia, that the log returns of the underlying asset are normally distributed. However, many researchers have shown that this assumption is violated in practice. Such violations include the statistical properties of heavy tails, volatility clustering, leptokurtosis and long memory. This paper considers the pricing of contingent claims when the underlying is assumed to display long memory, an issue that has heretofore not received much attention.Aim: We address several theoretical and practical issues in option pricing and implied volatility calibration in a fractional Black-Scholes market. We introduce a novel eight-parameter fractional Black-Scholes-inspired (FBSI) model for the implied volatility surface, and consider in depth the issue of calibration. One of the main benefits of such a model is that it allows one to decompose implied volatility into an independent long-memory component - captured by an implied Hurst exponent - and a conditional implied volatility component. Such a decomposition has useful applications in the areas of derivatives trading, risk management, delta hedging and dynamic asset allocation.Setting: The proposed FBSI volatility model is calibrated to South African equity index options data as well as South African Rand/American Dollar currency options data. However, given the focus on the theoretical development of the model, the results in this paper are applicable across all financial markets.Methods: The FBSI model essentially combines a deterministic function form of the 1-year implied volatility skew with a separate deterministic function for the implied Hurst exponent, thus allowing one to model both observed implied volatility surfaces as well as decompose them into independent volatility and long-memory components respectively. Calibration of the model makes use of a quasi-explicit weighted least-squares optimisation routine.Results: It is shown that a fractional Black-Scholes model always admits a non-constant implied volatility term structure when the Hurst exponent is not 0.5, and that 1-year implied volatility is independent of the Hurst exponent and equivalent to fractional volatility. Furthermore, we show that the FBSI model fits the equity index implied volatility data very well but that a more flexible Hurst exponent parameterisation is required to fit accurately the currency implied volatility data.Conclusion: The FBSI model is an arbitrage-free deterministic volatility model that can accurately model equity index implied volatility. It also provides one with an estimate of the implied Hurst exponent, which could be very useful in derivatives trading and delta hedging.","https://www.proquest.com/docview/1908470745?accountid=12870&bdid=124553&_bd=6emTxdwiQM7KaPIGYRX1BdgNFwc%3D","https://doi.org/10.4102/sajems.v20i1.1532"
"Detecting Multiple Structural Breaks in Systems of Linear Regression Equations With Integrated and Stationary Regressors","","Schweikert, Karsten","Oxford Bulletin of Economics and Statistics","Scholarly Journals","","87","4","2025-08-01","Aug 2025","850","865","850-865","03059049","","","ENG","In this paper, we propose a two‐step procedure based on the group LASSO estimator in combination with a backward elimination algorithm to detect multiple structural breaks in linear regressions with multivariate responses. Applying the two‐step estimator, we jointly detect the number and location of structural breaks and provide consistent estimates of the coefficients. Our framework is flexible enough to allow for a mix of integrated and stationary regressors, as well as deterministic terms. Using simulation experiments, we show that the proposed two‐step estimator performs competitively against the likelihood‐based approach in finite samples. However, the two‐step estimator is computationally much more efficient. An economic application to the identification of structural breaks in the term structure of interest rates illustrates this methodology.","https://www.proquest.com/docview/3229055577?accountid=12870&bdid=124553&_bd=6L%2F2B319ef55GBBPrKKZND67%2BhA%3D","https://doi.org/10.1111/obes.12666"
"Yield curve in an estimated nonlinear macro model","","","Journal of economic dynamics and control","Undefined","","35","8","2011-08-01","Aug 2011","1229","1244","1229-1244","0165-1889","0165-1889","","ENG","This paper estimates a sticky price macro model with US macro and term structure data using Bayesian methods. The model is solved by a nonlinear method. The posterior distribution of the parameters in the model is found to be bi-modal. The degree of nominal rigidity is high at one mode (''sticky price mode'') but is low at the other mode (''flexible price mode''). I find that the degree of nominal rigidity is important for identifying macro shocks that affect the yield curve. When prices are more flexible, a slowly varying inflation target of the central bank is the main driver of the overall level of the yield curve by changing long-run inflation expectations. In contrast, when prices are more sticky, a highly persistent markup shock is the main driver. The posterior probability of each mode is sensitive to the use of observed proxies for inflation expectations. Ignoring additional information from survey data on inflation expectations significantly reduces the posterior probability of the flexible price mode. Incorporating this additional information suggests that yield curve fluctuations can be better understood by focusing on the flexible price mode. Considering nonlinearities of the model solution also increases the posterior probability of the flexible price mode, although to a lesser degree than using survey data information. All rights reserved, Elsevier","https://www.proquest.com/docview/873847948?accountid=12870&bdid=124553&_bd=bh3WgB0KtAOWeCL4WGjnuXBnY8k%3D","https://doi.org/10.1016/j.jedc.2011.03.003"
"Is BRCA Mutation Testing Cost Effective for Early Stage Breast Cancer Patients Compared to Routine Clinical Surveillance? The Case of an Upper Middle-Income Country in Asia","","Lim, Ka Keat; Yoon, Sook Yee; Taib, Nur Aishah Mohd; Shabaruddin, Fatiha Hana; Dahlui, Maznah; Woo, Yin Ling; Thong, Meow Keong; Teo, Soo Hwang; Chaiyakunapruk, Nathorn","Applied Health Economics and Health Policy","Scholarly Journals","","16","3","2018-06-01","Jun 2018","395","406","395-406","11755652","","","ENG","Objective Previous studies showed that offering BRCA mutation testing to population subgroups at high risk of harbouring the mutation may be cost effective, yet no evidence is available for low- or middle-income countries (LMIC) and in Asia. We estimated the cost effectiveness of BRCA mutation testing in early-stage breast cancer patients with high pre-test probability of harbouring the mutation in Malaysia, an LMIC in Asia. Methods We developed a decision analytic model to estimate the lifetime costs and quality-adjusted life-years (QALYs) accrued through BRCA mutation testing or routine clinical surveillance (RCS) for a hypothetical cohort of 1000 early-stage breast cancer patients aged 40 years. In the model, patients would decide whether to accept testing and to undertake risk-reducing mastectomy, oophorectomy, tamoxifen, combinations or neither. We calculated the incremental cost-effectiveness ratio (ICER) from the health system perspective. A series of sensitivity analyses were performed. Results In the base case, testing generated 11.2 QALYs over the lifetime and cost US$4815 per patient whereas RCS generated 11.1 QALYs and cost US$4574 per patient. The ICER of US$2725/QALY was below the cost-effective thresholds. The ICER was sensitive to the discounting of cost, cost of BRCA mutation testing and utility of being risk-free, but the ICERs remained below the thresholds. Probabilistic sensitivity analysis showed that at a threshold of US$9500/QALY, 99.9% of simulations favoured BRCA mutation testing over RCS. Conclusions Offering BRCA mutation testing to early-stage breast cancer patients identified using a locally-validated risk-assessment tool may be cost effective compared to RCS in Malaysia.","https://www.proquest.com/docview/2149615290?accountid=12870&bdid=124553&_bd=10AcolB4bpSQHo01H6qzx%2BE3wks%3D","https://doi.org/10.1007/s40258-018-0384-8"
"Forecasting WTI crude oil futures returns: Does the term structure help?","","Bredin, Don; O'Sullivan, Conall; Spencer, Simon","Energy Economics","Scholarly Journals","","100","","2021-08-01","Aug 2021","1","","","01409883","","","ENG","Nelson-Siegel (NS) factors extracted from the term structure of WTI oil futures are shown to predict subsequent WTI holding period returns in-sample. This in-sample predictability is not diminished by augmenting with macroeconomic indicators or oil market specific predictors. Allowing the decay factor in the Nelson-Siegel model to vary over time improves in-sample predictions at medium horizon return forecasts. We conduct out-of-sample forecasting exercises on models that use NS factors, such as a simple two factor model that uses a composite leading indicator along with the NS decay factor, and a LASSO model that combines NS factors with macroeconomic indicators and oil market specific predictors. These models significantly reduce forecast errors relative to a no change benchmark across a range of return horizons and futures contract maturities. We also find consistent evidence that models that use the NS factors result in trading strategies with higher Sharpe ratios and better skewness properties than buy and hold strategies and historical mean strategies.","https://www.proquest.com/docview/2575099676?accountid=12870&bdid=124553&_bd=bZ1p%2FcQA9ul5U%2B2uQOt55qaYy3Q%3D","https://doi.org/10.1016/j.eneco.2021.105350"
"Forecasting the Volatility of US Oil and Gas Firms With Machine Learning","","Díaz, Juan D.; Hansen, Erwin; Cabrera, Gabriel","Journal of Forecasting","Scholarly Journals","","44","4","2025-07-01","Jul 2025","1383","1402","1383-1402","02776693","","","ENG","Forecasting the realized volatility of oil and gas firms is of interest to investors and practitioners trading on the energy spot and derivative markets. In this paper, we assess whether several machine learning (ML) techniques can offer superior forecasts compared to HAR models for predicting realized volatility at the firm level. Moreover, we investigate whether economically motivated variables and technical indicators contain valuable information for forecasting firm volatility beyond those contained in various volatility factors previously identified in the literature. Our results demonstrate that certain ML techniques provide superior forecasting accuracy compared to the benchmark model. Additionally, we identify variables such as the 1‐month treasury bill and the aggregate VIX index as significant drivers of realized firm volatility in the oil and gas industry.","https://www.proquest.com/docview/3228951717?accountid=12870&bdid=124553&_bd=zK7X9eo16PSS%2BVAHd3NwwSBRUi0%3D","https://doi.org/10.1002/for.3245"
"When there is no place to hide: correlation risk and the cross-section of hedge fund returns","","Buraschi, Andrea; Kosowski, Robert; Trojani, Fabio","Review of financial studies","Undefined","","27","2","2014-02-01","Feb 2014","581","616","581-616","0893-9454","0893-9454","","ENG","Using a novel data set on correlation swaps, we study the relation between correlation risk, hedge fund characteristics, and their risk-return profile. We find that the ability of hedge funds to create market-neutral returns is often associated with a significant exposure to correlation risk, which helps to explain the large abnormal returns found in previous models. We also estimate a significant negative market price of correlation risk, which accounts for the cross-section of hedge fund excess returns. Finally, we detect a pronounced nonlinear relation between correlation risk exposure and the tail risk of hedge fund returns. [PUBLICATION ABSTRACT] Reprinted by permission of Oxford University Press","https://www.proquest.com/docview/1506424431?accountid=12870&bdid=124553&_bd=1MjBZxu4b6%2BnQfpBysX1cJTp%2Fic%3D",""
"Functional shocks to inflation expectations and real interest rates and their macroeconomic effects","","","Review of World Economics","Scholarly Journals","","160","4","2024-11-01","Nov 2024","1543","1575","1543-1575","16102878","","","ENG","This paper applies a recently developed method (Inoue and Rossi, 2021) to estimate functional inflation expectations and ex-ante real interest rate shocks, and then examines their macroeconomic effects in the context of a Functional Vector Autoregressive model with exogenous variables (Functional VARX). Monthly data from January 1998 to May 2023 for the US, the UK and the euro area are used for the analysis. The estimated impulse responses show significant effects of the functional shocks on both inflation and output. In addition, threshold functional local projections indicate that the effects are nonlinear and depend on central bank credibility. Further, inflation expectations shocks have similar effects to supply (demand) ones when they are driven by long-term (short-term) changes. In the presence of an inverted (steepening) real interest rate term structure, the effects are inflationary (deflationary) and expansionary (recessionary). Finally, the responses of inflation, output and the policy rate are driven primarily by the slope and curvature factors of the term structure shocks, which contain important information not captured by traditional scalar shocks.","https://www.proquest.com/docview/3144446178?accountid=12870&bdid=124553&_bd=S7krg6y07ew8g%2B39T1dNvUTVrOs%3D","https://doi.org/10.1007/s10290-024-00538-4"
"SF-Transformer: A Mutual Information-Enhanced Transformer Model with Spot-Forward Parity for Forecasting Long-Term Chinese Stock Index Futures Prices","","Mao, Weifang; Liu, Pin; Huang, Jixian","Entropy (Basel, Switzerland)","Undefined","","26","6","2024-05-30","May 30, 2024","","","","1099-4300","","","ENG","The complexity in stock index futures markets, influenced by the intricate interplay of human behavior, is characterized as nonlinearity and dynamism, contributing to significant uncertainty in long-term price forecasting. While machine learning models have demonstrated their efficacy in stock price forecasting, they rely solely on historical price data, which, given the inherent volatility and dynamic nature of financial markets, are insufficient to address the complexity and uncertainty in long-term forecasting due to the limited connection between historical and forecasting prices. This paper introduces a pioneering approach that integrates financial theory with advanced deep learning methods to enhance predictive accuracy and risk management in China's stock index futures market. The SF-Transformer model, combining spot-forward parity and the Transformer model, is proposed to improve forecasting accuracy across short and long-term horizons. Formulated upon the arbitrage-free futures pricing model, the spot-forward parity model offers variables such as stock index price, risk-free rate, and stock index dividend yield for forecasting. Our insight is that the mutual information generated by these variables has the potential to significantly reduce uncertainty in long-term forecasting. A case study on predicting major stock index futures prices in China demonstrates the superiority of the SF-Transformer model over models based on LSTM, MLP, and the stock index futures arbitrage-free pricing model, covering both short and long-term forecasting up to 28 days. Unlike existing machine learning models, the Transformer processes entire time series concurrently, leveraging its attention mechanism to discern intricate dependencies and capture long-range relationships, thereby offering a holistic understanding of time series data. An enhancement of mutual information is observed after introducing spot-forward parity in the forecasting. The variation of mutual information and ablation study results highlights the significant contributions of spot-forward parity, particularly to the long-term forecasting. Overall, these findings highlight the SF-Transformer model's efficacy in leveraging spot-forward parity for reducing uncertainty and advancing robust and comprehensive approaches in long-term stock index futures price forecasting.The complexity in stock index futures markets, influenced by the intricate interplay of human behavior, is characterized as nonlinearity and dynamism, contributing to significant uncertainty in long-term price forecasting. While machine learning models have demonstrated their efficacy in stock price forecasting, they rely solely on historical price data, which, given the inherent volatility and dynamic nature of financial markets, are insufficient to address the complexity and uncertainty in long-term forecasting due to the limited connection between historical and forecasting prices. This paper introduces a pioneering approach that integrates financial theory with advanced deep learning methods to enhance predictive accuracy and risk management in China's stock index futures market. The SF-Transformer model, combining spot-forward parity and the Transformer model, is proposed to improve forecasting accuracy across short and long-term horizons. Formulated upon the arbitrage-free futures pricing model, the spot-forward parity model offers variables such as stock index price, risk-free rate, and stock index dividend yield for forecasting. Our insight is that the mutual information generated by these variables has the potential to significantly reduce uncertainty in long-term forecasting. A case study on predicting major stock index futures prices in China demonstrates the superiority of the SF-Transformer model over models based on LSTM, MLP, and the stock index futures arbitrage-free pricing model, covering both short and long-term forecasting up to 28 days. Unlike existing machine learning models, the Transformer processes entire time series concurrently, leveraging its attention mechanism to discern intricate dependencies and capture long-range relationships, thereby offering a holistic understanding of time series data. An enhancement of mutual information is observed after introducing spot-forward parity in the forecasting. The variation of mutual information and ablation study results highlights the significant contributions of spot-forward parity, particularly to the long-term forecasting. Overall, these findings highlight the SF-Transformer model's efficacy in leveraging spot-forward parity for reducing uncertainty and advancing robust and comprehensive approaches in long-term stock index futures price forecasting.","https://www.proquest.com/docview/3072294721?accountid=12870&bdid=124553&_bd=3n6Xt6rwgN6BkCdt4VeUo4DwBds%3D","https://doi.org/10.3390/e26060478"
"On multicollinearity and the value of the shape parameter in the term structure Nelson-Siegel model","","León, Angel; Rubia, Antonio; Sanchis-Marco, Lidia","Aestimatio","Scholarly Journals","","","16","2018-01-01","2018","8","","8-29","21730164","","","ENG","This paper investigates the sensitivity of the dynamic Nelson-Siegel factor loadings to the value of the shape parameter, λ. It also analyses the multicollinearity problem and addresses how to mitigate this issue in the estimation process. First, we find that the selection of a fixed λ is not optimal due to the collinearity problems. Second, we observe a substantial difference between the forecasting performance of the traditional estimation procedures and that of the ridge regression approach. Finally, we implement a Monte Carlo simulation exercise in order to study the statistical distribution of the estimates of the model parameters and thus determine the extent to which they differ from the real values. Furthermore, we find that multicollinearity between the factors of the NS model can, in the case of ordinary least squares estimation with a fixed parameter λ, result in greater differences between the estimates and the actual parameter values. Ridge regression corrects such differences and produces more stable estimates than the ordinary linear and nonlinear least squares methods.","https://www.proquest.com/docview/1943517750?accountid=12870&bdid=124553&_bd=OOQV2Ojz%2BJUWsGufE1zHu8TvBO0%3D","https://doi.org/10.5605/IEB.16.1"
"Machine learning algorithms applied to the estimation of liquidity: the 10-year United States treasury bond","","Luque Raya, Ignacio Manuel; Pablo Luque Raya","European Journal of Management and Business Economics","Scholarly Journals","","33","3","2024-07-01","2024","341","365","341-365","24448451","","","SPA","PurposeHaving defined liquidity, the aim is to assess the predictive capacity of its representative variables, so that economic fluctuations may be better understood.Design/methodology/approachConceptual variables that are representative of liquidity will be used to formulate the predictions. The results of various machine learning models will be compared, leading to some reflections on the predictive value of the liquidity variables, with a view to defining their selection.FindingsThe predictive capacity of the model was also found to vary depending on the source of the liquidity, in so far as the data on liquidity within the private sector contributed more than the data on public sector liquidity to the prediction of economic fluctuations. International liquidity was seen as a more diffuse concept, and the standardization of its definition could be the focus of future studies. A benchmarking process was also performed when applying the state-of-the-art machine learning models.Originality/valueBetter understanding of these variables might help us toward a deeper understanding of the operation of financial markets. Liquidity, one of the key financial market variables, is neither well-defined nor standardized in the existing literature, which calls for further study. Hence, the novelty of an applied study employing modern data science techniques can provide a fresh perspective on financial markets.","https://www.proquest.com/docview/3069047528?accountid=12870&bdid=124553&_bd=FIfzQa3E%2BwMsYeuwBEY3ApugOTI%3D","https://doi.org/10.1108/EJMBE-06-2022-0176"
"A comparison of machine learning and econometric models for pricing perpetual Bitcoin futures and their application to algorithmic trading","","Malik, Avinash","Expert Systems","Scholarly Journals","","40","10","2023-12-01","Dec 2023","","","","02664720","","","ENG","Bitcoin (BTC) perpetual futures contracts are highly leveraged speculative trading instruments with daily market trading of $45 Billion. BTC perpetual futures are derivative contracts, which depend upon the underlying BTC SPOT (current) price. Pricing perpetual futures fairly is hard, using traditional arbitrage arguments, because of the volatile nature of the so called funding rate, which is used as the replacement of risk free rate in the Cryptocurrency market. This work presents a novel technique for pricing BTC futures contracts using conditional volatility and mean models. Intra‐day high‐frequency futures' return volatility and mean are modelled using different ML and econometric techniques. A comparison is made using statistical measures to find the model that best captures the intra‐day conditional mean and volatility. Exponential generalized autoregressive conditional heteroskedasticity is shown to be an almost unbiased predictor of intra‐day volatility, while a constant autoregressive moving average (0, 0) model best captures the conditional mean of the returns. A market directional high frequency trading algorithm is developed using the volatility and mean models. The algorithm first prices the futures contract at some future point of time using the volatility and mean regression models. Next, the slope between the current futures price and the expected price are used to predict the market direction. A long or short position is taken depending upon the expected market direction movement. Extensive back‐testing results show absolute returns of 1500%–8000% depending upon the transaction fees and leverage used. On average, the market direction is predicted correctly 85% of the time by the best model. Finally, the trading technique is market neutral, in that it gives large positive returns, with low SD, in both bull and bear markets.","https://www.proquest.com/docview/2885381987?accountid=12870&bdid=124553&_bd=t4xi5NCvbOtLeEASw4jBEigWJnc%3D","https://doi.org/10.1111/exsy.13414"
"Algorithmic sign prediction and covariate selection across eleven international stock markets","","Karhunen, Markku","Expert Systems with Applications","Scholarly Journals","","115","","2019-01-01","Jan 2019","256","","","0957-4174","","","ENG","I investigate whether an expert system can be used for profitable long-term asset management. The trading strategy of the expert system needs to be based on market predictions. To this end, I generate binary predictions of the market returns by using statistical and machine-learning algorithms. The methods used include logistic regressions, regularized logistic regressions and similarity-based classification. I test the methods in a contemporary data set involving data from eleven developed markets. Both statistical and economic significance of the results are considered. As an ensemble, the results seem to indicate that there is some degree of mild predictability in the stock markets. Some of the results obtained are highly significant in the economic sense, featuring annualized excess returns of 3.1% (France), 2.9% (Netherlands) and 0.8% (United States). However, statistically significant results are seldom found. Consequently, the results do not completely invalidate the efficient-market hypothesis.","https://www.proquest.com/docview/2131210345?accountid=12870&bdid=124553&_bd=1%2FUCVqheFr5KVAbtnPkRogobZwk%3D",""
"Green bonds forecasting: evidence from pre-crisis, Covid-19 and Russian–Ukrainian crisis frameworks","","Souhir Amri Amamou; Mouna Ben Daoud; Bargaoui, Saoussen Aguir","Journal of Economic Studies","Scholarly Journals","","52","1","2025-01-01","2025","179","193","179-193","01443585","","","ENG","PurposeWithout precedent, green bonds confront, for the first time since their emergence, a twofold crisis context, namely the Covid-19-Russian–Ukrainian crisis period. In this context, this paper aims to investigate the connectedness between the two pioneering bond market classes that are conventional and treasury, with the green bonds market.Design/methodology/approachIn their forecasting target, authors use a Support Vector Regression model on daily S&P 500 Green, Conventional and Treasury Bond Indexes for a year from 2012 to 2022.FindingsAuthors argue that conventional bonds could better explain and predict green bonds than treasury bonds for the three studied sub-periods (pre-crisis period, Covid-19 crisis and Covid-19-Russian–Ukrainian crisis period). Furthermore, conventional and treasury bonds lose their forecasting power in crisis framework due to enhancements in market connectedness relationships. This effect makes spillovers in bond markets more sensitive to crisis and less predictable. Furthermore, this research paper indicates that even if the indicators of the COVID-19 crisis have stagnated and the markets have adapted to this rather harsh economic framework, the forecast errors persist higher than in the pre-crisis phase due to the Russian–Ukrainian crisis effect not yet addressed by the literature.Originality/valueThis study has several implications for the field of green bond forecasting. It not only illuminates the market participants to the best market forecasters, but it also contributes to the literature by proposing an unadvanced investigation of green bonds forecasting in Crisis periods that could help market participants and market policymakers to anticipate market evolutions and adapt their strategies to period specificities.","https://www.proquest.com/docview/3149227402?accountid=12870&bdid=124553&_bd=2x%2Ft6rKMZEC%2BNTBXBFpyKkbGxBU%3D","https://doi.org/10.1108/JES-01-2024-0061"
"DISAPPROPRIATION","","Lawrence, Matthew B","Columbia Law Review","Scholarly Journals","","120","1","2020-01-01","Jan 2020","1","89","1-89","00101958","","","ENG","In recent years, Congress has repeatedly failed to appropriate funds necessary to honor legal commitments (or entitlements) that are themselves enacted in permanent law. The Appropriations Clause has forced the government to defy legislative command and break such commitments, with destructive results for recipients and the rule of law. This Article is the first to address this poorly understood phenomenon, which it labels a form of ""disappropriation."" The Article theorizes recent high-profile disappropriations as one probabilistic consequence of Congress's decision to create permanent legislative payment commitments that the government cannot honor without periodic, temporary appropriations. Such partially temporary programs include Medicaid and scores of other important, permanent features of the administrative state. The Article's core descriptive contribution is to explain that while dissonance between Congress's legislative and appropriations powers creates the destructive possibility of disappropriation, it can also preserve for Congress enduring influence (over the executive) and majoritarian control (against the ""dead hand"" and leadership) that Congress would surrender if it instead exercised both its legislative and appropriations powers permanently. This insight-that Congress's ability to legislate permanently but appropriate temporarily makes disappropriation possible but also alters he balance of powers-has theoretical implications for constitutional doctrine, the separation of powers, the design of new legislative commitments, and efforts to reduce the harms of disappropriation. The Article's normative component addresses the regulation and assdjudication of disappropriation in light of these implications. It conceptualizes shutdowns as aggregations of distinctive disappropriations and cautions that prior scholarly analyses of proposals to prevent shutdowns by financially penalizing legislators for failing to appropriate funds necessary to honor pre-existing commitments are incomplete because they fail to consider upstream impacts on the balance of powers. And it explains that courts could play a salutary role without interfering with the balance of powers by favoring rules that promote durability but not entrenchment, that is, by adopting rules that tend to reduce the ex ante likelihood of disappropriation without undermining the credibility of the threat of disappropriation. In practice, this weighs in favor of judicial approaches that prevent inadvertent disappropriation by reducing uncertainty and private information. Courts should therefore adopt an interpretive presumption against disappropriation, empower civil servants to enforce disappropriation ex ante rather than empower Congress to do so ex post (as the House of Representatives sought to do in House v. Burwell), and endeavor to adjudicate actions seeking damages in the aftermath of disappropriation in ways that make the availability of such damages more predictable while avoiding interference with the political branches.","https://www.proquest.com/docview/2382073681?accountid=12870&bdid=124553&_bd=OkGwpzB62mUP%2FrHZuIZTWeDgfcQ%3D",""
"Do Post-Corona European Economic Policies Lift Growth Prospects? Exploring an ML-Methodology","","Herzog, Bodo","Journal of Risk and Financial Management","Scholarly Journals","","15","3","2022-01-01","2022","120","","","19118066","","","ENG","This article explores the determinants of people’s growth prospects in survey data as well as the impact of the European recovery fund to future growth. The focus is on the aftermath of the Corona pandemic, which is a natural limit to the sample size. We use Eurobarometer survey data and macroeconomic variables, such as GDP, unemployment, public deficit, inflation, bond yields, and fiscal spending data. We estimate a variety of panel regression models and develop a new simulation-regression methodology due to limitation of the sample size. We find the major determinant of people’s growth prospect is domestic GDP per capita, while European fiscal aid does not significantly matter. In addition, we exhibit with the simulation-regression method novel scientific insights, significant outcomes, and a policy conclusion alike.","https://www.proquest.com/docview/2642460294?accountid=12870&bdid=124553&_bd=7g1q0hMhvDkVVEzYPfCc7v1qY5c%3D","https://doi.org/10.3390/jrfm15030120"
"Forecasts from a nonlinear T-bill rate model","","Larrain, Maurice; Pagano, Michael","Financial Analysts Journal","Scholarly Journals","","49","6","1993-11-01","Nov/Dec 1993","83","","83","0015198X","","","ENG","An analysis evaluated out-of-sample forecasts of the US 90-day Treasury bill rate generated by a nonlinear structure.  The nonlinear model used is based on earlier work by Larrain (1991).  It contains 2 main components: 1.  the K-map, which includes lagged, nonlinear forms of the T-bill interest rate, and 2.  the Z-map, which comprises macroeconomic variables such as GNP, inflation, the money supply, and wealth.  The K-map represents the nonlinear technical component of the model, while the Z-map captures the behavioral influences on short-term interest rates.  The model was tested using quarterly data for the 90-day US Treasury bill rate for the period 1962:1-1988:1.  It is shown that a nonlinear T-bill rate model can be used to forecast out-of-sample interest rates.  The resulting forecasts represent a genuine improvement over naive forecasts.  The nonlinear model yielded consistent directional changes that anticipated actual interest rate turning points over the 3-year forecasting period.","https://www.proquest.com/docview/219199157?accountid=12870&bdid=124553&_bd=WqjgDcTgxgDpQg1RWpLkkcRYYN8%3D",""
"Estimating latent asset-pricing factors","","Lettau, Martin; Pelger, Markus","Journal of econometrics","Undefined","Elsevier B.V.","218","1 p.1-31","2020-09-01","Sep 2020","1","31","p. 1-31","0304-4076","0304-4076","","ENG","We develop an estimator for latent factors in a large-dimensional panel of financial data that can explain expected excess returns. Statistical factor analysis based on Principal Component Analysis (PCA) has problems identifying factors with a small variance that are important for asset pricing. We generalize PCA with a penalty term accounting for the pricing error in expected returns. Our estimator searches for factors that can explain both the expected return and covariance structure. We derive the statistical properties of the new estimator and show that our estimator can find asset-pricing factors, which cannot be detected with PCA, even if a large amount of data is available. Applying the approach to portfolio data we find factors with Sharpe-ratios more than twice as large as those based on conventional PCA and with smaller pricing errors.","https://www.proquest.com/docview/2400446560?accountid=12870&bdid=124553&_bd=MHExl4T4Vxq625UdfBK0LI0CIsY%3D","https://doi.org/10.1016/j.jeconom.2019.08.012"
"Exploring External Influences on Cryptocurrency Prices: Using A Multi-Analytical Approach","","Daruwala, Zaheda","International Journal of Economics and Financial Issues","Scholarly Journals","","15","4","2025-01-01","2025","363","","363-377","21464138","","","ENG","Cryptocurrencies have experienced exponential growth within the last decade, with market capitalization hovering above the one-trillion-dollar mark since 2022. One area of concern for current and potential crypto users and investors is their unprecedented price volatility. As cryptos become interlinked with the regulated financial system, questions emerge regarding the possibility of linkages of their prices to the external environments. Financial and macroeconomic factors of inflation, economic growth, interest rates, currency exchange rates, equity market returns, corporate bond yields, gold and oil prices are examined against the cryptocurrency returns. This study encompasses a multi-analytical approach, firstly with the empirical tests of Spearman’s correlational analysis to discover the most pertinent relationships, followed by the PCA analysis to reduce redundancy. The predictive regression model of the Granger Causality test, a vector autoregression (VAR) time series forecasting method, is applied to examine whether the highly effective factors Granger cause the crypto price movements. The Machine Learning Random Forest Regression is also applied where a nuanced understanding of the external factors affecting cryptos prices is gained. The findings of this study pertain to more recent times when the pandemic crisis has subsided and stable economies are in place. The results examined four major cryptos of Bitcoin, Binance Coin, Ripple and Tether, where most behaviours suggest that users and investors are willing to take on riskier assets during periods of economic growth, a strong equity market complements crypto demands and gold and oil are good substitutes for cryptos. Tether, a stablecoin, was the least impacted by external factors and behaved similarly to a fiat currency. This investigation into external factors will empower cryptocurrency users and investors with valuable insights into the crypto price mechanisms, enabling them to refine their investing and portfolio diversification strategies.","https://www.proquest.com/docview/3219806333?accountid=12870&bdid=124553&_bd=Yenlq010%2Fd07dT%2Bfl%2FdD4n56Eo8%3D","https://doi.org/10.32479/ijefi.19455"
"Modeling Multi-horizon Electricity Demand Forecasts in Australia: A Term Structure Approach","","Hurn, Stan; Vance, Martin; Tian, Jing","The Energy Journal","Scholarly Journals","","44","3","2023-05-01","May 2023","","","","01956574","","","ENG","The Australian Electricity Market Operator generates one-day ahead electricity demand forecasts for the National Electricity Market in Australia and updates these forecasts over time until the time of dispatch. Despite the fact that these forecasts play a crucial role in the decision-making process of market participants, little attention has been paid to their evaluation and interpretation. Using half-hourly data from 2011 to 2015 for New South Wales and Queensland, it is shown that the official half-hourly demand forecasts do not satisfy the econometric properties required of rational forecasts. Instead there is a relationship between forecasts and forecast horizon similar to a term structure model of interest rates. To study the term structure of demand forecasts, a factor analysis that uses a small set of latent factors to explain the common variation among multiple observables is implemented. A three-factor model is identified with the factors admitting interpretation as the level, slope and curvature of the term structure of forecasts. The validity of the model is reinforced by assessing the economic value of demand forecasts. It is demonstrated that simple adjustments to long-horizon electricity demand forecasts based on the three estimated factors can enhance the informational content of the official forecasts.","https://www.proquest.com/docview/2802919914?accountid=12870&bdid=124553&_bd=kDbTcB3e9yKmpw1AL0mDaKdzfgY%3D","https://doi.org/10.5547/01956574.44.2.shur"
"Will the Emperor Discover He Has No Clothes Before the Empire Is Sold?","","Bucks, Dan R","National Tax Journal","Scholarly Journals","","44","3","1991-09-01","Sep 1991","311","","311","00280283","","","ENG","Transfer pricing and the failure of the arms length method to correctly attribute income to taxing jurisdictions is a major problem in US tax policy.  The Subcommittee on Oversight of the House Ways and Means Committee has estimated that the federal government is losing $30 billion annually as a result of transfer pricing problems relating to US subsidiaries of foreign multinationals.  While the US Treasury Department believes that the problem is covered by arms length pricing adjustments, thus far, the arms length pricing policy method has failed.  The Treasury Department has broad legal authority to adopt methods beyond this narrow technique.  The transfer pricing problem should occupy the best efforts and attention of the scholars and public and private practitioners who make up the core of the US tax community.  Major lines of inquiry and dialogue are needed to find alternative solutions to this problem.","https://www.proquest.com/docview/203292021?accountid=12870&bdid=124553&_bd=uPwTlMtaZefw%2F9YZBei18Plvvq0%3D",""
"Long-term fiscal implications of funding assisted reproduction: a generational accounting model for Spain","","Matorras, R; Villoro, R; González-Domínguez, A; Pérez-Camarero, S; Hidalgo-Vega, A; Polanco, C","Reproductive biomedicine & society online","Undefined","","1","2","2015-12-01","Dec 2015","113","","113-122","2405-6618","","","ENG","The aim of this study was to assess the lifetime economic benefits of assisted reproduction in Spain by calculating the return on this investment. We developed a generational accounting model that simulates the flow of taxes paid by the individual, minus direct government transfers received over the individual's lifetime. The difference between discounted transfers and taxes minus the cost of either IVF or artificial insemination (AI) equals the net fiscal contribution (NFC) of a child conceived through assisted reproduction. We conducted sensitivity analysis to test the robustness of our results under various macroeconomic scenarios. A child conceived through assisted reproduction would contribute €370,482 in net taxes to the Spanish Treasury and would receive €275,972 in transfers over their lifetime. Taking into account that only 75% of assisted reproduction pregnancies are successful, the NFC was estimated at €66,709 for IVF-conceived children and €67,253 for AI-conceived children. The return on investment for each euro invested was €15.98 for IVF and €18.53 for AI. The long-term NFC of a child conceived through assisted reproduction could range from €466,379 to €-9,529 (IVF) and from €466,923 to €-8,985 (AI). The return on investment would vary between €-2.28 and €111.75 (IVF), and €-2.48 and €128.66 (AI) for each euro invested. The break-even point at which the financial position would begin to favour the Spanish Treasury ranges between 29 and 41 years of age. Investment in assisted reproductive techniques may lead to positive discounted future fiscal revenue, notwithstanding its beneficial psychological effect for infertile couples in Spain.The aim of this study was to assess the lifetime economic benefits of assisted reproduction in Spain by calculating the return on this investment. We developed a generational accounting model that simulates the flow of taxes paid by the individual, minus direct government transfers received over the individual's lifetime. The difference between discounted transfers and taxes minus the cost of either IVF or artificial insemination (AI) equals the net fiscal contribution (NFC) of a child conceived through assisted reproduction. We conducted sensitivity analysis to test the robustness of our results under various macroeconomic scenarios. A child conceived through assisted reproduction would contribute €370,482 in net taxes to the Spanish Treasury and would receive €275,972 in transfers over their lifetime. Taking into account that only 75% of assisted reproduction pregnancies are successful, the NFC was estimated at €66,709 for IVF-conceived children and €67,253 for AI-conceived children. The return on investment for each euro invested was €15.98 for IVF and €18.53 for AI. The long-term NFC of a child conceived through assisted reproduction could range from €466,379 to €-9,529 (IVF) and from €466,923 to €-8,985 (AI). The return on investment would vary between €-2.28 and €111.75 (IVF), and €-2.48 and €128.66 (AI) for each euro invested. The break-even point at which the financial position would begin to favour the Spanish Treasury ranges between 29 and 41 years of age. Investment in assisted reproductive techniques may lead to positive discounted future fiscal revenue, notwithstanding its beneficial psychological effect for infertile couples in Spain.","https://www.proquest.com/docview/2056763631?accountid=12870&bdid=124553&_bd=PIKzcZG95IgY%2BkhurLjhym7E7yE%3D","https://doi.org/10.1016/j.rbms.2016.04.001"
"Asian holding of US Treasury securities: trade integration as a threshold","","Terada-Hagiwara, Akiko","Journal of the Japanese and international economies","Undefined","","25","3","2011-09-01","Sep 2011","321","335","321-335","0889-1583","0889-1583","","ENG","This paper empirically investigates if there have been any shifts in regimes with Asian holding of US long-term Treasury securities with particular attention paid to the role of growing regional integration in trade. A panel regression estimation of eight Asian countries for 1998-2004 confirms the striking persistency of the portfolio weight of US Treasury securities. It also reveals, without a surprise, that the traditionally strong trade link with US as well as exchange rate regime and volatility of local currency bond index explain observed overinvestment in US Treasury securities deviating from what can be warranted by the market share of the US Treasury securities. What is interesting, however, is the estimated regime switches as found when examined with a threshold estimation (Hansen, 1999). We find three thresholds which divide the sample into four regimes-a decreasing persistency as intraregional trade link becomes tighter. All rights reserved, Elsevier","https://www.proquest.com/docview/889174699?accountid=12870&bdid=124553&_bd=Pv%2BX2sH5HNIfXGgUHlZrZgU0lcA%3D","https://doi.org/10.1016/j.jjie.2011.07.001"
"United States banking stability: An explanation through machine learning","","Fernández Fernández, José Alejandro","Banks and Bank Systems","Scholarly Journals","","15","4","2020-01-01","2020","137","","137-149","18167403","","","ENG","In this paper, an analysis of the prediction of bank stability in the United States from 1990 to 2017 is carried out, using bank solvency, delinquency and an ad hoc bank stability indicator as variables to measure said stability. Different machine learning assembly models have been used in the study, a random forest is developed because it is the most accurate of all those tested. Another novel element of the work is the use of partial dependency graphs (PDP) and individual conditional expectation curves (ICES) to interpret the results that allow observing for specific values how the banking variables vary, when the macro-financial variables vary.It is concluded that the most determining variables to predict bank solvency in the United States are interest rates, specifically the mortgage rate and the 5 and 10-year interest rates of treasury bonds, reducing solvency as these rates increase. For delinquency, the most important variable is the unemployment rate in the forecast. The financial stability index is made up of the normalized difference between the two factors obtained, one for solvency and the other for delinquency. The index prediction concludes that stability worsens as BBB corporate yield increases.","https://www.proquest.com/docview/2477707782?accountid=12870&bdid=124553&_bd=SgArmyQJoZZ3ZAYLmTTIGdClvVc%3D","https://doi.org/10.21511/bbs.15(4).2020.12"
"Nonlinear structural estimation of corporate bond liquidity","","","Review of Quantitative Finance and Accounting","Scholarly Journals","","64","2","2025-02-01","Feb 2025","799","827","799-827","0924865X","","","ENG","We estimate the term structure of corporate bond liquidity premiums using a dual estimation technique. Our estimates reveal that the term structures of the liquidity premiums were positively sloped and concave for each category of creditworthiness and in three economic epochs. As the macroeconomy transitioned from a pre-crisis to a crisis period, liquidity premiums elevated across time to maturity for both investment grade and speculative grade bonds. With the migration of the financial system from stress to relative calm, the premiums on both grades of debt declined for all maturities.","https://www.proquest.com/docview/3162425844?accountid=12870&bdid=124553&_bd=PVpwWd1zXgtbZOQWABQufPPA9AM%3D","https://doi.org/10.1007/s11156-024-01323-y"
"Dimension Reduction via Penalized GLMs for Non-Gaussian Response: Application to Stock Market Volatility","","Li, Tao; Li, Tao; Li, Tao; Desmond, Anthony F; Stengos, Thanasis","Journal of Risk and Financial Management","Scholarly Journals","","14","12","2021-01-01","2021","583","","","19118066","","","ENG","We fit U.S. stock market volatilities on macroeconomic and financial market indicators and some industry level financial ratios. Stock market volatility is non-Gaussian distributed. It can be approximated by an inverse Gaussian (IG) distribution or it can be transformed by Box–Cox transformation to a Gaussian distribution. Hence, we used a Box–Cox transformed Gaussian LASSO model and an IG GLM LASSO model as dimension reduction techniques and we attempted to identify some common indicators to help us forecast stock market volatility. Via simulation, we validated the use of four models, i.e., a univariate Box–Cox transformation Gaussian LASSO model, a three-phase iterative grid search Box–Cox transformation Gaussian LASSO model, and both canonical link and optimal link IG GLM LASSO models. The latter two models assume an approximately IG distributed response. Using these four models in an empirical study, we identified three macroeconomic indicators that could help us forecast stock market volatility. These are the credit spread between the U.S. Aaa corporate bond yield and the 10-year treasury yield, the total outstanding non-revolving consumer credit, and the total outstanding non-financial corporate bonds.","https://www.proquest.com/docview/2612803877?accountid=12870&bdid=124553&_bd=62%2BsLgFxyxw06uYgZO1ff9E2ty4%3D","https://doi.org/10.3390/jrfm14120583"
"An automated financial indices-processing scheme for classifying market liquidity regimes","","Gu, Xing; Mamon, Rogemar; Davison, Matt; Yu, Hao","International Journal of Control","Scholarly Journals","","94","3","2021-03-01","Mar 2021","735","756","735-756","00207179","","","ENG","A multivariate hidden Markov model (HMM)-based approach is developed to capture simultaneously the regime-switching dynamics of four financial market indicators: Treasury-Euro Dollar rate spread, US dollar index, volatility index and S&P 500 bid-ask spread. These indicators exhibit stochasticity, mean reversion, spikes and state memory, and they are deemed to drive the main characteristics of liquidity risk and regarded to mirror financial markets' liquidity levels. In this paper, an online system is proposed in which observed indicators are processed and the results are then interfaced with an advanced alert mechanism that gives out appropriate measures. In particular, two stochastic models, with HMM-modulated parameters switching between liquidity regimes, are integrated to capture the evolutions of the four time series or their transformations. Parameter estimation is accomplished by deriving adaptive multivariate filters. Indicators' joint empirical characteristics are captured well and useful early warnings are obtained for occurrence prediction of illiquidity episodes.","https://www.proquest.com/docview/2490842005?accountid=12870&bdid=124553&_bd=XtndqrcmCdh7l6fV8lswCyyzmYc%3D","https://doi.org/10.1080/00207179.2019.1616225"
"Comprehensive evidence implies a higher social cost of CO2","","Rennert, Kevin; Errickson, Frank; Prest, Brian C; Rennels, Lisa; Newell, Richard G; Pizer, William; Kingdon, Cora; Wingenroth, Jordan; Cooke, Roger; Parthum, Bryan; Smith, David; Cromar, Kevin; Diaz, Delavane; Moore, Frances C; Müller, Ulrich K; Plevin, Richard J; Raftery, Adrian E; Ševčíková, Hana; Sheets, Hannah; Stock, James H; Tan, Tammy; Watson, Mark; Wong, Tony E; Anthoff, David","Nature","Scholarly Journals","","610","7933","2022-10-27","Oct 27, 2022","687","692H","687-692,692A-692H","00280836","","","ENG","The social cost of carbon dioxide (SC-CO2) measures the monetized value of the damages to society caused by an incremental metric tonne of CO2 emissions and is a key metric informing climate policy. Used by governments and other decision-makers in benefit-cost analysis for over a decade, SC-CO2 estimates draw on climate science, economics, demography and other disciplines. However, a 2017 report by the US National Academies of Sciences, Engineering, and Medicine1 (NASEM) highlighted that current SC-CO2 estimates no longer reflect the latest research. The report provided a series ofrecommendations for improving the scientific basis, transparency and uncertainty characterization of SC-CO2 estimates. Here we show that improved probabilistic socioeconomic projections, climate models, damage functions, and discounting methods that collectively reflect theoretically consistent valuation of risk, substantially increase estimates of the SC-CO2. Our preferred mean SC-CO2 estimate is $185 per tonne ofCO2 ($44-$413 per tCO2: 5%-95% range, 2020 US dollars) at a near-term risk-free discount rate of 2%, a value 3.6 times higher than the US government's current value of $51per tCO2. Our estimates incorporate updated scientific understanding throughout all components of SC-CO2 estimation in the new open-source Greenhouse Gas Impact Value Estimator (GIVE) model, in a manner fully responsive to the near-term NASEM recommendations. Our higher SC-CO2 values, compared with estimates currently used in policy evaluation, substantially increase the estimated benefits of greenhouse gas mitigation and thereby increase the expected net benefits of more stringent climate policies.","https://www.proquest.com/docview/2729973697?accountid=12870&bdid=124553&_bd=rAoAs0Z13DO4qJfquiBo4%2BWYqsU%3D","https://doi.org/10.1038/s41586-022-05224-9"
"Digital transformation: statistical evaluation of success factors of an ICO-campaign","","Rasskazova, Albina; Koroleva, Elena; Rasskazov, Sergey","IOP Conference Series. Materials Science and Engineering","Scholarly Journals","","497","1","2019-03-01","Mar 2019","","","","17578981","","","ENG","High rates of growth of the ICO market and its excess returns stipulate a significant interest of investors to projects which use initial token allocation (ICO) for attracting investments. This work takes into account the fact that even a potentially profitable project may fail to collect the required amount of money and to start placing tokens on the stock exchange. We are speaking about success of an ICO-campaign for fund raising. In order to estimate the influence of factors and check the suggested research hypotheses, logistic regression was used. The selection included 672 projects. As a dependent variable, the proportion of the amount collected in the ICO process from the required value is selected. Depending on the tested hypothesis the influencing variables took into account the presence of a pre-sale stage and the bounty program and also the price of the token, the upper limit of fund raising, the duration of the ICO-campaign and the number of team members. The work results allow token emitters to substantiate managing the success of the ICO-campaign of the project and the investors to see whether it deserves their attention. Besides, the obtained materials can be useful for specialists in forming the legal framework of token transactions.","https://www.proquest.com/docview/2560938521?accountid=12870&bdid=124553&_bd=G1dMXa2fne3iYc2%2BvA4pLXO994g%3D","https://doi.org/10.1088/1757-899X/497/1/012087"
"Nonlinear least squares estimator for generalized diffusion processes with reflecting barriers","","Han, Yuecai; Zhang, Dingwen","Stochastics","Scholarly Journals","","97","1","2025-01-01","Jan 2025","1","20","1-20","17442508","","","ENG","In this paper, we investigate the parameter estimation problem for generalized diffusion processes with two-sided reflected barriers. The estimator is obtained using the nonlinear least squares method based on discretely observed processes. Under certain regularity conditions, we obtain consistency and establish the asymptotic normality of the proposed estimator. Our method can be readily applied to the one-sided reflected diffusion processes. Numerical results, including a two-factor financial model, show that the proposed estimator performs well with large sample sizes. The U.S. treasury rate data is used to illustrate the theoretical results.","https://www.proquest.com/docview/3152800373?accountid=12870&bdid=124553&_bd=KPBXXJ5y2KKlFz4KJduPOxKzvjQ%3D","https://doi.org/10.1080/17442508.2024.2393257"
"Tail-dependence in stock-return pairs","","Fortin, Ines; Kuzmics, Christoph","International Journal of Intelligent Systems in Accounting, Finance and Management","Scholarly Journals","","11","2","2002-04-01","Apr/Jun 2002","89","","89","1500615X","","","ENG","The lower-of-cost-or-market principle implies that assets may be sold above book value, by which hidden reserves are disclosed. To avoid taxation of these hidden reserves, in German-speaking countries       companies are allowed to transfer them to a newly purchased asset within a fixed time period. In this       paper, the optimal timing of hidden reserves transfers is developed with special attention to the term       structure of interest rates and interest rate risk, and using the replicating principle known from the field       of finance. The paper presents one model under certainty and, as a generalization of this model, another       model under interest rate risk. In both models, the criterion used for decision-making is the value of the       right to transfer, which can be interpreted as the initial cost of a replicating/hedging strategy for tax       payments saved/incurred. In the model under certainty, the net present value concept is used to derive       the value of the right to transfer. The procedure used in the model under interest rate risk is a       combination of flexible planning and the no-arbitrage approach common in derivatives pricing. It is       shown that the right to transfer hidden reserves with flexible timing is equivalent to an American-style       exchange option. In addition, the impact of term-structure volatility on the value of the right to transfer       is analyzed. The technique presented in this paper can also be used to solve other timing problems       resulting from trade-offs between early and late tax payments/tax benefit. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/214362631?accountid=12870&bdid=124553&_bd=8ix%2Ba91M49H%2BoU8LymB%2Fx9fHI2k%3D",""
"On the Nonlinear Specifications of Short-Term Interest Rate Behavior: Evidence from Euro-Currency Markets","","Chiang, Thomas C; Jeanette Jin Chiang","Review of Quantitative Finance and Accounting","Scholarly Journals","","12","4","1999-06-01","Jun 1999","351","","351-370","0924865X","","","ENG","This paper presents a coherent nonlinear interest rate model that incorporates the dynamics of the error correction specification into the traditional term structure model. The joint tests based on six Euro-Currency rates indicate that the linear specification should be rejected. The estimated equation suggests that the linear components - the change of the long-term interest rate and the error correcting term are highly significant. The nonlinear components involving the higher order of the independent variables, the cross products, the lagged error squares, and/or the ARCH effect also present significant explanatory power for predicting short-term Euro-Currency rate changes, confirming the non-linear specifications. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/210309253?accountid=12870&bdid=124553&_bd=uHirKtv9H5PjZSsDfREKpz5qvF0%3D",""
"Legislative and Administrative Reforms in the Motor Carrier Industry and Returns to Stockholders","","Bruning, Edward R","Journal of Transport Economics and Policy","Scholarly Journals","","21","3","1987-09-01","Sep 1987","289","","289","00225258","","","ENG","Administrative and legislative actions have noticeably altered the relationship between the public and motor carriers.  To determine the reactions to various administrative and legislative events that took place between 1977 and 1980, an excess return-to-stockholders analysis was employed.  Data were obtained for 31 motor carriers from weekly issues of Transport Topics for the period January 1970-December 1981.  The study focused on the deviation between actual and expected rates of return.  Results indicated significant variations in returns during the period 1977-1986.  Cumulative prediction errors (CPE) were given special attention due to the gradual nature of the reform process.  Analysis also revealed that equity returns: 1.  climbed during the initial stages of economic reform, 2.  leveled off after the first year, and 3.  fell consistently throughout the remaining months of the implementation period.  No visible difference was apparent either in terms of absolute size or in the direction of change in monthly CPEs when the effects upon equity returns of administrative and legislative actions were contrasted.","https://www.proquest.com/docview/217074373?accountid=12870&bdid=124553&_bd=C2vXBCw5fU50Z5qBnPsMlb7JIP0%3D",""
"The Micromechanics of the Federal Funds Market: Implications for Day-of-the-Week Effects in Funds Rate Variability","","Spindt, Paul A; Hoffmeister, J Ronald","Journal of Financial and Quantitative Analysis","Scholarly Journals","","23","4","1988-12-01","Dec 1988","401","","401","00221090","","","ENG","Because of the central role it plays in monetary policy and the term structure, the federal funds rate is arguably the most important interest rate in the US capital market.  Day-of-the-week effects in the level and high-low trading range of the funds rate are examined by developing a model of the federal funds market.  Its predictions are tested using data for the period February 1984-December 1986.  Agents represented in the model include the Federal Reserve, a single large funds trading bank, and numerous institutions.  The 2 latter agents participate directly in the funds market.  It is demonstrated that in a continuous market with asynchronous trading, regulatory constraints and accounting conventions that focus agents' attention on discrete time instants have important implications for the dynamics of trading activity and realized market prices.","https://www.proquest.com/docview/211856744?accountid=12870&bdid=124553&_bd=tMHQPg7rkgY3zIOwk49%2B3tF1qzQ%3D",""
"The Use of Simulation in Vascular Surgery Education: Current State and Future Directions","","Fereydooni, Arash; Sgroi, Michael David","Seminars in vascular surgery","Undefined","","38","2","2025-06-01","Jun 2025","163","","163-171","1558-4518","","","ENG","Simulation-based training (SBT) has become essential in vascular surgery education, providing a risk-free environment for skill development. This scoping review evaluates the current state of vascular surgery simulation, highlighting validated models, educational impact, and areas for improvement. A systematic literature search was conducted in PubMed, Embase, and Scopus, following PRISMA-ScR guidelines. Studies assessing validated simulation models for open and endovascular procedures, vascular anastomosis, carotid interventions, peripheral vascular interventions, and nontechnical skills training were included. Data extraction focused on fidelity, skill acquisition, procedural efficiency, and accessibility. Validated high-fidelity models, including 3D-printed, virtual reality (VR), and pulsatile cadaveric systems, significantly enhance technical proficiency and confidence. Bench and porcine models improve vascular anastomosis training, while VR-based simulators enhance catheter manipulation and decision-making. However, simulation remains limited by high costs, accessibility challenges, and lack of standardized nontechnical skills training. Simulation improves competency in vascular surgery but requires further integration into training curricula. AI-driven assessments, hybrid simulation models, and expanded cost-effective solutions are needed to bridge existing gaps. Standardization and broader adoption of simulation will enhance competency-based training and improve patient outcomes.Simulation-based training (SBT) has become essential in vascular surgery education, providing a risk-free environment for skill development. This scoping review evaluates the current state of vascular surgery simulation, highlighting validated models, educational impact, and areas for improvement. A systematic literature search was conducted in PubMed, Embase, and Scopus, following PRISMA-ScR guidelines. Studies assessing validated simulation models for open and endovascular procedures, vascular anastomosis, carotid interventions, peripheral vascular interventions, and nontechnical skills training were included. Data extraction focused on fidelity, skill acquisition, procedural efficiency, and accessibility. Validated high-fidelity models, including 3D-printed, virtual reality (VR), and pulsatile cadaveric systems, significantly enhance technical proficiency and confidence. Bench and porcine models improve vascular anastomosis training, while VR-based simulators enhance catheter manipulation and decision-making. However, simulation remains limited by high costs, accessibility challenges, and lack of standardized nontechnical skills training. Simulation improves competency in vascular surgery but requires further integration into training curricula. AI-driven assessments, hybrid simulation models, and expanded cost-effective solutions are needed to bridge existing gaps. Standardization and broader adoption of simulation will enhance competency-based training and improve patient outcomes.","https://www.proquest.com/docview/3219323936?accountid=12870&bdid=124553&_bd=GcyTgojb65d8h3BwrFiiXrODvY8%3D","https://doi.org/10.1053/j.semvascsurg.2025.03.001"
"A New Credit Spread to Predict Economic Activities in China","","Wang, Lei; Nie, Changhong; Wang, Shouyang","Journal of Systems Science and Complexity","Scholarly Journals","","32","4","2019-01-01","2019","1140","1166","1140-1166","10096124","","","ENG","In recent years, the relationship between bond spreads and macro economy has been studied extensively by economists in western countries. However, few attentions were paid on this topic in China. This essay regards Chinese bond market as a complex system and constructs bond indices for China with the bottom-up approach. The authors use the data of 3,205 non-financial corporate bonds from February 2010 to October 2017 and construct a new spread noted as the PE_SOE spread. The authors find that the PE_SOE spread has a negative impact on economic activities and has the best predictive ability at short-run forecasting horizons, owing to the institutional superiority of the state-owned enterprises in China. The Treasury bond yields are found to have the best predictive ability at long-run horizons. Both spread shock and Treasury yield shock could lead to deflation and declines in economic activities, and the Treasury yield shock has a more severe and persistent impact on the economy due to the financial accelerator mechanism. PE_SOE spread is proved to be a better indicator for Chinese corporate bond market and can be widely used not only in future Chinese economic studies, but also for Chinese government’s macroeconomic monitoring and warning.","https://www.proquest.com/docview/2270055088?accountid=12870&bdid=124553&_bd=iE9x6uAG6kVvlfKouY%2BFgoR3AmM%3D","https://doi.org/10.1007/s11424-019-8033-3"
"Does high frequency trading affect technical analysis and market efficiency? And if so, how?","","Manahov, Viktor; Hudson, Robert; Gebka, Bartosz","Journal of international financial markets, institutions and money","Undefined","","28","","2014-01-01","Jan 2014","131","157","131-157","1042-4431","1042-4431","","ENG","In this paper we investigate how high frequency trading affects technical analysis and market efficiency in the foreign exchange (FX) market by using a special adaptive form of the Strongly Typed Genetic Programming (STGP)-based learning algorithm. We use this approach for real one-minute high frequency data of the most traded currency pairs worldwide: EUR/USD, USD/JPY, GBP/USD, AUD/USD, USD/CHF, and USD/CAD. The STGP performance is compared with that of parametric and non-parametric models and validated by two formal empirical tests. We perform in-sample and out-of-sample comparisons between all models on the basis of forecast performance and investment return. Furthermore, our paper shows the relative strength of these models with respect to the actual trading profit generated by their forecasts. Empirical experiments suggest that the STGP forecasting technique significantly outperforms the traditional econometric models. We find evidence that the excess returns are both statistically and economically significant, even when appropriate transaction costs are taken into account. We also find evidence that HFT has a beneficial role in the price discovery process. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/1521333006?accountid=12870&bdid=124553&_bd=756aLbfny8jsvu0WyG1dAHiPgzo%3D",""
"A Public Administration Moment: Forging an Agenda for Financial Regulatory Reform","","Khademian, Anne M","Public Administration Review","Scholarly Journals","","69","4","2009-07-01","Jul/Aug 2009","595","","595-602,561","00333352","","","ENG","The numbers are staggering. As the financial crisis deepens, American financial companies will lose an estimated $3.6 trillion in non-performing loans and lost asset value (Lohr 2009). Nationally, home prices have fallen more than 18% from peak levels -- as much as 40% in some states -- and in 2008, lenders initiated more than 2.25 million home foreclosures (Duke 2009). The biggest financial crisis since the Great Depression, as the Treasury Department describes it, is a crisis of confidence, of capital, of credit, and of consumer and business demand. Just as staggering, however, is the lack of attention given to the government administrative capacities that failed going into the crisis, and that require fervent attention as they grope toward a reengineered financial system and regulatory structure. Public administration scholars and practitioners play a vital role in forging the future of finance.","https://www.proquest.com/docview/197178280?accountid=12870&bdid=124553&_bd=lXgzA%2BCFtvog9RAkjT7dDoOfPFs%3D","https://doi.org/10.1111/j.1540-6210.2009.02008.x"
"The information in the term structure: A non-parametric investigation","","Mizrach, Bruce","Journal of Forecasting","Scholarly Journals","","15","3","1996-04-01","Apr 1996","137","","137","02776693","","","ENG","A non-linear term structure model is proposed that nests the discrete and continuous time models as special cases.  The model is estimated nonparametrically using nearest-neighbors regression.  In sample, the non-linear model matches the standard theories, but out of sample, it offers substantial improvement.  Linear models fail to track future interest rates: a random walk dominates the forward rate as a predictor for 3-month Treasury bills.  A non-linear forecast based on the spread is shown statistically to be the best forecast.","https://www.proquest.com/docview/219221764?accountid=12870&bdid=124553&_bd=BI3LIFVP%2F805uSpulG6m5Zmnys8%3D",""
"Optimal credit allocation under regime uncertainty with sensitivity analysis","","Bernis, Guillaume; Carassus, Laurence; Docq, Grégoire; Scotti, Simone","International journal of theoretical and applied finance","Undefined","","18","1","2015-02-01","Feb 2015","1550002","1-1550002-27","1550002-1-1550002-27","0219-0249","0219-0249","","ENG","We consider the problem of credit allocation in a regime-switching model. The global evolution of the credit market is driven by a benchmark, the drift of which is given by a two-state continuous-time hidden Markov chain. We apply filtering techniques to obtain the diffusion of the credit assets under partial observation and show that they have a specific excess return with respect to the benchmark. The investor performs a simple mean-variance allocation on credit assets. However, returns and variance matrix have to be computed by a numerical method such as Monte Carlo, because of the dynamics of the system and the non-linearity of the asset prices. We use the theory of Dirichlet forms to deal with the uncertainty on the excess returns. This approach provides an estimation of the bias and the variance of the optimal allocation, and return. We propose an application in the case of a sectorial allocation with Credit Default Swaps (CDS), fully calibrated with observable data or direct input given by the portfolio manager. Reprinted by permission of World Scientific Publishing","https://www.proquest.com/docview/1698954246?accountid=12870&bdid=124553&_bd=gczvObrYVAbMXGQ4sO7NHA0BsCY%3D","https://doi.org/10.1142/S0219024915500028"
"Climate, race, and the cost of capital in the municipal bond market","","Smull, Erika; Kodra, Evan; Stern, Adam; Teras, Andrew; Bonanno, Michael; Doyle, Martin","PLoS One","Scholarly Journals","","18","8","2023-08-01","Aug 2023","e0288979","","","19326203","","","ENG","Both climate risk and race are factors that may affect municipal bond yields, yet each has received relatively limited empirical research attention. We analyzed > 712,000 municipal bonds representing nearly 2 trillion USD in par outstanding, focusing on credit spread or the difference between a debt issuer’s interest cost to borrow and a benchmark “risk-free” municipal rate. The relationship between credit spread and physical climate risk is significant and slightly positive, yet the coefficient indicates no meaningful spread penalty for increased physical climate risk. We also find that racial composition (the percent of a community that is Black) explains a statistically significant and meaningful portion of municipal credit spreads, even after controlling for a variety of variables in domains such as geographic location of issuer, bond structure (e.g., bond maturity), credit rating, and non-race economic variables (e.g., per capita income). Assuming 4 trillion USD in annual outstanding par across the entire municipal market, and weighting each issuer by its percent Black, an estimated 19 basis point (bp) penalty for Black Americans sums to approximately 900 million USD annually in aggregate. Our combined findings indicate a systemic mispricing of risk in the municipal bond market, where race impacts the cost of capital, and climate does not.","https://www.proquest.com/docview/2848182040?accountid=12870&bdid=124553&_bd=s5qGCA%2Fg6ZeLmoVQ2k9Mj2ORjuk%3D","https://doi.org/10.1371/journal.pone.0288979"
"An indicator of future inflation extracted from the steepness of the interest rate yield curve along its entire length","","Frankel, Jeffery A; Lown, Cara S","The Quarterly Journal of Economics","Scholarly Journals","","109","2","1994-05-01","May 1994","517","","517","00335533","","","ENG","The term-structure slope contains information about expected future inflation.  Mishkin shows that the spread between the 12-month and 3-month interest rates helps predict the difference between 12-month and 3-month inflation.  An analysis applies a simple existing framework, which lets the real interest rate vary in the short run but converge to a constant in the long run, to this problem.  The appropriate indicator of expected inflation uses the entire length of the yield curve, estimating the steepness of a specific nonlinear transformation, rather than being restricted to a spread between 2 points.  The resulting indicator better predicts inflation, over 1960-1991.","https://www.proquest.com/docview/210999283?accountid=12870&bdid=124553&_bd=U%2BgKwsqaPCbKMUSxXYnyHjeRMrY%3D",""
"A hybrid EMD-AR model for nonlinear and non-stationary wave forecasting","","Wen-yang, Duan; Li-min, Huang; Yang, Han; De-tai, Huang","Journal of Zhejiang University. Science. A","Scholarly Journals","","17","2","2016-01-01","2016","115","129","115-129","1673565X","","","ENG","Accurate wave forecasting with a couple of hours of warning time offers improvements in safety for maritime operation-related activities. Autoregressive (AR) model is an efficient and highly adaptive approach for wave forecasting. However, it is based on linear and stationary theory and hence has limitations in forecasting nonlinear and non-stationary waves. Inspired by the capability of empirical mode decomposition (EMD) technique in handling nonlinear and non-stationary signals, this paper describes the development of a hybrid EMD-AR model for nonlinear and non-stationary wave forecasting. The EMDAR model was developed by coupling an AR model with the EMD technique. Nonlinearity and non-stationarity were overcome by decomposing the wave time series into several simple components for which the AR model is suitable. The EMD-AR model was implemented using measured significant wave height data from the National Data Buoy Center, USA. Prediction results from various locations consistently show that the hybrid EMD-AR model is superior to the AR model. This demonstrates that the EMD technique is effective in processing nonlinear and non-stationary waves.","https://www.proquest.com/docview/1898073424?accountid=12870&bdid=124553&_bd=zPN5hBN8cCNQnQM5dwalQDBWWmM%3D","https://doi.org/10.1631/jzus.A1500164"
"Threshold Dynamics of Short-term Interest Rates: Empirical Evidence and Implications for the Term Structure","","Archontakis, Theofanis; Lemke, Wolfgang","Economic Notes","Scholarly Journals","","37","1","2008-02-01","Feb 2008","75","","75-117","03915026","","","ENG","This paper studies a nonlinear one-factor term structure model in discrete time. The short-term interest rate follows a self-exciting threshold autoregressive (SETAR) process that allows for shifts in the intercept and the variance. In comparison with a linear model, we find empirical evidence in favour of the threshold model for Germany and the US. Based on the estimated short-rate dynamics we derive the implied arbitrage-free term structure of interest rates. Since analytical solutions are not feasible, bond prices are computed by means of Monte Carlo integration. The resulting term structure captures stylized facts of the data. In particular, it implies a nonlinear relation between long rates and the short rate.","https://www.proquest.com/docview/195894428?accountid=12870&bdid=124553&_bd=f0TZAlPlcon3xKANOCcPqIHEY6k%3D","https://doi.org/10.1111/j.1468-0300.2008.00189.x"
"Nonlinearities and divergences in the process of European financial integration","","Raileanu-Szeles, Monica; Albu, Lucian","Economic modelling","Undefined","","46","","2015-04-01","Apr 2015","416","425","416-425","0264-9993","0264-9993","","ENG","This paper aims to analyze the process of financial integration in the EU-27 area, from 2000 to 2013, using nonparametric methods. Besides a set of other nonparametric measures (e.g. Hartigen and Hartigen test, Kernel density estimation), the stochastic kernel indicates the presence of two or even more convergence clubs into the bond yield density distribution, in the short term, middle term and long term as well. The financial crisis has intensified the divergences emerging within the EU-27, leading to the multimodality of bond yield density distribution, and also to the decline of the financial integration process in the long term. In comparison with traditional parametric approaches used in the convergence literature, the nonparametric measures are found to provide new and more reliable insights to the literature of financial integration. All rights reserved, Elsevier","https://www.proquest.com/docview/1680170342?accountid=12870&bdid=124553&_bd=BK2%2FADtwRAX1SvrNomZRT7XMBtU%3D",""
"Are there nonlinear speculative bubbles in commodities prices?","","Ahmed, Ehsan; Rosser, J Barkley; Uppal, Jamshed Y","Journal of post Keynesian economics","Undefined","","36","3","2014-03-01","Mar 2014","415","438","415-438","0160-3477","0160-3477","","ENG","Daily price movements of seventeen commodities are tested for the possible presence of nonlinear speculative bubbles during 1991-2012. A VAR model for logarithmic first differences of each is estimated with one-year Treasury bill rates, U.S. dollar value, a world stock market index, and an overall commodities price index using Hamilton regime switching and Hurst rescaled range tests. Residuals after removing ARCH for all seventeen commodity price series are tested for remaining nonlinearity using the BDS test. These tests fail to reject the presence of bubble-like trends and nonlinearity beyond ARCH for all seventeen commodity series. However, we note that we are unable to overcome the misspecified fundamentals problem, which means we cannot argue that we have definitely found speculative bubbles. At most we can argue that our results indicate that these markets appear to exhibit excess volatility and unexplained trends. [PUBLICATION ABSTRACT] Reprinted by permission of M.E. Sharpe, Inc.","https://www.proquest.com/docview/1528874540?accountid=12870&bdid=124553&_bd=3cQTkMx8AWTN4UqHaI8I7kJSHdI%3D",""
"Cointegration and detectable linear and nonlinear causality: analysis using the London Metal Exchange lead contract","","Chen, An-Sing; Lin, James Wuh","Applied economics","Undefined","","36","11","2004-06-01","Jun 2004","1157","1168","1157-1168","0003-6846","0003-6846","","ENG","This study applies linear and nonlinear Granger causality tests to examine the dynamic relation between London Metal Exchange (LME) cash prices and three possible predictors. The analysis uses matched quarterly inventory, UK Treasury bill interest rates, futures prices and cash prices for the commodity lead traded on the LME. The effects of cointegration on both linear and nonlinear Granger causality tests is also examined. When cointegration is not modelled, evidence is found of both linear and nonlinear causality between cash prices and analysed predictor variables. However, after controlling for cointegration, evidence of significant nonlinear causality is no longer found. These results contribute to the empirical literature on commodity price forecasting by highlighting the relationship between cointegration and detectable linear and nonlinear causality. The importance of interest rate and inventory as well as futures price in forecasting cash prices is also illustrated. Failure to detect significant nonlinearity after controlling for cointegration may also go some way to explaining the reason for the disappointing forecasting performances of many nonlinear models in the general finance literature. It may be that the variables are correct, but the functional form is overly complex and a standard VAR or VECM may often apply. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/37881015?accountid=12870&bdid=124553&_bd=F%2BIcF%2BHaDjmuD6whXWndlMBxnpA%3D",""
"A semiparametric approach for modelling multivariate nonlinear time series","","Samadi, S Yaser; Hajebi, Mahtab; Rahman Farnoosh","The Canadian Journal of Statistics","Scholarly Journals","","47","4","2019-12-01","Dec 2019","668","687","668-687","03195724","","","ENG","AbstractIn this article, a semiparametric time‐varying nonlinear vector autoregressive (NVAR) model is proposed to model nonlinear vector time series data. We consider a combination of parametric and nonparametric estimation approaches to estimate the NVAR function for both independent and dependent errors. We use the multivariate Taylor series expansion of the link function up to the second order which has a parametric framework as a representation of the nonlinear vector regression function. After the unknown parameters are estimated by the maximum likelihood estimation procedure, the obtained NVAR function is adjusted by a nonparametric diagonal matrix, where the proposed adjusted matrix is estimated by the nonparametric kernel estimator. The asymptotic consistency properties of the proposed estimators are established. Simulation studies are conducted to evaluate the performance of the proposed semiparametric method. A real data example on short‐run interest rates and long‐run interest rates of United States Treasury securities is analyzed to demonstrate the application of the proposed approach. The Canadian Journal of Statistics 47: 668–687; 2019 © 2019 Statistical Society of Canada","https://www.proquest.com/docview/2314144166?accountid=12870&bdid=124553&_bd=ACJAZPiPsa6ijy994BuFnVDX1O4%3D","https://doi.org/10.1002/cjs.11518"
"The contribution of wealth concentration to the subprime crisis: a quantitative estimation","","Goda, Thomas; Lysandrou, Photis","Cambridge journal of economics","Undefined","","38","2","2014-03-01","Mar 2014","301","327","301-327","0309-166X","0309-166X","","ENG","The crisis that broke out in mid-2007 was caused by the fact that the collateralised debt obligation (CDO) market had grown to a size sufficient to wreak general havoc when it suddenly collapsed. Several authors have argued that economic inequality was important to the growth of this market. This paper attempts to strengthen this argument by concentrating attention on global wealth concentration. After summarising recent evidence on the negative impact of investor demand on US bond yields in the pre-crisis period, new evidence regarding the specific contribution of high-net-worth individuals to this negative impact is presented. The paper then goes on to show how, after having helped to cause a yield problem in the major US debt markets, high-net-worth individuals (via hedge funds) continued to be a major source of the pressure on US banks to resolve this yield problem through the mass production of CDOs. [PUBLICATION ABSTRACT] Reprinted by permission of Oxford University Press","https://www.proquest.com/docview/1521335144?accountid=12870&bdid=124553&_bd=P2Gx%2FzvZJ9hirbwrsr2LNse9CnQ%3D",""
"A parametric nonlinear model of term structure dynamics","","Ahn, Dong-Hyun; Gao, Bin","Review of financial studies","Undefined","","12","4(Supp.)","1999-01-01","1999","721","762","721-762","0893-9454","0893-9454","","ENG","","https://www.proquest.com/docview/38799352?accountid=12870&bdid=124553&_bd=aH%2BFewxW2cDbmGmkWqml8Yautto%3D",""
"Rival Models in Policy Optimization","","Becker, R; Dwolatzky, B; Karakitsos, E; Rustem, B","Journal of Economic Dynamics & Control","Scholarly Journals","","10","1,2","1986-06-01","Jun 1986","75","","75","01651889","","","ENG","The design of policy in the presence of rival models of the same macroeconomic system has received little attention in the literature.  The rival models are such that each fits the data reasonably well and is generally based on a different school of thought and so has a different structure.  The present analysis summarizes 2 ways in which policy optimization can be used to derive policies that are compatible with more than one model structure.  This is done by using algorithms that can handle simultaneously more than one model and objective function.  Two large-scale forecasting models of the UK economy are employed simultaneously to obtain optimal policies.  These are the HM Treasury model (public version, 1982) and the model of the National Institute of Economic and Social Research (model 6).  The common ''do-nothing'' case is investigated and the simulation results reported.","https://www.proquest.com/docview/196682830?accountid=12870&bdid=124553&_bd=Oao7e77WYAh%2FNQ0jToIbigV0Jt8%3D",""
"Local lagged adapted generalized method of moments and applications","","Otunuga, Olusegun M; Ladde, Gangaram S; Ladde, Nathan G","Stochastic Analysis and Applications","Undefined","Taylor & Francis Group Ltd., 2 Park Square Oxford OX14 4RN United Kingdom","35","1","2017-01-02","January 2, 2017","110","143","110-143","0736-2994","1532-9356","","ENG","In this work, an attempt is made for developing the local lagged adapted generalized method of moments (LLGMM). This proposed method is composed of: 1) development of the stochastic model for continuous-time dynamic process; 2) development of the discrete-time interconnected dynamic model for statistic process; 3) utilization of Euler-type discretized scheme for nonlinear and nonstationary system of stochastic differential equations; 4) development of generalized method of moment/observation equations by employing lagged adaptive expectation process; 5) introduction of the conceptual and computational parameter estimation problem; 6) formulation of the conceptual and computational state estimation scheme; and 7) definition of the conditional mean square epsilon -best sub-optimal procedure. The development of LLGMM is motivated by parameter and state estimation problems in continuous-time nonlinear and nonstationary stochastic dynamic model validation problems in biological, chemical, engineering, financial, medical, physical, and social sciences. The byproducts of LLGMM are the balance between model specification and model prescription of continuous-time dynamic process and the development of discrete-time interconnected dynamic model of local sample mean and variance statistic process (DTIDMLSMVSP). DTIDMLSMVSP is the generalization of statistic (sample mean and variance) drawn from the static dynamic population problems. Moreover, it is also an alternative approach to the GARCH (1,1) model and its many related variant models (e.g., EGARCH model, GJR GARCH model). It provides an iterative scheme for updating statistic coefficients in a system of generalized method of moment/observation equations. Furthermore, application of the LLGMM method to stochastic differential dynamic models for energy commodity price, U.S. Treasury bill yield interest rate U.S.-U.K. foreign exchange rate exhibits its unique role and scope.","https://www.proquest.com/docview/1904237712?accountid=12870&bdid=124553&_bd=e%2BW2itsfmI5QnMHA5oPJtRexD4E%3D","https://doi.org/10.1080/07362994.2016.1213640"
"The SR approach: A new estimation procedure for non-linear and non-Gaussian dynamic term structure models","","Andreasen, Martin M; Christensen, Bent Jesper","Journal of econometrics","Undefined","Elsevier B.V.","184","2 p.420-451","2015-02-01","Feb 2015","420","451","p. 420-451","0304-4076","0304-4076","","ENG","This paper suggests a new approach for estimating linear and non-linear dynamic term structure models with latent factors. We impose no distributional assumptions on the factors which therefore may be non-Gaussian. The novelty of our approach is to use many observables (yields or bond prices) in the cross-section dimension. This implies that the latent factors can be determined quite accurately by a sequence of cross-section regressions. We also show how output from these regressions can be used to obtain model parameters by a two- or three-step moment-based estimation procedure.","https://www.proquest.com/docview/2189536514?accountid=12870&bdid=124553&_bd=WXce9o0E5VBxFGRcpe0PWpGvMYw%3D","https://doi.org/10.1016/j.jeconom.2014.10.002"
"The expectations hypothesis of the term structure when interest rates are close to zero","","Ruge-Murcia, Francisco J","Journal of monetary economics","Undefined","","53","7","2006-10-01","Oct 2006","1409","1424","1409-1424","0304-3932","0304-3932","","ENG","In an economy where cash can be stored costlessly in nominal terms, the nominal interest rate is bounded below by zero. This paper derives the implications of this non-negativity constraint for the term structure and shows that it induces a nonlinear and convex relation between short- and long-term interest rates. The long-term rate responds asymmetrically to changes in the short-term rate, and by less than that is predicted by the benchmark linear model. In particular, a decrease in the short-term rate produces a smaller response in the long-term rate than an increase of the same magnitude. The empirical predictions of the model are examined using data from Japan. All rights reserved, Elsevier","https://www.proquest.com/docview/36524628?accountid=12870&bdid=124553&_bd=ssfe3xqfGbZjZGQTKpZx2Lkg0Qs%3D","https://doi.org/10.1016/j.jmoneco.2005.07.014"
"Pricing with finite dimensional dependence","","Gourieroux, C; Monfort, A","Journal of econometrics","Undefined","Elsevier B.V.","187","2 p.408-417","2015-08-01","Aug 2015","408","417","p. 408-417","0304-4076","0304-4076","","ENG","We consider derivative pricing in factor models, where the factor is Markov with Finite Dimensional Dependence (FDD). The FDD condition allows for explicit formulas for derivative prices and their term structure and in this respect is a serious competitor of models with affine dynamic factors. The approach is illustrated by a comparison of the prices of realized and integrated volatility swaps. We show that the usual practice of replacing a payoff written on the realized volatility by the payoff written on the integrated volatility can imply pricing errors which are not negligible when the volatility of the volatility is large.","https://www.proquest.com/docview/2189531101?accountid=12870&bdid=124553&_bd=YhkJY2X1Rw7zWL7oKyo0bOIS7K8%3D","https://doi.org/10.1016/j.jeconom.2015.02.027"
"A new optimisation approach to assess optimal asset allocation in European non-life insurance companies","","Jarraya, Bilel","International Journal of Applied Decision Sciences","Scholarly Journals","","14","4","2021-01-01","2021","461","476","461-476","17558077","","","ENG","This study addresses the allocation of optimal assets in non-life insurance companies' environment with a new vision. Most previous studies are based on the maximisation of the utility function. However, in this paper, we focused on the maximisation of technical efficiency (TE). In order to validate our objective, we select a set of European non-life insurance companies (ENIC) over the period 2008-2014. In the first step, we estimate the production function characterised by the directional output distance function (DODF). In the second one, we use two metaheuristics (PSO and GA) to assess the optimal asset allocation (OAA). The empirical results show that the proportion allocated to the 'alternative investment with high-risk high-return' (AIhh) is on average lower than those found in previous studies. However, the percentage allocated to the 'risk-free assets' (RFA) is on average different from zero. This can be explained by the attention given to the competitiveness, survival and long-term profitability respecting the maximisation of TE. So, any insurance company must give more attention to the presence of different stakeholders and resolve the conflicts of interest between them.","https://www.proquest.com/docview/2548917139?accountid=12870&bdid=124553&_bd=a8mMS8Ho24I7b5wuYl5MOL2Iogk%3D","https://doi.org/10.1504/IJADS.2021.116004"
"Modelling portfolio defaults using hidden Markov models with covariates","","Banachewicz, Konrad; Lucas, André; Vaart, Aad van der","Econometrics journal","Undefined","","11","1","2008-01-01","2008","155","171","155-171","1368-4221","1368-4221","","ENG","We extend the hidden Markov Model for defaults of Crowder et al. (2005, Quantitative Finance 5, 27-34) to include covariates. The covariates enhance the prediction of transition probabilities from high to low default regimes. To estimate the model, we extend the EM estimating equations to account for the time varying nature of the conditional likelihoods due to sample attrition and extension. Using empirical U.S. default data, we find that GDP growth, the term structure of interest rates and stock market returns impact the state transition probabilities. The impact, however, is not uniform across industries. We only find a weak correspondence between industry credit cycle dynamics and general business cycles. Reprinted by permission of Blackwell Publishing","https://www.proquest.com/docview/37048379?accountid=12870&bdid=124553&_bd=lG%2FHVqXq95HOoDCY%2FDl%2FP%2FrpO9o%3D","https://doi.org/10.1111/j.1368-423X.2008.00232.x"
"Forecasting interest rate swap spreads using domestic and international risk factors: evidence from linear and non-linear models","","Lekkos, Ilias; Milas, Costas; Panagiotidis, Theodore","Journal of forecasting","Undefined","","26","8","2007-12-01","Dec 2007","601","619","601-619","0277-6693","0277-6693","","ENG","This paper explores the ability of factor models to predict the dynamics of US and UK interest rate swap spreads within a linear and a non-linear framework. We reject linearity for the US and UK swap spreads in favour of a regime-switching smooth transition vector autoregressive (STVAR) model, where the switching between regimes is controlled by the slope of the US term structure of interest rates. We compare the ability of the STVAR model to predict swap spreads with that of a non-linear nearest-neighbours model as well as that of linear AR and VAR models. We find some evidence that the non-linear models predict better than the linear ones. At short horizons, the nearest-neighbours (NN) model predicts better than the STVAR model US swap spreads in periods of increasing risk conditions and UK swap spreads in periods of decreasing risk conditions. At long horizons, the STVAR model increases its forecasting ability over the linear models, whereas the NN model does not outperform the rest of the models. Copyright John Wiley & Sons. Reproduced with permission. An electronic version of this article is available online at http://www.interscience.wiley.com","https://www.proquest.com/docview/36952526?accountid=12870&bdid=124553&_bd=h1BpWJk1YEMPwSyf%2BQul%2FRfNlqI%3D","https://doi.org/10.1002/for.1048"
"Economic impacts on the money supply process","","Gauger, Jean","Journal of Macroeconomics","Scholarly Journals","","20","3","1998-07-01","Summer 1998","553","","553-577","01640704","","","ENG","Economic theory of asset holding behavior predicts multiplier responses to economic variables such as interest rates or real income.  However, standard treatments in macro and monetary models frequently assume simplistic multiplier behavior.  Potential economic impacts are often assumed to be negligible, or occur slowly, and not of practical importance.  A study empirically assesses impacts from economic variables on monetary multipliers.  Results show that economic variables have significant impacts on the monetary multipliers.  These multiplier impacts can no longer legitimately be assumed away.  Rather, results call for attention to multiplier movements as a new standard treatment in theoretical and empirical macroeconomic models.","https://www.proquest.com/docview/229549741?accountid=12870&bdid=124553&_bd=zCYDh1L7dFYCAMXifsN4M7N1%2B1o%3D",""
"The 'probability of recession': evaluating probabilistic and non-probabilistic forecasts from probit models of US recessions","","Ratcliff, Ryan","Economics letters","Undefined","","121","2","2013-11-01","Nov 2013","311","315","311-315","0165-1765","0165-1765","","ENG","This letter evaluates forecasts from probit models that use the slope of the yield curve to forecast recessions. These models give reliable non-probabilistic warnings of recessions, but the estimated probabilities do not match the conditional frequency of recession months. [PUBLICATION ABSTRACT] All rights reserved, Elsevier","https://www.proquest.com/docview/1521332785?accountid=12870&bdid=124553&_bd=6VdFNmyccB%2FdUEIQhR3UOErzUFs%3D",""
"Unemployment and inflation dynamics prior to the economic downturn of 2007-2008","","Guastello, Stephen J; Myers, Adam","Nonlinear dynamics, psychology, and life sciences","Undefined","","13","4","2009-10-01","Oct 2009","445","","445-66","1090-0578","1090-0578","","ENG","This article revisits a long-standing theoretical issue as to whether a ""natural rate"" of unemployment exists in the sense of an exogenously driven fixed-point Walrasian equilibrium or attractor, or whether more complex dynamics such as hysteresis or chaos characterize an endogenous dynamical process instead. The same questions are posed regarding a possible natural rate of inflation along with an investigation of the actual relationship between inflation and unemployment for which extent theories differ. Time series of unemployment and inflation for US data - were analyzed using the exponential model series and nonlinear regression for capturing Lyapunov exponents and transfer effects from other variables. The best explanation for unemployment was that it is a chaotic variable that is driven in part by inflation. The best explanation for inflation is that it is also a chaotic variable driven in part by unemployment and the prices of treasury bills. Estimates of attractors' epicenters were calculated in lieu of classical natural rates.This article revisits a long-standing theoretical issue as to whether a ""natural rate"" of unemployment exists in the sense of an exogenously driven fixed-point Walrasian equilibrium or attractor, or whether more complex dynamics such as hysteresis or chaos characterize an endogenous dynamical process instead. The same questions are posed regarding a possible natural rate of inflation along with an investigation of the actual relationship between inflation and unemployment for which extent theories differ. Time series of unemployment and inflation for US data - were analyzed using the exponential model series and nonlinear regression for capturing Lyapunov exponents and transfer effects from other variables. The best explanation for unemployment was that it is a chaotic variable that is driven in part by inflation. The best explanation for inflation is that it is also a chaotic variable driven in part by unemployment and the prices of treasury bills. Estimates of attractors' epicenters were calculated in lieu of classical natural rates.","https://www.proquest.com/docview/734062132?accountid=12870&bdid=124553&_bd=21FVVe%2FTyIUOfaF%2BB%2B2UwNqHDgU%3D",""
"Is BRCA Mutation Testing Cost Effective for Early Stage Breast Cancer Patients Compared to Routine Clinical Surveillance? The Case of an Upper Middle-Income Country in Asia","","Lim, Ka Keat; Yoon, Sook Yee; Mohd Taib, Nur Aishah; Shabaruddin, Fatiha Hana; Dahlui, Maznah; Woo, Yin Ling; Thong, Meow Keong; Teo, Soo Hwang; Chaiyakunapruk, Nathorn","Applied health economics and health policy","Undefined","","16","3","2018-06-01","Jun 2018","395","","395-406","1179-1896","","","ENG","Previous studies showed that offering BRCA mutation testing to population subgroups at high risk of harbouring the mutation may be cost effective, yet no evidence is available for low- or middle-income countries (LMIC) and in Asia. We estimated the cost effectiveness of BRCA mutation testing in early-stage breast cancer patients with high pre-test probability of harbouring the mutation in Malaysia, an LMIC in Asia.OBJECTIVEPrevious studies showed that offering BRCA mutation testing to population subgroups at high risk of harbouring the mutation may be cost effective, yet no evidence is available for low- or middle-income countries (LMIC) and in Asia. We estimated the cost effectiveness of BRCA mutation testing in early-stage breast cancer patients with high pre-test probability of harbouring the mutation in Malaysia, an LMIC in Asia.We developed a decision analytic model to estimate the lifetime costs and quality-adjusted life-years (QALYs) accrued through BRCA mutation testing or routine clinical surveillance (RCS) for a hypothetical cohort of 1000 early-stage breast cancer patients aged 40 years. In the model, patients would decide whether to accept testing and to undertake risk-reducing mastectomy, oophorectomy, tamoxifen, combinations or neither. We calculated the incremental cost-effectiveness ratio (ICER) from the health system perspective. A series of sensitivity analyses were performed.METHODSWe developed a decision analytic model to estimate the lifetime costs and quality-adjusted life-years (QALYs) accrued through BRCA mutation testing or routine clinical surveillance (RCS) for a hypothetical cohort of 1000 early-stage breast cancer patients aged 40 years. In the model, patients would decide whether to accept testing and to undertake risk-reducing mastectomy, oophorectomy, tamoxifen, combinations or neither. We calculated the incremental cost-effectiveness ratio (ICER) from the health system perspective. A series of sensitivity analyses were performed.In the base case, testing generated 11.2 QALYs over the lifetime and cost US$4815 per patient whereas RCS generated 11.1 QALYs and cost US$4574 per patient. The ICER of US$2725/QALY was below the cost-effective thresholds. The ICER was sensitive to the discounting of cost, cost of BRCA mutation testing and utility of being risk-free, but the ICERs remained below the thresholds. Probabilistic sensitivity analysis showed that at a threshold of US$9500/QALY, 99.9% of simulations favoured BRCA mutation testing over RCS.RESULTSIn the base case, testing generated 11.2 QALYs over the lifetime and cost US$4815 per patient whereas RCS generated 11.1 QALYs and cost US$4574 per patient. The ICER of US$2725/QALY was below the cost-effective thresholds. The ICER was sensitive to the discounting of cost, cost of BRCA mutation testing and utility of being risk-free, but the ICERs remained below the thresholds. Probabilistic sensitivity analysis showed that at a threshold of US$9500/QALY, 99.9% of simulations favoured BRCA mutation testing over RCS.Offering BRCA mutation testing to early-stage breast cancer patients identified using a locally-validated risk-assessment tool may be cost effective compared to RCS in Malaysia.CONCLUSIONSOffering BRCA mutation testing to early-stage breast cancer patients identified using a locally-validated risk-assessment tool may be cost effective compared to RCS in Malaysia.","https://www.proquest.com/docview/2018027373?accountid=12870&bdid=124553&_bd=%2B1ySJD9C%2Fl%2FNNgVRWeo5KwypwQg%3D","https://doi.org/10.1007/s40258-018-0384-8"
"Structural Laplace Transform and Compound Autoregressive Models","","Darolles, Serge; Gourieroux, Christian; Jasiak, Joann","Journal of Time Series Analysis","Undefined","Blackwell Publishing Ltd., 9600 Garsington Road Oxford OX4 2DQ UK, [URL:http://www.blackwellpublishing.com]","27","4","2006-07-01","Jul 2006","477","503","477-503","0143-9782","1467-9892","","ENG","This paper presents a new general class of compound autoregressive (Car) models for non-Gaussian time series. The distinctive feature of the class is that Car models are specified by means of the conditional Laplace transforms. This approach allows for simple derivation of the ergodicity conditions and ensures the existence of forecasting distributions in closed form, at any horizon. The last property is of particular interest for applications to finance and economics that investigate the term structure of variables and/or of their nonlinear transforms. The Car class includes a number of time-series models that already exist in the literature, as well as new models introduced in this paper. Their applications are illustrated by examples of portfolio management, term structure and extreme risk analysis.","https://www.proquest.com/docview/746230887?accountid=12870&bdid=124553&_bd=IvxdkWOOolsMhKJOB6YUJMd3m58%3D","https://doi.org/10.1111/j.1467-9892.2006.00479.x"
"Nonlinearity and Flight‐to‐Safety in the Risk‐Return Trade‐Off for Stocks and Bonds","","Tobias, Adrian; Crump, Richard K; Vogt, Erik","The Journal of Finance","Scholarly Journals","","74","4","2019-08-01","Aug 2019","1931","1973","1931-1973","00221082","","","ENG","We document a highly significant, strongly nonlinear dependence of stock and bond returns on past equity market volatility as measured by the VIX. We propose a new estimator for the shape of the nonlinear forecasting relationship that exploits variation in the cross‐section of returns. The nonlinearities are mirror images for stocks and bonds, revealing flight‐to‐safety: expected returns increase for stocks when volatility increases from moderate to high levels while they decline for Treasuries. These findings provide support for dynamic asset pricing theories in which the price of risk is a nonlinear function of market volatility.","https://www.proquest.com/docview/2257969542?accountid=12870&bdid=124553&_bd=dYGgFrB427jYcWLZBi4f8E5wyCw%3D","https://doi.org/10.1111/jofi.12776"
"Are corporate bond market returns predictable?","","Hong, Y; Lin, H; Wu, C.","Journal of banking and finance","Undefined","","36","8","2012-08-01","Aug 2012","2216","2232","2216-2232","0378-4266","0378-4266","","ENG","This paper examines the predictability of corporate bond returns using the transaction-based index data for the period from October 1, 2002 to December 31, 2010. We find evidence of significant serial and cross-serial dependence in daily investment-grade and high-yield bond returns. The serial dependence exhibits a complex nonlinear structure. Both investment-grade and high-yield bond returns can be predicted by past stock market returns in-sample and out-of-sample, and the predictive relation is much stronger between stocks and high-yield bonds. By contrast, there is little evidence that stock returns can be predicted by past bond returns. These findings are robust to various model specifications and test methods, and provide important implications for modeling the term structure of defaultable bonds. All rights reserved, Elsevier","https://www.proquest.com/docview/1034347584?accountid=12870&bdid=124553&_bd=cQNYGYVN4uB3WoglALFLZXvHP58%3D","https://doi.org/10.1016/j.jbankfin.2012.04.001"
"Option price sensitivities through fuzzy numbers","","Letizia Guerra, Maria; Sorini, Laerte; Stefanini, Luciano","Computers & Mathematics with Applications","Undefined","Elsevier Science, The Boulevard Kidlington Oxford OX5 1GB UK","61","3","2011-02-01","Feb 2011","515","526","515-526","0898-1221","0898-1221","","ENG","The main motivation in using fuzzy numbers in finance lies in the need for modelling the uncertainty and vagueness that are implicit in many situations. However, the fuzzy approach should not be considered as a substitute for the probabilistic approach but rather as a complementary way to describe the model peculiarities. Here, we consider, in particular, the Black and Scholes model for option pricing, and we show that the fuzzification of some key parameters enables a sensitivity analysis of the option price with respect to the risk-free interest rate, the final value of the underlying stock price, the volatility, and also better forecasts (see Thavaneswaran etaaal. (2009) for details). The sensitivities with respect to the variables of the model are represented by different letters of the Greek alphabet and they play an important role in the definition of the shape of the fuzzy option price.","https://www.proquest.com/docview/864411955?accountid=12870&bdid=124553&_bd=NC1Xu%2B75uvcjO6C6rTkI9b6XWbY%3D","https://doi.org/10.1016/j.camwa.2010.11.024"
"An application of comonotonicity theory in a stochastic life annuity framework","","Liu, Xiaoming; Jang, Jisoo; Kim, Sun Mee","Insurance Mathematics & Economics","Undefined","North-Holland, P.O. Box 211 Amsterdam 1000 AE Netherlands","48","2","2011-03-01","Mar 2011","271","279","271-279","0167-6687","0167-6687","","ENG","A life annuity contract is an insurance instrument which pays pre-scheduled living benefits conditional on the survival of the annuitant. In order to manage the risk borne by annuity providers, one needs to take into account all sources of uncertainty that affect the value of future obligations under the contract. In this paper, we define the concept of annuity rate as the conditional expected present value random variable of future payments of the annuity, given the future dynamics of its risk factors. The annuity rate deals with the non-diversifiable systematic risk contained in the life annuity contract, and it involves mortality risk as well as investment risk. While it is plausible to assume that there is no correlation between the two risks, each affects the annuity rate through a combination of dependent random variables. In order to understand the probabilistic profile of the annuity rate, we apply comonotonicity theory to approximate its quantile function. We also derive accurate upper and lower bounds for prediction intervals for annuity rates. We use the Lee-Carter model for mortality risk and the Vasicek model for the term structure of interest rates with an annually renewable fixed-income investment policy. Different investment strategies can be handled using this framework.","https://www.proquest.com/docview/954629919?accountid=12870&bdid=124553&_bd=Dvc%2BLXGCLk%2BLmfPdAbiplVgglzU%3D","https://doi.org/10.1016/j.insmatheco.2010.11.008"
"The Role of Regime Shifts in the Term Structure of Interest Rates: Further Evidence from an Emerging Market","","Saltoglu, Burak; Yazgan, M Ege","Emerging Markets Finance & Trade","Undefined","M.E. Sharpe, Armonk NY","48","supp 5","2012-11-01","November 2012","48","63","48-63","1540-496X","1540-496X","","ENG","In this paper, we investigate the interrelationships among Turkish interest rates having different maturities by using a regime-switching vector error correction model. We find a relationship of long-run equilibrium among interest rates having various maturities. Furthermore, we conclude that term structure dynamics exhibit significant nonlinearity. A forecasting experiment also reveals that the nonlinear term structure models fare better in forecasting than other linear specifications. However, we cannot conclude that interest rate adjustments are made in an asymmetric way in the long run. Adapted from the source document.","https://www.proquest.com/docview/1364727189?accountid=12870&bdid=124553&_bd=fRqHEHeGCeWxYDzh5tULNlOAYsk%3D","https://doi.org/10.2753/REE1540-496X4806S504"
"Federal Deficits and the Conduct of Monetary Policy","","Bradley, Michael D","Journal of Macroeconomics","Scholarly Journals","","6","4","1984-10-01","Fall 1984","411","","411","01640704","","","ENG","Due to the large and persistent deficits during the 1970s and 1980s, much attention has been focused on the impact of fiscal policy on monetary policy.  Pressures have been exerted on the Federal Reserve to acquire Treasury debt through open market operations because of the persistent deficits.  It is argued that there are limitations on reduced-form studies in the examination of the impact of deficits on monetary policy, and an alternative approach is suggested.  The analysis examines fiscal policy's impact on the variables the Fed most closely controls - nonborrowed reserves and the Federal funds rate.  The model is estimated using data from the 11 1/2 year period from January 1980-June 1981.  Results show 3 improvements over previous models: 1.  The theoretical model may be used to derive equations that determine both the Federal funds rate and nonborrowed reserves.  2.  The likelihood of biasing results by the inclusion of extraneous influences is reduced.  3.  Expansion of reserves is found to come from the supply side, not from demand pressure.","https://www.proquest.com/docview/229573175?accountid=12870&bdid=124553&_bd=1Wd6ZDYk1tFD3iJz0qY5Wweb%2BWc%3D",""
"Connectedness network and dependence structure mechanism in green investments","","Lundgren, Amanda Ivarsson; Milicevic, Adriana; Uddin, Gazi Salah; Kang, Sang Hoon","Energy Economics","Scholarly Journals","","72","","2018-05-01","May 2018","145","","","01409883","","","ENG","We present an empirical study of renewable energy stock returns and their relation to four major investment asset classes-stocks, currency, US Treasury bonds, and oil-and several sources of uncertainty. Applying nonlinear causality and connectedness network analysis on data covering the period 2004–2016, we investigate the directionality and connectedness among different asset classes, as well as between uncertainties. First, from the results of the estimation of directionality and network spillovers, it can be concluded that the European stock market has a strong market dependence on renewable energy stock prices. Second, uncertainties have an economically significant impact on both return and volatility spillover in energy investments. Third, most of the uncertainties are net transmitters of volatility connectedness during the global financial crisis (GFC) and European sovereign debt crisis (ESDC).","https://www.proquest.com/docview/2097667804?accountid=12870&bdid=124553&_bd=94QS%2BzQaB36%2BhGeUuIbnA1NxF%2Fs%3D",""
"A non-linear forecast combination procedure for binary outcomes","","Lahiri, Kajal; Yang, Liu","Studies in nonlinear dynamics and econometrics","Undefined","","20","4","2016-09-01","September 2016","421","421","421","1081-1826","1081-1826","","ENG","We develop a non-linear forecast combination rule based on copulas that incorporate the dynamic interaction between individual predictors. This approach is optimal in the sense that the resulting combined forecast produces the highest discriminatory power as measured by the receiver operating characteristic (ROC) curve. Under additional assumptions, this rule is shown to be equivalent to the quintessential linear combination scheme. To illustrate its usefulness, we apply this methodology to optimally aggregate two currently used leading indicators -- the ISM new order diffusion index and the yield curve spread -- to predict economic recessions in the United States. We also examine the sources of forecasting gains using a counterfactual experimental set up. Reprinted by permission of Berkeley Electronic Press","https://www.proquest.com/docview/1835023802?accountid=12870&bdid=124553&_bd=jcm%2B52mcC5pk1z9N%2FQJj356Fih8%3D",""
"An application of comonotonicity theory in a stochastic life annuity framework","","Liu, X; Jang, J; Mee Kim, S.","Insurance mathematics and economics","Undefined","","48","2","2011-03-01","Mar 2011","271","279","271-279","0167-6687","0167-6687","","ENG","A life annuity contract is an insurance instrument which pays pre-scheduled living benefits conditional on the survival of the annuitant. In order to manage the risk borne by annuity providers, one needs to take into account all sources of uncertainty that affect the value of future obligations under the contract. In this paper, we define the concept of annuity rate as the conditional expected present value random variable of future payments of the annuity, given the future dynamics of its risk factors. The annuity rate deals with the non-diversifiable systematic risk contained in the life annuity contract, and it involves mortality risk as well as investment risk. While it is plausible to assume that there is no correlation between the two risks, each affects the annuity rate through a combination of dependent random variables. In order to understand the probabilistic profile of the annuity rate, we apply comonotonicity theory to approximate its quantile function. We also derive accurate upper and lower bounds for prediction intervals for annuity rates. We use the Lee-Carter model for mortality risk and the Vasicek model for the term structure of interest rates with an annually renewable fixed-income investment policy. Different investment strategies can be handled using this framework. All rights reserved, Elsevier","https://www.proquest.com/docview/857120523?accountid=12870&bdid=124553&_bd=kz%2FpXgf0HqRha%2B94JihD2JPXPWA%3D","https://doi.org/10.1016/j.insmatheco.2010.11.008"
"A risk index model for uncertain portfolio selection with background risk","","Huang, Xiaoxia; Jiang, Guowei; Gupta, Pankaj; Mehlawat, Mukesh Kumar","Computers & Operations Research","Scholarly Journals","","132","","2021-08-01","Aug 2021","1","","","03050548","","","ENG","This study proposes a new uncertain risk index model with background risk and presents its deterministic equivalents. The security returns and background asset returns are assumed as uncertain variables and estimated by experts. To discuss the influence of background risk on investment decisions, we compare the proposed model with a variant without background risk and find that the portfolio with background risk produces an equal or lower return than the one without background risk. The effects of changes in the standard deviation of background asset and the risk-free interest rate on optimal expected value are discussed. Two different risk measures for portfolio optimization model with background risk are compared, viz., the risk index model with background risk is further compared with the mean chance model with background risk. The nonlinear risk index model is solved by using a genetic algorithm. The efficiency of the genetic algorithm and the applications of the proposed models are illustrated through numerical experiments.","https://www.proquest.com/docview/2545257555?accountid=12870&bdid=124553&_bd=6u%2BY%2F3s8wX3RltMDyWXE4HXYPjc%3D","https://doi.org/10.1016/j.cor.2021.105331"
"A micro data approach to the identification of credit crunches","","Rottmann, Horst; Wollmershäuser, Timo","Applied economics","Undefined","","45","17","2013-06-01","Jun 2013","2423","2441","2423-2441","0003-6846","0003-6846","","ENG","This article presents a micro data approach to the identification of credit crunches. Using a survey among German firms which regularly queries the firms' assessment of the current willingness of banks to extend credit, we estimate the probability of a restrictive loan supply policy by time taking into account the creditworthiness of borrowers. Creditworthiness is approximated by firm-specific factors, e.g. the firms' assessment of their current business situation and their business expectations. After controlling for the return on the banks' risk-free investment alternative, which is also likely to affect the supply of loans, we derive a credit crunch indicator, which measures that part of the shift in the loan supply that is neither explained by firm-specific factors nor by the opportunity costs of providing risky loans. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/1267025797?accountid=12870&bdid=124553&_bd=8UQ4pZ1ngBpwW47QXZtV2Dms4s8%3D",""
"The expected inflation channel of government spending in the postwar US","","Dupor, Bill; Li, Rong","European economic review","Undefined","","74","","2015-02-01","Feb 2015","36","56","36-56","0014-2921","0014-2921","","ENG","There exist sticky price models in which the output response to a government spending change can be large if the central bank is nonresponsive to inflation. According to this 'expected inflation channel,' government spending drives up expected inflation, which in turn, reduces the real interest rate and leads to an increase in private consumption. This paper examines whether the channel was important in the post-WWII U.S., with particular attention to the 2009 Recovery Act period. First, we show that a model calibrated to have a large output multiplier requires a large response of expected inflation to a government spending shock. Next, we show that this large response is inconsistent with structural vector autoregression evidence from the Federal Reserve's passive policy period (1959-1979). Then, we study expected inflation measures during the Recovery Act period in conjunction with a panel of professional forecaster surveys, a cross-country comparison of bond yields and fiscal policy news announcements. We show that the expected inflation response was too small to engender a large output multiplier. All rights reserved, Elsevier","https://www.proquest.com/docview/1663902353?accountid=12870&bdid=124553&_bd=HGaTTmtTJi5YxomFCUBEfDnixfI%3D",""
"The Information Content of a Nonlinear Macro-Finance Model for Commodity Prices","","Khan, Saqib; Khokher, Zeigham; Simin, Timothy","The Review of Financial Studies","Scholarly Journals","","30","8","2017-08-01","Aug 2017","2818","","","08939454","","","ENG","State-of-the-art term structure models of commodity prices have serious difficulties extrapolating the prices of long-maturity futures contracts from short-dated contracts. This situation is problematic for valuing real commodity-linked assets. We estimate a nonlinear four-factor continuous time model of commodity price dynamics. The model nests many previous specifications. To estimate the model, we use crude oil prices and inventories. The inventory data and nonlinear price dynamics have a large impact on oil price forecasts. The additional factor in our model compared with current three-factor models has a significant impact on model-implied long-maturity futures prices. [web URL: https://academic.oup.com/rfs/article/30/8/2818/2682976/The-Information-Content-of-a-Nonlinear-Macro]","https://www.proquest.com/docview/1947584327?accountid=12870&bdid=124553&_bd=RC524TBV7JWS7d6l08tyHhOo13g%3D",""
"Local lagged adapted generalized method of moments and applications","","Otunuga, Olusegun M; Ladde, Gangaram S; Ladde, Nathan G","Stochastic Analysis and Applications","Scholarly Journals","","35","1","2017-01-01","Jan 2017","110","","110-143","07362994","","","ENG","In this work, an attempt is made for developing the local lagged adapted generalized method of moments (LLGMM). This proposed method is composed of: 1) development of the stochastic model for continuous-time dynamic process; 2) development of the discrete-time interconnected dynamic model for statistic process; 3) utilization of Euler-type discretized scheme for nonlinear and nonstationary system of stochastic differential equations; 4) development of generalized method of moment/observation equations by employing lagged adaptive expectation process; 5) introduction of the conceptual and computational parameter estimation problem; 6) formulation of the conceptual and computational state estimation scheme; and 7) definition of the conditional mean square [epsilon]-best sub-optimal procedure. The development of LLGMM is motivated by parameter and state estimation problems in continuous-time nonlinear and nonstationary stochastic dynamic model validation problems in biological, chemical, engineering, financial, medical, physical, and social sciences. The byproducts of LLGMM are the balance between model specification and model prescription of continuous-time dynamic process and the development of discrete-time interconnected dynamic model of local sample mean and variance statistic process (DTIDMLSMVSP). DTIDMLSMVSP is the generalization of statistic (sample mean and variance) drawn from the static dynamic population problems. Moreover, it is also an alternative approach to the GARCH (1,1) model and its many related variant models (e.g., EGARCH model, GJR GARCH model). It provides an iterative scheme for updating statistic coefficients in a system of generalized method of moment/observation equations. Furthermore, application of the LLGMM method to stochastic differential dynamic models for energy commodity price, U.S. Treasury bill yield interest rate U.S.-U.K. foreign exchange rate exhibits its unique role and scope.","https://www.proquest.com/docview/1923356131?accountid=12870&bdid=124553&_bd=zz%2FrzaRNSJrstxeGE96oyeSjEXQ%3D","https://doi.org/10.1080/07362994.2016.1213640"
"Retrospectives Irving Fisher's appreciation and interest (1896) and the Fisher relation","","Dimand, Robert W; Betancourt, Rebeca Gomez","Journal of economic perspectives","Undefined","","26","4","2012-09-01","Sep 2012","185","196","185-196","0895-3309","0895-3309","","ENG","Irving Fisher's monograph Appreciation and Interest (1896) proposed his famous equation showing expected inflation as the difference between nominal interest and real interest rates. In addition, he drew attention to insightful remarks and numerical examples scattered through the earlier literature, and he derived results ranging from the uncovered interest arbitrage parity condition between currencies to the expectations theory of the term structure of interest rates. As J. Bradford DeLong wrote in this journal (Winter 2000), 'The story of 20th century macroeconomics begins with Irving Fisher' and specifically with Appreciation and Interest because 'the transformation of the quantity theory of money into a tool for making quantitative analyses and predictions of the price level, inflation, and interest rates was the creation of Irving Fisher.' I discuss the message of Appreciation and Interest, and assess how original he was. [PUBLICATION ABSTRACT]","https://www.proquest.com/docview/1272074563?accountid=12870&bdid=124553&_bd=GTf1MRXHa7LctwW6eGXGDHiSLhQ%3D",""
"Pricing participating longevity-linked life annuities: a Bayesian Model Ensemble approach","","Bravo, Jorge Miguel","European actuarial journal","Undefined","","12","1","2022-01-01","Jan 2022","125","","125-159","2190-9741","","","ENG","Participating longevity-linked life annuities (PLLA) in which benefits are updated periodically based on the observed survival experience of a given underlying population and the performance of the investment portfolio are an alternative insurance product offering consumers individual longevity risk protection and the chance to profit from the upside potential of financial market developments. This paper builds on previous research on the design and pricing of PLLAs by considering a Bayesian Model Ensemble of single population generalised age-period-cohort stochastic mortality models in which individual forecasts are weighted by their posterior model probabilities. For the valuation, we adopt a longevity option decomposition approach with risk-neutral simulation and investigate the sensitivity of results to changes in the asset allocation by considering a more aggressive lifecycle strategy. We calibrate models using Taiwanese (mortality, yield curve and stock market) data from 1980 to 2019. The empirical results provide significant valuation and policy insights for the provision of a cost effective and efficient risk pooling mechanism that addresses the individual uncertainty of death, while providing appropriate retirement income and longevity protection.Participating longevity-linked life annuities (PLLA) in which benefits are updated periodically based on the observed survival experience of a given underlying population and the performance of the investment portfolio are an alternative insurance product offering consumers individual longevity risk protection and the chance to profit from the upside potential of financial market developments. This paper builds on previous research on the design and pricing of PLLAs by considering a Bayesian Model Ensemble of single population generalised age-period-cohort stochastic mortality models in which individual forecasts are weighted by their posterior model probabilities. For the valuation, we adopt a longevity option decomposition approach with risk-neutral simulation and investigate the sensitivity of results to changes in the asset allocation by considering a more aggressive lifecycle strategy. We calibrate models using Taiwanese (mortality, yield curve and stock market) data from 1980 to 2019. The empirical results provide significant valuation and policy insights for the provision of a cost effective and efficient risk pooling mechanism that addresses the individual uncertainty of death, while providing appropriate retirement income and longevity protection.","https://www.proquest.com/docview/2528816066?accountid=12870&bdid=124553&_bd=Rf%2FF1SoVPuz2w4xXNh7vzK4Za5g%3D","https://doi.org/10.1007/s13385-021-00279-w"
"A production function analysis of commercial dairy farms in the highlands of Eritrea using ridge regression","","Ghebremariam, W K; Ortmann, G F; Nsahlai, I V","Agrekon","Undefined","","45","2","2006-06-01","Jun 2006","225","242","225-242","0303-1853","0303-1853","","ENG","This study presents a production function analysis of fresh milk production in the Highlands of Eritrea, where most dairy farmers in Eritrea are located. To ensure representative production functions, this region was divided into three relatively homogenous study areas, namely Central Zone, Mendefera and Dekemhare. Most data for the study were collected in a survey of 120 respondents using a structured questionnaire. To obviate the problem of multicollinearity among explanatory variables, ridge regression was used to estimate milk production functions for each study area. Production elasticities of variable inputs, marginal products (MPx), values of marginal products (VMPx), marginal rates of input substitution (MRS) and leastcost combinations of purchased concentrates and forage were estimated for the three regions. The VMPs of all inputs for Central Zone dairy farmer respondents were estimated to be greater than their input prices, implying that the resources were under-utilized from a profit-maximising perspective (i.e. where VMPx = Px). However, respondents in Mendefera and Dekemhare used concentrates in excess of optimum levels (i.e. VMPx < Px). Analysis of the least-cost combination of purchased concentrates and forage suggests that dairy farmer respondents were also not allocating these resources on a minimum-cost basis. However, the profit maximizing and least-cost criteria assume perfect knowledge, a risk-free environment and competitive markets. Improved information, farmer training and better infrastructure (roads and telecommunications) to promote competitive markets could help to enhance resource allocation decisions by dairy producers. Reprinted by permission of Landbou-Ekonomievereniging van Suid-Afrika = Agricultural Economics Association of Southern Africa","https://www.proquest.com/docview/36581079?accountid=12870&bdid=124553&_bd=TeMtTMwvKdN5f9Uk520yHOXvZjM%3D",""
"Structural models of corporate bond pricing with maximum likelihood estimation","","Li, K L; Wong, Hoi Ying","Journal of empirical finance","Undefined","","15","4","2008-09-01","Sep 2008","751","777","751-777","0927-5398","0927-5398","","ENG","This paper empirically examines the proxy, volatility-restriction (VR) and maximum likelihood (ML) approaches to implementing structural corporate bond pricing models, and documents that ML estimation is the best among the three implementation methods. Empirical studies using either the proxy approach or the VR method conclude that barrier-independent models significantly underestimate corporate bond yields. Although barrier-dependent models tend to overestimate the yield on average, they generate a sizable degree of underestimation. The present paper shows that the proxy approach is an upwardly biased estimator of the corporate assets and makes the empirical framework work systematically against structural models of corporate bond pricing. The VR approach may generate inconsistent corporate bond prices or may fail to give a positive corporate bond price for some structural models. When the Merton, LS, BD and LT models are implemented with ML estimation, we find substantial improvement in their performances. Our empirical analysis shows that the LT model is very accurate for predicting short-term bond yields, whereas the LS and BD models are good predictors for medium-term and long-term bonds. The Merton model however significantly overestimates short-term bond yields and underestimates long-term bond yields. Unlike empirical studies in the past, the Merton model implemented with ML estimation does not consistently underestimate corporate bond yields. All rights reserved, Elsevier","https://www.proquest.com/docview/36945670?accountid=12870&bdid=124553&_bd=3B8XUNfW878W0kEHCvol%2BGe0hYY%3D","https://doi.org/10.1016/j.jempfin.2008.01.001"
"Multiplicative parameters and estimators: applications in economics and finance","","Jasiulewicz, Helena; Kordecki, Wojciech","Annals of Operations Research","Undefined","Springer Science+Business Media, Van Godewijckstraat 30 Dordrecht 3311 GX Netherlands","238","1-2","2016-03-01","March 2016","299","313","299-313","0254-5330","1572-9338","","ENG","In this paper, we pay our attention to multiplicative parameters of random variables and their estimators. We study multiplicative properties of the multiplicative expectation and multiplicative variation as well as their estimators. For distributions having applications in finance and insurance we provide their multiplicative parameters and their properties. We consider, among others, heavy-tailed distributions such as lognormal and Pareto distributions, applied to the modelling of large losses. We discuss multiplicative models, in which the geometric mean and the geometric standard deviation are more natural than their arithmetic counterparts. We provide two examples from the Warsaw Stock Exchange in 1995-2009 and from a bid of 52-week treasury bills in 1992-2009 in Poland as an illustrative example.","https://www.proquest.com/docview/1800490006?accountid=12870&bdid=124553&_bd=er1BPoVNCd7gln0pd9%2FyOw%2Bafx4%3D","https://doi.org/10.1007/s10479-015-2035-x"
"THE SPECULATIVE DEMAND FOR MONEY - AN ALTERNATIVE APPROACH","","Laumas, G S","The American Journal of Economics and Sociology","Scholarly Journals","","35","1","1976-01-01","JAN. 1976","37","","37","00029246","","","ENG","THE SPECULATIVE DEMAND FOR MONEY HAS OCCUPIED AN IMPORTANT ROLE IN KEYNES' GENERAL THEORY.  SINCE THEN IT HAS RECEIVED ONLY SPORADIC ATTENTION, DUE LARGELY TO THE FACT THAT THE THEORY IN ITS ORIGINAL FORM HAS USUALLY FAILED TO SURVIVE THE EMPIRICAL TESTS.  THE SPECULATIVE DEMAND FOR MONEY IS ESTIMATED USING THE GENERAL FRAMEWORK OF THE 'EFFICIENT MARKETS THEORY'.  THE PERIOD COVERED IS OF A RELATIVELY STABLE INSTITUTIONAL SETTING FOLLOWING THE 1951 U.S.  TREASURY-FEDERAL RESERVE ACCORD.  THE RESULTS FOR THIS PERIOD STRONGLY INDICATE THE EXISTENCE OF THE SPECULATIVE DEMAND FOR MONEY.  TABLE.  NOTES.","https://www.proquest.com/docview/217665763?accountid=12870&bdid=124553&_bd=93wXxHlshRNm0ZbFbXNU%2BpmS%2BLc%3D","https://doi.org/10.1111/j.1536-7150.1976.tb01210.x"
"The “probability of recession”: Evaluating probabilistic and non-probabilistic forecasts from probit models of U.S. recessions","","Ratcliff, Ryan","Economics letters","Undefined","Elsevier B.V.","121","2 p.311-315","2013-11-01","Nov 2013","311","315","p. 311-315","0165-1765","0165-1765","","ENG","This letter evaluates forecasts from probit models that use the slope of the yield curve to forecast recessions. These models give reliable non-probabilistic warnings of recessions, but the estimated probabilities do not match the conditional frequency of recession months.","https://www.proquest.com/docview/2253212087?accountid=12870&bdid=124553&_bd=5Z0k1VC5%2FDMi1e4pzojad0IdyZk%3D","https://doi.org/10.1016/j.econlet.2013.09.002"
"The multifactor nature of the volatility of futures markets","","Chiarella, Carl; Tô, Thuy-Duong","Computational economics","Undefined","","27","2-3","2006-04-01","Apr 2006","163","184","163-184","0927-7099","0927-7099","","ENG","This paper estimates a model of interest rate dynamics containing multi-factor Wiener and single-factor Poisson jump volatility components. Data from the highly liquid but short term futures markets are used. The difficult numerical problem of estimating such multi-factor models is resolved by using a genetic algorithm to carry out the optimization procedure. It is established that the multi-factor Wiener volatility components are adequate to model the interest rate dynamics without the need to incorporate Poisson jump components, the existence of which would create difficulties in the practical use of interest rate models. Reprinted by permission of Springer","https://www.proquest.com/docview/36541457?accountid=12870&bdid=124553&_bd=vogFb8RaiBb2C40UAxuE6tMX6Yk%3D","https://doi.org/10.1007/s10614-006-9023-9"
"Non-linear and asymmetric linkages between real growth in the Euro area and global financial market conditions: new evidence","","Mili, Mehdi; Sahut, Jean-Michel; Teulon, Frédéric","Economic modelling","Undefined","","29","3","2012-05-01","May 2012","734","741","734-741","0264-9993","0264-9993","","ENG","This paper deals with transition mechanisms through which financial market conditions affect real economic growth in the Euro area. The informational content of financial variables for predicting real economic growth is assessed, allowing for asymmetric responses to shocks. A nonlinear framework is developed based on a smooth transition model for which the effects of shocks can vary across business cycles when financial indicators modify both the endogenous and state variables. Global financial variables are shown to significantly affect real growth in the Euro area, particularly during periods of recession. Changes in stock market index and yield slope have asymmetric effects on real growth. In recessionary periods, the slope of the US yield curve does not have a significant impact on growth in the Euro area. All rights reserved, Elsevier","https://www.proquest.com/docview/1024211436?accountid=12870&bdid=124553&_bd=3vCbWONqdFsrPvPLQUYH5FRrVUg%3D","https://doi.org/10.1016/j.econmod.2012.01.008"
"The UK Companies Act of 2006, the Sarbanes-Oxley Act of 2002, and important reviews of 2009. Implications for the certainty equivalent coefficient net present value criterion","","Paulo, S","International Journal of Law and Management","Undefined","Emerald Group Publishing Limited, 60-62 Toller Lane Bradford West Yorkshire BD8 9BY UK","52","6","2010-01-01","2010","469","480","469-480","1754-243X","1754-243X","","ENG","Purpose - The purpose of this paper is to draw attention to the fact that the certainty equivalent coefficient net present value criterion, CEC(NPV), in disregarding a fundamental requirement for the calculation of cash flows for purposes of discounted cash flow analysis, invalidates this capital budgeting criterion from the perspective of sound research methodology. The paper also investigates the impact of the UK Companies Act of 2006, the Sarbanes-Oxley Act of 2002, and important reviews such as the Turner Review of 2009, the Walker Review of 2009, and the Review of the Combined Code of 2009 on this operationally invalid capital budgeting criterion, as well as its impact on the process of financial managerial decision making. Design/methodology/approach - The CEC(NPV) as a discounted cash flow capital budgeting criterion was examined from the perspective of the axioms of cash flow estimation as well as from the definition of the cost of capital in order to ascertain the contribution of this criterion to financial management. The relevant sections of the UK Companies Act of 2006, the Sarbanes-Oxley Act of 2002, the Turner Review of 2009, the Walker Review of 2009, and the Review of the Combined Code of 2009 were studied in order to establish whether the CEC(NPV) was able to satisfy the requirements of this legislation and these important reviews. Findings - The CEC(NPV) is construct invalid and does not measure what it purports to measure: it over-states financial viability. As a consequence, it does not meet the requirements of sound research methodology and therefore is at odds with the UK Companies Act of 2006, the Sarbanes-Oxley Act of 2002, and falls foul of the Turner Review of 2009, the Walker Review of 2009, the 2009 Review of the Combined Code issued by the Financial Reporting Council. As such it cannot be endorsed by the Financial Services Authority. Originality/value - The paper usefully shows that the CEC(NPV) denies financial managers application of Fisherian analysis for resolving conflicts in the rankings of mutually exclusive projects, and, the comparison of project cost of capital with their respective internal rates of return. Comparisons of the internal rate of return, not with the risk-free rate (that is assumed to be a constant and which exhibits minimal variability in comparison with the cost of capital), but with the cost of capital cost of capital, are a sine qua non for managerial decision making, especially capital budgeting.","https://www.proquest.com/docview/849485630?accountid=12870&bdid=124553&_bd=i32XAI1Rr2TGYqTpNccHsLURHx0%3D","https://doi.org/10.1108/17542431011093162"
"Consumption, aggregate wealth and expected stock returns: a quantile cointegration approach","","Quineche, Ricardo","Studies in Nonlinear Dynamics and Econometrics","Scholarly Journals","","26","5","2022-12-01","Dec 2022","","","","1081-1826","","","ENG","This paper empirically examines the long-run relationship between consumption, asset wealth and labor income (i.e., cay) in the United States through the lens of a quantile cointegration approach. The advantage of using this approach is that it allows for a nonlinear relationship between these variables depending on the level of consumption. We estimate the coefficients using a Phillips–Hansen type fully modified quantile estimator to correct for the presence of endogeneity in the cointegrating relationship. To test for the null of cointegration at each quantile, we apply a quantile CUSUM test. Results show that: (i) consumption is more sensitive to changes in labor income than to changes in asset wealth for the entire distribution of consumption, (ii) the elasticity of consumption with respect to labor income (asset wealth) is larger at the right (left) tail of the consumption distribution than at the left (right) tail, (iii) the series are cointegrated around the median, but not in the tails of the distribution of consumption, (iv) using the estimated cay obtained for the right (left) tail of the distribution of consumption improves the long-run (short-run) forecast ability on real excess stock returns over a risk-free rate.","https://www.proquest.com/docview/2762942606?accountid=12870&bdid=124553&_bd=h2XQODc3yAEeUqTwDmYFVIOyd9U%3D","https://doi.org/10.1515/snde-2020-0059"
"Out-of-sample forecasts and nonlinear model selection with an example of the term structure of interest rates","","Liu, Yamei; Enders, Walter","Southern economic journal","Undefined","","69","3","2003-01-01","Jan 2003","520","540","520-540","0038-4038","0038-4038","","ENG","","https://www.proquest.com/docview/38415114?accountid=12870&bdid=124553&_bd=53nFTNK74IDgLHDXtpcxiVkA4D8%3D",""
"Interest rate term structure modeling using free-knot splines","","Fernández-Rodríguez, Fernando","Journal of business","Undefined","","79","6","2006-11-01","Nov 2006","3083","3100","3083-3100","0021-9398","0021-9398","","ENG","In this article a new methodology for estimating the term structure of interest rates is developed. Using polynomial splines, a reliable approximation to term structure may depend crucially upon intelligent selection of numbers and position of spline knots, which can be a combinatorially very complex task. A different approach based on heuristic optimization techniques called genetic algorithms is presented. The optimal spline function takes into account the goodness of fit of the spline function. The new methodology was applied to estimating the term structure using data on zero-coupon Euro market bonds. Reprinted by permission of the University of Chicago Press. © All rights reserved","https://www.proquest.com/docview/36585209?accountid=12870&bdid=124553&_bd=bvgNTjzjMsdCBiqLM5ocueeR0mk%3D",""
"Human health risk assessment for exposure to BTEXN in an urban aquifer using deterministic and probabilistic methods: A case study of Chennai city, India","","Rajasekhar, Bokam; Nambi, Indumathi M; Govindarajan, Suresh Kumar","Environmental pollution (Barking, Essex : 1987)","Undefined","","265","Pt B","2020-10-01","Oct 2020","114814","","114814","1873-6424","","","ENG","The aquifer in Tondiarpet, Chennai, had been severely contaminated with petroleum fuels due to an underground pipeline leakage. Groundwater samples were analyzed quarterly for priority pollutants such as benzene, toluene, ethylbenzene, xylenes, and naphthalene (BTEXN) using purge and trap gas chromatography and mass spectrometer from 2016 to 2018. The maximum concentrations of BTEXN in groundwater at the site were found to be greater than the permissible limits significantly. Among the five sampling locations (MW1, MW2, MW3, MW4, and MW5), mean BTEXN levels were found to be higher near MW2, confirming the source location of petroleum leakage. Human health risk assessment was carried out using deterministic and probabilistic methods for exposure to BTEXN by oral and dermal exposure pathways. Risk analysis indicated that mean cancer and non-cancer risks were many times higher than the allowable limits of 1E-06 and 1 respectively in all age groups (children, teens, and adults), implying the adverse health effects. Oral exposure is predominately contributing (60-80%) to the total health risk in comparison to the dermal exposure route. Variability and uncertainty were addressed using the Monte Carlo simulations and the resultant minimum, maximum, 5th, 95th, and mean percentile risks were predicted. Under the random exposure conditions to BTEXN, it was estimated that the risk would become unacceptable for >98.7% of the exposed population. Based on the sensitivity analysis, exposure duration, and ingestion rate are the crucial variables contributing significantly to the health risk. As part of the risk management, preliminary remediation goals for the study site were estimated, which require >99% removal of the BTEXN contamination for risk-free exposures. It is suggested that the residents of Tondiarpet shouldn't utilize the contaminated groundwater mainly for oral ingestion to lower the cancer incidence related to exposure to BTEXN.The aquifer in Tondiarpet, Chennai, had been severely contaminated with petroleum fuels due to an underground pipeline leakage. Groundwater samples were analyzed quarterly for priority pollutants such as benzene, toluene, ethylbenzene, xylenes, and naphthalene (BTEXN) using purge and trap gas chromatography and mass spectrometer from 2016 to 2018. The maximum concentrations of BTEXN in groundwater at the site were found to be greater than the permissible limits significantly. Among the five sampling locations (MW1, MW2, MW3, MW4, and MW5), mean BTEXN levels were found to be higher near MW2, confirming the source location of petroleum leakage. Human health risk assessment was carried out using deterministic and probabilistic methods for exposure to BTEXN by oral and dermal exposure pathways. Risk analysis indicated that mean cancer and non-cancer risks were many times higher than the allowable limits of 1E-06 and 1 respectively in all age groups (children, teens, and adults), implying the adverse health effects. Oral exposure is predominately contributing (60-80%) to the total health risk in comparison to the dermal exposure route. Variability and uncertainty were addressed using the Monte Carlo simulations and the resultant minimum, maximum, 5th, 95th, and mean percentile risks were predicted. Under the random exposure conditions to BTEXN, it was estimated that the risk would become unacceptable for >98.7% of the exposed population. Based on the sensitivity analysis, exposure duration, and ingestion rate are the crucial variables contributing significantly to the health risk. As part of the risk management, preliminary remediation goals for the study site were estimated, which require >99% removal of the BTEXN contamination for risk-free exposures. It is suggested that the residents of Tondiarpet shouldn't utilize the contaminated groundwater mainly for oral ingestion to lower the cancer incidence related to exposure to BTEXN.","https://www.proquest.com/docview/2410705436?accountid=12870&bdid=124553&_bd=9UwhP0Pq18pHZzbj1ggFSKyvTu4%3D","https://doi.org/10.1016/j.envpol.2020.114814"
"Viewpoint: Can technology create a risk-free market?","","Ozemhoya, Carol","OR-MS Today","Scholarly Journals","","44","3","2017-06-01","Jun 2017","","","","10851038","","","ENG","Some people worry about technology costing people jobs and taking over the world as has been portrayed in many major motion pictures, such as the ""Matrix"" series. In fact, many of the advances in technology have made their lives easier and safer and, well, cheaper. There's also advanced technology's impact on financial markets. Artificial intelligence, for example, can enable a trader, financial analyst or even an ordinary person to predict the volatility of the stock markets and even specific stocks. That comes with advanced technology systems that are designed to monitor social media and news sources. One such system, called Vector, tracks social media and news coverage of specific trends, companies, stocks, even personalities and returns information that can assist its user in making crucial financial moves.","https://www.proquest.com/docview/2104172058?accountid=12870&bdid=124553&_bd=EhpCjtDpJR0K1sxOCdTWcSS0vc0%3D",""
"A constrained least square method for estimating a smooth, nonnegative forward rate sequence","","Konno, H; Ito, S","International journal of theoretical and applied finance","Undefined","","8","7","2005-11-01","Nov 2005","989","998","989-998","0219-0249","0219-0249","","ENG","We will develop an efficient method for estimating a smooth nonnegative forward rate sequence using the market price of riskless bonds. This method is an improvement of the classical Carleton-Cooper's method based on standard least squares method, which often generates a non-smooth forward rate sequence and hence is not used in practice. The method to be proposed in this paper is intended to resolve this difficulty. We will impose a smoothness condition while maintaining the fitting error within an acceptable level. The resulting optimization problem is shown to be convex in the region of interest. Therefore, we can calculate a globally optimal solution very fast by standard nonlinear programming algorithms. We will demonstrate that this method generates a smooth forward rate sequence at the expense of a very small increase of fitting error. Reprinted by permission of World Scientific Publishing","https://www.proquest.com/docview/37742666?accountid=12870&bdid=124553&_bd=rutABLF4qwtZOI44zXkQaZTrhEI%3D",""
"Bounded Shooting: A Method for Solving Large Non-Linear Econometric Models Under the Assumption of Consistent Expectations","","Spencer, Peter D","Oxford Bulletin of Economics and Statistics","Scholarly Journals","","47","1","1985-02-01","Feb 1985","79","","79","03059049","","","ENG","The ''multiple shooting'' method can overcome the error propagation problem, which precludes the use of the basic shooting method in most econometric applications.  The multiple method, however, vastly increases the dimensions of the iterative technique used to garner the values of the expectational variables.  Developed by Lipton, Poterba, Sachs, and Summers, the multiple shooting method works well for small sample models.  For forecasting and policy simulation models, this ''multiple'' method will be ruled out.  An alternative method, which takes care of the error problem and keeps the original dimensions for the iterative procedure, is the ''bounded shooting'' method.  The choice of whether to use this bounded method is a matter of trial and error.  The newest procedure has worked admirably on simulations of the Treasury model of the UK economy.","https://www.proquest.com/docview/194246877?accountid=12870&bdid=124553&_bd=TgP%2Fc%2FYJ7DU8wQZBf0YNhIV463k%3D",""
"The behavior of short-term interest rates: international evidence of non-linear adjustment","","Haug, Alfred A; Siklos, Pierre L","Studies in nonlinear dynamics and econometrics","Undefined","","10","4","2006-12-01","Dec 2006","","","","1558-3708","1558-3708","","ENG","This study tests whether changes in the short-term interest rate can best be modelled in a non-linear fashion. We argue that there are good theoretical and empirical reasons for adopting this strategy. Using monthly data from several industrialized countries, namely Canada, Germany, Sweden, Switzerland, UK, and US, we show that the short-term interest rate movements are better explained, usually via the exponential smooth transition autoregression (ESTR). Unlike the existing literature on non-linear estimation, we consider a number of candidates for the transition variable. These include: an error correction term, estimated from an underlying cointegrating relationship predicted by the expectations hypothesis, the US term spread, the domestic spread, inflation and output growth forecasts, and deviations from an inflation target in the case of Canada, the UK and Sweden. The sample spans the period from 1960-1998. We reject linearity in the behavior of short-term interest rate changes and instead find support for a non-linear model with the (lagged) domestic spread as the transition variable. However, other more economically meaningful alternatives perform just as well. For example, in the case of the inflation targeting countries in our sample, the most appropriate transition variable can be the deviation from the publicly announced inflation target. We supplement estimates with extensive diagnostic testing of the non-linear model to ensure that we can reject the linear alternative with reasonable confidence. We believe that changes in central bank policies, and in the reaction of market participants over time to such changes, argue in favor of the non-linear estimation approach. We also argue that any model of the term structure estimated over a fairly long span of time necessitates resort to non-linear estimation methods. Reprinted by permission of Berkeley Electronic Press","https://www.proquest.com/docview/838990868?accountid=12870&bdid=124553&_bd=nAYOn4a9ge8JVhERaMH5lbznG0Q%3D",""
"Can Voluntary Insurance ensure risk-free digital-banking in Chinese-economy: seeking attentions?","","Rahman, Akim M; Islam, Saadi","Journal of Chinese Economic and Business Studies","Scholarly Journals","","20","2","2022-05-01","May 2022","139","158","139-158","14765284","","","ENG","In today’s business-world, services are carried out in a competitive manner country-wise such as China. Banking services are no different, which has resulted digital-banking. Bank Laws regulated by Central-Bank of China are characterized by evolving many factors that are often unpredictable. It faces serious pitfalls being it riskiness. Most cases, customers don’t read terms & conditions of services. Customers don’t save contract-copy. These weaknesses cause abuses. Customer faces perceived-risk. Dealing with challenges in Chinese-economy, application of Akim’s model - Voluntary Insurance (VI) can be impetus for policy-design, which can increase number of users. Welfare Analyses are used for guidance on setting insurance-price ensuring customer’s efficiency-cost so that the VI becomes appealing to parties involved. It can lead to higher number-of-users. In scenario, bank itself is an insurance-seller, the existence of adverse-selection is detected. Here estimated welfare-cost associated with inefficient-pricing created by adverse-selection is quantitatively small; however, advantageous-selection results opposite. Welfare assessment under alternative policy intervention in Chinese-economy will be vital for future-study.","https://www.proquest.com/docview/2681644138?accountid=12870&bdid=124553&_bd=%2F2wMfsJOo0KaWRh1mFrFtYf7RYc%3D","https://doi.org/10.1080/14765284.2021.1929792"
"Switching regimes in the term structure of interest rates during U.S. post-war: a case for the Lucas proof equilibrium","","Vázques, Jesús","Studies in nonlinear dynamics and econometrics","Undefined","","8","1","2004-03-01","Mar 2004","","","","1558-3708","1558-3708","","ENG","Farmer (1991) suggests that in a model in which there are multiple rational expectations (RE) equilibria agents may find it useful to coordinate their expectations in a unique RE equilibrium which is immune to the Lucas Critique. In this paper, we evaluate Lucas proof (LP) equilibrium performance in the context of the term structure of interest rates model by using post-war US data. Estimation results show that LP equilibrium exhibits some important features of the data that are not reproduced by the fundamental equilibrium. For instance, the short rate behaves as a random walk in a regime characterized by low conditional volatility, whereas the term spread Granger-causes changes in the short-rate in periods characterized by high conditional volatility. Reprinted by permission of Berkeley Electronic Press","https://www.proquest.com/docview/37874707?accountid=12870&bdid=124553&_bd=90Dn5z89hMJerPg0gtiFQrZWdTI%3D",""
"Is nonlinear drift implied by the short end of the term structure?","","Takamizawa, Hideyuki","Review of financial studies","Undefined","","21","1","2008-01-01","Jan 2008","311","346","311-346","0893-9454","0893-9454","","ENG","Nonlinear drift models of the short rate are estimated using data on the short end of the term structure, where the cross-sectional relation is obtained by an analytical approximation. The findings reveal that (i) nonlinear physical drift is not implied unless it is strongly affected by cross-sectional dimensions of the data; (ii) nonlinear risk-neutral drift that allows for fast mean reversion for high rates is desirable to explain and predict observed patterns of yield spreads; and (iii) for higher frequency data from which transitory shocks are removed, (ii) still remains valid although the nonlinearity is somewhat reduced. Reprinted by permission of Oxford University Press","https://www.proquest.com/docview/36873081?accountid=12870&bdid=124553&_bd=hTY680vPmZIInvXG0VqUT5kCn6c%3D","https://doi.org/10.1093/rfs/hhm072"
"Quasi-likelihood estimation of a threshold diffusion process","","Su, Fei; Chan, Kung-sik","Journal of econometrics","Undefined","Elsevier B.V.","189","2 p.473-484","2015-12-01","Dec 2015","473","484","p. 473-484","0304-4076","0304-4076","","ENG","The threshold diffusion process, first introduced by Tong (1990), is a continuous-time process satisfying a stochastic differential equation with a piecewise linear drift term and a piecewise smooth diffusion term, e.g., a piecewise constant function or a piecewise power function. We consider the problem of estimating the (drift) parameters indexing the drift term of a threshold diffusion process with continuous-time observations. Maximum likelihood estimation of the drift parameters requires prior knowledge of the functional form of the diffusion term, which is, however, often unavailable. We propose a quasi-likelihood approach for estimating the drift parameters of a two-regime threshold diffusion process that does not require prior knowledge about the functional form of the diffusion term. We show that, under mild regularity conditions, the quasi-likelihood estimators of the drift parameters are consistent. Moreover, the estimator of the threshold parameter is super consistent and weakly converges to some non-Gaussian continuous distribution. Also, the estimators of the autoregressive parameters in the drift term are jointly asymptotically normal with distribution the same as that when the threshold parameter is known. The empirical properties of the quasi-likelihood estimator are studied by simulation. We apply the threshold model to estimate the term structure of a long time series of US interest rates. The proposed approach and asymptotic results can be readily lifted to the case of a multi-regime threshold diffusion process.","https://www.proquest.com/docview/2189534307?accountid=12870&bdid=124553&_bd=U98WFapSVU7S9271biH6xAqc7m8%3D","https://doi.org/10.1016/j.jeconom.2015.03.038"
"An Application of the Capital Asset Pricing Model to Divisional Required Returns","","Van Horne, James C","Financial Management","Scholarly Journals","","9","1","1980-04-01","Spring 1980","14","","14","00463892","","","ENG","A study was made of the application of the capital asset pricing model in decisions regarding capital investments.  The Finnigan Corporation, a high technology company specializing in spectrometer and encoder systems, was the objective of the study.  In 1977, the financial basis for the company's goals was changed from return on sales to return on assets, with minimum required rates of return used as a basis for investment analysis.The specific investment hurdle rates were based on estimates of the cost of debt and equity, with a capitalization balance of one-third debt and two-thirds equity.  The cost of debt was based on the marginal cost of debt adjusted for the impact of taxes.  The cost of equity is proportional to the risk-free rate; plus the product of the beta coefficient and the expected return on the market portfolio less the risk-free rate; plus a return factor for the residual risk.  The rates of return developed through this procedure are considered as minimal.  In addition, goals for managers are based on improvements to rate of return, rather than growth in sales.","https://www.proquest.com/docview/208178448?accountid=12870&bdid=124553&_bd=pDXrsi8CI74SiRWm6EBx7V3f1pQ%3D",""
"Interest rate spreads as predictors of German inflation and business cycles","","Ivanova, D; Lahiri, K; Seitz, F","International Journal of Forecasting","Undefined","","16","1","2000-01-01","2000","39","58","39-58","0169-2070","0169-2070","","ENG","We have studied the comparative performance of a number of interest rate spreads as predictors of the German inflation and business cycle in the post-Bretton Woods era. The two-regime Markov-switch model that we used as a nonlinear filter allows the dynamic behavior of the economy to vary between expansions and recessions in terms of duration and volatility. We found that the bank term structure, the public term structure, and the spread based on the call rate predicted all recessions with a comfortable lead, although they lagged some of the recoveries by a few months. The bank-public spread generates a series of false signals, and missed completely the upturn in the mid-1970s, but detected the last two recoveries with an average lead of nearly 12 months. The source of the predictive power of interest rate spreads lies in the information they contain not only about monetary policy, but also about an assortment of general macroeconomic shocks. The filter probabilities from three of the interest rate differentials also foreshadowed the long swings in the German inflation rate remarkably well, with a lead time of 2-4 years without any false signals.","https://www.proquest.com/docview/18160067?accountid=12870&bdid=124553&_bd=aBJnBXya8WZpNKCRJQkw9guTnHs%3D",""
"Forecasts from a nonlinear t-bill rate model","","Larrain, Maurice; Pagano, Michael","Financial analysts journal","Undefined","","49","6","1993-11-01","Nov 1993","83","88","83-88","0015-198X","0015-198X","","ENG","","https://www.proquest.com/docview/38562743?accountid=12870&bdid=124553&_bd=LEIsR8fYu%2B%2BJtFOvSMlH8i22iIs%3D",""
"Comprehensive evidence implies a higher social cost of CO2","","Rennert, Kevin; Errickson, Frank; Prest, Brian C; Rennels, Lisa; Newell, Richard G; Pizer, William; Kingdon, Cora; Wingenroth, Jordan; Cooke, Roger; Parthum, Bryan; Smith, David; Cromar, Kevin; Diaz, Delavane; Moore, Frances C; Müller, Ulrich K; Plevin, Richard J; Raftery, Adrian E; Ševčíková, Hana; Sheets, Hannah; Stock, James H; Tan, Tammy; Watson, Mark; Wong, Tony E; Anthoff, David","Nature","Undefined","","610","7933","2022-10-01","Oct 2022","687","","687-692","1476-4687","","","ENG","The social cost of carbon dioxide (SC-CO2) measures the monetized value of the damages to society caused by an incremental metric tonne of CO2 emissions and is a key metric informing climate policy. Used by governments and other decision-makers in benefit-cost analysis for over a decade, SC-CO2 estimates draw on climate science, economics, demography and other disciplines. However, a 2017 report by the US National Academies of Sciences, Engineering, and Medicine1 (NASEM) highlighted that current SC-CO2 estimates no longer reflect the latest research. The report provided a series of recommendations for improving the scientific basis, transparency and uncertainty characterization of SC-CO2 estimates. Here we show that improved probabilistic socioeconomic projections, climate models, damage functions, and discounting methods that collectively reflect theoretically consistent valuation of risk, substantially increase estimates of the SC-CO2. Our preferred mean SC-CO2 estimate is $185 per tonne of CO2 ($44-$413 per tCO2: 5%-95% range, 2020 US dollars) at a near-term risk-free discount rate of 2%, a value 3.6 times higher than the US government's current value of $51 per tCO2. Our estimates incorporate updated scientific understanding throughout all components of SC-CO2 estimation in the new open-source Greenhouse Gas Impact Value Estimator (GIVE) model, in a manner fully responsive to the near-term NASEM recommendations. Our higher SC-CO2 values, compared with estimates currently used in policy evaluation, substantially increase the estimated benefits of greenhouse gas mitigation and thereby increase the expected net benefits of more stringent climate policies.The social cost of carbon dioxide (SC-CO2) measures the monetized value of the damages to society caused by an incremental metric tonne of CO2 emissions and is a key metric informing climate policy. Used by governments and other decision-makers in benefit-cost analysis for over a decade, SC-CO2 estimates draw on climate science, economics, demography and other disciplines. However, a 2017 report by the US National Academies of Sciences, Engineering, and Medicine1 (NASEM) highlighted that current SC-CO2 estimates no longer reflect the latest research. The report provided a series of recommendations for improving the scientific basis, transparency and uncertainty characterization of SC-CO2 estimates. Here we show that improved probabilistic socioeconomic projections, climate models, damage functions, and discounting methods that collectively reflect theoretically consistent valuation of risk, substantially increase estimates of the SC-CO2. Our preferred mean SC-CO2 estimate is $185 per tonne of CO2 ($44-$413 per tCO2: 5%-95% range, 2020 US dollars) at a near-term risk-free discount rate of 2%, a value 3.6 times higher than the US government's current value of $51 per tCO2. Our estimates incorporate updated scientific understanding throughout all components of SC-CO2 estimation in the new open-source Greenhouse Gas Impact Value Estimator (GIVE) model, in a manner fully responsive to the near-term NASEM recommendations. Our higher SC-CO2 values, compared with estimates currently used in policy evaluation, substantially increase the estimated benefits of greenhouse gas mitigation and thereby increase the expected net benefits of more stringent climate policies.","https://www.proquest.com/docview/2709741492?accountid=12870&bdid=124553&_bd=kWhsgj9qo3xam1DaWxpONtDieBU%3D","https://doi.org/10.1038/s41586-022-05224-9"
"Predicting Future Earnings Changes Using Machine Learning and Detailed Financial Data","","Chen, Xi; YANG HA (TONY) CHO; Dou, Yiwei; Lev, Baruch","Journal of Accounting Research","Scholarly Journals","","60","2","2022-05-01","May 2022","467","515","467-515","00218456","","","ENG","We use machine learning methods and high‐dimensional detailed financial data to predict the direction of one‐year‐ahead earnings changes. Our models show significant out‐of‐sample predictive power: the area under the receiver operating characteristics curve ranges from 67.52% to 68.66%, significantly higher than the 50% of a random guess. The annual size‐adjusted returns to hedge portfolios formed based on the prediction of our models range from 5.02% to 9.74%. Our models outperform two conventional models that use logistic regressions and small sets of accounting variables, and professional analysts’ forecasts. Analyses suggest that the outperformance relative to the conventional models stems from both nonlinear predictor interactions missed by regressions and the use of more detailed financial data by machine learning.","https://www.proquest.com/docview/2652771167?accountid=12870&bdid=124553&_bd=3JrSXHhwtaj1iFYyd0iy%2Fjuexxg%3D","https://doi.org/10.1111/1475-679X.12429"
"The term structure of policy rules","","Smith, J M; Taylor, John B","Journal of monetary economics","Undefined","","56","7","2009-10-01","Oct 2009","907","917","907-917","0304-3932","0304-3932","","ENG","A formula is derived that links the coefficients of the monetary policy rule for the short-term interest rate to the coefficients of the implied affine equations for long-term interest rates. The formula predicts that an increase in the coefficients in the monetary policy rule will lead to an increase in the coefficients in the affine equations. Empirical evidence for such a prediction is provided. The curve of the response coefficients by maturity is also predicted by the formula. The formula's predictive accuracy and its closed form make it a useful tool for studying the policy implications of embedding no-arbitrage affine theories into macro models. All rights reserved, Elsevier","https://www.proquest.com/docview/37237163?accountid=12870&bdid=124553&_bd=dLC643dReP5RW1IwkYRM19qPyi0%3D","https://doi.org/10.1016/j.jmoneco.2009.09.004"
"Predicting interest rates using shrinkage methods, real‐time diffusion indexes, and model combinations","","Swanson, Norman R; Xiong, Weiqi; Yang, Xiye","Journal of Applied Econometrics","Scholarly Journals","","35","5","2020-08-01","Aug 2020","587","613","587-613","08837252","","","ENG","In the context of predicting the term structure of interest rates, we explore the marginal predictive content of real‐time macroeconomic diffusion indexes extracted from a “data rich” real‐time data set, when used in dynamic Nelson–Siegel (NS) models of the variety discussed in Svensson (NBER technical report, 1994; NSS) and Diebold and Li (Journal of Econometrics, 2006, 130, 337–364; DNS). Our diffusion indexes are constructed using principal component analysis with both targeted and untargeted predictors, with targeting done using the lasso and elastic net. Our findings can be summarized as follows. First, the marginal predictive content of real‐time diffusion indexes is significant for the preponderance of the individual models that we examine. The exception to this finding is the post “Great Recession” period. Second, forecast combinations that include only yield variables result in our most accurate predictions, for most sample periods and maturities. In this case, diffusion indexes do not have marginal predictive content for yields and do not seem to reflect unspanned risks. This points to the continuing usefulness of DNS and NSS models that are purely yield driven. Finally, we find that the use of fully revised macroeconomic data may have an important confounding effect upon results obtained when forecasting yields, as prior research has indicated that diffusion indexes are often useful for predicting yields when constructed using fully revised data, regardless of whether forecast combination is used, or not. Nevertheless, our findings also underscore the potential importance of using machine learning, data reduction, and shrinkage methods in contexts such as term structure modeling.","https://www.proquest.com/docview/2434621512?accountid=12870&bdid=124553&_bd=ScN3bGs9uAAvIBsXfEQrmYcXAP4%3D","https://doi.org/10.1002/jae.2768"
"The Stern Review on the Economic Effects of Climate Change","","","Population And Development Review","Undefined","Blackwell Publishing Ltd., 9600 Garsington Road Oxford OX4 2DQ UK, [URL:http://www.blackwellpublishing.com]","32","4","2006-12-01","Dec 2006","793","798","793-798","0098-7921","1728-4457","","ENG","In a study of the economics of climate change commissioned by the British government, released on 30 October, the former World Bank chief economist Sir Nicholas Stern presents a vigorously argued case for early curtailment of greenhouse gas emissions and proposes mitigation strategies that appear to offer highly favorable benefit-cost ratios. An excerpt from the Executive Summary of the Stern Review, concerned with the nature and magnitude of the deleterious economic consequences of anticipated climate change, is printed below. The principal scientific reviews of knowledge of climate change, its consequences, and mitigation strategies are the (roughly) quinquennial reports of the Intergovernmental Panel on Climate Change (IPCC)-the work of hundreds of lead authors, subjected in turn to elaborate peer review and line-by-line scrutiny by interested governments. They represent a broad, though not total, expert consensus. The third IPCC assessment was issued in 2001; the fourth, already in draft, will be released next year. The Stern Review draws heavily on this scientific underpinning, but goes further than the IPCC exercise in computing economic values for the projected changes and costing out remedial policy responses. More forthright in style and emphatic in its conclusions, it reads as a resounding call to international action. The Review explores the implications of atmospheric concentrations of carbon dioxide and other greenhouse gases being capped at 550ppm (parts per million), double the preindustrial level, an objective it argues is feasible. That concentration would be reached by 2050 at current emission rates, or by 2035 if emissions rise as expected. The resulting warming, it believes, would be 2-5 degree C, roughly in accord with the IPCC's third-assessment estimates (see the Documents section of PDR 27, no. 1 for the IPCC projections). The positive feedbacks identified in some recent studies, generated by processes such as release of methane from permafrost, could lead to still higher temperatures. The forecast effects described are by now familiar, though no less grim for being so: species extinctions, expanding disease zones, reductions in surface water availability, coastal flooding, ocean acidification, and so on. The Review translates these effects into economic losses, adjusting for risk, using Monte Carlo simulation applied to an integrated assessment model (the so-called PAGE 2002 model). The exercise, requiring many heroic-and often contestable-assumptions, produces the most quoted figures in the report: that climate change 'will reduce welfare by an amount equivalent to a reduction in consumption per head of between 5 and 20%'-now and into the future. The absolute magnitude of those projected economic losses is made arbitrarily large by their permanence. Typical benefit-cost calculations applied to appraisal of development projects convert such long-term trajectories into a present value using a discount rate comparable to a market interest rate or some (lower) assumed rate of time preference. The Stern Review, however, argues that any discounting is ethically inappropriate for this global issue: 'if a future generation will be present, we suppose that it has the same claim on our ethical attention as the current one' (p. 31). The only exception is an allowance for the possibility that future generations are not present-through human extinction-which is held to justify a minuscule discount rate of 0.1 percent per annum (p. 161). The percentage economic losses from climate change appear less daunting if set against the recent pace of expansion in the world economy. Real per capita income growth since 1990 has averaged about 1.5 percent per year worldwide, and about 3 percent in developing countries. In such a regime, a 5 percent one-time drop to a lower expansion path is no more than a two- or three-year delay in attaining a given income level. For China and India, whose economies are doubling in size each decade, even a 20 percent reduction in income would be a mere hiccough on the path to affluence-hardly enough to motivate major shifts in lifestyle ambitions. The dire repercussions on global environments of a greenhouse warming at the upper end of the forecast range are poorly captured by those percentages. Demography has a marginal place in the Review. The underlying IPCC emission scenarios incorporate expected population growth, using the UN medium projections. Many of the climate-change effects incur costs that are similarly magnified by population growth. One-sixth of the world's population is 'threatened' by water scarcities; 1 in 20 people may be displaced by a rising sea level; mortality may increase from vector-borne diseases and from malnutrition linked to income losses. The later part of the Review is concerned with mitigation and adaptation strategies. It lays out an ambitious set of policies for transition to a low-carbon economy that could stabilize greenhouse gas concentrations over the next several decades. By 2050, emissions would have to be 25 percent below today's and emissions per unit of GDP 75 percent below. In perhaps the most problematic part of the exercise the Review asserts that such cuts could be achieved at a cost of only around 1 percent of annual global GDP-implying that investment in mitigation should be strongly favored on straightforward economic grounds. (This figure, like others in the Review, is acknowledged to lie within a substantial envelope of uncertainty-here a range of -1.0 percent to +3.5 percent of global GDP (p. 212), or, drawing on a wider range of models, -4 percent to +15 percent (p. 241).) In the decades before the investment pays off, adverse consequences of the warming trends already underway must be dealt with by adaptation, such as through better disaster preparedness, lessening the vulnerability of infrastructure, and risk-pooling measures. The excerpt is from pp. iii-iv and vi-xi. The full Stern Review (579 pages), the executive summary, and the commissioned background papers are available online at 'http://www.hm-treasury.gov.uk/independent_reviews/stern_review_ec o nomics_climate_change/sternreview_index.cfm'. A hard copy of the Review will be issued by Cambridge University Press.","https://www.proquest.com/docview/20244092?accountid=12870&bdid=124553&_bd=R6EENaBhnBSzY5i6yEdO8O0TaCo%3D","https://doi.org/10.1111/j.1728-4457.2006.00153.x"
"Forecasting Key Macroeconomic Variables of the South African Economy using Bayesian Variable Selection","","Chama-Chiliba, M C; Gupta, R; Nkambule, N; Tlotlego, N","Journal of Applied Sciences (Faisalabad)","Undefined","Asian Network for Scientific Information, 308-Lasani Town Sargodha Rd Faislabad 38090 Pakistan","12","7","2012-01-01","20120000","645","652","645-652","1812-5654","1812-5654","","ENG","This study analyzed the forecasting performances of various multivariate models in predicting 1-8-quarters-ahead of the growth rate of GDP, the consumer price index inflation rate and the three months Treasury bill rate for South Africa over an out-of-sample period of 2000:Q1-2011:Q2, using an in-sample period of 1960:Ql-1999:Q4. The study compared the forecasting performances of the classical and the Minnesota-type Bayesian vector autoregressive (VAR) models with those of linear (fixed-parameter) and nonlinear (time-varying parameter) VARs involving a stochastic search algorithm for variable selection, estimated using Markov Chain Monte Carlo methods. In general, the study finds that variable selection, whether imposed on a time-varying VAR or a fixed parameter VAR, and non-linearity in VARs, play an important part in improving predictions when compared to the linear fixed coefficients classical VAR. However, the results does not indicate marked gains in forecasting power across the different Bayesian models, as well as, over the classical VAR model, possibly because the problem of over parameterization in the classical VAR is not that acute in our three-variable system. Hence, future research would aim to look at VAR models that include over 10 variables.","https://www.proquest.com/docview/1762131951?accountid=12870&bdid=124553&_bd=TQwgbaZVeGyHF01olCnKRl22e1k%3D","https://doi.org/10.3923/jas.2012.645.652"
"The contribution of wealth concentration to the subprime crisis: a quantitative estimation","","Goda, Thomas; Lysandrou, Photis","Cambridge Journal of Economics","Undefined","Oxford University Press, UK","38","2","2014-03-01","March 2014","301","327","301-327","0309-166X","0309-166X","","ENG","The crisis that broke out in mid-2007 was caused by the fact that the collateralised debt obligation (CDO) market had grown to a size sufficient to wreak general havoc when it suddenly collapsed. Several authors have argued that economic inequality was important to the growth of this market. This paper attempts to strengthen this argument by concentrating attention on global wealth concentration. After summarising recent evidence on the negative impact of investor demand on US bond yields in the pre-crisis period, new evidence regarding the specific contribution of high-net-worth individuals to this negative impact is presented. The paper then goes on to show how, after having helped to cause a yield problem in the major US debt markets, high-net-worth individuals (via hedge funds) continued to be a major source of the pressure on US banks to resolve this yield problem through the mass production of CDOs. Adapted from the source document.","https://www.proquest.com/docview/1559005390?accountid=12870&bdid=124553&_bd=eAbu1slBCpF9GrTWv4GYJ3rh%2F3U%3D","https://doi.org/10.1093/cje/bet061"
"Psychological pathways to fraud: understanding and preventing fraud in organizations","","Murphy, Pamela R; Dacin, M Tina","Journal of business ethics","Undefined","","101","4","2011-07-01","Jul 2011","601","618","601-618","0167-4544","0167-4544","","ENG","In response to calls for more research on how to prevent or detect fraud (ACAP, Final Report of the Advisory Committee on the Auditing Profession, United States Department of the Treasury, Washington, DC, 2008; AICPA, SAS No. 99: Consideration of Fraud in a Financial Statement Audit, New York, NY, 2002; Carcello et al., Working Paper, University of Tennessee, Bentley University and Kennesaw State University, 2008; Wells, Journal of Accountancy, 2004), we develop a framework that identifies three psychological pathways to fraud, supported by multiple theories relating to moral intuition and disengagement, rationalization, and the role played by negative affect. The purpose of developing the framework is twofold: (1) to draw attention to important yet under-researched aspects of ethical decision-making, and (2) to increase our understanding of the psychology of committing fraud. Our framework builds on the existing fraud triangle (PCAOB, Consideration of fraud in a financial statement audit. AU Section_316, www.pcaobus.org http://www.pcaobus.org URL , 2005) which is used by auditors to assess fraud risk. The fraud triangle is composed of three factors that, together, predict the likelihood of fraud within an organization: opportunity, incentive/pressure, and attitude/rationalization. We find that, when faced with the opportunity and incentive/pressure, there are three psychological pathways to fraud nestled within attitude/rationalization: (1) lack of awareness, (2) intuition coupled with rationalization, and (3) reasoning. These distinctions are important for fraud prevention because each of these paths is driven by a different psychological mechanism. This framework is useful in a number of ways. First, it identifies certain insidious situational factors in which individuals commit fraud without recognizing it. Second, it extends our knowledge of rationalization by theorizing that individuals use rationalization to avoid or reduce the negative affect that accompanies performing an unethical behavior. Negative affect is important because individuals wish to avoid it. Third, it identifies several other methods fraudsters use to reduce negative affect, each of which could serve as potential ""psychological red flags"" and helps predict future fraudulent behavior. Finally, our framework can be used as a theoretical foundation to explore several interventions designed to prevent fraud. Reprinted by permission of Springer","https://www.proquest.com/docview/880337343?accountid=12870&bdid=124553&_bd=thM3NNT2nU6EnR%2FkTShVGECzg80%3D","https://doi.org/10.1007/s10551-011-0741-0"
"On estimability of parsimonious term structure models: an experiment with the nelson-siegel specification","","Virmani, Vineet","Applied economics letters","Undefined","","19","17","2012-11-01","Nov 2012","1703","1706","1703-1706","1350-4851","1350-4851","","ENG","This study addresses operational issues in estimation of parsimonious term structure models. When using price errors, objective function in term structure estimation is a nonlinear function of the model parameters. This necessarily entails using numerical optimization techniques for estimation, which brings to fore the issue of (sensitivity of final results to) the choice of initialization of the optimization routine. This study assesses the sensitivity of the final objective function value and the final parameter vector to the choice of the 'initial guess' during the estimation of the popular Nelson-Siegel model. It turns out that there exist regions in the shape of the objective function where a slight change in (seemingly reasonable) initial vector takes one far from optimum. Choice of the (range of) 'best' starting vector turns out to be an empirical matter. Grid search is recommended. One must first get to a subset of initial values that results in the objective function value near a minimum and then assess the sensitivity of the final parameter vector to those relevant (subset of) initial values. The study illustrates the process using a typical trading day's data. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/1272082951?accountid=12870&bdid=124553&_bd=Qw9bpsbyGMEEMeDUYYe3bG8Bx3A%3D",""
"Nonparametric conditional density estimation of short-term interest rate movements: procedures, results and risk management implications","","Kalda, Ankit; Siddiqui, Sikandar","Applied financial economics","Undefined","","23","8","2013-04-01","Apr 2013","671","684","671-684","0960-3107","0960-3107","","ENG","This article shows how to estimate the conditional density of daily changes in the 3-month T-bill rate, using an extension of the kernel-based estimator proposed by Rosenblatt (1969). The shape of the estimated density is allowed to vary with both the level and the lagged change in rates. Due to the nonparametric character of the estimation procedure, the model produces conditional quantile estimates that are based only on the data and are independent of the modellers' assumptions. The obtained results do not support the assumption of systematically mean-reverting behaviour underlying some theoretical models of short-term interest rate dynamics. However, they clearly indicate the presence of nonlinear first-order autocorrelation and volatility clustering effects, as well as a positive relationship between yield volatility and level. Reprinted by permission of Routledge, Taylor and Francis Ltd.","https://www.proquest.com/docview/1349396005?accountid=12870&bdid=124553&_bd=9rSd0FjE5%2BQg4g1RPPDs3Kfqdto%3D","https://doi.org/10.1080/09603107.2012.741677"
"High and Volatile Real Interest Rates: Where Does the Fed Fit In?","","Antoncic, Madelyn","Journal of Money, Credit, and Banking","Scholarly Journals","","18","1","1986-02-01","Feb 1986","18","","18","00222879","","","ENG","Attention is focused on the question of whether the advent of the increased volatility and level of the real rate of interest was concurrent with the Federal Reserve's October 1979 change in operating procedures.  Within the framework of a model employed by Garbade and Wachtel (1978), the ex ante interest rate can be estimated using a time-varying parameter regression technique.  The data consist of the midmonth values of the implicit price deflator for the personal consumption expenditure index and the midmonth quotations, on a discount rate basis, of one-month Treasury bill yields.  The sample period is January 1965-December 1984.  The results show that neither the high level nor the high degree of volatility of the real rate was coincident with the Fed's policy change.  Analysis indicates that the point in time at which the volatility increased was April 1980, not October 1979.  Furthermore, the real rate was not significantly different from zero throughout most of the 1970s and remained so until October 1980.","https://www.proquest.com/docview/195354547?accountid=12870&bdid=124553&_bd=BBwBb9v70wfCg%2FOqv9KGg3Xxm1Q%3D",""
"Modelling financial time series with threshold nonlinearity in returns and trading volume","","So, Mike K P; Chen, Cathy W S; Chiang, Thomas C; Lin, Doris S Y","Applied Stochastic Models in Business and Industry","Undefined","John Wiley & Sons, Inc , 111 River Street, Hoboken, NJ, 07030-5774, USA, [mailto:custserv@wiley.com], [URL:http://www.wiley.com]","23","4","2007-07-01","July-Aug. 2007","319","338","319-338","1524-1904","1524-1904","","ENG","This paper investigates the effect of past returns and trading volumes on the temporal behaviour of international market returns. We propose a class of nonlinear threshold time-series models with generalized autoregressive conditional heteroscedastic disturbances. Using Bayesian approach, an implementation of Markov chain Monte Carlo procedure is used to obtain estimates of unknown parameters. The proposed family of models incorporates changes in log of volumes in the sense of regime changes and asymmetric effects on the volatility functions. The results show that when differences of log volumes are involved in the system of log return and volatility models, an optimum selection can be achieved. In all the five markets considered, both mean and variance equations involve volumes in the best models selected. Our best models produce higher posterior-odds ratios than that in Gerlach et al.'s (Phys. A Statist. Mech. Appl. 2006; 360:422-444) models, indicating that our return-volume partition of regimes can offer extra gain in explaining return-volatility term structure.","https://www.proquest.com/docview/30093832?accountid=12870&bdid=124553&_bd=jX3SsP%2BaewfWua6ZKo9V0i8LGvs%3D","https://doi.org/10.1002/asmb.674"
"THE PREDICTIVE POWER OF STOCK-MARKET INDICATORS","","Branch, Ben","Journal of Financial and Quantitative Analysis","Scholarly Journals","","11","2","1976-06-01","JUNE 1976","269","","269","00221090","","","ENG","IN THE PAST, THERE HAS BEEN A SIGNIFICANT RELATIONSHIP BETWEEN SOME MARKET INDICATORS AND SUBSEQUENT STOCK-MARKET PERFORMANCE.  THE MOST SUCCESSFUL INDICATORS APPEAR TO BE THE CASH POSITION OF MUTUAL-FUNDS AND THE TREASURY-BILL RATE.  OTHER INDICATORS THAT MAY HAVE SOME FORECASTING ABILITY INCLUDE TOLSR, CONFIDENCE INDEX, SPECIALIST'S SHORT SALES, SECONDARY DISTRIBUTIONS, AND THE INFLATION RATE.  THE STABILITY OF A RELATIONSHIP INVOLVING THESE VARIABLES HOWEVER, IS IN DOUBT.  IN PARTICULAR IT MAY WELL BE THAT INDICATORS WITH FORECASTING ABILITY IN AN EARLIER TIME PERIOD MAY BE LOSING THEIR VALUE.  THIS RESULT WOULD BE EXPECTED TO FOLLOW FROM INCREASING ATTENTION GIVEN TO THE INDICATORS.  AN INDICATOR THAT WORKS WELL IN ONE PERIOD MAY THEREBY ATTRACT ENOUGH ATTENTION TO MAKE IT USELESS IN A LATER PERIOD.  TABLES.","https://www.proquest.com/docview/211896961?accountid=12870&bdid=124553&_bd=sa1TIYhlkyiKPn1fliJtjTQ8yoM%3D",""
"Hoarding the herd: the convenience of productive stocks","","Oglend, Atle; Zhang, Dengjun; Asche, Frank","Journal of futures markets","Undefined","","35","7","2015-07-01","Jul 2015","679","694","679-694","0270-7314","0270-7314","","ENG","This paper investigates the convenience yield that emerges in markets with productive stocks. We isolate the economic fundamentals giving rise to the yield, and show how these map to the empirical convenience yield measure. A model for price dynamics is derived from an economic model for optimal stock levels. We show how the price process reduces to a simple non-linear first-order Markov process. The model is estimated for the Norwegian market for farmed salmon by Generalized Methods of Moments, where stock growth is approximated by sea-water temperature. Our estimation result supports the theorized role of stock growth as a convenience yield component. Our results are relevant for the functioning of futures markets for commodities such as fish and other animal production where systematic stock growth affects the term structure. © 2014 Wiley Periodicals, Inc. Jrl Fut Mark 35:679-694, 2015 Copyright John Wiley & Sons. Reproduced with permission. An electronic version of this article is available online at http://www.interscience.wiley.com","https://www.proquest.com/docview/1695988598?accountid=12870&bdid=124553&_bd=4b%2BOmtg50Hphfkl1T%2FH1w%2B8D18A%3D","https://doi.org/10.1002/fut.21679"
"Yield curve and recession forecasting in a machine learning framework","","Gogas, Periklis; Papadimitriou, Theophilos; Matthaiou, Maria; Chrysanthidou, Efthymia","Computational economics","Undefined","","45","4","2015-04-01","Apr 2015","635","645","635-645","0927-7099","0927-7099","","ENG","In this paper, we investigate the forecasting ability of the yield curve in terms of the U.S. real GDP cycle. More specifically, within a Machine Learning framework, we use data from a variety of short (treasury bills) and long term interest rates (bonds) for the period from 1976:Q3 to 2011:Q4 in conjunction with the real GDP for the same period, to create a model that can successfully forecast output fluctuations (inflation and output gaps) around its long-run trend. We focus our attention in correctly forecasting the instances of output gaps referred for the purposes of our analysis here as recessions. In this effort, we applied a Support Vector Machines technique for classification. The results show that we can achieve an overall forecasting accuracy of 66.7 and 100_% accuracy in forecasting recessions. These results are compared to the alternative standard logit and probit model, to provide further evidence about the significance of our original model. Reprinted by permission of Springer","https://www.proquest.com/docview/1676089372?accountid=12870&bdid=124553&_bd=4cjfnDmIJ%2BCfbdNFE%2B5Zbba9uJQ%3D","https://doi.org/10.1007/s10614-014-9432-0"
"Generalist CEOs and Credit Ratings*","","Ma, Zhiming; Ruan, Lufei; Wang, Danye; Zhang, Haiyan","Contemporary Accounting Research","Scholarly Journals","","38","2","2021-07-01","Summer 2021","1009","1036","1009-1036","08239150","","","ENG","A recent trend is that firms prefer to hire generalist CEOs with transferable skills (across firms or industries) over hiring specialist CEOs, but the consequences of this trend are unclear. In this study, we examine whether credit rating agencies consider a CEO's general skills as a credit risk factor when assessing an entity's overall creditworthiness. We predict and find that generalist CEOs are associated with lower credit ratings, suggesting that the presence of generalist CEOs is a significant credit rating factor. We also find that generalist CEOs are likely to take on more risks, which leads to more volatile performance ex post, and our path analyses confirm default risk is a significant mediator between credit ratings and CEOs' general skills. Our results hold in the presence of additional controls (e.g., CEO characteristics and corporate governance), when applying different fixed‐effect models and different matching methods, and for a subsample with forced CEO turnover. We also find that the negative relationship is attenuated for R&D‐intensive firms and firms in competitive industries. Last, we provide evidence that firms with generalist CEOs face higher borrowing costs, such as bond yields and syndicated loan spreads. Overall, our results contribute to a growing literature on the costs and benefits of hiring generalist CEOs, by providing a full picture of why hiring a generalist CEO may benefit shareholders but also cause misalignments with bondholders' interests.","https://www.proquest.com/docview/2539490179?accountid=12870&bdid=124553&_bd=e9CI3XMq9c78utkl%2FyVsq7lFl%2FM%3D","https://doi.org/10.1111/1911-3846.12662"
"Unit-Roots Test for Time-Series Data with a Linear Time Trend","","Said, Said E","Journal of Econometrics","Scholarly Journals","","47","2,3","1991-02-01","Feb/Mar 1991","285","","285","03044076","","","ENG","Time-series models are useful for forecasting, but most standard methods of fitting such models require the series to be stationary.  Recently, many tests for detecting unit roots in time-series data (tests for nonstationarity) have been proposed.  A test is developed for unit roots in autoregressive integrated moving average (ARIMA) models containing a linear time trend term.  The method of testing is based on the estimation procedure suggested in Fuller (1976), which is basically a nonlinear type of estimation.  The test statistic is standard output from most regression programs and has a limit distribution whose percentiles have been tabulated.  The use of the unit-root estimator and its corresponding limiting distribution in hypothesis testing is demonstrated using one-year US Treasury bill data.","https://www.proquest.com/docview/196646274?accountid=12870&bdid=124553&_bd=zJUfODflQqrpYMNwxLFgtWr%2B5jc%3D",""
"The Co-Integrated Vector Autoregression with Errors-in-Variables","","Nielsen, Heino Bohn","Econometric reviews","Undefined","","35","2","2016-01-01","0, 2016","169","169","169","0747-4938","0747-4938","","ENG","The co-integrated vector autoregression is extended to allow variables to be observed with classical measurement errors (ME). For estimation, the model is parametrized as a time invariant state-space form, and an accelerated expectation-maximization algorithm is derived. A simulation study shows that (i) the finite-sample properties of the maximum likelihood (ML) estimates and reduced rank test statistics are excellent (ii) neglected measurement errors will generally distort unit root inference due to a moving average component in the residuals, and (iii) the moving average component may-in principle-be approximated by a long autoregression, but a pure autoregression cannot identify the autoregressive structure of the latent process, and the adjustment coefficients are estimated with a substantial asymptotic bias. An application to the zero-coupon yield-curve is given.","https://www.proquest.com/docview/1771454167?accountid=12870&bdid=124553&_bd=p4YxsGMtXs%2FyPnerlnzaW5iw6r0%3D",""
"Big data analytics in economics: What have we learned so far, and where should we go from here?","","Swanson, Norman R; Xiong, Weiqi","The Canadian Journal of Economics","Scholarly Journals","","51","3","2018-08-01","Aug 2018","695","746","695-746","00084085","","","ENG","Research into predictive accuracy testing remains at the forefront of the forecasting field. One reason for this is that rankings of predictive accuracy across alternative models, which under misspecification are loss function dependent, are universally utilized to assess the usefulness of econometric models. A second reason, which corresponds to the objective of this paper, is that researchers are currently focusing considerable attention on so‐called big data and on new (and old) tools that are available for the analysis of this data. One of the objectives in this field is the assessment of whether big data leads to improvement in forecast accuracy. In this survey paper, we discuss some of the latest (and most interesting) methods currently available for analyzing and utilizing big data when the objective is improved prediction. Our discussion includes a summary of various so‐called dimension reduction, shrinkage and machine learning methods as well as a summary of recent tools that are useful for ranking prediction models associated with the implementation of these methods. We also provide a brief empirical illustration of big data in action, in which we show that big data are indeed useful when predicting the term structure of interest rates.","https://www.proquest.com/docview/2084430156?accountid=12870&bdid=124553&_bd=cpYSVkdKfmXiOtIKQ9lncHHORtc%3D","https://doi.org/10.1111/caje.12336"
"Interest Rate Term Structure Estimation with Exponential Splines: A Note","","Shea, Gary S","The Journal of Finance","Scholarly Journals","","40","1","1985-03-01","Mar 1985","319","","319","00221082","","","ENG","In a recent paper, Vasicek and Fong (1982) develop exponential spline functions as models of the interest rate term structure and contend that such models are superior to polynomial spline models.  Empirical applications of their technique are presented.  The analysis suggests that modeling with exponential spline functions will yield forward rates that are unstable and fluctuate much like forward rates obtained with polynomial splines.  While the Vasicek-Fong (VF) model is just as capable of modeling the term structure as are ordinary polynomial splines, it brings no practical advantages to the modeling task.  Not only is it just as necessary to constrain and coax the VF model to achieve reasonable term structure approximations, but the exponential transformation of the data and the imposed asymptotics do not seem to add any more realism to the estimated term structure.  There is the extra computational burden of estimating a nonlinear rather than a linear model, and the exponential data transformation often makes for very ill-conditioned sample data.  Moreover, the resulting term structure estimates are quite likely almost identical to those from a polynomial spline model.","https://www.proquest.com/docview/194704357?accountid=12870&bdid=124553&_bd=Z3EADZ5i%2F2EsZmssJaJOivZzgRQ%3D",""
"Recent empirical evidence on the impact of the primary budget deficit on nominal longer term treasury note interest rate yields","","Cebula, Richard J","Global Business & Economics Review","Undefined","Inderscience Enterprises Ltd , World Trade Center Bldg , 29 Rout de Pre-Bois, Case Postale 896, Geneve 15, CH-1215, Switzerland, [mailto:dorgham@pop3.powernet.co.uk], [URL:http://DRL:http://www.inderscience.com/search/index.php?action=record&rec_id=6919&prevQuery=&ps=10&m=orhttp://www.inderscience.com]","7","1","2005-01-01","2005","47","58","47-58","1097-4954","1097-4954","","ENG","This study empirically investigates the impact of the federal budget deficit on the nominal interest rate yields on seven and ten year treasury notes over the 1992-2003 period. To measure the budget deficit, the primary budget deficit, which excludes net interest payments by the treasury, is adopted. In a loanable funds model that includes the monetary base, expected inflation, an ex ante real short term interest rate yield and an ex ante real intermediate term interest rate yield, the percentage growth rate of real GDP, and the percentage growth rate of the S&P 500 stock index, instrumental variables estimations using quarterly data reveal that the primary deficit has raised the nominal interest rate yields on both seven year and ten year treasury notes over the study period, raising serious concerns about the currently surging national debt.","https://www.proquest.com/docview/29042881?accountid=12870&bdid=124553&_bd=tqRjg1c55zhriy3gOCIrwVr8gcE%3D","https://doi.org/10.1504/GBER.2005.006919"
"Recovering default risk from CDS spreads with a nonlinear filter","","Guarin, Alexander; Liu, Xiaoquan; Ng, Wing Lon","Journal of economic dynamics and control","Undefined","","38","1","2014-01-01","Jan 2014","87","104","87-104","0165-1889","0165-1889","","ENG","We propose a nonlinear filter to estimate the time-varying default risk from the term structure of credit default swap (CDS) spreads. Based on the numerical solution of the Fokker-Planck equation (FPE) using a meshfree interpolation method, the filter performs a joint estimation of the risk-neutral default intensity and CIR model parameters. As the FPE can account for nonlinear functions and non-Gaussian errors, the proposed framework provides outstanding flexibility and accuracy. We test the nonlinear filter on simulated spreads and apply it to daily CDS data of the Dow Jones Industrial Average component companies from 2005 to 2010 with supportive results. [PUBLICATION ABSTRACT] All rights reserved, Elsevier","https://www.proquest.com/docview/1493999260?accountid=12870&bdid=124553&_bd=HMtawTiX07t5UOyrlBidBjhDklc%3D",""
"Structural Laplace transform and compound autoregressive models","","Darolles, S; Gourieroux, C; Jasiak, J","Journal of time series analysis","Undefined","","27","4","2006-07-01","Jul 2006","477","504","477-504","0143-9782","0143-9782","","ENG","This paper presents a new general class of compound autoregressive (Car) models for non-Gaussian time series. The distinctive feature of the class is that Car models are specified by means of the conditional Laplace transforms. This approach allows for simple derivation of the ergodicity conditions and ensures the existence of forecasting distributions in closed form, at any horizon. The last property is of particular interest for applications to finance and economics that investigate the term structure of variables and/or of their nonlinear transforms. The Car class includes a number of time-series models that already exist in the literature, as well as new models introduced in this paper. Their applications are illustrated by examples of portfolio management, term structure and extreme risk analysis. Reprinted by permission of Blackwell Publishers","https://www.proquest.com/docview/838989838?accountid=12870&bdid=124553&_bd=5%2BHxYnQMOTnpN8UD5%2Fx7NG8vFUQ%3D","https://doi.org/10.1111/j.1467-9892.2006.00479.x"
"Leveraging latent representations for milk yield prediction and interpolation using deep learning","","Liseune, Arno; Salamone, Matthieu; Van den Poel, Dirk; Van Ranst, Bonifacius; Hostens, Miel","Computers and Electronics in Agriculture","Scholarly Journals","","175","","2020-08-01","Aug 2020","1","","","0168-1699","","","ENG","In this study, we propose a lactation model that estimates the daily milk yield by using autoencoders to generate a latent representation of all milk yields observed during the entire lactation cycle, irrespective of the length of the time interval between the different measurements. More specifically, we propose a sequential autoencoder (SAE) to process the sequential data, extract and decode the low-dimensional representations and generate the milk yield sequences. The SAE is compared with a more traditional multilayer perceptron model (MLP) which uses herd and parity information and lagged milk yields as input. Results show that incorporating the recorded daily milk yields, lactation number, herd statistics as well as reproduction and health events the cow encountered during the lactation cycle results in the most qualitative latent representations. Moreover, by leveraging these low-dimensional encodings, the SAE reconstructed the entire milk yield curve with a higher accuracy than the MLP. Hence, we present a framework that is able to infer missing milk yields along the entire lactation curve which facilitates selection and culling decisions as well as the estimation of future earnings and costs. Furthermore, the model allows farmers to enhance their animal monitoring systems as it incorporates the sequence of health and reproduction events to forecast the cow's future productivity.","https://www.proquest.com/docview/2448458126?accountid=12870&bdid=124553&_bd=Vx7b1zNm9F5Ybl%2FzOHvGL0gKcZ4%3D","https://doi.org/10.1016/j.compag.2020.105600"
"A nonlinear model of the term structure of interest rates","","Tice, Julian; Webber, Nick","Mathematical Finance","Scholarly Journals","","7","2","1997-04-01","Apr 1997","177","","177-209","09601627","","","ENG","An economically motivated 2-factor term structure model that generalizes existing stochastic mean term structure models is presented.  By allowing a certain parameter to acquire dynamical behavior, the 2-factor model is extended to obtain a nonlinear 3-factor model that is shown, in a deterministic version, to be equivalent to the Lorenz system of differential equations.  With reasonable parameter values the model exhibits chaotic behavior.  It successfully emulates certain properties of interest rates including cyclical behavior on a business cycle time scale.  Estimation and pricing issues are discussed.  Standard PCA techniques used to estimate HJM type models are observed to be equivalent to dimensional estimates commonly applied to spatial data in nonlinear systems analysis.  It is concluded that techniques commonly used in the analysis of nonlinear systems may be directly applicable to interest rate models, offering new insights in the development of these models.  Tests of nonlinearity in interest rate behavior may need to focus on long cycle times.","https://www.proquest.com/docview/230020998?accountid=12870&bdid=124553&_bd=chqqbzaiCIib%2BAL%2Fb5Qb6XxW7Ok%3D",""
"Forecasting Key Macroeconomic Variables of the South African Economy using Bayesian Variable Selection","","Chama-Chiliba, M C; Gupta, R; Nkambule, N; Tlotlego, N","Journal of Applied Sciences (Faisalabad)","Undefined","Asian Network for Scientific Information, 308-Lasani Town Sargodha Rd Faislabad 38090 Pakistan","12","7","2012-01-01","2012","645","652","645-652","1812-5654","1812-5654","","ENG","This study analyzed the forecasting performances of various multivariate models in predicting 1-8-quarters-ahead of the growth rate of GDP, the consumer price index inflation rate and the three months Treasury bill rate for South Africa over an out-of-sample period of 2000:Q1-2011:Q2, using an in-sample period of 1960:Ql-1999:Q4. The study compared the forecasting performances of the classical and the Minnesota-type Bayesian vector autoregressive (VAR) models with those of linear (fixed-parameter) and nonlinear (time-varying parameter) VARs involving a stochastic search algorithm for variable selection, estimated using Markov Chain Monte Carlo methods. In general, the study finds that variable selection, whether imposed on a time-varying VAR or a fixed parameter VAR, and non-linearity in VARs, play an important part in improving predictions when compared to the linear fixed coefficients classical VAR. However, the results does not indicate marked gains in forecasting power across the different Bayesian models, as well as, over the classical VAR model, possibly because the problem of over parameterization in the classical VAR is not that acute in our three-variable system. Hence, future research would aim to look at VAR models that include over 10 variables.","https://www.proquest.com/docview/1266762085?accountid=12870&bdid=124553&_bd=n0Lfmn3bsLgW%2FWAsBoumps2lwfg%3D","https://doi.org/10.3923/jas.2012.645.652"
"Vector equilibrium correction models with non-linear discontinuous adjustments","","Bec, Frédérique; Rahbek, Anders","Econometrics journal","Undefined","","7","2","2004-01-01","2004","628","651","628-651","1368-4221","1368-4221","","ENG","Cointegration is studied for a non-linear autoregressive process characterized by discontinuous and regime-dependent equilibrium or error correction. Here the disequilibrium, as measured by the norm of linear 'stable' or cointegrating relations, determines the regime and hence the equilibrium correction of the process. Importantly, switching between regimes is thereby allowed to be caused endogenously. The transition function may be either observable as in, e.g. threshold processes, or unobservable when transition probabilities are specified as in, e.g. autoregressive conditional root processes. Conditions for stationarity, geometric ergodicity as well as existence of moments are derived using a general multivariate Markov process. From these conditions it is shown that imposing parametric restrictions on only one of the regimes of the non-linear vector autoregression is sufficient to ensure higher-order moments and linear cointegrating relations which are geometrically ergodic and hence also stationary. Additionally, estimation is considered when the cointegrating relations are known and asymptotic theory is provided for this case. Based on many existing empirical analyses of, e.g. real exchange rates and interest rates spreads, the proposed dynamics appears to be desirable. This is also reflected in the included analysis of the German term structure where empirical evidence is found for discontinuous threshold error correction as opposed to classic linear error correction. Reprinted by permission of Blackwell Publishing","https://www.proquest.com/docview/38041067?accountid=12870&bdid=124553&_bd=qzwLkMzxt2Xsi2MjgjCxo%2BqjKW0%3D",""
"Discrete-Time Affine Q Term Structure Models with Generalized Market Prices of Risk","","Le, Anh; Singleton, Kenneth; Dai, Qiang","Review of financial studies","Undefined","","23","5","2010-05-01","May 2010","2184","2184","2184","0893-9454","0893-9454","","ENG","This article develops a rich class of discrete-time, nonlinear dynamic term structure models (DTSMs). Under the risk-neutral measure, the distribution of the state vector Xt resides within a family of discrete-time affine processes that nests the exact discrete-time counterparts of the entire class of continuous-time models in Duffie and Kan (1996) and Dai and Singleton (2000). Under the historical distribution, our approach accommodates nonlinear (nonaffine) processes while leading to closed-form expressions for the conditional likelihood functions for zero-coupon bond yields. As motivation for our framework, we show that it encompasses many of the equilibrium models with habit-based preferences or recursive preferences and long-run risks. We illustrate our methods by constructing maximum likelihood estimates of a nonlinear discrete-time DTSM with habit-based preferences in which bond prices are known in closed form. We conclude that habit-based models, as typically parameterized in the literature, do not match key features of the conditional distribution of bond yields. [PUBLICATION ABSTRACT] Reprinted by permission of Oxford University Press","https://www.proquest.com/docview/1866655252?accountid=12870&bdid=124553&_bd=UjZOhNxXu8qyOUh9bOaAzCN4Sdk%3D",""
