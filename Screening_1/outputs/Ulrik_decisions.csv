paper_id,title,abstract,authors,year,doi,link,database,llm_summary,i1_hint,i2_hint,i3_hint,model,reviewer,decision,notes,timestamp
a2291dc0a2cab336,A Comprehensive Approach to Residual Value Analysis in the Luxury Automotive Market,"Global automotive markets have introduced new complexities, from the surge in powertrain diversity to evolving consumer purchasing habits. In the luxury car segment, residual value (RV), the car’s actual value at the end of ownership, is particularly significant. A high RV translates into lower overall ownership costs, as the car retains more of its value over time, which can boost demand as well as leasing margin. For this reason, the analysis of RV offers key insights for strategic decision-making. The present study leverages a large-scale global dataset spanning a 10-year period, capturing both internal vehicle features and three available external market conditions (CPI, unemployment rate, and 10-year bond yield). Our approach employs machine learning techniques, particularly CatBoost, achieving a mean absolute percentage error of around 5%, deemed highly acceptable within the industry. Moreover, a novel method to enhance the reliability and interpretability of RV estimations is proposed by quantifying depreciation thresholds and mitigating distortions related to sample composition via a “Standard Vehicle” concept. The approach has been validated by Ferrari S.p.A., the provider of the data, serving as a robust tool for automotive industry stakeholders.",A. Ghibellini; A. Scioletti; M. Coletto; L. Bononi; M. Gabbrielli,2025,10.1109/access.2025.3591765,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11091377,ieeexplore,"This study analyzes residual values in the luxury automotive market using a large global dataset and machine learning (CatBoost). It incorporates vehicle features and market conditions (CPI, unemployment, bond yield) to predict residual values with high accuracy (MAPE ~5%). A novel method using depreciation thresholds and a ""Standard Vehicle"" concept enhances reliability and interpretability. The approach was validated by Ferrari S.p.A.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:21:46.569772
b5415c8117608d9f,A Discussion of Non-Gaussian Price Processes for Energy and Commodity Operations,"Energy sources and commodities exhibit high price risk. This risk is thus an important feature of operational models of the value chains for these goods. These models typically employ Gaussian-based representations of the evolution of this uncertainty. This approach facilitates the optimization of operational policies but is at odds with empirical facts about energy and commodity prices, which are better captured by non-Gaussian processes. We discuss this alternative modeling strategy, focusing on Lévy processes. As an illustration, we show that it substantially increases the optimal policy value in a simplified merchant natural gas storage setting. Further, we highlight potential implications of using this approach to formulate realistic energy and commodity operations models. Our work has broader relevance for modeling the dynamics of both other market variables and operational quantities, such as exchange rates and demand forecasts. The study of how the adoption of non-Gaussian processes may impact energy and commodity operations is an appealing area for future research. © 2021 Elsevier B.V., All rights reserved.","Gambaro, A.M.; Secomandi, N.",2021,10.1111/poms.13250,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096644292&doi=10.1111%2Fpoms.13250&partnerID=40&md5=5666d8014dd126fe7d35d4bc4040ac34,scopus,"This paper discusses the use of non-Gaussian processes, specifically Lévy processes, to model the price dynamics of energy and commodities, arguing that these are more empirically accurate than traditional Gaussian models. It illustrates the benefits with a natural gas storage example and suggests broader implications for operational models and forecasting.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:21:56.331869
f9836cc4dd014711,A Gaussian Process of Yield Rates Calibrated with Strips,"This paper presents a Gaussian multivariate factor model of the term structure of interest rates. It shows that there exists a martingale valuation law of the factors so that the price function of a zero-coupon bond is an exponential spline. The model’s linear and Gaussian structure yields a simple model where estimation and calibration are relatively easy to do. Using yield data on stripped bonds, the spline model gives a very good approximation of the yield curve at all times. Moreover, the crucial Gaussian assumption is reasonable when modeling the dynamics for short periods like one year. © 2001 Taylor & Francis Group, LLC. © 2017 Elsevier B.V., All rights reserved.","Carrière, J.F.",2001,10.1080/10920277.2001.10595995,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011238970&doi=10.1080%2F10920277.2001.10595995&partnerID=40&md5=b9fd767ad96ca600385575d9c079e5fb,scopus,"This paper introduces a Gaussian multivariate factor model for interest rate term structures, where bond prices are represented by exponential splines. The model's linear and Gaussian properties facilitate straightforward estimation and calibration. Empirical results using stripped bond yield data demonstrate the spline model's effectiveness in approximating yield curves, with the Gaussian assumption being valid for short-term dynamics.",True,True,False,gemini-2.5-flash-lite,Ulrik,M,,2025-10-13T15:23:20.675356
fd4f0e95b6a42d4c,A Machine Learning Approach to Forecast Economic Recessions-An Italian Case Study,"In economic activity, recessions represent a period of failure in Gross Domestic Product (GDP) and usually are presented as episodic and non-linear. For this reason, they are difficult to predict and appear as one of the main problems in macroeconomics forecasts. A classic example turns out to be the great recession that occurred between 2008 and 2009 that was not predicted. In this paper, the goal is to give a different, although complementary, approach concerning the classical econometric techniques, and to show how Machine Learning (ML) techniques may improve short-term forecasting accuracy. As a case study, we use Italian data on GDP and a few related variables. In particular, we evaluate the goodness of fit of the forecasting proposed model in a case study of the Italian GDP. The algorithm is trained on Italian macroeconomic variables over the period 1995:Q1-2019:Q2. We also compare the results using the same dataset through Classic Linear Regression Model. As a result, both statistical and ML approaches are able to predict economic downturns but higher accuracy is obtained using Nonlinear Autoregressive with exogenous variables (NARX) model.","Cicceri, Giovanni; Inserra, Giuseppe; Limosani, Michele",2020,10.3390/math8020241,,wos,"This paper presents a Machine Learning (ML) approach, specifically a Nonlinear Autoregressive with exogenous variables (NARX) model, to forecast economic recessions using Italian GDP data. The ML model is trained on macroeconomic variables from 1995:Q1-2019:Q2 and compared against a Classic Linear Regression Model. The study concludes that while both methods can predict downturns, the NARX model achieves higher accuracy.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:23:39.299413
1f7924612848e55b,A Machine-Learning-Based Approach for Natural Gas Futures Curve Modeling,"This work studies the term structure dynamics in the natural gas futures market, focusing on the Dutch Title Transfer Facility (TTF) daily futures prices. At first, using the whole dataset, we compared the in-sample fitting performance of three models: the four-factor dynamic Nelson–Siegel–Svensson (4F-DNSS) model, the five-factor dynamic De Rezende–Ferreira (5F-DRF) model, and the B-spline model. Our findings suggest that B-spline is the method that achieves the best in-line fitting results. Then, we turned our attention to forecasting, using data from 20 January 2011 to 13 May 2022 as the training set and the remaining data, from 16 May to 13 June 2022, for day-ahead predictions. In this second part of the work we combined the above mentioned models (4F-DNSS, 5F-DRF and B-spline) with a Nonlinear Autoregressive Neural Network (NAR-NN), asking the NAR-NN to provide parameter tuning. All the models provided accurate out-of-sample prediction; nevertheless, based on extensive statistical tests, we conclude that, as in the previous case, B-spline (combined with an NAR-NN) ensured the best out-of-sample prediction.",,2023,10.3390/en16124746,,proquest,"This study compares the performance of three models (4F-DNSS, 5F-DRF, and B-spline) for modeling the term structure of natural gas futures prices, specifically the TTF. The B-spline model demonstrated superior in-sample fitting. For day-ahead predictions, the B-spline model, when combined with a Nonlinear Autoregressive Neural Network (NAR-NN) for parameter tuning, achieved the best out-of-sample prediction accuracy.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:23:45.359222
99d0e8a05fcc941c,A Markov regime-switching model for the semiconductor industry cycles,"Because of the huge fluctuation in the semiconductor business, it has been a challenging work for the industry researchers to predict the turning points of the semiconductor industry cycles. To catch the cyclical behavior of the semiconductor business, we propose a Markov Regime-Switching model with two regimes representing expansion and contraction. The simple nonlinear, two states, regime-switching model shows a successful in-sample prediction on the contraction of semiconductor industry sales during the period of 1990:01-2003:08. (c) 2006 Elsevier B.V. All rights reserved.","Liu, Wen-Hsien; Chyi, Yih-Luan",2006,10.1016/j.econmod.2006.02.007,,wos,This paper proposes a Markov regime-switching model with two states (expansion and contraction) to predict turning points in the semiconductor industry cycles. The model successfully predicted the contraction in sales from 1990 to 2003.,True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:23:56.375179
d476fa9fc94bed8b,A New Linear Estimator for Gaussian Dynamic Term Structure Models,"This article proposes a novel regression-based approach to the estimation of Gaussian dynamic term structure models. This new estimator is an asymptotic least-square estimator defined by the no-arbitrage conditions upon which these models are built. Further, we note that our estimator remains easy-to-compute and asymptotically efficient in a variety of situations in which other recently proposed approaches might lose their tractability. We provide an empirical application in the context of the Canadian bond market.","de los Rios, Antonio Diez",2015,10.1080/07350015.2014.948176,,wos,"This paper introduces a new regression-based estimator for Gaussian dynamic term structure models, which is asymptotically efficient and easy to compute. It is applied to the Canadian bond market.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:24:07.919127
e87df0ce8abe00f6,A Novel Particle Swarm Optimizer and Its Application to the Yield Curve Estimation Problem,"Particle swarm optimization (PSO) has been considered as one of the main swarm intelligence algorithms for solving single-objective optimization problem. How to update the velocities and positions of a swarm of particles is key to its optimization performance. In this paper, we propose to use the moving average of the local best positions visited so far as a key information to update the velocities and positions. Further, a central learning strategy is proposed in which the center of the local best positions is computed and used to update the global best position. Combining these two strategies with the updating formulas which are inspired by the free electron model in metal conductors placed in an external electric field, we name the proposed PSO algorithm as PSO with moving average and central learning strategies (dubbed as MAPSO). We test the performance of MAPSO on the CEC 2017 test problems with 10 and 30 dimensions. Experimental results show that MAPSO significantly outperforms some well-known PSOs in general. We then apply MAPSO on a very challenging real-world problem, i.e. the yield curve estimation problem, in macroeconomics. Our experimental study on the yield curve estimation problem with Shanghai interbank offered rates shows that MAPSO can effectively solve the problem and achieve the state-of-the-art performance.",J. Zhang; B. Shi,2022,10.1109/access.2022.3220792,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9943541,ieeexplore,"This paper introduces a novel Particle Swarm Optimization (PSO) algorithm called MAPSO, which incorporates moving average and central learning strategies inspired by the free electron model. MAPSO demonstrates superior performance on benchmark test problems and is effectively applied to the yield curve estimation problem using Shanghai interbank offered rates, achieving state-of-the-art results.",True,True,False,gemini-2.5-flash-lite,Ulrik,M,,2025-10-13T15:24:23.240418
f2a47be779f44ec8,A Public Administration Moment: Forging an Agenda for Financial Regulatory Reform,"The numbers are staggering. As the financial crisis deepens, American financial companies will lose an estimated $3.6 trillion in non-performing loans and lost asset value (Lohr 2009). Nationally, home prices have fallen more than 18% from peak levels -- as much as 40% in some states -- and in 2008, lenders initiated more than 2.25 million home foreclosures (Duke 2009). The biggest financial crisis since the Great Depression, as the Treasury Department describes it, is a crisis of confidence, of capital, of credit, and of consumer and business demand. Just as staggering, however, is the lack of attention given to the government administrative capacities that failed going into the crisis, and that require fervent attention as they grope toward a reengineered financial system and regulatory structure. Public administration scholars and practitioners play a vital role in forging the future of finance.",,2009,10.1111/j.1540-6210.2009.02008.x,,proquest,This article discusses the failure of government administrative capacities during the financial crisis and emphasizes the role of public administration scholars and practitioners in reengineering the financial system and regulatory structure. It highlights the significant financial losses and foreclosures resulting from the crisis.,False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:24:27.027622
868c96ac24ae4368,"A Public, Open, and Independently-Curated Database of Happiness Coefficients","We present a nascent database of happiness coefficients. This is a synthesis of evidence on the size of improvements to human life experience that can be expected from changing objective, policy-amenable circumstances. The wealth of data on people’s self-reported satisfaction with life in a wide variety of circumstances, from around the world, including respondents undergoing a diversity of changes and life events and subject to a variety of public policies and policy changes, has provided a rich base of knowledge about what makes life good. This growing research literature has in recent years been met with interest from central governments looking for accountable but more human-centred approaches to measuring progress, as well as for communicating objectives, making policy, and allocating resources. Meanwhile, frameworks for benefit-cost accounting using inference from life satisfaction data have been devised. In some cases central government finance departments and treasuries are incorporating this approach into their formal methodology for budgeting. The body of causal inference about these effects is still somewhat diffuse. Collating, reviewing, and synthesizing such evidence should be led initially by academia and ultimately by a broad academic, civil society, and government collaboration. We report on the assembly of a database of summary estimates for Canada, supplemented where needed by evidence from around the world. The categorized domains of individual experience and circumstances include Education, Environment, Work, Finances, Health, Social Capital, and Crime. The paper also explains the context for and limitations of the use of a database of happiness coefficients.",,2023,10.1007/s10902-023-00652-4,,proquest,"This paper introduces a public, open, and independently curated database of happiness coefficients, which quantify the impact of policy-amenable circumstances on life experience. It synthesizes evidence from global data on life satisfaction, relevant for governments seeking human-centered progress measures and resource allocation. The database covers domains like Education, Environment, Work, Finances, Health, Social Capital, and Crime, with a focus on Canada. The paper also discusses the context and limitations of using such coefficients.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:24:29.550194
baf7dc5cdf61fdca,A Quantitative Investment Model Based on Random Forest and Sentiment Analysis,"In recent years, under the influence of economic globalization and anti-globalization, the stock market has experienced great fluctuations in China. Quantitative investment has attracted a lot of attention because of its characteristics of maintaining stable returns. Existing research is unilaterally based on quantitative data or qualitative data for analysis to construct a quantitative investment model. This paper considers both quantitative and qualitative data to construct a more comprehensive model than that in the past. Based on the optimized database, we present a combinational model named RF-SA, which is composed of random forest and sentiment analysis model. First of all, this paper uses the SBS algorithm to select the characteristics of stock transaction historical data, optimizes the prediction database, reduces data redundancy, and improves the accuracy of the model. Secondly, we analyze the characteristics of the Chinese stock market and study the advantages and disadvantages of many data mining algorithms, and select random forest model, the most suitable model, to build the first step of stock selection model. Then, through the analysis of public opinion, the confidence index of the stockholders is calculated; on this basis, the results of the RF model and the confidence index are combined to make a second choice for the stock, and the quantitative investment portfolio is obtained, and excess returns can be obtained. The results of empirical data show that, the RF-SA model obtains a higher rate of return than the investment model of the Shanghai Stock Index.",,2020,10.1088/1742-6596/1575/1/012083,,proquest,"This paper proposes a quantitative investment model (RF-SA) combining Random Forest and Sentiment Analysis, utilizing both quantitative (historical stock transaction data) and qualitative (public opinion sentiment) data to construct a more comprehensive model than previous approaches. The model optimizes historical data using the SBS algorithm and employs Random Forest for initial stock selection, followed by sentiment analysis to calculate a confidence index for a second selection stage, aiming to achieve excess returns. Empirical results indicate the RF-SA model outperforms the Shanghai Stock Index.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:24:44.047210
b91ed97fec43aa60,A Rational Theory of Mutual Funds' Attention Allocation,"The question of whether and how mutual fund managers provide valuable services for their clients motivates one of the largest literatures in finance. One candidate explanation is that funds process information about future asset values and use that information to invest in high-valued assets. But formal theories are scarce because information choice models with many assets are difficult to solve as well as difficult to test. This paper tackles both problems by developing a new attention allocation model that uses the state of the business cycle to predict information choices, which in turn, predict observable patterns of portfolio investments and returns. The predictions about fund portfolios' covariance with payoff shocks, cross-fund portfolio and return dispersion, and their excess returns are all supported by the data. These findings offer new evidence that some investment managers have skill and that attention is allocated rationally. © 2016 Elsevier B.V., All rights reserved.","Kacperczyk, M.; Van Nieuwerburgh, S.; Veldkamp, L.",2016,10.3982/ecta11412,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961238568&doi=10.3982%2FECTA11412&partnerID=40&md5=7c9b7cee943ebb7a5cb2bd4e745f8a5f,scopus,"This paper develops a new attention allocation model for mutual funds, linking business cycle states to information choices and subsequent investment patterns and returns. The model's predictions regarding portfolio covariance with payoff shocks, return dispersion, and excess returns are empirically supported, suggesting rational attention allocation and manager skill.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:24:48.406217
1eac02bbd502ef6e,A Rigorous Statistical Comparison of Deep Learning Models for US Treasury Yield Prediction,"The intrinsic nonlinearity and dynamic relationships in interest rate fluctuations present a substantial challenge when forecasting financial time series, particularly US Treasury yields. These intricate relationships are sometimes not adequately captured by traditional econometric models. In recent years, deep learning (DL) methodologies have gained prominence in the financial market, offering advanced predictive capabilities by modeling high-dimensional dependencies and nonlinear interactions inside yield curves. To enhance the predictive accuracy of short-term (13-week) and long-term (5-year) US Treasury yields, this study leverages advanced deep learning models, including convolutional neural networks (CNNs), long short-term memory (LSTM) networks, and gated recurrent units (GRUs). A comprehensive statistical evaluation is performed to assess model performance through key error metrics such as root mean squared error (RMSE), mean squared error (MSE), mean absolute error (MAE), the coefficient of determination (R2), maximum error, and minimum error, as well as SAFE metrics (Sustainability, Accuracy, Fairness, Explainability) for a holistic assessment. To ensure a robust comparison, we employed the paired t-test to determine if the differences in model predictions are statistically significant. Additionally, we analyzed correlation metrics using Pearson and Spearman coefficients, which evaluate the models’ ability to capture both linear dependencies and ranking trends in yield fluctuations. This rigorous framework not only benchmarks the predictive power of each model but also provides deeper insights into their effectiveness in forecasting treasury yields across different time horizons.",,2025,10.1007/s43069-025-00497-y,,proquest,"This study compares the performance of deep learning models (CNNs, LSTMs, GRUs) for predicting US Treasury yields (13-week and 5-year). It uses various error metrics, SAFE metrics, t-tests, and correlation coefficients to rigorously evaluate the models' predictive accuracy and ability to capture yield curve dynamics, suggesting deep learning models may outperform traditional methods.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T15:25:04.927550
e5bc9c76cee36aba,A Simulation and Empirical Study of the Maximum Likelihood Estimator for Stochastic Volatility Jump-Diffusion Models,"We investigate the behaviour of the maximum likelihood estimator (MLE) for stochastic volatility jump-diffusion models commonly used in financial risk management. A simulation study shows the practical conditions under which the MLE behaves according to theory. In an extensive empirical study based on nine indices and more than 6000 individual stocks, we nonetheless find that the MLE is unable to replicate key higher moments. We then introduce a moment-targeted MLE - robust to model misspecification - and revisit both simulation and empirical studies. We find it performs better than the MLE, improving the management of financial risk.","Begin, Jean-Francois; Boudreault, Mathieu",2025,10.1515/snde-2023-0028,,wos,"This study examines the Maximum Likelihood Estimator (MLE) for stochastic volatility jump-diffusion models. A simulation and empirical study using financial data show that the standard MLE has limitations in capturing higher moments. The authors propose a moment-targeted MLE, which demonstrates improved performance in both simulations and empirical analyses, leading to better financial risk management.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:25:16.522793
5c56da8a165400ea,A Synthetic Data Generation Technique for Enhancement of Prediction Accuracy of Electric Vehicles Demand,"In terms of electric vehicles (EVs), electric kickboards are crucial elements of smart transportation networks for short-distance travel that is risk-free, economical, and environmentally friendly. Forecasting the daily demand can improve the local service provider’s access to information and help them manage their short-term supply more effectively. This study developed the forecasting model using real-time data and weather information from Jeju Island, South Korea. Cluster analysis under the rental pattern of the electric kickboard is a component of the forecasting processes. We cannot achieve noticeable results at first because of the low amount of training data. We require a lot of data to produce a solid prediction result. For the sake of the subsequent experimental procedure, we created synthetic time-series data using a generative adversarial networks (GAN) approach and combined the synthetic data with the original data. The outcomes have shown how the GAN-based synthetic data generation approach has the potential to enhance prediction accuracy. We employ an ensemble model to improve prediction results that cannot be achieved using a single regressor model. It is a weighted combination of several base regression models to one meta-regressor. To anticipate the daily demand in this study, we create an ensemble model by merging three separate base machine learning algorithms, namely CatBoost, Random Forest (RF), and Extreme Gradient Boosting (XGBoost). The effectiveness of the suggested strategies was assessed using some evaluation indicators. The forecasting outcomes demonstrate that mixing synthetic data with original data improves the robustness of daily demand forecasting and outperforms other models by generating more agreeable values for suggested assessment measures. The outcomes further show that applying ensemble techniques can reasonably increase the forecasting model’s accuracy for daily electric kickboard demand.",,2023,10.3390/s23020594,,proquest,"This study proposes a method to improve the prediction accuracy of electric vehicle (EV) demand, specifically focusing on electric kickboards. The authors developed a forecasting model using real-time and weather data from Jeju Island, South Korea. To address the issue of insufficient training data, they generated synthetic time-series data using a Generative Adversarial Network (GAN) and combined it with the original data. An ensemble model, comprising CatBoost, Random Forest, and XGBoost, was employed to further enhance prediction accuracy. The results indicate that the combination of synthetic data and ensemble techniques significantly improves the robustness and accuracy of daily demand forecasting for electric kickboards.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:25:20.340560
f187ea8de5111e6f,A VECM analysis of Bitcoin price using time-varying cointegration approach,"This study proposed an optimal model to examine the relationship between the Bitcoin price and six macroeconomic variables – the Bitcoin price, Standard and Poor's 500 volatility index, US treasury 10-year yield, US consumer price index, gold price and dollar index. It also examined the effectiveness of the vector error correction model (VECM) in analyzing the interrelationship among these variables. The authors employed the following approach: first, the authors sampled the period August 2010–February 2022. This is because Bitcoin achieved a market capitalization of more than US$1 tn over this period, gaining market attention and acceptance from retail, corporate and institutional investors. Second, the authors employed a VECM with the six macroeconomic variables. Finally, the authors expanded the long-run equilibrium relationship (time-invariant cointegration)-based VECM to develop a time-varying cointegration (TVC) VECM. The authors estimated the TVC VECM using the Chebyshev polynomial specification based on various information criteria. The results showed that the Bitcoin price can be modeled with the VECM (p = 1, r = 1). The TVC approach generated more explanatory power for Bitcoin pricing, indicating the effectiveness of the approach for modeling the long-run relationship between Bitcoin price and macroeconomic variables. © 2023 Elsevier B.V., All rights reserved.","Lee, Y.; Rhee, J.H.",2022,10.1108/jdqs-01-2022-0001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150338859&doi=10.1108%2FJDQS-01-2022-0001&partnerID=40&md5=14ed575c3c7ffa374c533ddd0c3a53b7,scopus,"This study analyzes the relationship between Bitcoin price and six macroeconomic variables using a time-varying cointegration (TVC) Vector Error Correction Model (VECM). The TVC VECM approach, estimated using Chebyshev polynomials, demonstrated greater explanatory power for Bitcoin pricing compared to traditional VECM, suggesting its effectiveness in modeling long-run relationships.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:25:23.108294
df93e71ba8fb12f7,A comparison of multitask and single task learning with artificial neural networks for yield curve forecasting,"The yield curve is the centrepiece in bond markets, a massive asset class with an overall size of USD 100 trillion that remains relatively under-investigated using machine learning. This paper is the first comprehensive study using artificial neural networks in the context of yield curve forecasting. Specifically, two models were used for forecasting the European yield curve: multivariate linear regression and multilayer perceptron (MLP), at five forecasting horizons, from next day to 20 days ahead. Five variants of the MLP were analysed with different sets of features: target to predict (univariate); the most relevant features; all generated features; and the former two incorporating synthetic data generated by the linear regression model. Additionally, two different techniques of multitask learning were employed: simultaneous modelling and transformation into multiple single task learning. The results show that considering all forecasting horizons, the MLP using the most relevant features achieved the best results and the addition of synthetic data tends to improve accuracy. Furthermore, different targets and forecasting horizons resulted in different relevant features, reinforcing the importance of custom-built models. In the two multitask learning methodologies no clear differentiation could be demonstrated, and several explaining factors are identified. Overall, the outcome is very encouraging for the development of better forecasting systems for fixed income markets.",,2019,10.1016/j.eswa.2018.11.012,,proquest,"This paper presents the first comprehensive study using artificial neural networks (ANNs) for European yield curve forecasting. It compares multivariate linear regression and multilayer perceptron (MLP) models at five forecasting horizons. Various MLP configurations were tested, including different feature sets and the incorporation of synthetic data. Multitask learning techniques were also explored. The MLP with the most relevant features showed the best performance, with synthetic data generally improving accuracy. The study highlights the need for custom models for different targets and horizons, and found no clear advantage for multitask learning in this context.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T15:26:06.909476
bac703195941f32a,A comparison of nonlinear methods for predicting earnings surprises and returns,"We compare four nonlinear methods on their ability to learn models from data. The problem requires predicting whether a company will deliver an earnings surprise a specific number of days prior to announcement. This problem has been well studied in the literature using linear models. A basic question is whether machine learning-based nonlinear models such as tree induction algorithms, neural networks, naive Bayesian learning, and genetic algorithms perform better in terms of predictive accuracy and in uncovering interesting relationships among problem variables. Equally importantly, if these alternative approaches perform better, why? And how do they stack up relative to each other? The answers to these questions are significant for predictive modeling in the financial arena, and in general for problem domains characterized by significant nonlinearities. In this paper, we compare the four above-mentioned nonlinear methods along a number of criteria. The genetic algorithm turns out to have some advantages in finding multiple ""small disjunct"" patterns that can be accurate and collectively capable of making predictions more often than its competitors. We use some of the nonlinearities we discovered about the problem domain to explain these results.",V. Dhar; D. Chou,2001,10.1109/72.935099,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=935099,ieeexplore,"This paper compares four nonlinear machine learning methods (tree induction, neural networks, naive Bayesian learning, and genetic algorithms) for predicting earnings surprises and returns, aiming to determine if they outperform traditional linear models and understand why. The genetic algorithm showed an advantage in identifying multiple predictive patterns.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:26:29.342821
8a149439aecedfa5,A comparison of risk-premium forecasts implied by parametric versus nonparametric conditional mean estimators,"This paper computes parametric estimates of a time-varying risk premium model and compares the one-step-ahead forecasts implied by that model with those given by a nonparametric kernel estimator of the conditional mean function. The conditioning information used for the nonparametric analysis is that implied by the theoretical model of time-varying risk. Thus, the kernel estimator is used, in conjunction with a nonparametric diagnostic test for in-sample residual nonlinear structure, to assess the adequacy of the parametric model in capturing any structure in the excess returns. Our results support the parametric specification of an asset pricing model in which the conditional beta is the ratio of the relevant components of the conditional covariance matrix of returns modelled as a bivariate generalized ARCH process. Although the predictable component of the conditional moments is relatively small, the parametric estimator of the risk premia has somewhat more out-of-sample forecasting ability than does the kernel estimator. Hence, the superior in-sample performance of the latter may be attributed to overfitting. © 1992. © 2014 Elsevier B.V., All rights reserved.","McCurdy, T.H.; Stengos, T.",1992,10.1016/0304-4076(92)90071-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0011463942&doi=10.1016%2F0304-4076%2892%2990071-X&partnerID=40&md5=5201c426cd455c9821ffe152c1cd7b83,scopus,"This paper compares parametric and nonparametric (kernel) estimators for forecasting risk premiums. It finds that while the nonparametric estimator captures more in-sample structure, the parametric estimator has slightly better out-of-sample forecasting ability, suggesting potential overfitting in the nonparametric approach. The study supports a parametric asset pricing model with a conditional beta derived from a bivariate GARCH process.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:26:51.535472
d3acea4f9be74018,A daily view of the term structure dynamics: Some international evidence,"The paper employs daily interest rates from the short-end of the Eurocurrency market in order to test the validity of the Expectations Hypothesis (EH). In particular, exploiting the stochastic trends embedded in the time series the EH implications are tested in a multivariate cointegration framework. The empirical findings indicate that once daily rates are used the estimated coefficients are very close to their theoretical values as predicted by the EH. Furthermore, we cannot reject the hypothesis that the EH is an adequate description of the US yield curve. Similarly, for the German and UK yield curves the number of common stochastic trends present in their yield curves is consistent with the EH. However, the restrictions imposed by the theory on parameters of the cointegration space are rejected.","Drakos, K",2002,10.1023/a:1014851101861,,wos,"This paper tests the Expectations Hypothesis (EH) using daily Eurocurrency interest rates and a multivariate cointegration framework. The findings suggest that the EH is a valid description for the US, German, and UK yield curves when daily data is used, although theoretical restrictions on cointegration parameters are rejected.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:27:11.892085
0e5f8a823c00b204,A factor pricing model based on machine learning algorithm,"We adopt Discrete Wavelet Transform (DWT) and Support Vector Regression (SVR) algorithm to predict stock returns and form a time-varying Machine Learning (ML) factor based on the predicted returns for improving the classical asset pricing in the Chinese stock market from 2000 to 2020. The results show that the sorted portfolios formed by the predicted return rates can obtain significant excess returns in the Chinese market. Furthermore, our research shows that incorporating the ML factor into the CH4 and FF5 model can improve the pricing power significantly. It indicates that the ML factor can complement the traditional pricing models. We also find the performance of factor models depend on macroeconomy and market sentiment, that is, the better the macroeconomic and stock market performance, the stronger the pricing power of the factor models in the Chinese market. Additionally, we explore whether ML factor falls under short-term, median-term, and long-term momentum and reversal factors, and our analysis demonstrates that the ML factor is more effective than momentum and reversal factors. © 2023 Elsevier B.V., All rights reserved.","Fang, Y.; Chen, Y.; Ren, H.",2023,10.1016/j.iref.2023.06.012,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165250152&doi=10.1016%2Fj.iref.2023.06.012&partnerID=40&md5=5d7b8619f3b34ab111872af48b27b9aa,scopus,This study develops a time-varying Machine Learning (ML) factor using Discrete Wavelet Transform (DWT) and Support Vector Regression (SVR) to predict stock returns in the Chinese market (2000-2020). The ML factor significantly improves the pricing power of traditional asset pricing models (CH4 and FF5) and outperforms momentum and reversal factors. The factor's performance is influenced by macroeconomic conditions and market sentiment.,True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:27:21.603395
9d117d54bee8c73e,A general equilibrium (GE) model of the term structure applied to Australian securities,"The Double Square Root (DSR) GE model of the term structure is fitted to Australian security yield data over the period 2 January 1984 to 15 December 1995 - a data set of 3041 yields on four securities: 30 and 90-day BAB: and 5 and 10-year bonds. Applying both the OLS and GMM estimators we find a nonlinear, reduced form relationship between these yields and the risk free rate. So we conclude that GE models explain a diverse range of Australian yield curve shapes and that Australian bond prices are not necessarily inversely related to interest rates. © 199S Roulledge. © 2017 Elsevier B.V., All rights reserved.","Felmingham, B.S.; Norton Grey, W.",1998,10.1080/135048598354122,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33744459271&doi=10.1080%2F135048598354122&partnerID=40&md5=14ea2b3eb6434db4e77834f89eebf639,scopus,"This paper applies the Double Square Root (DSR) General Equilibrium (GE) model to Australian security yield data from 1984 to 1995, analyzing 30-day and 90-day BABs, and 5-year and 10-year bonds. Using OLS and GMM estimators, the study finds a nonlinear relationship between yields and the risk-free rate, suggesting GE models can explain various yield curve shapes in Australia and that bond prices are not always inversely related to interest rates.",True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:27:38.792038
1c4239d6298f5cb3,A generalized bootstrap method to determine the yield curve,"A new technique is described for operationalizing the bootstrap methodology to estimate the yield curve given any available data set of bond yields. The problem of missing data points is dealt with using symbolic cubic spline interpolation. To make such an approach tractable the computer algebra system Maple is employed to symbolically generate the interpolation equations for the missing data points and to solve the nonlinear equation system in order to obtain the points on the yield curve. Several examples with real data demonstrate the usefulness of the methodology. © 2000, Taylor & Francis Group, LLC. © 2019 Elsevier B.V., All rights reserved.","Deaves, R.; Parlar, M.",2000,10.1080/13504860010021162,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066185898&doi=10.1080%2F13504860010021162&partnerID=40&md5=af033d7b30bfd2da8123b454f987e7d0,scopus,"This paper introduces a generalized bootstrap method for estimating the yield curve using any available bond yield data. It addresses missing data points through symbolic cubic spline interpolation, utilizing the Maple computer algebra system to generate and solve interpolation equations. The methodology's effectiveness is demonstrated with real data examples.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:27:52.617181
42306d1389b76f62,A hybrid EMD-AR model for nonlinear and non-stationary wave forecasting,"Accurate wave forecasting with a couple of hours of warning time offers improvements in safety for maritime operation-related activities. Autoregressive (AR) model is an efficient and highly adaptive approach for wave forecasting. However, it is based on linear and stationary theory and hence has limitations in forecasting nonlinear and non-stationary waves. Inspired by the capability of empirical mode decomposition (EMD) technique in handling nonlinear and non-stationary signals, this paper describes the development of a hybrid EMD-AR model for nonlinear and non-stationary wave forecasting. The EMDAR model was developed by coupling an AR model with the EMD technique. Nonlinearity and non-stationarity were overcome by decomposing the wave time series into several simple components for which the AR model is suitable. The EMD-AR model was implemented using measured significant wave height data from the National Data Buoy Center, USA. Prediction results from various locations consistently show that the hybrid EMD-AR model is superior to the AR model. This demonstrates that the EMD technique is effective in processing nonlinear and non-stationary waves.",,2016,10.1631/jzus.a1500164,,proquest,"This paper proposes a hybrid Empirical Mode Decomposition (EMD) and Autoregressive (AR) model (EMD-AR) for forecasting nonlinear and non-stationary wave data. The EMD technique decomposes the wave time series into simpler components, allowing the AR model to perform more effectively. The model was tested using significant wave height data and showed superior performance compared to the standalone AR model, demonstrating the effectiveness of EMD in handling complex wave dynamics.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:28:08.609467
06dce1e4e6c88e26,A hybrid convolutional neural network with long short-term memory for statistical arbitrage,"We propose a CNN-LSTM deep learning model, which has been trained to classify profitable from unprofitable spread sequences of cointegrated stocks, for a large scale market backtest ranging from January 1991 to December 2017. We show that the proposed model can achieve high levels of accuracy and successfully derives features from the market data. We formalize and implement a trading strategy based on the model output which generates significant risk-adjusted excess returns that are orthogonal to market risks. The generated out-of-sample Sharpe ratio and alpha coefficient significantly outperform the reference model, which is based on a standard deviation rule, even after accounting for transaction costs.","Eggebrecht, P.; Luetkebohmert, E.",2023,10.1080/14697688.2023.2181707,,wos,"This paper introduces a hybrid CNN-LSTM deep learning model for statistical arbitrage in financial markets. The model classifies profitable spread sequences of cointegrated stocks and is backtested on data from 1991 to 2017. The strategy based on the model achieves significant risk-adjusted excess returns, outperforming a reference model in terms of Sharpe ratio and alpha, even after transaction costs.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:28:22.999732
6a29710c06b32305,A neural-network analyzer for mortality forecast,"This article proposes a neural-network approach to predict and simulate human mortality rates. This semi-parametric model is capable to detect and duplicate non-linearities observed in the evolution of log-forces of mortality. The method proceeds in two steps. During the first stage, a neural-network-based generalization of the principal component analysis summarizes the information carried by the surface of log-mortality rates in a small number of latent factors. In the second step, these latent factors are forecast with an econometric model. The term structure of log-forces of mortality is next reconstructed by an inverse transformation. The neural analyzer is adjusted to French, UK and US mortality rates, over the period 1946-2000 and validated with data from 2001 to 2014. Numerical experiments reveal that the neural approach has an excellent predictive power, compared to the Lee-Carter model with and without cohort effects. © 2018 Elsevier B.V., All rights reserved.","Hainaut, D.",2018,10.1017/asb.2017.45,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041374415&doi=10.1017%2Fasb.2017.45&partnerID=40&md5=95ab9244ef17be4d7010801baa451b81,scopus,"This article introduces a neural network model for predicting human mortality rates by summarizing log-mortality rates into latent factors, forecasting these factors with an econometric model, and reconstructing the mortality structure. The model was applied to French, UK, and US mortality data and showed superior predictive power compared to the Lee-Carter model.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:28:27.118288
a5854e7f313205c3,A non-linear dynamic model of the variance risk premium,We propose a new class of non-linear diffusion processes for modeling financial markets data. Our non-linear diffusions are obtained as transformations of affine processes. We show that asset-pricing and estimation is possible and likelihood estimation is straightforward. We estimate a non-linear diffusion model for the VIX index under both the objective measure and the risk-neutral measure where the latter is obtained from futures prices. We find evidence of significant non-linearity under both measures. We define the difference between the P and Q drift as a measure of the variance risk premium and show that it has strong predictive power for stock returns.,,2015,10.1016/j.jeconom.2015.02.038,,proquest,"This paper introduces a novel non-linear diffusion model for financial markets, derived from transformations of affine processes. The model allows for straightforward asset pricing and likelihood estimation. Empirical analysis using the VIX index under both objective and risk-neutral measures reveals significant non-linearity. The variance risk premium, defined as the difference between P and Q drifts, is shown to be a strong predictor of stock returns.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:28:40.581266
75bf2bd602a393cf,A parametric factor model of the term structure of mortality,"The prototypical Lee–Carter mortality model is characterized by a single common time factor that loads differently across age groups. In this paper, we propose a parametric factor model for the term structure of mortality where multiple factors are designed to influence the age groups differently via parametric loading functions. We identify four different factors: a factor common for all age groups, factors for infant and adult mortality, and a factor for the “accident hump” that primarily affects mortality of relatively young adults and late teenagers. Since the factors are identified via restrictions on the loading functions, the factors are not designed to be orthogonal but can be dependent and can possibly cointegrate when the factors have unit roots. We suggest two estimation procedures similar to the estimation of the dynamic Nelson–Siegel term structure model. First, a two-step nonlinear least squares procedure based on cross-section regressions together with a separate model to estimate the dynamics of the factors. Second, we suggest a fully specified model estimated by maximum likelihood via the Kalman filter recursions after the model is put on state space form. We demonstrate the methodology for US and French mortality data. We find that the model provides a good fit of the relevant factors and, in a forecast comparison with a range of benchmark models, it is found that, especially for longer horizons, variants of the parametric factor model have excellent forecast performance. © 2019 Elsevier B.V., All rights reserved.","Haldrup, N.; Rosenskjold, C.P.T.",2019,10.3390/econometrics7010009,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069524567&doi=10.3390%2Feconometrics7010009&partnerID=40&md5=25f49d47a3a9211b38babce433e20709,scopus,"This paper proposes a parametric factor model for the term structure of mortality, extending the Lee-Carter model by incorporating multiple factors with parametric loading functions that influence age groups differently. It identifies factors for common influence, infant/adult mortality, and the 'accident hump'. The model is estimated using nonlinear least squares or maximum likelihood via the Kalman filter and is demonstrated with US and French mortality data. The model shows good fit and excellent forecast performance, especially for longer horizons, compared to benchmark models.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:28:46.297580
e897cf6b8fd84b04,A semiparametric approach for modelling multivariate nonlinear time series,"AbstractIn this article, a semiparametric time‐varying nonlinear vector autoregressive (NVAR) model is proposed to model nonlinear vector time series data. We consider a combination of parametric and nonparametric estimation approaches to estimate the NVAR function for both independent and dependent errors. We use the multivariate Taylor series expansion of the link function up to the second order which has a parametric framework as a representation of the nonlinear vector regression function. After the unknown parameters are estimated by the maximum likelihood estimation procedure, the obtained NVAR function is adjusted by a nonparametric diagonal matrix, where the proposed adjusted matrix is estimated by the nonparametric kernel estimator. The asymptotic consistency properties of the proposed estimators are established. Simulation studies are conducted to evaluate the performance of the proposed semiparametric method. A real data example on short‐run interest rates and long‐run interest rates of United States Treasury securities is analyzed to demonstrate the application of the proposed approach. The Canadian Journal of Statistics 47: 668–687; 2019 © 2019 Statistical Society of Canada",,2019,10.1002/cjs.11518,,proquest,"This article proposes a semiparametric time-varying nonlinear vector autoregressive (NVAR) model for nonlinear vector time series data. It combines parametric and nonparametric estimation approaches, using a multivariate Taylor series expansion for the parametric part and a nonparametric kernel estimator for adjustment. The method's consistency is established, and its performance is evaluated through simulations and a real-data example on US Treasury securities interest rates.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,Maybe not ML enough,2025-10-13T15:29:21.675191
bf4b6db3d4bf4d55,A sparse enhanced indexation model with chance and cardinality constraints,"Enhanced indexation aims to construct a portfolio to track and outperform the performance of a stock market index by employing both passive and active fund management strategies. This paper presents a novel sparse enhanced indexation model with chance and cardinality constraints. Its goal is to maximize the excess return that can be attained with a high probability, while the model allows a fund manger to limit the number of stocks in the portfolio and specify the maximum tolerable relative market risk. In particular, we model the asset returns as random variables and estimate their probability distributions by the Capital Asset Pricing Model or Fama-French 3-factor model, and measure the relative market risk with the coherent semideviation risk function. We deal with the chance constraint via distributionally robust approach and present a second-order cone programming and a semidefinite programming safe approximation for the model under different sets of potential distribution functions. A hybrid genetic algorithm is applied to solve the NP-hard problem. Numerical tests are conducted on the real data sets from major international stock markets, including USA, UK, Germany and China. The results demonstrate that the proposed model and the method can efficiently solve the enhanced indexation problem and our approach can generally achieve sparse tracking portfolios with good out-of-sample excess returns and high robustness.",,2018,10.1007/s10898-017-0513-1,,proquest,"This paper introduces a sparse enhanced indexation model that aims to maximize excess return with high probability, while limiting the number of stocks and relative market risk. It uses random variables for asset returns, estimates distributions via CAPM or Fama-French 3-factor models, and measures risk with semideviation. The model is approximated using second-order cone programming and semidefinite programming, and solved with a hybrid genetic algorithm. Numerical tests on international stock market data show the model efficiently creates sparse portfolios with good out-of-sample excess returns and robustness.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:29:44.873153
78460dede1ee17a6,A stock selection algorithm hybridizing grey wolf optimizer and support vector regression,"Artificial intelligence remarkably facilitates quantitative investment. A latest intelligent search algorithm, grey wolf optimizer, is well integrated with support vector regression machine to obtain the optimal portfolio. The performance of the hybrid algorithm is empirically investigated through transactional and financial data from stock markets of America and China. The experimental results indicate that (i) the proposed algorithm is able to stably achieve excess returns; (ii) compared with genetic algorithm, particle swarm optimization, gravitational search algorithm and harmony search, the enhanced grey wolf optimizer significantly boots the predictive performance of support vector regression machine; (iii) the proposed algorithm can achieve the better profitability and the higher reliability in Chinese A-share market.",,2021,10.1016/j.eswa.2021.115078,,proquest,"This study proposes a hybrid algorithm combining the Grey Wolf Optimizer (GWO) and Support Vector Regression (SVR) for stock selection and portfolio optimization. The algorithm's performance is evaluated using US and Chinese stock market data, demonstrating its ability to generate excess returns and outperform other metaheuristic algorithms in predictive accuracy. The hybrid approach shows improved profitability and reliability, particularly in the Chinese A-share market.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:29:53.273362
c39f49834e05eba2,A structural econometric model of price discrimination in the French mortgage lending industry,"We propose a model of discrimination in the market for mortgages. The model explains accepted loan applications and simultaneously determines loan sizes and interest rates. A competitive and a discriminating monopoly version of the model are proposed. Offered interest rates and loan sizes are a function of observable borrower characteristics. The competitive model rests on a marginal condition, reflecting contract optimality, to which a zero-profit condition is added. In contrast, the discriminating monopoly maximizes profits under a borrower participation constraint, reflecting the availability of a rental market as an outside option. Each version of the model is a bivariate, nonlinear model, and is estimated by standard maximum likelihood methods. The data used for estimation is a sample of clients of a French network of mortgage lenders. We show the presence of ""social discrimination"" in the data, the loan conditions depending not only on the borrower's wage and down payment, but also on the borrower's occupational status. Abnormally high risk premia in the competitive version of the model suggest the presence of market power, justifying an attempt at estimating its monopolistic version. The discriminating monopoly model estimates show that the borrowers' price-elasticity of demand for housing varies with occupational status, and is inversely related with the lender's interest rate markups. This confirms that the lender exploits structural differences in the preferences to discriminate, as predicted by standard theories. © 2003 Elsevier B.V. All rights reserved. © 2008 Elsevier B.V., All rights reserved.","Gary-Bobo, R.J.; Larribeau, S.",2004,10.1016/j.ijindorg.2003.07.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0346962780&doi=10.1016%2Fj.ijindorg.2003.07.002&partnerID=40&md5=10ab500b28b6878f5d1a556e8a2af88b,scopus,"This paper presents a structural econometric model to analyze price discrimination in the French mortgage lending market. It considers both competitive and discriminating monopoly scenarios, explaining loan applications, sizes, and interest rates based on borrower characteristics. The study finds evidence of ""social discrimination,"" where loan terms are influenced by occupational status, and suggests market power exists, justifying the analysis of a monopolistic version. The discriminating monopoly model confirms that lenders exploit differences in borrower preferences and price elasticity of demand to discriminate.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:30:03.413331
7fe86973d0f86928,A two-regime threshold model with conditional skewed Student t distributions for stock returns,"This paper proposes a two-regime threshold model for the conditional distribution of stock returns in which returns follow a distinct skewed Student t distribution within each regime: the model allows capturing time variation in the conditional distribution of returns, as well as higher order moments. An application of the model to daily U.S. stock returns illustrates the advantages of the proposed model in comparison to alternative specifications: the model performs well in terms of in-sample fit; it more accurately estimates the conditional volatility; and it produces useful risk assessment as measured by the term structure of value at risk. (C) 2014 Elsevier B.V. All rights reserved.","Massacci, Daniele",2014,10.1016/j.econmod.2014.07.032,,wos,"This paper introduces a two-regime threshold model using conditional skewed Student t distributions to analyze stock returns. The model captures time-varying conditional distributions and higher-order moments. An application to U.S. stock returns demonstrates its superior in-sample fit, more accurate conditional volatility estimation, and improved risk assessment compared to other models.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:30:07.020755
b4063c4f4752f0dc,Accounting for correlations: Price adjustments in unit-cost construction contracts,"Macroeconomic conditions, such as commodity prices, affect the cost of construction projects. In a volatile market environment, contractors respond by adding premiums in bid prices when highway agencies pass such risk on to contractors by using fixed-price contracts. How much of the commodity cost risk should highway agencies pass on to contractors? More specifically, this study aims to investigate the impact of correlation among commodity prices on optimal risk-hedging decisions. A weighted least-squares regression model is used to estimate the risk premium; both univariate time series and vector time series models are estimated and applied to simulate changes in commodity prices over time, including the effect of correlation. A genetic algorithm is used as a solution approach to a multiobjective optimization problem (cost versus future risk exposure). In a case study, project cost risks are shown to be significantly underestimated if correlations are not accounted for. © 2023 Elsevier B.V., All rights reserved.","Zhou, X.; Damnjanović, I.D.",2012,10.3141/2297-17,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026873013&doi=10.3141%2F2297-17&partnerID=40&md5=e436631f1dfbd0d2ab0a0a1fa0768ffd,scopus,"This study investigates the impact of commodity price correlations on optimal risk-hedging decisions in unit-cost construction contracts. It uses a weighted least-squares regression model, univariate and vector time series models, and a genetic algorithm to simulate commodity price changes and optimize cost versus risk exposure. The findings indicate that project cost risks are significantly underestimated when correlations are not considered.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:30:15.872299
e869368c4a48ce29,Advanced Option Pricing and Hedging with Q-Learning: Performance Evaluation of the QLBS Algorithm,"This article provides an overview of the recent advances in reinforcement learning (RL) for pricing and hedging financial instruments, focusing on the Q-Learning Black-Scholes (QLBS) approach. This RL approach bridges the traditional Black-Scholes-Merton (BSM) model with artificial intelligence algorithms, enabling option pricing and hedging in a completely model-free and data-driven way. The study evaluates the QLBS algorithm’s performance across different state variables and scenarios for a European put option, showing that the model accurately estimates option prices under varying volatility levels, hedging frequencies, risk-free rates, and when dividends are included. Additionally, the QLBS method shows robust performance in pricing and hedging options across different moneyness levels, with more pronounced deviations from the BSM model for deep in-the-money options under higher risk aversion. The empirical analysis also incorporates proportional transaction costs using at-the-money S&P 500 call options, revealing varied implications for profitability and risk mitigation, influenced by the choice of state variables. The article sheds light on the QLBS model’s explainability by providing detailed technical notes and a numerical example, and additionally, the results reveal its high practical relevance. © 2025 Elsevier B.V., All rights reserved.","Stoiljkovic, Z.",2025,10.3905/jod.2025.1.222,https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000150110&doi=10.3905%2Fjod.2025.1.222&partnerID=40&md5=2458dcaba8e795c55b724323df4ee627,scopus,"This article introduces the Q-Learning Black-Scholes (QLBS) algorithm, a reinforcement learning approach for model-free, data-driven option pricing and hedging. The study evaluates QLBS performance for European put options under various conditions (volatility, interest rates, dividends, moneyness) and incorporates transaction costs for S&P 500 call options. The QLBS model demonstrates accurate price estimation and robust hedging, with explainability features and practical relevance highlighted.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:30:30.706162
6935cf79559f8c33,"Ambiguity reduction by objective model selection, with an application to the costs of the EU 2030 climate targets","I estimate the cost of meeting the EU 2030 targets for greenhouse gas emission reduction, using statistical emulators of ten alternative models. Assuming a first-best policy implementation, I find that total and marginal costs are modest. The statistical emulators allow me to compute the risk premiums, which are small, because the EU is rich and the policy impact is small. The ensemble of ten models allows me to compute the ambiguity premium, which is small for the same reason. I construct a counterfactual estimate of recent emissions without the climate policy and use that to test the predictive skill of the ten models. The models that show the lowest cost of emission reduction also have the lowest skill for Europe in recent times. © 2018 Elsevier B.V., All rights reserved.","Tol, R.S.J.",2014,10.3390/en7116886,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912033606&doi=10.3390%2Fen7116886&partnerID=40&md5=885f426cc74a9fa09f0696aff6b5bf0b,scopus,"This study estimates the cost of meeting the EU 2030 climate targets using statistical emulators of ten alternative models. It finds that total and marginal costs are modest, with small risk and ambiguity premiums due to the EU's wealth and the policy's limited impact. The models with lower emission reduction costs showed lower predictive skill for recent European emissions.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:30:34.613212
e040435996e03d39,An Application of Damped Diffusion for Modeling Volatility Dynamics,"This paper proposes a damped constant elasticity variance (CEV) stochastic volatility (DCEV) model, which remedies the possible explosive behavior of the CEV model and also accommodates the mean-reverting dynamics more appropriately than the nonlinear drift (NLD) stochastic volatility model. As the DCEV model maintains the linear drift, an analytic formula is available to efficiently infer latent variances from VIX levels, after which both its physical and risk-neutral parameters can be simultaneously estimated with the maximum-likelihood approach given S&P 500 returns and inferred variances. The DCEV model outperforms the CEV and NLD models in in-sample fitting performance and in out-of-sample variance forecasting under the physical measure. It also exhibits superior ability in out-of-sample option pricing over the CEV and models under the risk-neutral measure. This satisfactory performance demonstrates the suitability of describing volatility dynamics with the DCEV model and the potential of applying this to study other issues.","Hung, Mao-Wei; Ko, Yi-Chen; Wang, Jr-Yan",2023,10.1093/jjfinec/nbab018,,wos,"This paper introduces a Damped Constant Elasticity Variance (DCEV) stochastic volatility model to address limitations in existing models for volatility dynamics. The DCEV model, which allows for mean-reversion and avoids explosive behavior, enables efficient inference of latent variances from VIX levels. The model's parameters are estimated using maximum likelihood with S&P 500 returns and inferred variances. Empirical results show the DCEV model outperforms CEV and Nonlinear Drift (NLD) models in fitting and forecasting volatility under the physical measure, and in option pricing under the risk-neutral measure.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:30:41.955079
60d9d62ef78644a0,An adaptively managed dynamic portfolio selection model using a time-varying investment target according to the market forecast,"In this paper, we propose an adaptive investment strategy (AIS) based on a dynamic portfolio selection model (DPSM) that uses a time-varying investment target according to the market forecast. The DPSM allows for flexible investments, setting relatively aggressive investment targets when market growth is expected and relatively conservative targets when the market is expected to be less attractive. The model further allows investments to be liquidated into risk-free assets when the market forecast is pessimistic. By dynamically determining the investment target, the DPSM allows construction of portfolios that are more responsive to market changes, while eliminating the possibility of the model becoming infeasible under certain market conditions. When the proposed DPSM is implemented in real-life investment scenarios using the AIS, the portfolio is rebalanced according to a predefined rebalancing cycle and the model's input parameters are estimated on each rebalancing date using an exponentially weighted moving average (EWMA) estimator. To evaluate the performance of the proposed approach, a 7-year investment experiment was conducted using historical stock returns data from 10 different stock markets around the world. Performance was assessed and compared using diverse measures. Superior performance was achieved using the AIS proposed herein compared with various benchmark approaches for all performance measures. In addition, we identified a converse relationship between the average trading volume of a market and the value of the weighting parameter prescribed to the EWMA estimator, which maximizes cumulative returns in each market. © 2020 Elsevier B.V., All rights reserved.","Jung, J.; Kim, S.",2015,10.1057/jors.2014.72,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937210799&doi=10.1057%2Fjors.2014.72&partnerID=40&md5=8aa29123405930fe4848e304ee973f23,scopus,"This paper introduces an adaptive investment strategy (AIS) using a dynamic portfolio selection model (DPSM) with a time-varying investment target based on market forecasts. The model adjusts investment aggressiveness based on expected market growth, liquidates into risk-free assets during pessimistic forecasts, and is rebalanced using an exponentially weighted moving average (EWMA) estimator. A 7-year experiment with historical stock data from 10 global markets demonstrated superior performance compared to benchmarks.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:31:05.325162
8071539ff0d58c9e,An empirical comparison of transformed diffusion models for VIX and VIX futures,"Transformed diffusions (TDs) are nonlinear functions of continuous-time affine diffusion processes. Since they are flexible models with tractable analytic properties, financial modelling with TDs has become increasing popular in recent years. We first provide a formal classification of TD models into drift-driven, diffusion-driven, and distribution-driven according to their empirical emphases and specification strategies. Motivated by the stylized distributional features of VIX such as skewness and excess kurtosis, we then propose a pair of new distribution-driven TDs for modelling VIX dynamics and pricing VIX futures by directly incorporating such information into the specification of the transformation. We conduct a comprehensive empirical investigation into the relative performance of the three classes of models against several empirically relevant criteria. Our focus is on the in-sample goodness-of-fit measure and the out-of-sample forecast accuracy for modelling VIX and pricing VIX futures, as well as the stock return predictability of the implied Variance Risk Premium. Our findings demonstrate that the newly proposed distribution-driven models have clear advantages over well-established alternatives in most of our exercises. © 2017 Elsevier B.V., All rights reserved.","Bu, R.; Jawadi, F.; Li, Y.",2017,10.1016/j.intfin.2016.08.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994910609&doi=10.1016%2Fj.intfin.2016.08.003&partnerID=40&md5=67c5023992ba98b3ea71cdfb9652d735,scopus,"This paper introduces and empirically compares three classes of Transformed Diffusion (TD) models for VIX dynamics and VIX futures pricing. The authors propose two new distribution-driven TD models that incorporate VIX's stylized distributional features (skewness, excess kurtosis). An empirical investigation assesses model performance based on in-sample fit, out-of-sample forecast accuracy for VIX and VIX futures, and implied Variance Risk Premium's stock return predictability. The proposed models show advantages over existing alternatives.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:31:09.377310
6f33af2fc1cab759,"An empirical investigation into the impact of US federal government budget deficits on the real interest rate yield on intermediate-term treasury issues, 1972-2012","This study provides new empirical evidence on the impact of the federal budget deficit on the real interest rate yields on intermediate-term debt issues of the US Treasury, represented herein by the ex post real interest rate yields on 3-year Treasury notes and 7-year Treasury notes, two interest rate measures that have received essentially no attention in the economics and finance literature in recent years. This study is couched within a loanable funds model that includes two ex post real interest rate yields, the monetary base as a per cent of GDP, the change in per capita real GDP, net financial capital inflows as a per cent of GDP and the budget deficit as a per cent of GDP. This study uses annual data for the study period 1972 to 2012, a time period that includes 'quantitative easing' monetary policies by the Federal Reserve. Two-stage least squares estimations reveal that the federal budget deficit, expressed as a per cent of GDP, exercised a positive and statistically significant impact on the ex post real interest rate yields on both 3-year and 7-year Treasury notes, even after allowing for quantitative easing and other factors. The study also considers the time period 1980 to 2012 and offers simple robustness testing. Reprinted by permission of Routledge, Taylor and Francis Ltd.",,2014,10.1080/00036846.2014.932050,,proquest,"This empirical study investigates the impact of US federal budget deficits on real interest rates of 3-year and 7-year Treasury notes from 1972-2012, using a loanable funds model. The findings indicate a positive and statistically significant relationship between budget deficits (as a percentage of GDP) and these real interest rates, even when accounting for quantitative easing and other economic factors. Robustness tests were also conducted for the period 1980-2012.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:31:27.310085
99367e520d9af0be,An infinite hidden Markov model for short-term interest rates,"The time-series dynamics of short-term interest rates are important as they are a key input into pricing models of the term structure of interest rates. In this paper we extend popular discrete time short-rate models to include Markov switching of infinite dimension. This is a Bayesian nonparametric model that allows for changes in the unknown conditional distribution over time. Applied to weekly U.S. data we find significant parameter change over time and strong evidence of non-Gaussian conditional distributions. Our new model with a hierarchical prior provides significant improvements in density forecasts as well as point forecasts. We find evidence of recurring regimes as well as structural breaks in the empirical application. © 2016 Elsevier B.V., All rights reserved.","Maheu, J.M.; Yang, Q.",2016,10.1016/j.jempfin.2016.06.006,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976337100&doi=10.1016%2Fj.jempfin.2016.06.006&partnerID=40&md5=afcfc5a06eb822eff1844bc60ca17c66,scopus,"This paper introduces an infinite hidden Markov model to capture the time-series dynamics of short-term interest rates. The Bayesian nonparametric model allows for changes in conditional distributions over time and was applied to weekly U.S. data. The findings indicate significant parameter changes, non-Gaussian conditional distributions, and evidence of recurring regimes and structural breaks. The proposed model improved density and point forecasts compared to existing models.",True,False,True,gemini-2.5-flash-lite,Ulrik,M,Maybe not ML enough?,2025-10-13T15:32:02.434671
a9d18ef3b66653ed,Analyzing the green bond index: A novel quantile-based high-dimensional approach,"The development of green bond markets is important for advancing energy efficiency, supporting renewable energy, encouraging sustainable investments, and safeguarding the environment. However, the inherent complexity and uncertainty of these markets pose significant challenges for both investors and researchers. In this study, we focus on analyzing the S&P Green Bond Index, a leading benchmark for monitoring the global green bond market. We introduce a new high-dimensional statistical method, the Quantile Group Adaptive Lasso, designed to accurately predict the returns of this index. Our empirical results demonstrate that this model surpasses several established forecasting techniques in both accuracy and stability. Furthermore, our analysis of economic significance highlights the critical influence of traditional energy-related predictors from G7 and BRICS countries on the global green bond markets. We also find that monetary policies and macroeconomic factors, such as M2 money supply, CPI, and government bond yields, play vital roles. Additionally, the robustness of our proposed method is confirmed. Overall, our study provides a powerful tool that not only significantly enhances forecasting performance but also deepens the understanding of the interplay between trends in green bond markets and information from energy sectors and broader economic conditions. © 2024 Elsevier B.V., All rights reserved.","Tao, L.; Jiang, W.; Ren, X.",2024,10.1016/j.irfa.2024.103659,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206793875&doi=10.1016%2Fj.irfa.2024.103659&partnerID=40&md5=2a3ac17fe37094fba78ff153a1937058,scopus,"This study introduces a novel Quantile Group Adaptive Lasso method to analyze and predict the returns of the S&P Green Bond Index. The empirical results show that this high-dimensional approach outperforms existing forecasting techniques. The analysis reveals that traditional energy-related predictors from G7 and BRICS countries, along with monetary policies and macroeconomic factors, significantly influence green bond markets. The robustness of the proposed method is also confirmed.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:32:08.667052
b4b97658e287ca70,Application of QGA-BP Neural Network in Debt Risk Assessment of Government Platforms,"How to correctly understand the existence of local government debt, study its risk classification and impact, give full play to the “dual nature” of debt with a full-caliber indicator system, and avoid debt risks to the greatest extent. That is the research direction of this article. In order to improve the accuracy and efficiency of risk assessment and effectively reduce the debt risk of government platform companies, a risk assessment method based on optimized back-propagation (BP) neural network is proposed. First, the method uses quantum genetic algorithm (quantum genetic algorithm, QGA) to adjust and determine the initial weight and threshold of BP neural network and realize the optimization of BP neural network model parameter setting. Then, the QGA-BP debt risk assessment of government platforms is verified that it performs well in the debt risk prediction of government platform companies, and its prediction accuracy and prediction speed are improved.",,2024,10.4018/ijitwe.335124,,proquest,"This study proposes a risk assessment method for government platform companies using an optimized back-propagation (BP) neural network, adjusted by a quantum genetic algorithm (QGA). The QGA optimizes the initial weights and thresholds of the BP network, aiming to improve the accuracy and efficiency of debt risk prediction and reduce overall debt risk.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:32:40.265475
73bbac9a2ecd9493,Application of evolutionary computation for rule discovery in stock algorithmic trading: A literature review,"Despite the wide application of evolutionary computation (EC) techniques to rule discovery in stock algorithmic trading (AT), a comprehensive literature review on this topic is unavailable. Therefore, this paper aims to provide the first systematic literature review on the state-of-the-art application of EC techniques for rule discovery in stock AT. Out of 650 articles published before 2013 (inclusive), 51 relevant articles from 24 journals were confirmed. These papers were reviewed and grouped into three analytical method categories (fundamental analysis, technical analysis, and blending analysis) and three EC technique categories (evolutionary algorithm, swarm intelligence, and hybrid EC techniques). A significant bias toward the applications of genetic algorithm-based (GA) and genetic programming-based (GP) techniques in technical trading rule discovery is observed. Other EC techniques and fundamental analysis lack sufficient study. Furthermore, we summarize the information on the evaluation scheme of selected papers and particularly analyze the researches which compare their models with buy and hold strategy (B&H). We observe an interesting phenomenon where most of the existing techniques perform effectively in the downtrend and poorly in the uptrend, and considering the distribution of research in the classification framework, we suggest that this phenomenon can be attributed to the inclination of factor selections and problem in transaction cost selections. We also observe the significant influence of the transaction cost change on the margins of excess return. Other influenced factors are also presented in detail. The absence of ways for market trend prediction and the selection of transaction cost are two major limitations of the studies reviewed. In addition, the combination of trading rule discovery techniques and portfolio selection is a major research gap. Our review reveals the research focus and gaps in applying EC techniques for rule discovery in stock AT and suggests a roadmap for future research. © 2015 Elsevier B.V., All rights reserved.","Hu, Y.; Liu, K.; Zhang, X.; Su, L.; Ngai, E.W.T.; Liu, M.",2015,10.1016/j.asoc.2015.07.008,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939799429&doi=10.1016%2Fj.asoc.2015.07.008&partnerID=40&md5=7ea181ab6877b4d9d39c04fed89bad36,scopus,"This systematic literature review examines the application of evolutionary computation (EC) techniques for discovering rules in stock algorithmic trading (AT). It analyzes 51 relevant articles published before 2013, categorizing them by analytical methods (fundamental, technical, blending) and EC techniques (evolutionary algorithm, swarm intelligence, hybrid EC). The review highlights a bias towards genetic algorithms and genetic programming for technical trading rules, with other EC techniques and fundamental analysis being less studied. It also discusses evaluation schemes, comparisons with buy-and-hold strategies, and identifies limitations such as the absence of market trend prediction and transaction cost selection methods. The paper suggests future research directions, including combining trading rule discovery with portfolio selection.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:32:43.587645
c5a0693edf0851ee,Application of statistical mechanics methodology to term-structure bond-pricing models,"Recent work in statistical mechanics has developed new analytical and numerical techniques to solve coupled stochastic equations. This paper applies the very fast simulated re-annealing and path-integral methodologies to the estimation of the Brennan and Schwartz two-factor term structure model. It is shown that these methodologies can be utilized to estimate more complicated n-factor nonlinear models. © 1991. © 2014 Elsevier B.V., All rights reserved.","Ingber, L.; Wehner, M.F.; Jabbour, G.M.; Barnhill, T.M.",1991,10.1016/0895-7177(91)90107-i,https://www.scopus.com/inward/record.uri?eid=2-s2.0-4344609903&doi=10.1016%2F0895-7177%2891%2990107-I&partnerID=40&md5=a10cc26f8f9082733f9325f7b75f0961,scopus,"This paper applies statistical mechanics techniques, specifically very fast simulated re-annealing and path-integral methodologies, to estimate the Brennan and Schwartz two-factor term structure model. The authors demonstrate that these methods can also be used for more complex n-factor nonlinear models.",True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:33:08.523587
ce0e67a56a1db07c,Applications of machine learning for corporate bond yield spread forecasting,"This article considers nine different predictive techniques, including state-of-the-art machine learning methods for forecasting corporate bond yield spreads with other input variables. We examine each method's out-of-sample forecasting performance using two different forecast horizons: (1) the in-sample dataset over 2003–2007 is used for one-year-ahead and two-year-ahead forecasts of non-callable corporate bond yield spreads; and (2) the in-sample dataset over 2003–2008 is considered to forecast the yield spreads in 2009. Evaluations of forecasting accuracy have shown that neural network forecasts are superior to the other methods considered here in both the short and longer horizon. Furthermore, we visualize the determinants of yield spreads and find that a firm's equity volatility is a critical factor in yield spreads. © 2021 Elsevier B.V., All rights reserved.","Kim, J.-M.; Kim, D.H.; Jung, H.",2021,10.1016/j.najef.2021.101540,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113399304&doi=10.1016%2Fj.najef.2021.101540&partnerID=40&md5=5ba74f57fb59d060a2c1775e12c696df,scopus,"This article evaluates nine predictive techniques, including machine learning methods, for forecasting corporate bond yield spreads. It compares their out-of-sample performance over one- and two-year horizons using data from 2003-2007 and 2003-2008. Neural networks showed superior forecasting accuracy, and equity volatility was identified as a critical factor in yield spreads.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:33:22.281595
57f111d0ba50fca7,Are corporate bond market returns predictable?,"This paper examines the predictability of corporate bond returns using the transaction-based index data for the period from October 1, 2002 to December 31, 2010. We find evidence of significant serial and cross-serial dependence in daily investment-grade and high-yield bond returns. The serial dependence exhibits a complex nonlinear structure. Both investment-grade and high-yield bond returns can be predicted by past stock market returns in-sample and out-of-sample, and the predictive relation is much stronger between stocks and high-yield bonds. By contrast, there is little evidence that stock returns can be predicted by past bond returns. These findings are robust to various model specifications and test methods, and provide important implications for modeling the term structure of defaultable bonds. All rights reserved, Elsevier",,2012,10.1016/j.jbankfin.2012.04.001,,proquest,"This paper investigates the predictability of corporate bond returns using transaction-based index data from October 2002 to December 2010. It finds significant serial and cross-serial dependence in daily investment-grade and high-yield bond returns, with a complex nonlinear structure in serial dependence. Both types of bond returns can be predicted by past stock market returns, with a stronger relationship for high-yield bonds. Stock returns, however, show little predictability from past bond returns. These results are robust and have implications for modeling the term structure of defaultable bonds.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:33:28.671598
302ced4755753438,Are embedded calls valuable? Evidence from agency bonds,"This paper examines the call option values embedded in callable agency bonds. For FHLB, FNMA, and SLMA bonds, call value estimates range from 1.23% of par to 1.47% on average, which are between those for the treasury and corporate debt securities. FHLMC bonds, on the other hand, have an average call value estimate of 2.85%. Call values are significantly larger for bonds with a longer remaining maturity and greater default risk. Most interestingly, call values in the call protection period are significantly larger than those in the callable period except for the SLMA bonds, whereas previous studies on corporate debt find no significant difference in call values between these two periods.In general, call value exhibits a downward trend over time as the callable bond approaches maturity. Also, call value is inversely related to the level of interest rates. Interest rate drops are usually accompanied by an increase in Call values. An analysis of the determinants of call values suggests the following conclusions. First, call values are negatively related to short-term interest rates and the slope of the yield curve, and positively related to coupon rate and remaining maturity. Second, bonds with a greater amount of call protection have smaller call values, which is in contrast with the finding in a previous study on corporate debt that call protection period has little effect on call value. (c) 2006 Elsevier B.V. All rights reserved.","King, Tao-Hsien Dolly",2007,10.1016/j.jbankfin.2006.02.001,,wos,"This paper analyzes the value of embedded call options in agency bonds (FHLB, FNMA, SLMA, FHLMC). It finds that call values vary across bond types and are influenced by maturity, default risk, and interest rate movements. Notably, call values are higher during the call protection period for most agency bonds, unlike findings for corporate debt. The study also identifies factors affecting call values, including interest rates, yield curve slope, coupon rate, maturity, and the presence of call protection.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:33:30.717821
4414f9a04e60c0a8,Are multi-factor Gaussian term structure models still useful? An empirical analysis on Italian BTPs,"In this paper, we empirically study models for pricing Italian sovereign bonds under a reduced form framework, by assuming different dynamics for the short-rate process. We analyze classical Cox-Ingersoll-Ross and Vasicek multi-factor models, with a focus on optimization algorithms applied in the calibration exercise. The Kalman filter algorithm together with a maximum likelihood estimation method are considered to fit the Italian term-structure over a 17-year horizon, including the global financial crisis, the euro area sovereign debt crisis and the Italian political turmoil in 2018. Analytic formulas for the gradient vector and the Hessian matrix of the likelihood function are provided. © 2022 Elsevier B.V., All rights reserved.","Bianchi, M.L.",2022,10.1080/03610918.2020.1721540,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078925539&doi=10.1080%2F03610918.2020.1721540&partnerID=40&md5=48175a83feef6a419ccf98cb26d0831d,scopus,"This paper empirically analyzes multi-factor Gaussian term structure models (Cox-Ingersoll-Ross and Vasicek) for pricing Italian sovereign bonds. It uses the Kalman filter and maximum likelihood estimation to fit the Italian term structure over a 17-year period, encompassing major financial crises. The study also provides analytic formulas for gradient and Hessian matrices in the likelihood function.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:33:53.901595
31af06ccc96e13d2,Are there nonlinear speculative bubbles in commodities prices?,"Daily price movements of seventeen commodities are tested for the possible presence of nonlinear speculative bubbles during 1991-2012. A VAR model for logarithmic first differences of each is estimated with one-year Treasury bill rates, U.S. dollar value, a world stock market index, and an overall commodities price index using Hamilton regime switching and Hurst rescaled range tests. Residuals after removing ARCH for all seventeen commodity price series are tested for remaining nonlinearity using the BDS test. These tests fail to reject the presence of bubble-like trends and nonlinearity beyond ARCH for all seventeen commodity series. However, we note that we are unable to overcome the misspecified fundamentals problem, which means we cannot argue that we have definitely found speculative bubbles. At most we can argue that our results indicate that these markets appear to exhibit excess volatility and unexplained trends. © 2014 M.E. Sharpe, Inc. All rights reserved. © 2020 Elsevier B.V., All rights reserved.","Ahmed, E.; Rosser, J.B.; Uppal, J.Y.",2014,10.2753/pke0160-3477360302,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898645711&doi=10.2753%2FPKE0160-3477360302&partnerID=40&md5=34a271069a89937d6ad612232df95cda,scopus,"This study investigates the presence of nonlinear speculative bubbles in commodity prices using daily data from 1991-2012 for seventeen commodities. It employs a VAR model with regime switching and Hurst rescaled range tests, and the BDS test on residuals after ARCH modeling. While the tests suggest bubble-like trends and nonlinearity, the authors acknowledge the limitation of not being able to definitively identify speculative bubbles due to the 'misspecified fundamentals' problem, concluding that the markets show excess volatility and unexplained trends.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:33:57.877896
e387f15db5d09f82,Artificial intelligence combined with nonlinear optimization techniques and their application for yield curve optimization,"This study makes use of the artificial intelligence approaches combined with some nonlinear optimization techniques for optimization of a well-known problem in financial engineering called yield curve. Yield curve estimation plays an important role on making strategic investment decisions. In this paper, we use two well-known parsimonious estimation models, Nelson-Siegel and Extended Nelson-Siegel, for the yield curve estimation. The proposed models of this paper are formulated as continuous nonlinear optimization problems. The resulted models are then solved using some nonlinear optimization and meta-heuristic approaches. The optimization techniques include hybrid GPSO parallel trust region-dog leg, Hybrid GPSO parallel trust region-nearly exact, Hybrid GPSO parallel Levenberg-Marquardt and Hybrid genetic electromagnetism like algorithm. The proposed models of this paper are examined using some real-world data from the bank of England and the results are analyzed. © 2017 Elsevier B.V., All rights reserved.","Soltani, R.; Sadjadi, S.J.; Rahnama, M.",2017,10.3934/jimo.2017014,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030552095&doi=10.3934%2Fjimo.2017014&partnerID=40&md5=9e10a6ec52920ca48e87b2e5a37a3950,scopus,This paper applies artificial intelligence and nonlinear optimization techniques to estimate the yield curve using Nelson-Siegel and Extended Nelson-Siegel models. It formulates the problem as a continuous nonlinear optimization task and solves it using hybrid GPSO algorithms with various nonlinear optimization methods. The models are tested with real-world data from the Bank of England.,True,True,False,gemini-2.5-flash-lite,Ulrik,M,,2025-10-13T15:34:15.292889
5dd844b0966c453d,Asian holding of US Treasury securities: trade integration as a threshold,"This paper empirically investigates if there have been any shifts in regimes with Asian holding of US long-term Treasury securities with particular attention paid to the role of growing regional integration in trade. A panel regression estimation of eight Asian countries for 1998-2004 confirms the striking persistency of the portfolio weight of US Treasury securities. It also reveals, without a surprise, that the traditionally strong trade link with US as well as exchange rate regime and volatility of local currency bond index explain observed overinvestment in US Treasury securities deviating from what can be warranted by the market share of the US Treasury securities. What is interesting, however, is the estimated regime switches as found when examined with a threshold estimation (Hansen, 1999). We find three thresholds which divide the sample into four regimes-a decreasing persistency as intraregional trade link becomes tighter. All rights reserved, Elsevier",,2011,10.1016/j.jjie.2011.07.001,,proquest,"This paper examines the holding of US Treasury securities by Asian countries, focusing on the impact of regional trade integration. Using panel regression for eight Asian countries from 1998-2004, it confirms the persistence of US Treasury security holdings and identifies trade links with the US, exchange rate regimes, and local currency bond volatility as explanatory factors. Notably, threshold estimation reveals regime switches, with decreasing persistence as intra-regional trade tightens.",True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:34:26.655063
6512de4ac6889893,Asset Pricing and Machine Learning: A critical review,"The latest development in empirical Asset Pricing is the use of Machine Learning methods to address the problem of the factor zoo. These techniques offer great flexibility and prediction accuracy but require special care as they strongly depart from traditional Econometrics. We review and critically assess the most recent and relevant contributions in the literature grouping them into five categories defined by the Machine Learning (ML) approach they employ: regularization, dimension reduction, regression trees/random forest (RF), neural networks (NNs), and comparative analyses. We summarize the empirical findings with particular attention to their economic interpretation providing hints for future developments. © 2024 Elsevier B.V., All rights reserved.","Bagnara, M.",2024,10.1111/joes.12532,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137459905&doi=10.1111%2Fjoes.12532&partnerID=40&md5=d514f0cebadfe1ab035f5fdd14a1fc49,scopus,"This review critically assesses recent Machine Learning (ML) applications in empirical Asset Pricing, focusing on addressing the 'factor zoo' problem. It categorizes contributions by ML approach (regularization, dimension reduction, RF, NNs, comparative analyses), summarizes empirical findings, and discusses economic interpretations and future directions.",True,False,True,gemini-2.5-flash-lite,Ulrik,Review,"Maybe not bonds, not clear from abstract",2025-10-13T15:34:59.394383
c525f00d6ca91a55,Asset market equilibrium under rational inattention,"We propose a noisy rational expectations equilibrium model of asset markets with rationally inattentive investors. We incorporate any finite number of assets with arbitrary correlation. We also do not restrict the signal form and show that investors optimally choose a single signal, which is a noisy linear combination of all risky assets. This generates comovement of asset prices and contagion of shocks, even when asset payoffs are negatively correlated. The model also provides testable predictions of the impact of risk aversion, aggregate risk, and information capacity on the security market line, the portfolio dispersion, and the abnormal return.",,2023,10.1007/s00199-021-01396-z,,proquest,"This paper presents a model of asset markets where investors are rationally inattentive. It incorporates multiple assets with arbitrary correlations and shows that investors optimally choose a single noisy signal, leading to comovement of asset prices and shock contagion. The model offers testable predictions regarding risk aversion, aggregate risk, and information capacity.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:35:03.863317
cb2acc4b493b7729,"Association between isolation of staphylococcus aureus one week after calving and milk yield, somatic cell count, clinical mastitis, and culling through the remaining lactation","Cows with isolation of Staphylococcus aureus approximately 1 week after calving and milk yield, somatic cell count (SCC), clinical mastitis (CM), and culling risk through the remaining lactation were assessed in 178 Norwegian dairy herds. Mixed models with repeated measures were used to compare milk yield and SCC, and survival analyses were used to estimate the hazard ratio for CM and culling. On average, cows with an isolate of Staph. aureus had a significantly higher SCC than culture-negative cows. If no post-milking teat disinfection (PMTD) was used, the mean values of SCC were 42 000, 61 000, 68 000 and 77 000 cells/ml for cows with no Staph. aureus isolate, with Staph. aureus isolated in 1 quarter, in 2 quarters and more than 2 quarters respectively. If iodine PMTD was used, SCC means were 36 000; 63 000; 70 000 and 122 000, respectively. Primiparous cows testing positive for Staph. aureus had the same milk yield curve as culture-negative cows, except for those with Staph. aureus isolated in more than 2 quarters. They produced 229 kg less during a 305-d lactation. Multiparous cows with isolation of Staph. aureus in at least 1 quarter produced 94161 kg less milk in 2nd and >3rd parity, respectively, and those with isolation in more than 2 quarters produced 303390 kg less than multiparous culture-negative animals during a 305-d lactation. Compared with culture-negative cows, the hazard ratio for CM and culling in cows with isolation of Staph. aureus in at least 1 quarter was 20 (1624) and 17 (1519), respectively. There was a decrease in the SCC and in the CM risk in culture-negative cows where iodine PMTD had been used, indicating that iodine PMTD has a preventive effect on already healthy cows. For cows testing positive for Staph. aureus in more than 2 quarters at calving, iodine PMTD had a negative effect on the CM risk and on the SCC through the remaining lactation. © 2008 Proprietors of Journal of Dairy Research 2008. © 2009 Elsevier B.V., All rights reserved.","Whist, A.C.; Osterås, O.; Sølverød, L.",2009,10.1017/s0022029908003592,https://www.scopus.com/inward/record.uri?eid=2-s2.0-61849171892&doi=10.1017%2FS0022029908003592&partnerID=40&md5=a117643932e2df01d89e6acaacd31332,scopus,"This study investigated the impact of Staphylococcus aureus isolation one week after calving on milk yield, somatic cell count (SCC), clinical mastitis (CM), and culling risk in Norwegian dairy herds. Results showed that cows with Staph. aureus isolation generally had higher SCC. Milk yield was reduced, particularly in multiparous cows with Staph. aureus in multiple quarters. The risk of CM and culling was significantly elevated in cows with Staph. aureus. The study also examined the effect of post-milking teat disinfection (PMTD), finding a preventive effect of iodine PMTD on healthy cows but a negative effect on CM risk and SCC in cows with Staph. aureus in more than two quarters.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:35:08.363559
4b22c1332c433aaa,Asymmetric impacts of individual investor sentiment on the time-varying risk-return relation in stock market,"This study investigates the impacts of investor sentiments, including individual sentiment and market-wide sentiments, on time-varying risk-return tradeoffs in the U.S. stock market using quantile regressions. Empirical results show that the individual sentiment has a significant negative effect on the time-varying risk-return tradeoff across all quantiles, indicating the heterogeneity of the individual sentiment effect. Specifically, the positive individual sentiment weakens the time-varying risk-return tradeoff while the negative individual sentiment enhances it. Besides, there are asymmetric effects of the individual sentiment at quantiles (0.25, 0.75), that is, a negative individual sentiment associated with bad news has a stronger impact than a positive individual sentiment associated with good news. These findings are robust for alternative estimate methods and individual sentiments. However, the study finds that the time-varying riskreturn tradeoff is less sensitive to the market-wide sentiment than to the individual sentiment, indicating that the individual sentiment is more useful and important in determining the stock price and variation.","He, Zhifang",2022,10.1016/j.iref.2021.11.018,,wos,"This study examines how individual and market-wide investor sentiments affect the time-varying risk-return relationship in the U.S. stock market using quantile regressions. It finds that individual sentiment significantly impacts this relationship across all quantiles, with positive sentiment weakening it and negative sentiment strengthening it. The impact of negative sentiment is stronger than positive sentiment, especially during bad news periods. The study concludes that individual sentiment is more influential than market-wide sentiment in stock price determination.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:35:19.577480
1b83d207f7348a04,Asymmetries in exchange rate pass-through and monetary policy principle: Some Caribbean empirical evidence,"The study shows that nonlinear models yield superior unbiased estimates which are free of serial correlation, heteroscedasticity and functional form instability problems which often affect linear models. All six countries have partial exchange rate pass-through, with only The Bahamas recording the lowest pass-through comparable with developed countries which target inflation. The rest of countries, and to a lesser extent Barbados, have high exchange rate pass-through which signifies their vulnerabilities to external inflation. Depreciation results in higher pass-through than appreciation, especially during rising prices/inflation. Nonlinear/threshold cointegration exists in all six countries. TAR results show asymmetric adjustment towards long-run equilibrium in The Bahamas, Guyana and to a lesser extent Jamaica, and symmetric adjustment in Barbados, Belize and Trinidad-Tobago. M-TAR results show asymmetric adjustment in four countries, while Guyana and Trinidad-Tobago experience symmetric adjustment. Taylor's rule is effective in The Bahamas, insignificant in Trinidad-Tobago; and ineffective in the rest of the countries. Appreciation is the most effective operating target for central banks to reduce inflation in The Bahamas, Barbados, Guyana and Jamaica. © 2019 Elsevier B.V., All rights reserved.","Ghartey, E.E.",2019,10.1016/j.najef.2018.05.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047390611&doi=10.1016%2Fj.najef.2018.05.001&partnerID=40&md5=031863a6cf182b0e8952be0d6eeb64d3,scopus,"This study utilizes nonlinear models to analyze exchange rate pass-through and monetary policy in six Caribbean countries. It finds partial pass-through in all countries, with The Bahamas showing the lowest. Depreciation leads to higher pass-through than appreciation. Nonlinear cointegration is present, and adjustment towards equilibrium is asymmetric in some countries. Taylor's rule effectiveness varies, and appreciation is identified as an effective tool for reducing inflation in several nations.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:35:27.242269
996de93213bec4cf,Audit firm tenure and the equity risk premium,"Although investor perceptions of audit quality play a critical role in maintaining systemic confidence in the integrity of financial accounting reports (Levitt [2000]), prior research on the effects of auditor tenure from an investor perspective is relatively sparse. In this study, we investigate whether investors price audit firm tenure for Big Five audits by examining the relation between tenure and the ex ante equity risk premium, that is, the excess of the company-specific ex ante cost of equity capital over the risk-free interest rate. Based on prior research, whereas the ""auditor learning"" argument predicts that audit quality will change in only one direction (i.e., improve) with tenure, the ""auditor-client closeness"" argument suggests that audit quality may decrease beyond some (albeit unspecified) length of tenure because of impaired auditor independence and objectivity. Consistent with prior theoretical arguments, we find some evidence of a nonlinear relation between audit firm tenure and the ex ante equity risk premium, that is, we find that the equity risk premium decreases in the early years of tenure but increases with additional years of tenure. These findings persist after we control for well-known risk factors and company characteristics that have been shown in prior research to be related to the cost of equity capital. The implications of our findings are discussed. © 2018 Elsevier B.V., All rights reserved.","Boone, J.P.; Khurana, I.K.; Raman, K.K.",2008,10.1177/0148558x0802300107,https://www.scopus.com/inward/record.uri?eid=2-s2.0-39049110814&doi=10.1177%2F0148558X0802300107&partnerID=40&md5=afbbdddf8ba8026c99f86443de6bb403,scopus,"This study investigates the relationship between audit firm tenure and the equity risk premium, examining whether investors price this tenure. The findings suggest a nonlinear relationship, where the equity risk premium initially decreases with tenure but then increases with longer tenure, even after controlling for other risk factors and company characteristics. The research explores the 'auditor learning' versus 'auditor-client closeness' arguments regarding audit quality.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:35:31.060207
83fe6cfa852a80cb,Baltic Dry Index Estimation With NARX Neural Network Model,"Abstract. BDI is a global trade indicator followed by those interested in maritime trade. But it has volatility, seasonality, and uncertain cyclicality. For this reason, in this study, the BDI has been estimated to provide preliminary information to those interested in maritime trade. NARX Neural Network which performs successfully in complex and nonlinear real-life problems is used. In addition, the NARX neural network model has not been found in a previous study used for BDI estimation. Eleven independent variables are used in this study, what increases the predictive power. Independent variables are Bloomberg Commodities Index (BCOM), Twitter-Based Economic Uncertainty Index (TEU), Twitter-Based Market Uncertainty Index (TMU), S&P 500 Index, MSCI World Index, €/$ Parity, VIX (CBOE), US 10-Year Bond Yield (%), Brent Oil (USD/Barrel), Economic Uncertainty Index and World Trade Volume (USD Billion). The Twitter-Based Economic Uncertainty Index (TEU) and Twitter-Based Market Uncertainty Index (TMU), which were not used before in BDI estimation studies, were included in the analysis and contributed to the literature. The data set contains daily data for the period 9.07.2012-31.08.2020. 11-day estimate values covering 1.09.2020-15.09.2020 are calculated. MAPE, MAE and RMSE performance criteria were calculated for the estimation values. Value of MAPE (2.96%), value of MAE (36.6%) and value of RMSE (46.68) were obtained. As a result, the estimate values were compared with the actual values.",,2023,10.15388/ekon.2023.102.1.4,,proquest,"This study estimates the Baltic Dry Index (BDI) using a NARX Neural Network model, incorporating eleven independent variables including commodity indices, uncertainty indices (including novel Twitter-based ones), stock market indices, currency parity, VIX, bond yields, oil prices, and world trade volume. The model was trained on daily data from 2012-2020 and used to forecast 11 days ahead. Performance metrics (MAPE, MAE, RMSE) were calculated, showing promising estimation accuracy.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:35:39.783668
dc9164700f08b9ff,Bank portfolio exposure to emerging markets and its effects on bank market value,"This study estimates a model of banking company equity returns taking into consideration book value and market value measures of their exposure to emerging markets debt. In this estimation, general systematic market factors, such as the rate of return on the S&P500 stock index and yields on a constant maturity 5-year Treasury note, are held constant such that the exposure variables are accounting for effects due to banks' exposure to emerging market debt. The results, although not uniform among banking companies, support the hypothesis that the extent of exposure to emerging market debt are factored into the valuation of banking company equity contemporaneously. The inclusion of a market value indicator adds to the explanation of equity returns of some banks. It is also clear that knowing the extent of the exposure on a book value basis is important information alone that may allow investors to take account of or evaluate the effects of changes in banking company equity valuation from LDC debt exposures. We also perform an event study for three major debt crises to determine whether the market recognizes the effects of these events on bank valuation. The event study results show that there is little information from identifying the time period of the crises on banking company equity returns. Explanations for this are that the information of these possible crises has been embedded in bank changes in exposure and that the market valuation of the emerging market debt is already accounted for by our model. (c) 2005 Elsevier B.V. All rights reserved.","Fissel, GS; Goldberg, L; Hanweck, GA",2006,10.1016/j.jbankfin.2005.05.013,,wos,"This study investigates the impact of bank portfolio exposure to emerging markets debt on bank market value. It uses a model to estimate equity returns, considering both book and market value measures of exposure, while controlling for general market factors. The findings suggest that emerging market debt exposure is contemporaneously factored into banking equity valuation. An event study on debt crises indicated limited direct impact on equity returns, possibly due to embedded information in exposure changes and prior market valuation.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:35:58.961380
b917561dfec7c669,Banking and Currency Crises: Differential Diagnostics for Developed Countries,"We identify a set of ‘rules of thumb’ that characterize economic, financial and structural conditions preceding the onset of banking and currency crises in 36 advanced economies over 1970–2010. We use the classification and regression tree methodology and its random forest extension, which permits the detection of key variables driving binary crisis outcomes, allows for interactions among key variables and determines critical tipping points. We distinguish between basic country conditions, country structural characteristics and international developments. We find that crises are more varied than they are similar. For banking crises, we find that low net interest rate spreads in the banking sector and a shallow, or inverted, yield curve is their most important forerunners in the short term. In the longer term, it is high house price inflation. For currency crises, high domestic short-term rates coupled with overvalued exchange rates are the most powerful short-term predictors. We find that both country structural characteristics and international developments are relevant banking-crisis predictors. Currency crises, however, seem to be driven more by country idiosyncratic, short-term developments. We find that some variables, such as the domestic credit gap, provide important unconditional signals, but it is difficult to use them as conditional signals and, more importantly, to find relevant threshold values. Copyright © 2016 John Wiley & Sons, Ltd. © 2017 Elsevier B.V., All rights reserved.","Joy, M.; Rusnák, M.; Šmídková, K.; Vašíček, B.",2017,10.1002/ijfe.1570,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997815830&doi=10.1002%2Fijfe.1570&partnerID=40&md5=ad5779af0086673cb5576a2c30dc058f,scopus,"This study identifies 'rules of thumb' for banking and currency crises in 36 advanced economies (1970-2010) using classification and regression trees and random forests. Key predictors for banking crises include low net interest rate spreads, inverted yield curves, and high house price inflation. For currency crises, high domestic short-term rates and overvalued exchange rates are significant short-term predictors. The study highlights that banking crises are influenced by both structural and international factors, while currency crises are more idiosyncratic and short-term driven.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:37:12.298267
8f362e0ee7b8047a,Bayesian Factor-adjusted Sparse Regression,"Many sparse regression methods are based on the assumption that covariates are weakly correlated, which unfortunately do not hold in many economic and financial datasets. To address this challenge, we model the strongly-correlated covariates by a factor structure: strong correlations among covariates are explained by common factors and the remaining variations are interpreted as idiosyncratic components. We then propose a factor-adjusted sparse regression model with both common factors and idiosyncratic components as decorrelated covariates and develop a semi-Bayesian method. Parameter estimation rate-optimality and model selection consistency are established by non-asymptotic analyses. We show on simulated data that the semi-Bayesian method outperforms its Lasso analogue, manifests insensitivity to the overestimates of the number of common factors, pays a negligible price when covariates are not correlated, scales up well with increasing sample size, dimensionality and sparsity, and converges fast to the equilibrium of the posterior distribution. Numerical results on a real dataset of U.S. bond risk premia and macroeconomic indicators also lend strong supports to the proposed method.Many sparse regression methods are based on the assumption that covariates are weakly correlated, which unfortunately do not hold in many economic and financial datasets. To address this challenge, we model the strongly-correlated covariates by a factor structure: strong correlations among covariates are explained by common factors and the remaining variations are interpreted as idiosyncratic components. We then propose a factor-adjusted sparse regression model with both common factors and idiosyncratic components as decorrelated covariates and develop a semi-Bayesian method. Parameter estimation rate-optimality and model selection consistency are established by non-asymptotic analyses. We show on simulated data that the semi-Bayesian method outperforms its Lasso analogue, manifests insensitivity to the overestimates of the number of common factors, pays a negligible price when covariates are not correlated, scales up well with increasing sample size, dimensionality and sparsity, and converges fast to the equilibrium of the posterior distribution. Numerical results on a real dataset of U.S. bond risk premia and macroeconomic indicators also lend strong supports to the proposed method.",,2022,10.1016/j.jeconom.2020.06.012,,proquest,"This paper proposes a Bayesian factor-adjusted sparse regression model to handle strongly correlated covariates, common in economic and financial data. The method models correlations using common factors and idiosyncratic components, decorrelating covariates. The authors establish theoretical properties and demonstrate superior performance over Lasso on simulated data, showing robustness and scalability. Empirical results on U.S. bond risk premia and macroeconomic indicators support the method's effectiveness.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T15:37:21.102612
331b25330b0d6585,Bayesian estimation of generalized hyperbolic skewed student GARCH models,"Efficient posterior simulators for two GARCH models with generalized hyperbolic disturbances are presented. The first model, GHt-GARCH, is a threshold GARCH with a skewed and heavy-tailed error distribution; in this model, the latent variables that account for skewness and heavy tails are identically and independently distributed. The second model, ODLV-GARCH, is formulated in terms of observation-driven latent variables; it automatically incorporates a risk premium effect. Both models nest the ordinary threshold t-GARCH as a limiting case. The GHt-GARCH and ODLV-GARCH models are compared with each other and with the threshold t-GARCH using five publicly available asset return data sets, by means of Bayes factors, information criteria, and classical forecast evaluation tools. The GHt-GARCH and ODLV-GARCH models both strongly dominate the threshold t-GARCH, and the Bayes factors generally favor GHt-GARCH over ODLV-GARCH. A Markov switching extension of GHt-GARCH is also presented. This extension is found to be an empirical improvement over the single-regime model for one of the five data sets. © 2010 Elsevier B.V. All rights reserved. © 2012 Elsevier B.V., All rights reserved.","Deschamps, P.J.",2012,10.1016/j.csda.2011.10.021,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862002336&doi=10.1016%2Fj.csda.2011.10.021&partnerID=40&md5=8ad3dd3fea5afe72e5ab50f367c7831f,scopus,"This paper presents Bayesian estimation methods for two GARCH models with generalized hyperbolic disturbances: GHt-GARCH and ODLV-GARCH. Both models are compared to the standard threshold t-GARCH model using asset return data. The proposed models generally outperform the standard model, with GHt-GARCH often favored over ODLV-GARCH. A Markov switching extension of GHt-GARCH is also introduced and found to be an improvement for one dataset.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:37:43.754775
ab700dd24895596c,Berry-Esseen inequalities for the fractional Black-Karasinski model of term structure of interest rates,"The Black-Karasinski model is a one-factor non-affine interest rate model as it describes interest rate movements driven by a single source of randomness and the drift function is a nonlinear function of the interest rate. The drift parameters represent the level and the speed of mean reversion of the interest rate. It belongs to the class of no-arbitrage models. The paper introduces some new approximate minimum contrast estimators of the mean reversion speed parameter in the model based on discretely sampled data which are efficient and studies their asymptotic distributional properties with precise rates of convergence. © 2022 Elsevier B.V., All rights reserved.","Bishwal, J.P.N.",2022,10.1515/mcma-2022-2111,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128529022&doi=10.1515%2Fmcma-2022-2111&partnerID=40&md5=0df5d76b3a1c89a37cef11986d99cff1,scopus,"This paper introduces approximate minimum contrast estimators for the mean reversion speed parameter in the fractional Black-Karasinski interest rate model, analyzing their asymptotic distributional properties and convergence rates using discretely sampled data. The model is a one-factor non-affine, no-arbitrage interest rate model.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:38:07.620245
f94a815f95694f43,Bias in the estimation of the mean reversion parameter in continuous time models,"It is well known that for continuous time models with a linear drift standard estimation methods yield biased estimators for the mean reversion parameter both in finite discrete samples and in large in-fill samples. In this paper, we obtain two expressions to approximate the bias of the least squares/maximum likelihood estimator of the mean reversion parameter in the Ornstein-Uhlenbeck process with a known long run mean when discretely sampled data are available. The first expression mimics the bias formula of Marriott and Pope (1954) for the discrete time model. Simulations show that this expression does not work satisfactorily when the speed of mean reversion is slow. Slow mean reversion corresponds to the near unit root situation and is empirically realistic for financial time series. An improvement is made in the second expression where a nonlinear correction term is included into the bias formula. It is shown that the nonlinear term is important in the near unit root situation. Simulations indicate that the second expression captures the magnitude, the curvature and the non-monotonicity of the actual bias better than the first expression. (C) 2012 Elsevier B.V. All rights reserved.","Yu, Jun",2012,10.1016/j.jeconom.2012.01.004,,wos,"This paper derives two expressions to approximate the bias of the least squares/maximum likelihood estimator for the mean reversion parameter in the Ornstein-Uhlenbeck process using discrete time data. The second expression, which includes a nonlinear correction term, is shown to be more accurate, especially in situations of slow mean reversion (near unit root), which are common in financial time series.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:38:15.705345
3f98ba9b92b7d6ec,Black-litterman model with views prediction using elman recurrent neural network,"The Black-Litterman model is a portfolio model that considers investor views. The purpose of this study is to develop the Black-Litterman (BL) portfolio model with views prediction using Elman Recurrent Neural Network (ERNN) on LQ-45 stocks. The ERNN model is one of the neural network models that adjusts the input using the output feedback from the hidden layer. The BL portfolio is generated based on the capital assets pricing model (CAPM) excess return equilibrium. The data used in CAPM model must fulfill the normality assumption which is checked by using Jarque Bera test. The selected stocks for the portfolio are the member of LQ-45 stocks which meet the normality assumption and have the highest expected excess return CAPM value, those are AKRA, BBNI, INCO, and JSMR stocks. The ERNN model is employed to those stocks to obtain the views prediction. Then, the Black-Litterman portfolio is constructed by combining the ERNN views of the stock returns and the expected equilibrium return yielded by the capital assets pricing model. Three designs of relative views are considered, each design is distinguished from the percentage of each stock return prediction. The simulation shows that the best portfolio is constructed based on the design of the first views due to the most accurate views prediction. © 2021 Elsevier B.V., All rights reserved.","Wutsqa, D.U.; Pamungkas, M.A.; Subekti, R.",2021,10.13189/ujaf.2021.090609,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120813748&doi=10.13189%2Fujaf.2021.090609&partnerID=40&md5=79efd1877b35d6a272814a5d81943845,scopus,"This study develops the Black-Litterman portfolio model by incorporating investor views predicted using an Elman Recurrent Neural Network (ERNN) for LQ-45 stocks. The model combines ERNN-predicted views with equilibrium returns from the Capital Asset Pricing Model (CAPM). The best portfolio was achieved with the first design of relative views, which showed the most accurate predictions.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:38:22.334356
8624241783a1b415,Blockchain Innovation for Sustainability: Unraveling Its Market Impact Through Public Attention and Financial Performance,"This study investigates the dynamic interplay between blockchain innovation, public attention, and financial performance, with a focus on sustainability applications. Using a state-space model and the Kalman filter, it analyzes data from blockchain-related patents and Google Trends to assess their influence on the excess returns of blockchain-focused exchange-traded funds (ETFs). The findings highlight that innovation activity significantly enhances financial performance, underscoring blockchain’s role as a general-purpose technology with transformative sustainability potential. Public attention, measured through search interest, independently drives investor sentiment and market outcomes, while the interaction between innovation and public attention does not exhibit significant synergistic effects, suggesting distinct channels of influence. This study contributes to the growing stream of literature in sustainable finance, innovation management, and behavioral finance by introducing a real-time measure of blockchain innovation for sustainability into an asset pricing model, by showing that patent activity and public attention operate as separate predictors of financial returns, and by advancing methodological practice through the use of a state-space approach to capture latent innovation dynamics. The findings suggest actionable strategies: investors can track patent-based innovation and search trends as early signals of thematic-ETF performance; industry leaders can align blockchain projects with sustainability goals to unlock valuation gains; and policymakers can foster environmental, social, and governance innovation ecosystems by encouraging transparent patent disclosure and public awareness.",C. Toscano Hernandez; F. P. Appio; F. Platania,2025,10.1109/tem.2025.3598382,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11123793,ieeexplore,"This study examines how blockchain innovation, public attention, and sustainability applications affect financial performance, specifically the returns of blockchain-focused ETFs. It uses a state-space model and Kalman filter to analyze patent data and Google Trends, finding that innovation boosts financial performance and public attention influences investor sentiment independently. The research contributes to sustainable finance and innovation management by introducing a real-time measure of blockchain innovation for sustainability and demonstrating that patent activity and public attention are separate predictors of financial returns. It suggests investors monitor patent and search trends for ETF performance, industry leaders align blockchain with sustainability for valuation gains, and policymakers foster innovation ecosystems.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:38:25.259380
45ce1b29701d0093,Bond Risk Premiums with Machine Learning,"We show that machine learning methods, in particular, extreme trees and neural networks (NNs), provide strong statistical evidence in favor of bond return predictability. NN forecasts based on macroeconomic and yield information translate into economic gains that are larger than those obtained using yields alone. Interestingly, the nature of unspanned factors changes along the yield curve: stock- and labor-market-related variables are more relevant for short-term maturities, whereas output and income variables matter more for longer maturities. Finally, NN forecasts correlate with proxies for time-varying risk aversion and uncertainty, lending support to models featuring both channels.",,2021,10.1093/rfs/hhaa062,,proquest,"This study demonstrates that machine learning techniques, specifically extreme trees and neural networks (NNs), offer significant statistical evidence for predicting bond returns. NN forecasts, incorporating macroeconomic and yield data, yield greater economic benefits than those using only yield information. The study also identifies that the influence of unspanned factors varies across the yield curve, with stock and labor market factors being more significant for shorter maturities and output/income factors for longer maturities. Furthermore, NN forecasts align with measures of time-varying risk aversion and uncertainty, supporting models that include these elements.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T15:38:48.966284
7c6e73c3fc3236c1,Buffered vector error-correction models: An application to the U.S. Treasury bond rates,"This paper extends the buffered autoregressive model to the buffered vector error-correction model (VECM). Least squares estimation and a reduced-rank estimation are discussed, and the consistency of the estimators on the delay parameter and threshold parameters is derived. We also propose a supWald test for the presence of buffer-type threshold effect. Under the null hypothesis of no threshold, the supWald test statistic converges to a function of Gaussian process. A bootstrap method is proposed to obtain the p-value for the supWald test. We investigate the effectiveness of our methods by simulation studies. We apply our model to study the monthly Federal bond rates of United States. We find the evidences of buffering regimes and the asymmetric error-correction effect. © 2022 Elsevier B.V., All rights reserved.","Lu, R.; Yu, P.L.H.",2021,10.1515/snde-2019-0047,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094603557&doi=10.1515%2Fsnde-2019-0047&partnerID=40&md5=79cc2936dd1fb0d52d32acd43219b341,scopus,"This paper introduces the buffered vector error-correction model (VECM) as an extension of the buffered autoregressive model. It covers estimation techniques, consistency of parameters, and a supWald test for threshold effects, with a bootstrap method for p-values. The model is applied to U.S. Treasury bond rates, revealing evidence of buffering regimes and asymmetric error-correction.",True,True,False,gemini-2.5-flash-lite,Ulrik,M,,2025-10-13T15:39:05.798638
f34bce48827c7358,Business performance assessment of small and medium-sized enterprises: Evidence from the Czech Republic,"Business performance assessment is one of the basic tasks of management. Business performance can be assessed using a number of methods. The basic ones include financial analysis, Balanced Scorecard or Economic Value Added (EVA). The paper is focused on SME business performance assessment based on Economic Value Added, calculated using the INFA build-up model. According to this method, companies were divided into four categories. The first category included companies with a positive EVA value. The second category included companies with negative EVA, but with the economic result above the risk-free rate. The third category included companies with a positive economic result above the risk-free rate. The fourth category included companies with a negative economic result. The model did not include companies with negative equity. The input represented 15 predictors based on their financial statements. The data were normalized and all extreme values, likely caused by a data rewriting error, were removed. Company performance is visualized by comparing Principal Component Analysis and Kohonen neural networks. Compared to similar research, the methods are compared using the data that analyzes the performance of companies. Both methods made it possible to visualize the given task. With regard to the purpose of facilitating the interpretation of the results, for the given case, the use of PC seems to be more appropriate.",,2021,10.21511/ppm.19(3).2021.35,,proquest,"This paper assesses the business performance of Czech SMEs using the Economic Value Added (EVA) method, categorizing companies based on their EVA values and economic results relative to the risk-free rate. It employs Principal Component Analysis (PCA) and Kohonen neural networks for visualization, finding PCA more interpretable for this task. The study utilizes 15 financial statement predictors, with data normalization and outlier removal.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:39:08.775803
3c9b8446c50f3d5d,Calendar anomolies and stock market volatility in selected Arab stock exchanges,"While seasonal effects for both advanced and emerging markets have been investigated extensively in mean and variance equations, Arab region asset markets have received much less attention. The objective of this article is to fill this gap in the literature by investigating the day-of-the-week effect in 12 major Arab stock markets using Arab Monetary Fund (AMF) daily index returns from May 2002 to December 2005. Our estimation strategy utilizes Autoregressive (AR) and Generalized Autoregressive Conditional Heteroscedastic (GARCH)-type specifications to allow for a time-varying variance. Among the most important results of this article are, first, is one-third of these markets exhibit significant day-of-the-week effect in returns. Second, two-third of these markets exhibit significant day-of-the-week effect on volatility. Third, most of these day-of-the-week effects are focused within the beginning and the end of the trading week. Finally, the existence of a significant risk premium was confirmed in five of the 12 studied markets.",,2009,10.1080/09603100802359976,,proquest,"This study investigates the day-of-the-week effect on stock returns and volatility in 12 Arab stock markets from May 2002 to December 2005, using AR and GARCH models. Findings indicate significant day-of-the-week effects in returns for one-third of markets and in volatility for two-thirds, often concentrated at the beginning and end of the trading week. A significant risk premium was also confirmed in five markets.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:39:11.063416
bb5517a95f6fd771,Can Ensemble Machine Learning Methods Predict Stock Returns for Indian Banks Using Technical Indicators?,"This paper develops ensemble machine learning models (XGBoost, Gradient Boosting, and AdaBoost in addition to Random Forest) for predicting stock returns of Indian banks using technical indicators. These indicators are based on three broad categories of technical analysis: Price, Volume, and Turnover. Various error metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), Mean Absolute Percentage Error (MAPE), Root-Mean-Squared-Error (RMSE) have been used to check the performance of the models. Results show that the XGBoost algorithm performs best among the four ensemble models. The mean of absolute error and the root-mean-square -error vary around 3–5%. The feature importance plots generated by the models depict the importance of the variables in predicting the output. The proposed machine learning models help traders, investors, as well as portfolio managers, better predict the stock market trends and, in turn, the returns, particularly in banking stocks minimizing their sole dependency on macroeconomic factors. The techniques further assist the market participants in pre-empting any price-volume action across stocks irrespective of their size, liquidity, or past turnover. Finally, the techniques are incredibly robust and display a strong capability in predicting trend forecasts, particularly with any large deviations.",,2022,10.3390/jrfm15080350,,proquest,"This study investigates the efficacy of ensemble machine learning models (XGBoost, Gradient Boosting, AdaBoost, and Random Forest) in predicting stock returns for Indian banks. The models utilize technical indicators derived from price, volume, and turnover data. Performance is evaluated using MAE, MSE, MAPE, and RMSE. XGBoost demonstrated the best performance, with MAE and RMSE around 3-5%. The findings suggest these models can aid traders and investors in predicting stock market trends, complementing traditional macroeconomic analysis.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:39:16.576279
af3aae430bbd5266,Can Voluntary Insurance ensure risk-free digital-banking in Chinese-economy: seeking attentions?,"In today’s business-world, services are carried out in a competitive manner country-wise such as China. Banking services are no different, which has resulted digital-banking. Bank Laws regulated by Central-Bank of China are characterized by evolving many factors that are often unpredictable. It faces serious pitfalls being it riskiness. Most cases, customers don’t read terms & conditions of services. Customers don’t save contract-copy. These weaknesses cause abuses. Customer faces perceived-risk. Dealing with challenges in Chinese-economy, application of Akim’s model - Voluntary Insurance (VI) can be impetus for policy-design, which can increase number of users. Welfare Analyses are used for guidance on setting insurance-price ensuring customer’s efficiency-cost so that the VI becomes appealing to parties involved. It can lead to higher number-of-users. In scenario, bank itself is an insurance-seller, the existence of adverse-selection is detected. Here estimated welfare-cost associated with inefficient-pricing created by adverse-selection is quantitatively small; however, advantageous-selection results opposite. Welfare assessment under alternative policy intervention in Chinese-economy will be vital for future-study.",,2022,10.1080/14765284.2021.1929792,,proquest,"This paper explores the potential of Voluntary Insurance (VI) to mitigate risks in China's digital banking sector. It discusses how VI, guided by Akim's model and welfare analyses, could encourage user adoption by addressing customer concerns about terms and conditions and perceived risks. The study also touches upon adverse and advantageous selection when banks act as insurance sellers, suggesting further policy interventions are needed.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:39:19.373124
b29c792181020dbb,Can climate change attention predict energy stock returns?,"We propose a climate change attention (CCA) index based on Google search volume index (GSVI) from 2004 to 2021 and show that it is an economically and statistically significant negative predictor for next month’s energy stock returns. The index is extracted using principal component analysis (PCA), but the results are similar by using the equal-weighted average method. Compared with 14 traditional macroeconomic predictors, CCA performs the best and provides complementary information when added into bivariate and multivariate macro predictive models. When further considering the effect of CCA’s forecasting power over different periods, strong evidence is shown that this outperformance is especially prominent in economic depressions and down market conditions. From the asset allocation perspective, CCA can provide a mean-variance investor with significant economic gains under alternative risk aversions. Our empirical results prove that investors’ attention to climate change contains predictive information for excess returns of global traditional energy stock index.",,2023,10.1007/s11356-023-28731-2,,proquest,"This study develops a climate change attention (CCA) index using Google search volume data from 2004-2021. The CCA index is found to be a significant negative predictor of future energy stock returns, outperforming traditional macroeconomic predictors, especially during economic downturns. The findings suggest that investor attention to climate change contains valuable predictive information for energy stock returns and can aid in asset allocation decisions.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:39:22.853298
1b5cd364557d4228,Can deep neural networks outperform Fama-MacBeth regression and other supervised learning approaches in stock returns prediction with asset-pricing factors?,"In asset pricing, most studies focus on finding new factors, such as macroeconomic factors or firm characteristics, to explain risk premiums. Investigating whether these factors help forecast stock returns remains active research in finance and computer science. This paper conducts an extensive comparative analysis using a large set of pricing factors. It compares out-of-sample stock-level and portfolio-level prediction performance among neural networks, the traditional Fama-MacBeth regression, and other supervised learning algorithms such as regression and tree-based algorithms. Our analysis shows the benefit of employing neural networks, and deeper neural networks enjoy marginal improvements in terms of prediction. © 2024 Elsevier B.V., All rights reserved.","Teng, H.-W.; Li, Y.-H.",2023,10.1007/s42521-023-00076-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207820403&doi=10.1007%2Fs42521-023-00076-y&partnerID=40&md5=06ef991afc31574f19f4f932a3174936,scopus,"This paper compares the stock return prediction performance of deep neural networks against traditional Fama-MacBeth regression and other supervised learning algorithms, using a large set of pricing factors. The study finds that neural networks, particularly deeper ones, offer marginal improvements in prediction accuracy.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:39:25.778500
38d168134a26a921,Can forward rates be used to improve interest rate forecasts?,"This paper evaluates the extent to which the explanatory power detected in the term structure in different markets and countries can actually be used to produce sensible forecasts of future short-term interest rates. Specifically, in spite of the forecasting connotation of the unbiasedness property of forward rates, actual evaluation of their forecasting performance has received scant attention in the literature on the term structure. This study uses monthly data for 1978-1998 on interest rates on Euro-deposits on the US dollar, yen, Deutsche mark, British pound, Spanish peseta, French franc, Italian lira and Swiss franc, comparing forecasts obtained from forward rates to those obtained from univariate autoregressions. By themselves, forward rates produce better one-step ahead forecasts, as well as better once-and-for all forecasts of 1-month interest rates over a full year horizon than those obtained from the own past of interest rates. The gain in one-step ahead forecasting disappears for longer maturities, although forward rates still produce better once-and-for all predictions of 3- and 6-month interest rates than univariate autoregressions for a number of currencies. © 2008 Elsevier B.V., All rights reserved.","Domínguez, E.; Novales, A.",2002,10.1080/09603100010007346,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036296125&doi=10.1080%2F09603100010007346&partnerID=40&md5=1ab9a64dfbdfbb88d297fb81367184c4,scopus,"This paper investigates whether forward rates can improve interest rate forecasts by comparing their performance against univariate autoregressions using monthly data from 1978-1998 for several currencies. The study finds that forward rates generally provide better one-step-ahead and one-and-for-all forecasts for short-term interest rates over a one-year horizon, although the advantage diminishes for longer maturities.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:39:35.582278
accc2a0866415987,Can gold or silver be used as a hedge against policy uncertainty and COVID-19 in the Chinese market?,"Purpose: The purpose of this study is to present evidence as to whether the use of gold or silver can be justified as an asset to hedge against policy uncertainty and COVID-19 in the Chinese market. Design/methodology/approach: By using a GARCH model with a generalized error distribution (GED), this study specifies that the gold (or silver) return is a function of a set of economic and uncertainty variables, which include volatility from interest rate innovation, a change in economic policy uncertainty (EPU), a change in geopolitical risk (GPR) and volatility due to pandemic diseases, while controlling for stock market returns, inflation rates, economic growth and the Chinese currency value. Findings: This study employs monthly data of gold and silver prices over the period from January 2002 to August 2021 to examine hedging behavior. Estimated results show that the gold return is positively correlated to the stock return and a rise in uncertainty from economic policy innovation, geopolitical risk, volatility due to US interest rate innovation as well as COVID-19 infection. This result suggests that gold cannot be used to hedge against a stock market decline, but can be used to hedge against uncertainty in general. However, the silver return only responds positively to a rise in uncertainty from the inflation rate and geopolitical risk. Evidence shows that silver returns are negatively correlated with stock returns, and display hedging characteristics. However, the evidence lacks statistically significance during the COVID-19 period, suggesting that the role of silver as a safe-haven asset against stock market turmoil is weak for this time period. Research limitations/implications: More general nonlinear specifications can be developed. The tests may include different measures of uncertainty that interact with each other or with the lagged error terms. An implication of the model is that gold can be used to hedge against a broad range of uncertainties for economic policy change, political risk and/or a pandemic. However, the use of gold as an asset to hedge against a stock downturn in Chinese market should be done with caution. Practical implications: This study has important policy implications as regards a choice in assets in formatting a portfolio to hedge against uncertainty. Specifically, this study presents empirical evidence on gold and silver return behavior and finds that gold returns respond positively to heightened uncertainty. Thus, gold is a good asset to hedge against uncertainty arising from policy innovations and infectious disease uncertainty. Social implications: This paper provides insightful information on the choice of assets toward hedging against risk in the uncertainty market conditions. It provides information to investors and policy makers to use gold price movements as a signal for detecting the arrival of uncertainty. This study also provides information for demanding a risk premium for infectious disease. Originality/value: This study empirically analyzes and verifies the role that gold serves as a safe haven asset to hedge against uncertainty in the Chinese market. This paper contributes to the literature by presenting evidence of risk/uncertainty premiums for holding gold against various sources of uncertainty such as economic policy uncertainty, geopolitical risk and equity market volatility due to US interest rate innovation and/or COVID-19. This study finds evidence that supports the use of a nonlinear specification, which demonstrates the interaction of uncertainty with the lagged change of infectious disease and helps to explain the gold/silver return behavior. Further, evidence shows that the gold return is positively correlated to the stock return. This finding contrasts with evidence in the US market. However, silver returns are negatively correlated with stock returns, but this correlation becomes insignificant during the period of COVID-19. © 2022 Elsevier B.V., All rights reserved.","Chiang, T.C.",2022,10.1108/cfri-12-2021-0232,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132296653&doi=10.1108%2FCFRI-12-2021-0232&partnerID=40&md5=4ea23791a60965a70d67bf3e4f586df2,scopus,"This study investigates whether gold or silver can serve as hedges against policy uncertainty and COVID-19 in the Chinese market using a GARCH model. Gold returns are positively correlated with stock returns and various uncertainties (economic policy, geopolitical risk, US interest rates, COVID-19), suggesting it hedges general uncertainty but not stock market declines. Silver returns are negatively correlated with stock returns and respond to inflation and geopolitical risk uncertainty, showing hedging characteristics, though this is weak during COVID-19. The findings imply gold is useful for hedging against broad uncertainties, but its use against stock downturns in China requires caution. The study highlights gold price movements as a potential signal for uncertainty and suggests a risk premium for infectious disease risk.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:39:38.670008
3e458c1ef4064bc0,Can investor attention predict oil prices?,"This paper sets out to investigate the predictive power of investor attention onto oil prices. We firstly construct investor attention index by using the Google search volume index (SVI) based on a broad set of words related to oil-related variables and terms that are directly linked to real economy to measure investor attention. Then the empirical work is performed via a novel hybrid approach and WN model (Westerlund and Narayan, 2012, 2014) that account for characteristics of persistency, endogeneity, and heteroskedasticity. The empirical results show that investor attention does exhibit statistically and economically significant in-sample and out-of-sample forecasting power to directly forecast oil prices for both daily data and weekly data. In addition, the results exhibit the term structure character, which are helpful for understanding the financial phenomena that irrational attentions have more effect in short-term decision-making. © 2017 Elsevier B.V., All rights reserved.","Han, L.; Lv, Q.; Yin, L.",2017,10.1016/j.eneco.2017.04.018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019673191&doi=10.1016%2Fj.eneco.2017.04.018&partnerID=40&md5=ca9f86fe67dec0c5b3eeae9ad04a2a64,scopus,"This paper investigates the predictive power of investor attention on oil prices using a Google search volume index to construct an investor attention index. It employs a hybrid approach and the WN model to account for persistency, endogeneity, and heteroskedasticity, finding statistically and economically significant in-sample and out-of-sample forecasting power for oil prices. The results also suggest that irrational attention has a greater effect on short-term decision-making.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:39:42.812157
81bda8db83234614,Can investors attention on oil markets predict stock returns?,"This paper sets out to explore the predictability of the U.S. equity risk premium directly based on investor attention to oil. We find that the predictive power of oil attention exhibits statistical and economic significance within different models in both in-sample and out-of-sample tests. Meanwhile, oil attention reveals considerable and robust economic value for asset allocation in the sense of positive utility gains. Furthermore, supportive evidence that oil attention is closely linked to stock market volatility endues it with a macroeconomic meaning, serving as an explanation for its predictive power. Overall, investor attention to oil does have a direct predictive power to forecast the U.S. stock excess returns. © 2019 Elsevier B.V., All rights reserved.","Yin, L.; Feng, J.",2019,10.1016/j.najef.2018.08.017,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052227023&doi=10.1016%2Fj.najef.2018.08.017&partnerID=40&md5=571887a6f6c671ca6e8211b013cc00c9,scopus,"This paper investigates whether investor attention to oil markets can predict U.S. stock returns. The findings indicate that oil attention has statistically and economically significant predictive power for the U.S. equity risk premium, demonstrated through various models and tests. The study also suggests that oil attention is linked to stock market volatility, providing a macroeconomic explanation for its predictive ability and offering economic value for asset allocation.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:39:44.492151
9d7c4c949713cefa,Can the Sharia-based Islamic Stock Market returns be forecasted using large number of predictors and models?,"This study employs 14 global economic and financial variables to predict the return of the Islamic stock market as identified by the Dow Jones Islamic Stock Market (DJIM). It implements alternative forecasting methods and allows for nonlinearity in the multivariate predictive regressions by estimating time-varying parameter models. All the methods fail to forecast the returns of the Sharia-based DJIM index over the out- of-sample period. The forecasts are weak at best, with only four predictors, the 3-month Treasury bill rate, inflation, oil price and return on the SandP500 Index, outperforming the benchmark autoregressive model of order one. The study suggests that the DJIM return is best predicted by an autocorrelation(1) model, and that future research should aim at analysing whether the performance of the linear autoregressive model can be improved by using nonlinear methods. Reprinted by permission of Routledge, Taylor and Francis Ltd.",,2014,10.1080/09603107.2014.924296,,proquest,"This study investigates the predictability of the Sharia-based Dow Jones Islamic Stock Market (DJIM) returns using 14 global economic and financial variables and various forecasting methods, including time-varying parameter models to account for nonlinearity. The findings indicate that most methods fail to forecast DJIM returns out-of-sample, with only a few predictors showing marginal improvement over a simple autoregressive model. The study concludes that an autocorrelation(1) model best predicts DJIM returns and suggests exploring nonlinear methods for future research.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:39:59.177550
d47ebdc5ea5914d1,Carbon risk and return prediction: Evidence from the multi-CNN method,"This paper investigates the carbon risk and its role in stocks’ return prediction by identifying the carbon risk information implied in feature engineering. We predict the stock returns with different neural networks, construct the investment portfolio according to the predicted returns and reflect the returns of stocks with different carbon risks through the relevant evaluation of the investment portfolio. Our Multi-CNN method can best collect information on different relationship types and make full use of graph structure data to identify carbon risks. With or without carbon factor, the stock market performance of high-carbon industry is better than that of medium-carbon industry, and the performance of low-carbon industry is the worst. Moreover, our finding is consistent in both Chinese and American markets. Investment should pay attention to carbon risk and requires corresponding carbon risk premium. © 2022 Elsevier B.V., All rights reserved.","Tang, J.; Li, J.",2022,10.3389/fenvs.2022.1035809,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142006137&doi=10.3389%2Ffenvs.2022.1035809&partnerID=40&md5=6eecf37eb1d8a397e2c08fbd38faa6c7,scopus,"This paper uses a Multi-CNN method to identify carbon risk information and predict stock returns. The study finds that high-carbon industries perform better than low-carbon industries, and suggests that investment should consider carbon risk and its associated premium. The findings are consistent across Chinese and American markets.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:40:01.013159
98032144cda08a39,Central Bank Transparency and Interest Rate Volatility,"Most central banks around the world have increased their transparency in recent decades. These developments have had an impact on financial markets. Several studies have analysed the impact of central bank transparency (CBT) on variables such as inflation volatility, exchange rate volatility, or stock market volatility. One variable that has not received enough attention is interest rate volatility, despite its importance for decision-makers in both financial markets and the real economy. The study uses a panel data set of a maximum of 93 countries over the years 1998–2017. We use panel data estimators (panel fixed effects and fixed effects filter). Our main findings are that CBT helps to reduce the volatility of several interest rates (money market rates, deposit rates, savings rates, Treasury bill yields and government bond yields), while it increases the volatility of monetary policy rates. The results are also significant from an economic point of view, as a small increase in CBT can reduce the variability of treasury bill rates by up to −8.2%, deposit rates by up to −9.1%, money market rates by up to −15.8% and savings rates by up to −20.4%. © 2024 Elsevier B.V., All rights reserved.","Weber, C.S.",2024,10.1002/ijfe.3072,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212859950&doi=10.1002%2Fijfe.3072&partnerID=40&md5=709d6898cc2a2cb5f01e3dd2e10c9f3a,scopus,"This study investigates the impact of central bank transparency (CBT) on interest rate volatility using panel data from up to 93 countries between 1998 and 2017. The findings indicate that increased CBT reduces the volatility of various interest rates, including money market rates, deposit rates, savings rates, Treasury bill yields, and government bond yields. However, it paradoxically increases the volatility of monetary policy rates. The study highlights the significant economic implications of these findings, showing that even small increases in CBT can lead to substantial reductions in the variability of several key interest rates.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:40:02.635438
218b2b4f103b094a,Challenges in macro-finance modeling,"This article discusses various challenges in the specification and implementation of ""macrofinance"" models in which macroeconomic variables and term structure variables are modeled together in a no-arbitrage framework. The author classifies macro-finance models into pure latent factor models (""internal basis models"") and models that have observed macroeconomic variables as state variables (""external basis models"") and examines the underlying assumptions behind these models. Particular attention is paid to the issue of unspanned short-run fluctuations in macroeconomic variables and their potentially adverse effect on the specification of external basis models. The author also discusses the challenge of addressing features such as structural breaks and timevarying inflation uncertainty. Empirical difficulties in the estimation and evaluation of macrofinance models are also discussed in detail. © 2009, The Federal Reserve Bank of St. Louis. © 2020 Elsevier B.V., All rights reserved.","Kim, D.H.",2009,10.20955/r.91.519-544,https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350561910&doi=10.20955%2Fr.91.519-544&partnerID=40&md5=c0fb7fe87ee07e159e0eeb472a1beb2c,scopus,"This article reviews challenges in macro-finance modeling, distinguishing between internal and external basis models. It highlights issues like unspanned short-run fluctuations, structural breaks, time-varying inflation uncertainty, and empirical estimation difficulties.",False,True,False,gemini-2.5-flash-lite,Ulrik,M,,2025-10-13T15:40:22.458869
6e02db71875332a7,China University Online Public Opinion Risk Dataset,"With the widespread popularity of social software and self-media, online public opinion incidents in colleges and universities occur frequently and present a complicated situation. In the big data era, university students have gained a more relaxed environment in which to receive and disseminate public opinion information, enabling them to spread their opinions and insights to the Internet more rapidly, thus exacerbating the riskiness of public opinion information dissemination. We constructed CUOPO, the first risk classification dataset of China university online public opinion, and screened out 10,255 representative public opinion texts from a large number of university online public opinion information, including 3,641 risk-free and 6,614 risky texts. These risky texts cover many fields, including 1,755 college livelihood risk texts, 767 campus safety risk texts, 1,395 school order risk texts, 906 university reputation risk texts, and 1,793 advertisement risk texts. The dataset contains various information about each network opinion, including authentic labels, text information, time information, and network information. Through an in-depth study of CUOPO, we found that universities have significant risk issues in the areas of livelihood, safety, teaching order, reputation, and advertisement diversion, which require great attention from university administrators. To validate the effectiveness of the CUOPO, we conduct extensive experiments on the dataset using a series of neural network methods to provide benchmark results for predicting online public opinion risk texts. We expect that CUOPO can provide strong data support for the study of the types of online public opinion risks in colleges and universities and thus play a positive role in promoting the progress of college and university public opinion research. The dataset is available at https://github.com/TianShengLee98/CUOPO-Dataset.",S. Wang; T. Li; X. Shen; H. Zhao,2024,10.1109/access.2024.3389974,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10501775,ieeexplore,"This paper introduces CUOPO, the first dataset for classifying online public opinion risks in Chinese universities. It contains 10,255 texts categorized as risk-free or risky, with risky texts further classified into livelihood, safety, order, reputation, and advertisement risks. The dataset includes labels, text, time, and network information. Experiments using neural networks validate the dataset's effectiveness for predicting public opinion risks, highlighting significant risk areas for university administrators.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:40:24.662825
1c852fb6a398bfae,Climate response uncertainty and the benefits of greenhouse gas emissions reductions,"Some recent research suggests that uncertainty about the response of the climate system to atmospheric greenhouse gas concentrations can have a disproportionately large influence on benefits estimates for climate change policies, potentially even dominating the effect of the discount rate. In this paper we conduct a series of numerical simulation experiments to investigate the quantitative significance of climate response uncertainty for economic assessments of climate change. First we characterize climate uncertainty by constructing two probability density functions-a Bayesian model-averaged and a Bayesian updated version-based on a combination of uncertainty ranges for climate sensitivity reported in the scientific literature. Next we estimate the willingness to pay of a representative agent for a range of emissions reduction policies using two simplified economic models. Our results illustrate the potential for large risk premiums in benefits estimates as suggested by the recent theoretical work on climate response uncertainty, and they show that the size and even the sign of the risk premium may depend crucially on how the posterior distribution describing the overall climate sensitivity uncertainty is constructed and on the specific shape of the damage function. © United States Environmental Protection Agency 2009. © 2017 Elsevier B.V., All rights reserved.","Newbold, S.C.; Daigneault, A.",2009,10.1007/s10640-009-9290-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-76149142167&doi=10.1007%2Fs10640-009-9290-8&partnerID=40&md5=c5d868d8ee46f868b523eb5a8baa76b1,scopus,"This paper investigates the impact of climate response uncertainty on the economic benefits of greenhouse gas emissions reductions. Using numerical simulations and probability density functions for climate sensitivity, the study estimates the willingness to pay for emissions reduction policies. Results indicate that uncertainty in climate response can lead to significant risk premiums in benefits estimates, which are sensitive to the construction of the climate sensitivity distribution and the shape of the damage function.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:40:26.822616
1aca9ba06a07d5ec,"Climate, race, and the cost of capital in the municipal bond market","Both climate risk and race are factors that may affect municipal bond yields, yet each has received relatively limited empirical research attention. We analyzed > 712,000 municipal bonds representing nearly 2 trillion USD in par outstanding, focusing on credit spread or the difference between a debt issuer's interest cost to borrow and a benchmark ""risk-free"" municipal rate. The relationship between credit spread and physical climate risk is significant and slightly positive, yet the coefficient indicates no meaningful spread penalty for increased physical climate risk. We also find that racial composition (the percent of a community that is Black) explains a statistically significant and meaningful portion of municipal credit spreads, even after controlling for a variety of variables in domains such as geographic location of issuer, bond structure (e.g., bond maturity), credit rating, and non-race economic variables (e.g., per capita income). Assuming 4 trillion USD in annual outstanding par across the entire municipal market, and weighting each issuer by its percent Black, an estimated 19 basis point (bp) penalty for Black Americans sums to approximately 900 million USD annually in aggregate. Our combined findings indicate a systemic mispricing of risk in the municipal bond market, where race impacts the cost of capital, and climate does not.Both climate risk and race are factors that may affect municipal bond yields, yet each has received relatively limited empirical research attention. We analyzed > 712,000 municipal bonds representing nearly 2 trillion USD in par outstanding, focusing on credit spread or the difference between a debt issuer's interest cost to borrow and a benchmark ""risk-free"" municipal rate. The relationship between credit spread and physical climate risk is significant and slightly positive, yet the coefficient indicates no meaningful spread penalty for increased physical climate risk. We also find that racial composition (the percent of a community that is Black) explains a statistically significant and meaningful portion of municipal credit spreads, even after controlling for a variety of variables in domains such as geographic location of issuer, bond structure (e.g., bond maturity), credit rating, and non-race economic variables (e.g., per capita income). Assuming 4 trillion USD in annual outstanding par across the entire municipal market, and weighting each issuer by its percent Black, an estimated 19 basis point (bp) penalty for Black Americans sums to approximately 900 million USD annually in aggregate. Our combined findings indicate a systemic mispricing of risk in the municipal bond market, where race impacts the cost of capital, and climate does not.",,2023,10.1371/journal.pone.0288979,,proquest,"This study analyzes over 712,000 municipal bonds to investigate the impact of climate risk and race on municipal bond yields. While climate risk shows a statistically significant but not meaningfully impactful relationship with credit spreads, the racial composition of a community (specifically the percentage of Black residents) significantly affects credit spreads, even after controlling for various economic and structural factors. The findings suggest a systemic mispricing of risk in the municipal bond market, where race influences the cost of capital, but climate risk does not.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:40:28.623235
d38268c443f9bed1,Climate-sensitive hydrological drought insurance for irrigated agriculture under deep uncertainty. Insightful results from the Cega River Basin in Spain,"This paper assesses the feasibility and robustness of an index-based insurance scheme against hydrological droughts under climate change. To this end, we develop a grand ensemble that samples both modeling and scenario uncertainty in the estimation of the insurance risk premium, so to reveal potential unfavorable surprises and minimize regret in the design of the proposed insurance scheme. The grand ensemble combines four microeconomic models and seven GAMLSS models, which are run for three alternative climate change scenarios: stationary climate/no climate change, RCP 2.6, and RCP 8.5. Methods are illustrated with an application to the Cega River Sub-basin (CRS) in central Spain. Results indicate that for a conventional deductible of 30%, the proposed index-based insurance scheme would be actuarially feasible and affordable under all models for the stationary climate scenario (i.e., robust). For climate change scenarios RCP 2.6 and 8.5 and a 30% deductible, the suggested index-based insurance would be actuarially feasible under most models, albeit some outliers point towards potential unfavorable surprises. Lower deductibles decrease feasibility, particularly for deductibles <10%.",,2022,10.1016/j.agwat.2022.107938,,proquest,"This paper evaluates an index-based insurance scheme for irrigated agriculture against hydrological droughts, considering climate change uncertainty. Using a comprehensive ensemble of microeconomic and GAMLSS models under various climate scenarios (stationary, RCP 2.6, RCP 8.5), the study finds the insurance to be feasible and affordable for a 30% deductible under a stationary climate. For climate change scenarios, it remains feasible for most models, though some outliers suggest potential risks, especially with deductibles below 10%.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:40:33.011280
9cb31eeb7dae5c0a,"Closed-Form Expansion, Conditional Expectation, and Option Valuation","Enlightened by the theory of Watanabe [Watanabe S (1987) Analysis of Wiener functionals (Malliavin calculus) and its applications to heat kernels. Ann. Probab. 15:1-39] for analyzing generalized random variables and its further development in Yoshida [Yoshida N (1992a) Asymptotic expansions for statistics related to small diffusions. J. Japan Statist. Soc. 22: 139-159], Takahashi [Takahashi A (1995) Essays on the valuation problems of contingent claims. Ph.D. thesis, Haas School of Business, University of California, Berkeley, Takahashi A (1999) An asymptotic expansion approach to pricing contingent claims. Asia-Pacific Financial Markets 6:115-151] as well as Kunitomo and Takahashi [Kunitomo N, Takahashi A (2001) The asymptotic expansion approach to the valuation of interest rate contingent claims. Math. Finance 11(1):117-151, Kunitomo N, Takahashi A (2003) On validity of the asymptotic expansion approach in contingent claim analysis. Ann. Appl. Probab. 13(3):914-952] etc., we focus on a wide range of multivariate diffusion models and propose a general probabilistic method of small-time asymptotic expansions for approximating option price in simple closed-form up to an arbitrary order. To explicitly construct correction terms, we introduce an efficient algorithm and novel closed-form formulas for calculating conditional expectation of multiplication of iterated stochastic integrals, which are potentially useful in a wider range of topics in applied probability and stochastic modeling for operations research. The performance of our method is illustrated through various models nested in constant elasticity of variance type processes. With an application in pricing options on VIX under GARCH diffusion and its multifactor generalization to the Gatheral double lognormal stochastic volatility models, we demonstrate the versatility of our method in dealing with analytically intractable non-Levy and non-affine models. The robustness of the method is theoretically supported by justifying uniform convergence of the expansion over the whole set of parameters.","Li, Chenxu",2014,10.1287/moor.2013.0613,,wos,"This paper proposes a general probabilistic method for approximating option prices using small-time asymptotic expansions, applicable to multivariate diffusion models. It introduces an algorithm and closed-form formulas for conditional expectations of iterated stochastic integrals, demonstrating its use in various models, including options on VIX under GARCH diffusion and double lognormal stochastic volatility models. The method's robustness is theoretically supported by uniform convergence.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:40:35.651032
c5534bf69e592d8c,Combined DEMATEL technique with a novel MCDM model for exploring portfolio selection based on CAPM,"This research proposes a novel MCDM model, including DEMATEL, ANP, and VIKOR for exploring portfolio selection based on CAPM. We probe into the influential factors and relative weights of risk-free rate, expected market return, and beta of the security. The purpose of this research is to establish an investment decision model and provides investors with a reference of portfolio selection most suitable for investing effects to achieve the greatest returns. Taking full consideration of the interrelation effects among criteria/variables of the decision model, this paper examined leading semiconductor companies spanning the hottest sectors of integrated circuit (IC) design, wafer foundry, and IC packaging by experts. Empirical findings revealed that risk-free rate was affected by budget deficit, discount rate, and exchange rate; expected market return was affected by country risk, industrial structure, and macroeconomic factors; and beta of the security was affected by firm-specific risk and financial risk. Also, the factors of the CAPM possessed a self-effect relationship according to the DEMATEL technique. In the eight evaluation criteria, macroeconomic criterion was the most important factor affecting investment decisions, followed by exchange rate and firm-specific risk. In portfolio selection, leading companies in the wafer foundry industry outperformed those in IC design and IC packaging, becoming the optimal portfolio of investors during the time that this study was conducted. (C) 2010 Elsevier Ltd. All rights reserved.","Ho, Wen-Rong Jerry; Tsai, Chih-Lung; Tzeng, Gwo-Hshiung; Fang, Sheng-Kai",2011,10.1016/j.eswa.2010.05.058,,wos,"This research introduces a new MCDM model combining DEMATEL, ANP, and VIKOR for portfolio selection based on CAPM. It analyzes the influence of risk-free rate, expected market return, and security beta, considering interrelations among criteria. The study uses expert evaluations of semiconductor companies and finds that macroeconomic factors, exchange rates, and firm-specific risk are key. The wafer foundry industry emerged as the optimal portfolio choice.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:40:37.337743
2fff7c85c30fc367,Comparing forecasting ability of parametric and non-parametric methods: An applications with Canadian monthly interest rates,"The primary objective of this article is to compare the forecasting ability of some recent parametric and non-parametric estimation methods by using monthly Canadian interest rate data between 1964:1-1999:1. The two-factor continous time term structure model of Brennan and Schwartz was estimated where the first factor represents the short rate and the second factor the long rate using the continuous time estimation procedures developed by Bergstrom. The interest rates using the multi-variate GARCH model developed by Engle and Kroner, and two non-parametric estimation methods namely, non-parametric kernel smoothing and the artificial neural networks was modelled. For the short-term rates, it has been found that, the Bergstrom's method and the artificial neural networks model have marginally better forecasting performance than that of the linear benchmark. For the long-term rates, none of the methods produced better forecasting precision than that of the benchmark. © 2004 Elsevier Science B.V., Amsterdam. All rights reserved.","Saltoǧlu, B.",2003,10.1080/09603100110111259,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037359312&doi=10.1080%2F09603100110111259&partnerID=40&md5=0d62d541ef5b9a7cbdf61bb322a0b625,scopus,"This article compares the forecasting ability of parametric (Brennan and Schwartz, multi-variate GARCH) and non-parametric (kernel smoothing, artificial neural networks) methods using Canadian monthly interest rate data from 1964 to 1999. For short-term rates, the Brennan and Schwartz method and artificial neural networks showed slightly better forecasting performance than a linear benchmark. For long-term rates, no method outperformed the benchmark.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T15:41:00.087210
435757a2aac6a115,Computer-aided resilience: Advanced techniques for disaster management in smart urban environments,"This research paper explores innovative contributions to the field of disaster management in smart urban environments, with a particular focus on integrating advanced computer-aided techniques, specifically GRU-CNN. Three key contributions are highlighted: (1) the development of dynamic risk assessment algorithms utilizing GRU-CNN for real-time analysis and predictive modeling, enabling proactive disaster mitigation; (2) the establishment of an integrated sensor network infrastructure for early warning systems, leveraging various sensors and GRU-CNN-based data analytics to detect and respond to potential disasters at their nascent stages; and (3) the implementation of human-centric resilience planning, utilizing GRU-CNN-based computer-aided tools to simulate disaster scenarios and engage communities in preparedness efforts. The dynamic risk assessment algorithms presented in this paper, powered by GRU-CNN, enable continuous monitoring and analysis of diverse data sources, fostering a proactive approach to disaster preparedness. The integrated sensor network architecture enhances early warning capabilities, allowing for timely responses to emerging threats through the application of GRU-CNN methodologies. Furthermore, the human-centric resilience planning approach introduces virtual simulations using GRU-CNN to model disaster scenarios, facilitating the testing and refinement of strategies in a risk-free environment. This approach not only ensures the adaptability of plans but also engages and educates communities, fostering a culture of preparedness, with GRU-CNN playing a pivotal role in the process. Through these contributions, this research paper seeks to advance the discourse on disaster management in smart urban environments, emphasizing the integration and effectiveness of GRU-CNN in enhancing resilience and response strategies. By leveraging cutting-edge GRU-CNN technologies and prioritizing community involvement, the proposed techniques aim to provide a more robust and adaptive response to the challenges posed by natural and man-made disasters in urban settings. © 2024 Elsevier B.V., All rights reserved.","Li, R.; Di, Y.; Tian, H.",2024,10.1016/j.scs.2024.105437,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192164396&doi=10.1016%2Fj.scs.2024.105437&partnerID=40&md5=5501812a88b27a6182b0b861baf448f2,scopus,"This paper presents advanced computer-aided techniques, specifically GRU-CNN, for disaster management in smart urban environments. It details three contributions: dynamic risk assessment algorithms for real-time analysis and prediction, an integrated sensor network for early warning systems using GRU-CNN data analytics, and human-centric resilience planning with GRU-CNN tools for scenario simulation and community engagement. The research aims to enhance urban resilience and response strategies through these GRU-CNN-powered methods.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:41:05.351492
d55b2643487b31d3,Computing Arbitrage-Free Yields in Multi-Factor Gaussian Shadow Rate Term Structure Models,"This paper develops an approximation to arbitrage-free bond yields in Gaussian shadow rate term structure models. In this class of models, yields are constrained to be above an effective lower bound, thus rendering standard bond pricing methods inapplicable. I propose approximating the nonlinear relationship between yields and state variables using moments of the censored normal distribution. In an empirical application, this approximation technique is accurate to within a fraction of a basis point. As I show, minimizing the yield approximation error is crucial for model estimation as even seemingly small errors can lead to economically meaningful inference biases. © 2024 Elsevier B.V., All rights reserved.","Priebsch, M.A.",2023,10.1142/s2010139223500131,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181668998&doi=10.1142%2FS2010139223500131&partnerID=40&md5=fcef3acf1d58d664f9d560482b5d0465,scopus,"This paper presents an approximation method for calculating arbitrage-free bond yields within Gaussian shadow rate term structure models. These models impose a lower bound on yields, necessitating a novel approach. The authors use moments of the censored normal distribution to approximate the nonlinear yield-state variable relationship, demonstrating its accuracy in an empirical test and highlighting the importance of minimizing approximation errors to avoid inference biases.",False,True,False,gemini-2.5-flash-lite,Ulrik,M,,2025-10-13T15:41:26.584643
8126b048e769df74,Condition Prediction for Existing Educational Facilities Using Artificial Neural Networks and Regression Analysis,"Infrastructural assets such as roads, bridges, and buildings make a considerable contribution to national economies. These assets deteriorate due to aging, environmental conditions, and other external factors. Maintaining the performance of an asset in line with rational repair strategies represents a considerable challenge for decision-makers, who may not pay attention to developing adequate maintenance plans or leave the assets unmaintained. Worldwide, organizations are under pressure to ensure the sustainability of their assets. Such organizations may burden their treasury with random maintenance operations, especially with a limited budget. This research aims to develop a generalized condition assessment approach to monitor and evaluate existing facility elements. The proposed approach represents a methodology to determine the element condition index (CI). The methodology is reinforced with an artificial neural network (ANN) model to predict the element deterioration. The performance of this model was evaluated by comparing the obtained predicted CIs with ordinary least squares (OLS) regression model results to choose the most accurate prediction technique. A case study was applied to a group of wooden doors. The ANN model showed reliable results with R2 values of 0.99, 0.98, and 0.99 for training, cross-validation, and testing sets, respectively. In contrast, the OLS model R2 value was 1.00. These results show the high prediction capability of both models with an advantage to the OLS model. Applying this approach to different elements can help decision-makers develop a preventive maintenance schedule and provide the necessary funds.",,2022,10.3390/buildings12101520,,proquest,"This research proposes a generalized condition assessment approach for existing educational facilities, using Artificial Neural Networks (ANN) and Ordinary Least Squares (OLS) regression to predict element deterioration and calculate a Condition Index (CI). The ANN model demonstrated high accuracy (R2 values of 0.99 for training, cross-validation, and testing), while the OLS model achieved an R2 of 1.00, indicating a slight advantage for OLS in this case study involving wooden doors. The approach aims to aid decision-makers in developing preventive maintenance schedules and allocating funds.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:41:32.406227
466b8b36926ebb9e,Connectedness network and dependence structure mechanism in green investments,"We present an empirical study of renewable energy stock returns and their relation to four major investment asset classes—stocks, currency, US Treasury bonds, and oil—and several sources of uncertainty. Applying nonlinear causality and connectedness network analysis on data covering the period 2004–2016, we investigate the directionality and connectedness among different asset classes, as well as between uncertainties. First, from the results of the estimation of directionality and network spillovers, it can be concluded that the European stock market has a strong market dependence on renewable energy stock prices. Second, uncertainties have an economically significant impact on both return and volatility spillover in energy investments. Third, most of the uncertainties are net transmitters of volatility connectedness during the global financial crisis (GFC) and European sovereign debt crisis (ESDC). © 2018 Elsevier B.V., All rights reserved.","Lundgren, A.I.; Milicevic, A.; Uddin, G.S.; Kang, S.H.",2018,10.1016/j.eneco.2018.04.015,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045660578&doi=10.1016%2Fj.eneco.2018.04.015&partnerID=40&md5=b1c26dcdb123c802a3c779b455053326,scopus,"This empirical study analyzes the connectedness network and dependence structure of renewable energy stock returns in relation to stocks, currency, US Treasury bonds, and oil, as well as various uncertainty sources. Using nonlinear causality and connectedness network analysis from 2004-2016, the study found that the European stock market is highly dependent on renewable energy stock prices. Uncertainties significantly impact return and volatility spillovers in energy investments, with most uncertainties acting as net transmitters of volatility during the GFC and ESDC.",True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:41:52.480483
66ceac4ab63fecab,Constant Proportion Portfolio Insurance Strategy in Southeast European Markets,"Background: In today's highly volatile and unpredictable market conditions, there are very few investment strategies that may offer a certain form of capital protection. The concept of portfolio insurance strategies presents an attractive investment opportunity.Objectives: The main objective of this article is to test the use of portfolio insurance strategies in Southeast European (SEE) markets. A special attention is given to modelling non-risky assets of the portfolio.Methods/Approach: Monte Carlo simulations are used to test the buy-and-hold, the constant-mix, and the constant proportion portfolio insurance (CPPI) investment strategies. A covariance discretization method is used for parameter estimation of bond returns.Results: According to the risk-adjusted return, a conservative constant mix was the best, the buy-and-hold was the second-best, and the CPPI the worst strategy in bull markets. In bear markets, the CPPI was the best in a high-volatility scenario, whereas the buy-and-hold had the same results in low- and medium-volatility conditions. In no-trend markets, the buy-and-hold was the first, the constant mix the second, and the CPPI the worst strategy. Higher transaction costs in SEE influence the efficiency of the CPPI strategy.Conclusions: Implementing the CPPI strategy in SEE could be done by combining stock markets from the region with government bond markets from Germany due to a lack of liquidity of the government bond market in SEE.",,2016,10.1515/bsrj-2016-0005,,proquest,"This article evaluates the Constant Proportion Portfolio Insurance (CPPI) strategy, along with buy-and-hold and constant-mix strategies, in Southeast European (SEE) markets using Monte Carlo simulations. It found that strategy performance varied significantly with market conditions (bull, bear, no-trend) and volatility. The study suggests that higher transaction costs in SEE markets impact CPPI efficiency and proposes combining SEE stock markets with German government bonds due to liquidity issues in SEE bond markets.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:41:56.323384
d4beb98aa69b728a,"Consumption, aggregate wealth and expected stock returns: a quantile cointegration approach","This paper empirically examines the long-run relationship between consumption, asset wealth and labor income (i.e., cay) in the United States through the lens of a quantile cointegration approach. The advantage of using this approach is that it allows for a nonlinear relationship between these variables depending on the level of consumption. We estimate the coefficients using a Phillips–Hansen type fully modified quantile estimator to correct for the presence of endogeneity in the cointegrating relationship. To test for the null of cointegration at each quantile, we apply a quantile CUSUM test. Results show that: (i) consumption is more sensitive to changes in labor income than to changes in asset wealth for the entire distribution of consumption, (ii) the elasticity of consumption with respect to labor income (asset wealth) is larger at the right (left) tail of the consumption distribution than at the left (right) tail, (iii) the series are cointegrated around the median, but not in the tails of the distribution of consumption, (iv) using the estimated cay obtained for the right (left) tail of the distribution of consumption improves the long-run (short-run) forecast ability on real excess stock returns over a risk-free rate.",,2022,10.1515/snde-2020-0059,,proquest,"This paper investigates the long-run relationship between consumption, aggregate wealth, and labor income using a quantile cointegration approach. It finds that consumption is more sensitive to labor income than asset wealth, with varying elasticities across the consumption distribution. Cointegration is observed around the median but not in the tails. The study also suggests that using estimated consumption-income ratios from different tails can improve long-run or short-run forecasts of real excess stock returns.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:41:59.382857
6ff1318102cc0b35,Corporate relation extraction for the construction of knowledge-bases against tax fraud,"Tax fraud is a criminal activity that entails significant losses for governments. Due to its clandestine nature, it is difficult to reliably estimate the amount of taxes evaded. To fight tax fraud, this investigation details the construction and evaluation of a corporate relation extraction system designed to access an unstructured knowledge-base and extract corporate relations for further validation. The system was developed in response to a need raised by the Treasury and Finance Department of the Provincial Council of Gipuzkoa (Spain). It follows a waterfall architecture that integrates Natural Language Processing (NLP) and Computer Vision (CV) components, including web scraping, optical character recognition, syntactic parsing, and information extraction. The proposed system produces a relational knowledge-base with structured data representing 23 types of corporate operations published in the Official Gazette of the Commercial Registry (e.g., incorporation of companies, terminations, capital increases and reductions, mergers and takeovers, etc.), allowing for comparison with the fiscal information available in the tax agency. Facilitating such comparison across distinct sources is key to identifying discrepancies that might be indicators of tax fraud. © 2025 Elsevier B.V., All rights reserved.","Lopez-Gazpio, I.; Baselga-Pascual, L.; Garmendia-Lazcano, A.",2025,10.1016/j.knosys.2025.113026,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215966196&doi=10.1016%2Fj.knosys.2025.113026&partnerID=40&md5=7d2cbcf4fc0162b01f57c357e1ef6ac4,scopus,"This paper describes the development and evaluation of a corporate relation extraction system to build a knowledge base for detecting tax fraud. The system integrates NLP and CV techniques to process unstructured data from official gazettes, extracting 23 types of corporate operations. This structured data can then be compared with fiscal information to identify potential tax evasion.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:42:01.746278
e5a46baf011f5c8b,Corrigendum: Bond Risk Premiums with Machine Learning,"In this note we revisit the empirical results in Bianchi, Büchner, and Tamoni (2020) after correcting for using information not available at the time the forecast was made. Although we note a decrease in out-of-sample $R^2$, the revised analysis confirms that bond excess return predictability from neural networks remains statistically and economically significant.",,2021,10.1093/rfs/hhaa098,,proquest,"This corrigendum revisits empirical results on bond risk premiums, correcting for look-ahead bias. The revised analysis confirms that neural networks significantly predict bond excess returns, despite a decrease in out-of-sample R-squared.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T15:42:13.805218
1f799a63b4ffb64c,Credibilistic risk aversion,"In the probabilistic risk aversion approach, risks are presumed as random variables with known probability distributions. However, in some practical cases, for example, due to the absence of historical data, the inherent uncertain characteristic of risks or different subject judgements from the decision-makers, risks may be hard or not appropriate to be estimated with probability distributions. Therefore, the traditional probabilistic risk aversion theory is ineffective. Thus, in order to deal with these cases, we suggest measuring these kinds of risks as fuzzy variables, and accordingly to present an alternative risk aversion approach by employing credibility theory. In the present paper, first, the definition of credibilistic risk premium proposed by Georgescu and Kinnunen [Fuzzy Inf. Eng., 2013, 5, 399–416] is revised by taking the initial wealth into consideration, and then a general method to compute the credibilistic risk premium is provided. Secondly, regarding the risks represented with the commonly used LR fuzzy intervals, a simple calculation formula of the local credibilistic risk premium is put forward. Finally, in a global sense, several equivalent propositions for comparative risk aversion under the credibility measurement are provided. Illustrated examples are presented to show the applicability of the theoretical findings. © 2017 Elsevier B.V., All rights reserved.","Liu, Y.; Zhou, J.; Pantelous, A.A.",2017,10.1080/14697688.2016.1264617,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008225393&doi=10.1080%2F14697688.2016.1264617&partnerID=40&md5=553152a688730680f0ca8955b348c249,scopus,"This paper proposes an alternative risk aversion approach using credibility theory to measure risks represented as fuzzy variables, addressing limitations of traditional probabilistic risk aversion when probability distributions are unknown or inappropriate. It revises the definition of credibilistic risk premium, provides a general method for its computation, and offers a simple formula for LR fuzzy intervals. The paper also presents equivalent propositions for comparative risk aversion under credibility measurement and includes illustrative examples.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:42:17.540713
af087fe826b75cd4,Credit Pit Detection in Subordinate Securities: A French Perspective,"The purpose of this research is to prepare a predictive model for identifying credit crisis using an artificial neural network. The paper also aims to find out the driver and driven relationship between various financial instruments like CDS, FRA, IRS, and the Volatility index (VCAC) and government securities for France. The model, thus, is directed towards finding a threshold for credit pit events and linking various events corresponding to that dates where the threshold is breached to validate the accuracy and usefulness of the model. From the research, it is found that for France, the CDS-FRA-VCAC model derives the threshold for VCAC to indicate the probability of credit crisis or financial market crash. It is also found that sovereign bonds have a huge impact on France economy including various derivatives. This is probably why the Eurozone debt crisis impacted France much more than the 2008 financial crash.",,2019,10.12725/ujbm.48.6,,proquest,"This study develops a predictive model using artificial neural networks to identify credit crises in French subordinate securities. It investigates the relationships between financial instruments like CDS, FRA, IRS, and the Volatility Index (VCAC) with government securities. The model aims to establish a threshold for credit pit events and links these events to breaches of the threshold. Findings indicate that the CDS-FRA-VCAC model can predict credit crises or market crashes in France, with sovereign bonds significantly impacting the French economy, explaining the greater impact of the Eurozone debt crisis compared to the 2008 financial crash.",True,True,True,gemini-2.5-flash-lite,Ulrik,M,Probably N,2025-10-13T15:42:37.822074
14c53eff72879cd2,Cross-predictability of industry return in trade network: Using LASSO,"This study tests the predictability power of returns across economically related industries, using monthly data over 1990-2010 and a machine learning model, the Least Absolute Shrinkage and Selection Operator (LASSO). This article presents evidence that LASSO identifies significant predictors of the returns of an individual industry among its interdependent industries. The results indicate cross-predictability of industry return by showing a significant relation between an industry's returns and the lagged returns of its LASSO-selected trade partners. The study finds that industries that are more central in the input-output network have a greater effect in predicting related industry return. It also computes out of sample (2011-2016) the mean return forecasts of the portfolio of industries based on the predictability effect of the lagged returns of trade partners. The self-financing trading strategy of buying (selling) a high (low) portfolio based on related industry lagged returns yields about 10.44 percent annual excess return (0.83 percent monthly), with an annual Sharpe ratio of about 0.86. The study shows that after controlling for the Fama-French (1993) three factors, the monthly returns from the self-financing trading strategies generate a significant alpha of 0.7 percent monthly over the period 2011-2016. © 2020 Elsevier B.V., All rights reserved.","Ashraf, R.",2019,10.3905/joi.2019.1.095,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090195969&doi=10.3905%2Fjoi.2019.1.095&partnerID=40&md5=c7c7979fbc72b7bbed6ea690a19b5740,scopus,"This study investigates the cross-predictability of industry returns within a trade network using the LASSO machine learning model. It demonstrates that lagged returns of trade partners can predict an industry's returns, with more central industries having a greater predictive impact. A trading strategy based on these predictions yields significant excess returns and alpha, even after controlling for Fama-French factors.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:42:44.189396
a4d80f5bda510793,Crude oil price forecasting: a biogeography-based optimization approach,"The importance of crude oil in the world economy has made it imperative for efficient models to be designed for predicting future prices. This paper proposes an alternative approach based on a time series and biogeography-based optimization (BMMR-BBO) for the estimation of the West Texas Intermediate (WTI) crude oil price. To evaluate the forecasting ability of the presented model, we compared its performance with those of time series functions. The results of the experiment showed that BMMR-BBO performed better than the other methods and is a fairly good option for crude oil price prediction. The proposed model can be useful in the formulation of policies related to international crude oil price estimations, development plans, and industrial production.","Dehghani, Hesam; Zangeneh, Mahsa",2018,10.1080/15567249.2018.1501121,,wos,"This paper proposes a new model, BMMR-BBO, which combines time series analysis with biogeography-based optimization to forecast West Texas Intermediate (WTI) crude oil prices. The model outperformed traditional time series methods in experiments and is suggested for policy formulation related to oil prices.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:42:50.310211
2bd7bf35284a9fc0,Daily Stock Returns Characteristics and Forecastability,"While stock prices and economic activity are interrelated in a nation, they are not coincident with each other. Stock prices are a leading economic indicator of the United States of America's (U.S.A. 's) economy. An economic variable that influences stock market prices is interest rates through an inverse relationship. The changes in stock prices (or stock returns) are generally caused by the demand for stocks. This paper reports on a study that investigates the underlying spectral and time-frequency characteristics of daily Standard and Poor's (S&P) 500, Dow Jones Industrial Average (DJIA), and National Association of Securities Dealers Automated Quotations (NASDAQ) composite stock returns, and changes in interest rate (namely, inverted 3-month Treasury bill). The study thereafter compared these findings with those obtained in a previous study by Joseph et al, which focused on monthly stock returns and interest rate data. Subsequent to studying stock returns and changes in interest rate that showed relatively similar spectral and frequency-time characteristics, this study investigated the forecastability of stock returns (in S&P 500, DJIA, and NASDAQ composite) by inverted interest rate (in 3-month Treasury bills) over prediction horizons of five and 30 days with the forecasting period covering the last 13 years. The measures of forecast accuracy used were root mean square error and correlation. The forecasts were favorable in all cases even with simpler neural network models. (c) 2017 The Authors. Published by Elsevier B.V.","Joseph, Anthony; Larrain, Maurice; Turner, Claude",2017,10.1016/j.procs.2017.09.033,,wos,"This study analyzes the spectral and time-frequency characteristics of daily stock returns (S&P 500, DJIA, NASDAQ) and changes in interest rates (3-month Treasury bill). It compares these findings with a previous study on monthly data. The research then investigates the forecastability of stock returns using interest rate changes over 5 and 30-day horizons, employing neural network models and finding favorable forecasts.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:43:40.719154
e1aea4fb54dfddef,De-noising option prices with the wavelet method,"Financial time series are known to carry noise. Hence, techniques to de-noise such data deserve great attention. Wavelet analysis is widely used in science and engineering to de-noise data. In this paper we show, through the use of Monte Carlo simulations, the power of the wavelet method in the de-noising of option price data. We also find that the estimation of risk-neutral density functions and out-of-sample price forecasting is significantly improved after noise is removed using the wavelet method. (C) 2012 Elsevier B.V. All rights reserved.","Haven, Emmanuel; Liu, Xiaoquan; Shen, Liya",2012,10.1016/j.ejor.2012.04.020,,wos,"This paper demonstrates the effectiveness of the wavelet method for de-noising option price data, showing improvements in risk-neutral density estimation and out-of-sample price forecasting through Monte Carlo simulations.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:43:45.827493
d9568c102a3985ba,Debt-stabilizing properties of GDP-linked securities: A macro-finance perspective,"We study the debt -stabilizing properties of indexing debt to GDP using a consumption -based macro -finance model. To this end, we derive quasi -analytical pricing formulas for any type of bond/equity by exploiting the discretization of the state -space, making large-scale simulations tractable. We find that GDP -linked security prices would embed time -varying risk premiums of about 40 basis points. For a fixed budget surplus, issuing GDP -linked securities does not imply more beneficial debt -to -GDP ratios in the long -run, while the debt -stabilizing budget surplus is more predictable at the expense of being higher. Our findings call into question the view that such securities tame debt.","Mouabbi, Sarah; Renne, Jean -Paul; Sahuc, Jean -Guillaume",2024,10.1016/j.jbankfin.2024.107131,,wos,"This paper investigates the debt-stabilizing effects of GDP-linked securities using a macro-finance model. It derives pricing formulas and conducts simulations, finding that while these securities embed risk premiums, they do not necessarily lead to more beneficial debt-to-GDP ratios or tame debt effectively. The budget surplus required for debt stabilization becomes higher but more predictable.",False,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:43:58.808741
bfb98861daf4485c,Deep Learning and Machine Learning Insights Into the Global Economic Drivers of the Bitcoin Price,"This study examines the connection between Bitcoin and global factors, including the VIX, the oil price, the US dollar index, the gold price, and interest rates estimated using the Federal funds rate and treasury securities rate, for forecasting analysis. Deep learning methodologies, including LSTM, GRU, CNN, and TFT, with machine learning algorithms such as XGBoost, LightGBM, and SVR, were employed to identify the optimal prediction model for the Bitcoin price. The findings indicate that the TFT model is the most successful predictive approach, with the gold price identified as the most relevant component in determining the Bitcoin price. After the gold indicator, the US dollar index was a substantial factor in the explanation of the Bitcoin price. The TFT model also included regulatory decisions and global events. It was estimated that the Bitcoin price was significantly influenced by the COVID-19 pandemic. After that, global climate events and China mining ban strongly affected the Bitcoin price. These findings indicate that regulatory decisions and global events determine the Bitcoin price in addition to macroeconomic factors. The VAR analysis was employed as a robustness check. The results indicate that gold and oil prices have a strong negative influence on Bitcoin, particularly in the long term. The paper has significant policy implications for investors, portfolio managers, and scholars.","Kose, Nezir; Gur, Yunus Emre; Unal, Emre",2025,10.1002/for.3258,,wos,"This study investigates the relationship between Bitcoin prices and global economic factors (VIX, oil price, US dollar index, gold price, interest rates) using deep learning (LSTM, GRU, CNN, TFT) and machine learning (XGBoost, LightGBM, SVR) models. The TFT model proved most effective, identifying gold price and US dollar index as key drivers. The study also highlights the impact of regulatory decisions, global events (COVID-19, climate events, China mining ban), and macroeconomic factors on Bitcoin prices, with VAR analysis confirming a long-term negative influence from gold and oil prices.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:44:04.403557
029287686acf7c81,Deep Learning for Bond Yield Forecasting: The LSTM-LagLasso,"We present long short-term memory (LSTM)-LagLasso, a novel explainable deep learning approach applied to bond yield forecasting. Our method involves feature selection from a large universe of potential features and forecasts bond yields using dynamic LSTM networks. It examines the internal gating signals of a trained LSTM and explains their dynamics through exogenous variables that may influence bond price formation. By considering these variables at various lags and using the Lasso technique for feature selection, we demonstrate how different hidden units within the LSTM dynamically adjust to make predictions across different temporal regimes and how their evolution is shaped by various external factors. In an empirical study on government bond yield forecasting, we demonstrate the statistical accuracy of LSTM-LagLasso compared to a multilayer perceptron (MLP) and highlight its explainability. © 2025 Elsevier B.V., All rights reserved.","Nunes, M.; Gerding, E.; McGroarty, F.; Niranjan, M.; Sermpinis, G.",2025,10.1002/ijfe.3116,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215673445&doi=10.1002%2Fijfe.3116&partnerID=40&md5=16a040114703ee0a5003b658cae9572e,scopus,"This paper introduces LSTM-LagLasso, a novel explainable deep learning method for bond yield forecasting. It uses feature selection from a broad set of potential features and dynamic LSTM networks to predict bond yields. The approach analyzes LSTM internal gating signals and explains their dynamics using exogenous variables that influence bond prices. The study empirically validates LSTM-LagLasso on government bond yield forecasting, showing its statistical accuracy and explainability compared to an MLP.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T15:44:16.683609
beadf3ba10095213,Deep Sequence Modeling: Development and Applications in Asset Pricing,"The authors predict asset returns and measure risk premiums using a prominent technique from artificial intelligence: deep sequence modeling. Because asset returns often exhibit sequential dependence that may not be effectively captured by conventional time-series models, sequence modeling offers a promising path with its data-driven approach and superior performance. In this article, the authors first overview the development of deep sequence models, introduce their applications in asset pricing, and discuss their advantages and limitations. They then perform a comparative analysis of these methods using data on US equities. They demonstrate how sequence modeling benefits investors in general through incorporating complex historical path dependence and that long short-term memory–based models tend to have the best out-of-sample performance. © 2022 Elsevier B.V., All rights reserved.","Cong, L.W.; Tang, K.; Wang, J.; Zhang, Y.",2021,10.3905/jfds.2020.1.053,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126541141&doi=10.3905%2Fjfds.2020.1.053&partnerID=40&md5=bc886caceb37d23d08acc78479f0ddd8,scopus,"This article explores the application of deep sequence modeling, a technique from artificial intelligence, to predict asset returns and measure risk premiums. The authors highlight the advantages of sequence modeling over conventional time-series models for capturing sequential dependence in asset returns. They provide an overview of deep sequence models, discuss their applications and limitations in asset pricing, and conduct a comparative analysis using US equity data. The study demonstrates that long short-term memory (LSTM)-based models generally perform best out-of-sample.",True,False,True,gemini-2.5-flash-lite,Ulrik,M,Need read more than abstract,2025-10-13T15:44:40.667711
20d437cdd0b20220,Deep learning with long short-term memory networks for financial market predictions,"Long short-term memory (LSTM) networks are a state-of-the-art technique for sequence learning. They are less commonly applied to financial time series predictions, yet inherently suitable for this domain. We deploy LSTM networks for predicting out-of-sample directional movements for the constituent stocks of the S&P 500 from 1992 until 2015. With daily returns of 0.46 percent and a Sharpe ratio of 5.8 prior to transaction costs, we find LSTM networks to outperform memory-free classification methods, i.e., a random forest (RAF), a deep neural net (DNN), and a logistic regression classifier (LOG). The outperformance relative to the general market is very clear from 1992 to 2009, but as of 2010, excess returns seem to have been arbitraged away with LSTM profitability fluctuating around zero after transaction costs. We further unveil sources of profitability, thereby shedding light into the black box of artificial neural networks. Specifically, we find one common pattern among the stocks selected for trading – they exhibit high volatility and a short-term reversal return profile. Leveraging these findings, we are able to formalize a rules-based short-term reversal strategy that yields 0.23 percent prior to transaction costs. Further regression analysis unveils low exposure of the LSTM returns to common sources of systematic risk – also compared to the three benchmark models. © 2018 Elsevier B.V., All rights reserved.","Fischer, T.; Krauß, C.",2018,10.1016/j.ejor.2017.11.054,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039970639&doi=10.1016%2Fj.ejor.2017.11.054&partnerID=40&md5=b5354f21b79010e8b9e0f8e44362b4ae,scopus,"This study applies Long Short-Term Memory (LSTM) networks to predict directional movements in S&P 500 stocks from 1992-2015. LSTMs outperformed random forest, deep neural net, and logistic regression models, showing significant excess returns until 2009. Profitability decreased after 2010, potentially due to arbitrage. The study identified high volatility and short-term reversal as key factors for LSTM profitability and developed a rules-based strategy. LSTM returns showed low exposure to systematic risk.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:45:02.589096
e2d80cda8686c72a,Detecting Multiple Structural Breaks in Systems of Linear Regression Equations With Integrated and Stationary Regressors,"In this paper, we propose a two‐step procedure based on the group LASSO estimator in combination with a backward elimination algorithm to detect multiple structural breaks in linear regressions with multivariate responses. Applying the two‐step estimator, we jointly detect the number and location of structural breaks and provide consistent estimates of the coefficients. Our framework is flexible enough to allow for a mix of integrated and stationary regressors, as well as deterministic terms. Using simulation experiments, we show that the proposed two‐step estimator performs competitively against the likelihood‐based approach in finite samples. However, the two‐step estimator is computationally much more efficient. An economic application to the identification of structural breaks in the term structure of interest rates illustrates this methodology.",,2025,10.1111/obes.12666,,proquest,"This paper introduces a two-step method using group LASSO and backward elimination to identify multiple structural breaks in linear regression models with multivariate responses. The method can handle both integrated and stationary regressors and deterministic terms, jointly determining the number and location of breaks while estimating coefficients consistently. Simulations show it is computationally efficient and competitive with likelihood-based methods. An application to the term structure of interest rates demonstrates its use.",True,True,False,gemini-2.5-flash-lite,Ulrik,M,,2025-10-13T15:45:17.561812
e24f1b7a54c54554,"Digital twin-based cyber-physical manufacturing systems, extended reality metaverse enterprise and production management algorithms, and Internet of Things financial and labor market technologies in generative artificial intelligence economics","Research background: Generative artificial intelligence (AI) and machine learning algorithms support industrial Internet of Things (IoT)-based big data and enterprise asset management in multiphysics simulation environments by industrial big data processing, modeling, and monitoring, enabling business organizational and managerial practices. Machine learning-based decision support and edge generative AI sensing systems can reduce persistent labor shortages and job vacancies and power productivity growth and labor market dynamics, shaping career pathways and facilitating occupational transitions by skill gap identification and laborintensive manufacturing job automation by path planning and spatial cognition algorithms, furthering theoretical implications for management sciences. Generative AI fintech, machine learning algorithms, and behavioral analytics can assist multi-layered payment and transaction processing screening with regard to authorized push payment, account takeover, and synthetic identity frauds, flagging suspicious activities and combating economic crimes by rigorous verification processes. Purpose of the article: We show that edge device management functionalities of cloud industrial IoT and virtual robotic simulation technologies configure plant production and route planning processes across cyber-physical production and industrial automation systems in multi-cloud immersive 3D environments, leading to tangible business outcomes by reinforcement learning and convolutional neural networks. Labor-augmenting automation and generative AI technologies can impact employment participation, increase wage and wealth inequality, and lead to potential job displacement and massive labor market disruptions. The deep learning capabilities of generative AI fintech in terms of adaptive behavioral analytics and credit scoring mechanisms can enhance financial transaction behaviors and algorithmic trading returns, identify fraudulent payment transactions swiftly, and improve financial forecasts, leading to customized investment recommendations and well-informed financial decisions. Methods: Machine learning-based study selection process and text mining systematic review management software and tools leveraged include Abstrackr, CADIMA, Colandr, DistillerSR, EPPI-Reviewer, JBI SUMARI, METAGEAR package for R, SluRp, and SWIFT-Active Screener. Such reference management systems are harnessed for methodologically rigorous evidence synthesis, study selection and characteristic extraction, predictive document classification, machine learning-based citation and record screening, bias assessment, article retrieval automation, and document classification and prioritization.Findings & value added: Industrial IoT and 3D augmented reality technologies can create business value by streamlining virtual product and remote asset management across extended reality-based navigation and robotic autonomous systems in smart factory environments by generative AI and machine learning algorithms, articulating business organizational level and theory of management implications. 3D simulation and operational modeling tools can execute and complete complex cognitive task-oriented and knowledge economy jobs, producing first-rate quality outputs swiftly while leading to unemployment spells, labor market disruptions, job displacement losses, and reduced earnings by machine learning clustering and spatial cognition algorithms.Generative AI decentralized finance, interoperable blockchain networks, cash flow management tools, and asset tokenization can mitigate fraud risks, enable digital fund and crypto investing servicing, and automate treasury operations by integrating real-time payment capabilities, routing and configurable workflows, and lending and payment technologies.","Lazaroiu, George; Gedeon, Tom; Rogalska, Elzbieta; Valaskova, Katarina; Nagy, Marek; Musa, Hussam; Zvarikova, Katarina; Poliak, Milos; Horak, Jakub; Cretoiu, Raluca Ionela; Krulicky, Tomas; Ionescu, Luminita; Popa, Catalin; Hurloiu, Lacramioara Rodica; Nistor, Filip; Avram, Laurentia Georgeta; Braga, Viorica",2024,10.24136/oc.3183,,wos,"This article explores the integration of generative AI, machine learning, digital twins, extended reality, and IoT within manufacturing and financial systems. It discusses how these technologies can optimize production, manage assets, and improve financial operations, including fraud detection and algorithmic trading. The paper also addresses the potential impacts on the labor market, such as job displacement and skill gaps, and outlines the systematic review methods used to analyze relevant literature.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:45:25.819728
69d40c22a0ca58a8,Dimension Reduction via Penalized GLMs for Non-Gaussian Response: Application to Stock Market Volatility,"We fit U.S. stock market volatilities on macroeconomic and financial market indicators and some industry level financial ratios. Stock market volatility is non-Gaussian distributed. It can be approximated by an inverse Gaussian (IG) distribution or it can be transformed by Box–Cox transformation to a Gaussian distribution. Hence, we used a Box–Cox transformed Gaussian LASSO model and an IG GLM LASSO model as dimension reduction techniques and we attempted to identify some common indicators to help us forecast stock market volatility. Via simulation, we validated the use of four models, i.e., a univariate Box–Cox transformation Gaussian LASSO model, a three-phase iterative grid search Box–Cox transformation Gaussian LASSO model, and both canonical link and optimal link IG GLM LASSO models. The latter two models assume an approximately IG distributed response. Using these four models in an empirical study, we identified three macroeconomic indicators that could help us forecast stock market volatility. These are the credit spread between the U.S. Aaa corporate bond yield and the 10-year treasury yield, the total outstanding non-revolving consumer credit, and the total outstanding non-financial corporate bonds.",,2021,10.3390/jrfm14120583,,proquest,"This study applies dimension reduction techniques using penalized Generalized Linear Models (GLMs) to forecast U.S. stock market volatility, which is non-Gaussian. The authors compare Box-Cox transformed Gaussian LASSO models with Inverse Gaussian (IG) GLM LASSO models, validating their performance through simulations and an empirical study. They identify three key macroeconomic indicators (credit spread, consumer credit, corporate bonds) that can help forecast stock market volatility.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:45:37.819677
1aaadcf8c464fe28,Disagreement in expectations and the credibility of monetary authorities in the Brazilian inflation targeting regime,"Based on market expectations reported by the Central Bank of Brazil for the SELIC interest rate, the IPCA inflation, the exchange rate (BRL/USD) and the growth rate of industrial production for four different forecasting horizons, this work analyzes the term structures of disagreement in expectations regarding the future values of these variables. It also investigates the driving factors of disagreement, paying special attention to the influence of monetary authorities’ credibility. An extensive regression analysis shows that the levels of the term structures of disagreement are negatively related to the output gap (although this result is not very robust); and that the levels of the term structures of disagreement in expectations about the IPCA inflation rate and the SELIC interest rate have a strong negative relationship with central bankers’ credibility; this relationship is positive in the case of the growth rate of industrial production. © 2019 Elsevier B.V., All rights reserved.","Vereda, L.V.; Curi, A.",2016,10.1016/j.econ.2016.03.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031719048&doi=10.1016%2Fj.econ.2016.03.002&partnerID=40&md5=3986f94f0699536c3421af3af3134519,scopus,"This study examines disagreement in market expectations regarding SELIC interest rate, IPCA inflation, exchange rate, and industrial production growth in Brazil. It finds that disagreement is negatively related to the output gap and positively related to central bankers' credibility for inflation and interest rates, but negatively for industrial production growth.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:45:40.917063
e877d6e0c89d5e6e,Discrete-time affine term structure models with generalized market prices of risk,"This article develops a rich class of discrete-time, nonlinear dynamic term structure models (DTSMs). Under the risk-neutral measure, the distribution of the state vector Xt resides within a family of discrete-time affine processes that nests the exact discrete-time counterparts of the entire class of continuous-time models in Duffie and Kan (1996) and Dai and Singleton (2000). Under the historical distribution, our approach accommodates nonlinear (nonaffine) processes while leading to closed-form expressions for the conditional likelihood functions for zero-coupon bond yields. As motivation for our framework, we show that it encompasses many of the equilibrium models with habit-based preferences or recursive preferences and long-run risks. We illustrate our methods by constructing maximum likelihood estimates of a nonlinear discrete-time DTSM with habit-based preferences in which bond prices are known in closed form. We conclude that habit-based models, as typically parameterized in the literature, do not match key features of the conditional distribution of bond yields. © 2010 The Author. © 2010 Elsevier B.V., All rights reserved.","Le, A.; Singleton, K.J.; Dai, Q.",2010,10.1093/rfs/hhq007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951229447&doi=10.1093%2Frfs%2Fhhq007&partnerID=40&md5=357de60632b52de4ee7c87b041b608ad,scopus,"This article presents a class of discrete-time, nonlinear dynamic term structure models (DTSMs) that generalize continuous-time affine models. It allows for nonlinear processes under the historical distribution, providing closed-form expressions for bond yield likelihoods. The framework includes equilibrium models with habit-based or recursive preferences and long-run risks. The authors illustrate their methods by estimating a nonlinear DTSM with habit-based preferences, finding that such models, as typically parameterized, do not fully capture the conditional distribution of bond yields.",True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:46:04.286663
f25a821e963e885a,Dissecting climate change risk and financial market instability: Implications for ecological risk management,"This research investigates the impact of climate challenges on financial markets by introducing an innovative approach to measure climate risk, specifically the aggregate climate change concern (ACCC) index. The study aims to assess and quantify the potential influence of climate change and risk-related factors on the performance and dynamics of financial markets. In this paper, concern is defined as the attention paid to the risk of climate change and the associated negative consequences. The findings demonstrate that the aggregate index exhibits robust predictability of market risk premiums, both within the sample and out-of-sample. By comparison, the index contains additional information beyond 14 economic predictors and 12 risk/uncertainty indexes in forecasting stock market return. In addition, the index proves valuable for mean-variance investors in asset allocation, leading to significant economic gains. The study identifies the index's ability to capture the reversal of temporary price crashes caused by overreactions to climate change risk. Furthermore, it exhibits stronger return forecasting capability for green stocks, non-state-owned enterprise (non-SOE) stocks, and stocks in regions with low air pollution. Particularly during periods of low air pollution and relaxed regulation, the index displays an enhanced ability to forecast returns. The study's findings provide valuable insights for policymakers and financial institutions as they address 21st-century environmental challenges. Moreover, these findings can inform the design of adaptive measures and interventions aimed at mitigating ecological risks and promoting sustainable economic growth.This research investigates the impact of climate challenges on financial markets by introducing an innovative approach to measure climate risk, specifically the aggregate climate change concern (ACCC) index. The study aims to assess and quantify the potential influence of climate change and risk-related factors on the performance and dynamics of financial markets. In this paper, concern is defined as the attention paid to the risk of climate change and the associated negative consequences. The findings demonstrate that the aggregate index exhibits robust predictability of market risk premiums, both within the sample and out-of-sample. By comparison, the index contains additional information beyond 14 economic predictors and 12 risk/uncertainty indexes in forecasting stock market return. In addition, the index proves valuable for mean-variance investors in asset allocation, leading to significant economic gains. The study identifies the index's ability to capture the reversal of temporary price crashes caused by overreactions to climate change risk. Furthermore, it exhibits stronger return forecasting capability for green stocks, non-state-owned enterprise (non-SOE) stocks, and stocks in regions with low air pollution. Particularly during periods of low air pollution and relaxed regulation, the index displays an enhanced ability to forecast returns. The study's findings provide valuable insights for policymakers and financial institutions as they address 21st-century environmental challenges. Moreover, these findings can inform the design of adaptive measures and interventions aimed at mitigating ecological risks and promoting sustainable economic growth.",,2025,10.1111/risa.14265,,proquest,"This study introduces the Aggregate Climate Change Concern (ACCC) index to measure climate risk and its impact on financial markets. The ACCC index demonstrates strong predictability of market risk premiums and stock market returns, outperforming traditional economic predictors. It also aids mean-variance investors in asset allocation and shows enhanced forecasting for green stocks, non-SOE stocks, and stocks in low-pollution regions, particularly during periods of relaxed regulation. The findings offer insights for policymakers and financial institutions in managing ecological risks and promoting sustainable growth.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:46:06.897944
10aa5400853f1e0c,Do Foreign Yield Curves Predict US Recessions and GDP Growth?,Foreign term spreads constructed from bond yields of non-U.S. G-7 constituents predict future U.S. recessions and foreign term spreads are stronger predictors of U.S. recessions occurring within the next year than U.S. term spreads. U.S. and foreign term spreads are both informative of the U.S. economy but over different horizons and for different components of economic activity. Smaller U.S. term spreads lead to smaller foreign term spreads and U.S. Dollar appreciation. Smaller foreign term spreads do not lead to significant U.S. Dollar depreciation but do lead to persistent declines in U.S. exports and foreign direct investment (FDI) flows into the United States. These findings are consistent with the proposition that foreign term spreads embed growth spillovers from the U.S. and the resulting Dollar strength and slowdown abroad spill back to the United States.,"Ahmed, Rashad; Chinn, Menzie D.",2024,10.1111/jmcb.13164,,wos,"This study investigates whether foreign yield curves can predict U.S. recessions and GDP growth. It finds that foreign term spreads are stronger predictors of upcoming U.S. recessions than domestic ones. Both U.S. and foreign term spreads offer insights into the U.S. economy, but at different time horizons and for different economic activities. Changes in U.S. term spreads influence foreign term spreads and the U.S. dollar, while foreign term spreads impact U.S. exports and FDI. These results support the idea that foreign term spreads reflect U.S. growth spillovers, which then feedback into the U.S. economy.",False,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:46:13.332756
fff1e1b48fd13413,Do local and global factors impact the emerging markets' sovereign yield curves? Evidence from a data‐rich environment,"This paper investigates the relation between yield curve and macroeconomic factors for 10 emerging sovereign bond markets using the sample from January 2006 to April 2019. To this end, the diffusion indices obtained under four categories (global variables, inflation, domestic financial variables, and economic activity) are incorporated by estimating dynamic panel data regressions together with the yield curve factors. Besides, in order to capture dynamic interaction between yield curve and macroeconomic/financial factors, a panel vector autoregressive (VAR) analysis based on the system generalized method of moments (GMM) approach is utilized. Empirical results suggest that the level factor responds to shocks originated from inflation, domestic financial variables, and global variables. Furthermore, the slope factor is affected by shocks in global variables, and the curvature factor appears to be influenced by domestic financial variables. We also show that macroeconomic/financial factors captures significant predictive information over yield curve factors by running individual country factor‐augmented predictive regressions and variable selection algorithms such ridge regression, least absolute shrinkage operator (LASSO), and Elastic Net. Our findings have important implications for policymakers and fund managers by explaining the underlying forces of movements in the yield curve and forecasting accurately dynamics of yield curve factors.",,2021,10.1002/for.2763,,proquest,"This paper examines the relationship between sovereign yield curves and macroeconomic factors in 10 emerging markets from 2006 to 2019. Using dynamic panel data regressions and a panel VAR approach, it finds that inflation, domestic financial variables, and global variables impact the level factor of the yield curve. Global variables affect the slope factor, and domestic financial variables influence the curvature factor. The study also demonstrates that macroeconomic/financial factors provide significant predictive information for yield curve factors through factor-augmented predictive regressions and machine learning techniques like ridge regression, LASSO, and Elastic Net.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T15:46:25.888478
d98996151ddb63ed,Does Real Estate Determine REIT Bond Risk Premia?,"This study is the first to examine the real estate-specific determinants of REIT bond risk premia. Using a dataset of 33,857 U.S. REIT bond yield spreads and 24 explanatory variables, we predict REIT bond yield spreads with a non-parametric artificial neural network algorithm and interpret the model’s predictions using the explainable machine learning method Accumulated Local Effect Plots (ALE). We report evidence of a direct real estate factor for U.S. REIT bond yield spreads proxied by real estate market total return and REIT property type. In addition, we find a property-type diversification risk premium for REIT bonds, indicating that there is no economic benefit in the form of lower cost of bond debt for most property-type diversification at the REIT-level. We argue that this is due to higher management and valuation complexity of diversified REIT portfolios. This study’s findings have relevant implications for REIT portfolio strategy and REIT capital structure decisions, as we show that specialized REITs generally have lower bond debt costs compared to diversified REITs. Moreover, a better understanding of the drivers influencing REIT bond risk premia helps investors to effectively manage bond portfolio risks. © 2025 Elsevier B.V., All rights reserved.","Kozak, J.; Nagl, C.; Nagl, M.; Beracha, E.; Schaefers, W.",2025,10.1007/s11146-025-10018-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007860488&doi=10.1007%2Fs11146-025-10018-7&partnerID=40&md5=745049e004467b65713fb8985dcc9bcd,scopus,"This study investigates the real estate determinants of REIT bond risk premia using a dataset of 33,857 U.S. REIT bond yield spreads. It employs a non-parametric artificial neural network and Accumulated Local Effect Plots (ALE) to analyze the data. The findings suggest that real estate market total return and REIT property type directly influence REIT bond yield spreads. Additionally, a property-type diversification risk premium exists, implying limited debt cost benefits for diversified REITs due to increased complexity. The study concludes that specialized REITs tend to have lower bond debt costs than diversified REITs, offering insights for REIT portfolio strategy and capital structure decisions.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:46:32.180495
bc5db5e2cc4b6eec,Does the mode of financing the budget deficit matter for inflation in Nigeria?,"Purpose: The motivation for this study is to determine whether inflation in Nigeria is driven by the Central Bank’s direct advances and Treasury bills/bonds as modes of financing the budget deficit. Hence, it examines whether the method of deficit financing significantly impacts inflation in Nigeria. Design/methodology/approach: Based on the nature of the study and the availability of data in Nigeria, this study employs the ARDL bound test estimation technique to analyse annual time-series data from 1981 to 2021. Findings: The ARDL bounds test approach to co-integration revealed a long-run co-integrating relationship between Central Bank advances, Treasury bills/bonds, and inflation in Nigeria. Furthermore, the ARDL results provide evidence of a negative and significant relationship between bonds and inflation in both the short and long run. In contrast, Central Bank advances exhibit a statistically significant direct effect on inflation in the short run and an indirect effect in the long run. Research limitations/implications: The study focuses solely on Nigeria, limiting the applicability of the findings to other nations with differing economic structures or fiscal policies. Secondly, while the ARDL bounds testing approach is appropriate for the research context, it may not capture complex nonlinear relationships or structural breaks within the dataset. Lastly, the exclusion of additional potential determinants of inflation, such as external shocks, geopolitical factors, or exchange rate dynamics, could restrict the comprehensiveness of the analysis. Practical implications: This study provides empirical evidence supporting the view that, to achieve lower inflation in Nigeria, policymakers should prioritize using bonds to finance the deficit budget, as they have been shown to have a short-and long-term deflationary effect on the economy. Originality/value: The novelty of this study lies in categorizing deficit budget financing (Central Bank advances and Treasury bills) and identifying which has the greatest impact on inflation in Nigeria. © 2025 Elsevier B.V., All rights reserved.","Abdullahi, S.M.; Kanang, A.A.; Gana, S.S.",2025,10.1108/ajems-04-2024-0265,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002467091&doi=10.1108%2FAJEMS-04-2024-0265&partnerID=40&md5=2af768eadcd1634b02656af15aeca46e,scopus,"This study investigates whether the method of financing Nigeria's budget deficit, specifically through Central Bank advances and Treasury bills/bonds, impacts inflation. Using ARDL bound testing on time-series data from 1981-2021, the research found a long-run relationship between these financing methods and inflation. Bonds showed a negative and significant relationship with inflation in both the short and long run, while Central Bank advances had a significant direct effect in the short run and an indirect effect in the long run. The study suggests prioritizing bonds for deficit financing to achieve lower inflation in Nigeria.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:46:51.967447
9d67744e2a06c457,"Dopamine D2 −141C Ins/Del and Taq1A polymorphisms, body mass index, and prediction error brain response","The prediction error model is a widely used paradigm that is conceptually based on neuronal dopamine function. However, whether dopamine receptor gene alleles contribute to human neuroimaging prediction error results is uncertain. Recent research implicated the dopamine D2 receptor in behavior response during a prediction error paradigm and we expected that polymorphisms of that receptor would contribute to prediction error brain response. In this study, healthy female participants in the early follicular phase of the menstrual cycle underwent a taste prediction error paradigm during functional magnetic resonance imaging. Participants were also genotyped for dopamine receptor polymorphisms. Our data suggest that the dopamine D2 receptor −141C Ins/Del and Taq1A polymorphisms together with body mass index selectively explain putamen prediction error response. This was true using a region of interest analysis as well as for a whole-brain analysis (FWE corrected). Polymorphisms for dopamine D1 or D4 receptors, dopamine transporter, or COMT did not significantly contribute to prediction error activation. The prediction error model is a computational reward-learning paradigm that is important in psychiatric research and has been associated with dopamine. The results from this study indicate that dopamine D2 receptor polymorphisms together with body mass index are important determinants to include in research that tests prediction error response of the brain. Psychiatric disorders are frequently associated with elevated or reduced body weight. Adding BMI to genetic information in brain-imaging studies that use reward and the prediction error paradigm may be important to increase validity and reliability of results.",,2018,10.1038/s41398-018-0147-1,,proquest,"This study investigated the relationship between dopamine D2 receptor gene polymorphisms (D2 -141C Ins/Del and Taq1A), body mass index (BMI), and brain response to prediction errors in healthy female participants using fMRI during a taste prediction error paradigm. The findings suggest that D2 polymorphisms and BMI collectively predict putamen prediction error response, highlighting their importance in brain imaging studies of reward and prediction error. Other dopamine-related gene polymorphisms did not show significant contributions.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:46:56.969982
4bd64fadf8327592,Dynamic Autoregressive Liquidity (DArLiQ),"We introduce a new class of semiparametric dynamic autoregressive models for the Amihud illiquidity measure, which captures both the long-run trend in the illiquidity series with a nonparametric component and the short-run dynamics with an autoregressive component. We develop a generalized method of moments (GMM) estimator based on conditional moment restrictions and an efficient semiparametric maximum likelihood (ML) estimator based on an iid assumption. We derive large sample properties for our estimators. Finally, we demonstrate the model fitting performance and its empirical relevance on an application. We investigate how the different components of the illiquidity process obtained from our model relate to the stock market risk premium using data on the S&P 500 stock market index. © 2024 Elsevier B.V., All rights reserved.","Hafner, C.M.; Linton, O.B.; Wang, L.",2024,10.1080/07350015.2023.2238790,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171686338&doi=10.1080%2F07350015.2023.2238790&partnerID=40&md5=87817b3788132f686907c6a32d52cff2,scopus,"This paper introduces Dynamic Autoregressive Liquidity (DArLiQ), a semiparametric model for the Amihud illiquidity measure. It combines nonparametric and autoregressive components to capture long-run trends and short-run dynamics. The study proposes GMM and ML estimators, derives their asymptotic properties, and demonstrates the model's performance and relevance through an application to the S&P 500 index, exploring the relationship between illiquidity components and the stock market risk premium.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:46:58.949409
1a2c221241c0c808,"Dynamic effect of Bitcoin, fintech and artificial intelligence stocks on eco-friendly assets, Islamic stocks and conventional financial markets: Another look using quantile-based approaches","Against the milieu of rapidly growing investment in technologically induced assets, this study examines the investment role of Bitcoin, fintech, and artificial intelligence (AI) stocks in relation to major environmentally friendly assets (green bonds, sustainable investments, and clean energy), Islamic stocks, and conventional financial markets using quantile-based approaches. To this end, we specifically examine the distributional and directional predictability between the returns of fintech, Bitcoin, and AI and various markets using the nonparametric causality-in-quantiles method and the cross-quantilogram correlation method respectively. We use daily data spanning March 9, 2018 to January 27, 2021. In terms of the distributional predictability of fintech, Bitcoin, and AI in relation to the traditional markets, Islamic stocks, clean energy stocks, and sustainable investments, we find strong evidence of causal asymmetry across quantiles and strong variations across markets. Likewise, findings in terms of directional predictability between the returns of fintech, Bitcoin, and AI and various markets infer that Islamic stocks act as a good hedge against Bitcoin. The S&P Treasury Bond and S&P Green Bond are also perfect hedges for fintech stocks, while S&P Global Clean Energy is a perfect hedge for AI stocks in terms of long-term dynamics. © 2023 Elsevier B.V., All rights reserved.","Abakah, E.J.A.; Tiwari, A.K.; Ghosh, S.; Doğan, B.",2023,10.1016/j.techfore.2023.122566,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152485944&doi=10.1016%2Fj.techfore.2023.122566&partnerID=40&md5=c1f97b045bdb4bd9b8444cb70ca68f6e,scopus,"This study investigates the relationship between Bitcoin, fintech, and AI stocks and eco-friendly assets, Islamic stocks, and conventional financial markets using quantile-based approaches. It employs nonparametric causality-in-quantiles and cross-quantilogram correlation methods to analyze distributional and directional predictability. The findings indicate causal asymmetry and variations across markets, with Islamic stocks, S&P Treasury Bond, S&P Green Bond, and S&P Global Clean Energy acting as hedges against specific tech assets under certain conditions.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:47:04.445067
ce15cb2f2a6fe0d0,"Dynamic spillovers and linkages between gold, crude oil, S&P 500, and other economic and financial variables. Evidence from the USA","This paper focuses on the price determinants of gold, and on the challenges associated with gold's safe haven property. Specifically, it analyses the interlinkages and the return spillover effect among gold, crude oil, S&P 500, dollar exchange rate, Consumer Price Index (CPI), economic policy uncertainty and Treasury bills, by employing a Vector Autoregression (VAR) and the spillover index of Diebold and Yilmaz (2012), Diebold and Yilmaz (2014). Monthly realized return series, covering the period from 2nd of January 1986 to 31st of December 2019 are used to examine the short-run linkages, and the return spillovers rolling-window estimates in analyzing the transmission mechanism in a time-varying fashion, respectively. Our findings identify gold as a strong dollar hedge, while crude oil and Treasury bills appear to drive inflation; they also indicate strong spillover effects between exchange rate and gold returns. In general, co-movement dynamics display state-dependent characteristics. Both total and directional spillovers increase significantly during market turbulence caused by severe financial crises such as the Global Financial Crisis (GFC) of 2007-2009 and the European Sovereign Debt Crisis of 2010-2012. Net spillovers switch between positive and negative values for all these markets, implying that the recipient/transmitter position changes drastically with market events. Economic policy uncertainty, stock market returns, and crude oil price returns are the main transmitters, while Treasury bills and CPI are the main return shock recipients. Gold and exchange rate act both as receivers and transmitters over the sample period.","Golitsis, Petros; Gkasis, Pavlos; Bellos, Sotirios K.",2022,10.1016/j.najef.2022.101785,,wos,"This paper investigates the dynamic spillovers and return transmission mechanisms among gold, crude oil, S&P 500, dollar exchange rate, CPI, economic policy uncertainty, and Treasury bills using VAR and spillover index models. It finds gold acts as a dollar hedge, crude oil and Treasury bills influence inflation, and significant spillovers exist between exchange rates and gold. Spillovers intensify during financial crises, with economic policy uncertainty, stock returns, and crude oil being key transmitters, and Treasury bills and CPI being key recipients. Gold and exchange rates exhibit dual roles as transmitters and receivers.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:47:05.969100
c3b936939fcbc181,Earthquake Insurance via CAT Bonds Utilizing Autoregressive Neural Networks and Active Faults,"Catastrophe (CAT) bonds necessitate a robust construction with regard to the estimated probability measure of their triggering parameter. This article concentrates on earthquakes as the primary natural catastrophe of concern. By leveraging the geometry of active faults for estimating default probability, we utilize seismic event information spanning up to 15,000 years in the past—thereby surpassing the restricted time range of available historical catalogs commonly used in other analyses, which typically cover only a few hundred years. This article introduces the design and pricing methodology of CAT bonds employing autoregressive neural networks, extending the standard VAR Nelson-Siegel model for yield curves. It presents a case study focused on the region of Greece, estimating that an additional spread of approximately 500 basis points over LIBOR constitutes the minimum premium required to attract an investor to undertake the associated risk. This premium could be absorbed by insured parties as an alternative to the conventional insurance process. © 2024 Elsevier B.V., All rights reserved.","Louloudis, E.; Zimbidis, A.; Tsekrekos, A.; Yannacopoulos, A.",2024,10.3905/jfi.2024.1.186,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206015299&doi=10.3905%2Fjfi.2024.1.186&partnerID=40&md5=16f2c58895e0134693f922a1467a33d0,scopus,"This article proposes a method for earthquake insurance using Catastrophe (CAT) bonds, leveraging autoregressive neural networks and active fault geometry to estimate default probabilities over a 15,000-year period. A case study in Greece suggests a minimum premium of 500 basis points over LIBOR is needed to attract investors, offering an alternative to traditional insurance.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:47:07.332971
189cf61c7efc6837,"Economic Freedom, Budget Deficits, and Perceived Risk from Larger National Debt-to-GDP Ratios: An Exploratory Analysis of Their Real Interest Rate Effects","Since the early 1980s, there have been a number of principally empirical studies of the impact of government budget deficits on interest rates that have typically tested the hypothesis that larger deficits raise interest rates. However, in more recent years, this topic has received far less attention. Accordingly, this study seeks to “update” the findings of such studies and to do so for the dominant North American economies of Canada and the U.S. Furthermore, in the pursuit of further insights into interest rates, the present study also investigates an effectively heretofore overlooked variable that arguably also might influence interest rates, namely, economic freedom. Finally, given the increased upward trend of government debt (relative to GDP) in recent years in Canada and the U.S., this study investigates the interest rate impact of rising national debt-to-GDP ratios. For the 1995–2024 period (and also in one estimate for the 1985–2001 period), this exploratory study finds compelling evidence (1) that the real interest rate yield on 10-year Treasuries in Canada and the real interest rate yield on 10-year U.S. Treasury notes are increasing functions of the central government budget deficits in both Canada and the U.S., respectively, and (2) the real interest rate yields on 10-year Treasuries in Canada and 10-year U.S. Treasury notes are both decreasing functions of economic freedom in Canada and the U.S., respectively. On the other hand, regarding the impact of a higher national debt-to-GDP ratio on the real ten-year Treasury yield, there is only very mixed support for an impact, with support for its impact coming from the Canadian estimates but no support whatsoever coming from the U.S. estimates.",,2024,10.3390/jrfm17100469,,proquest,"This exploratory study examines the impact of economic freedom, budget deficits, and national debt-to-GDP ratios on real interest rates for Canada and the U.S. from 1995-2024. It finds that larger budget deficits increase real interest rates, while greater economic freedom decreases them. The impact of higher debt-to-GDP ratios on real interest rates is mixed, with support found for Canada but not for the U.S.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:47:12.898084
9702a4f5490bd692,"Economic costs of Fusarium Head Blight, scab and deoxynivalenol","Fusarium Head Blight (FHB) has led to major economic costs for wheat and barley producers. Grain products and feed grain contaminated with deoxynivalenol (DON) (commonly known as vomitoxin) are subject to Food and Drug Administration advisory limits and as a result end-users place restrictions on their use. This has led to steep price discounts, as well as higher risks for producers and grain merchandisers. Varietal research has led to development of varieties that are resistant or moderately resistant to FHB. Studies indicate combinations of genetic resistance, fungicides and some management practices (combine settings, tillage practices, etc.) can be used to decrease economic costs due to FHB. The purpose of this study was to estimate the economic costs of scab. To do so we developed several economic models, analysed extensive data and conducted surveys of wheat flour millers, barley maltsters, and grain handlers. A detailed assessment of costs indicates the most important costs accrued by the wheat and barley industries were the risk premium paid to induce adoption of DON reducing technologies and the value of yield forgone. These were followed by the direct costs of fungicide, added shipping costs, testing and segregation and discounts.",,2018,10.3920/wmj2017.2204,,proquest,"This study estimates the economic costs of Fusarium Head Blight (FHB) in wheat and barley, focusing on the impact of deoxynivalenol (DON) contamination. It analyzes the costs associated with price discounts, risk premiums, yield losses, fungicide use, and segregation. The research suggests that combining genetic resistance, fungicides, and management practices can mitigate these economic impacts. The study utilized economic models, extensive data analysis, and surveys of industry stakeholders.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:47:16.021309
10e22f6f446668c0,Economic forces and seasonality in secirity returns,"This article finds strong seasonal behavior in the innovations for three Canadian macroeconomic variables (industrial production, unexpected inflation and GDP). An APT model is estimated as a restricted nonlinear multivariate regression system using seven macroeconomic variables, various residual market factor (RMF) proxies, and the returns on fifty size related portfolios of equities that traded on the Toronto Stock Exchange (TSE). As in Chen, Roll and Ross (1986), five macrofactors (lagged industrial production, lagged GDP, term structure, unexpected inflation, and risk premium) have significantly priced risk premia. The risk premia are insignificant for RMF based on two value weighted indices, and marginally significant (0.10 level) for the RMF based on an equally weighted index, which is somewhat consistent with McElroy and Burmeister (1988) and Brown and Otsuki (1989). The significance of the RMF risk premium appears not to be robust to whether portfolios or individual securities are used in the estimations. The significance of the estimated risk premia for the macrofactors also appear not to be robust to the number of portfolios (equations) used in the estimations. Unlike the risk premia estimates for the RMF, those for the other macrofactors are generally unaffected by the inclusion of a January dummy. This implies that the January seasonal remains a market phenomenon that requires further study. © 1992 Kluwer Academic Publishers. © 2007 Elsevier B.V., All rights reserved.","Kryzanowski, L.; Zhang, H.",1992,10.1007/bf00586436,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0039122166&doi=10.1007%2FBF00586436&partnerID=40&md5=7c54072676b2de26142e5bce6c6f16dc,scopus,"This study investigates seasonal patterns in Canadian macroeconomic variables and their impact on security returns. Using an APT model with seven macroeconomic variables and equity portfolio returns from the Toronto Stock Exchange, it identifies five macrofactors with significant risk premia. The study also examines the role of residual market factors (RMF) and finds that the January seasonal effect appears to be a market-wide phenomenon.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:47:24.068717
6af02ce8367645c4,Effectiveness of family policy in Russia: Evidence-based approach,"Family policy in Russia, is based on a “narrow” demographic interpretation that neglects policy effectiveness and impact of state support on fertility indicators. This gap can be addressed using the evidence-based approach, which embraces both the influence of public policies on fertility, and human capital. The paper discusses the theoretical underpinnings of policy based on the Becker-Barreau and Baldrin-Jones concepts. We show the importance of incorporating “Big Data” into family policy analysis to address the problem of data completeness and analytical information for family policy needs. We rely on A. Sagradov’s ideas about quantitative determination of population reproduction patterns with non-demographic processes, including institutional changes and transformation of economic mechanisms of family policy. We estimated the demographic result per unit of budget expenditures in Russia (based on empirical data from EMISS and the Federal Treasury for 86 regions from 2011 to 2021, with a breakdown by months). The “random forest” method is used to identify the key factors influencing the results of the machine learning model, and to demonstrate the significance of parameters for assessing the socio-economic effectiveness of family policy in Russia. The research findings indirectly confirm the pro-natalist nature of family policy in Russia, the effectiveness of which is ensured by economic mechanisms of direct cash payments to the population. The paper concludes with a discussion of the prospects for using an evidence-based approach to family policy in Russia. © 2021 Elsevier B.V., All rights reserved.","Kapoguzov, E.A.; Chupin, R.I.",2021,10.18522/2073-6606-2021-19-3-20-36,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119446410&doi=10.18522%2F2073-6606-2021-19-3-20-36&partnerID=40&md5=2ee5f6c1dca99c380322ca57d563bd35,scopus,"This paper examines the effectiveness of Russian family policy using an evidence-based approach, incorporating theoretical concepts and empirical data. It highlights the need for ""Big Data"" and quantitative analysis, utilizing the ""random forest"" method to identify key factors influencing policy outcomes. The findings suggest that Russia's family policy is pro-natalist and effective through direct cash payments.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:47:30.187593
0657bf71f73e0954,Efficient MCMC estimation of some elliptical copula regression models through scale mixtures of normals,"This paper proposes an efficient estimation method for some elliptical copula regression models by expressing both copula density and marginal density functions as scale mixtures of normals (SMN). Implementing these models using the SMN is novel and allows efficient estimation via Bayesian methods. An innovative algorithm for the case of complex semicontinuous margins is also presented. We utilize the facts that copulas are invariant to the location and scale of the margins; all elliptical distributions have the same correlation structure; and some densities can be represented by the SMN. Two simulation studies, one on continuous margins and the other on semicontinuous margins, highlight the favorable performance of the proposed methods. Two empirical studies, one on the US excess returns and one on the Thai wage earnings, further illustrate the applicability of the proposals. © 2019 Elsevier B.V., All rights reserved.","Wichitaksorn, N.; Gerlach, R.; Choy, S.T.B.",2019,10.1002/asmb.2410,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053731638&doi=10.1002%2Fasmb.2410&partnerID=40&md5=f78b5cba81fbb9780f1904c40f0be3e3,scopus,This paper introduces an efficient Bayesian estimation method for elliptical copula regression models by representing both copula and marginal densities as scale mixtures of normals (SMN). It includes a novel algorithm for semicontinuous margins and demonstrates favorable performance through simulation and empirical studies on US excess returns and Thai wage earnings.,True,False,True,gemini-2.5-flash-lite,Ulrik,M,Need read more than abstract,2025-10-13T15:47:49.305373
b9ed21f0c6e8f1fe,Efficient importance sampling maximum likelihood estimation of stochastic differential equations,"Maximum likelihood estimation (MLE) of stochastic differential equations (SDEs) is difficult because in general the transition density function of these processes is not known in closed form, and has to be approximated somehow. An approximation based on efficient importance sampling (EIS) is detailed. Monte Carlo experiments, based on widely used diffusion processes, evaluate its performance against an alternative importance sampling (IS) strategy, showing that EIS is at least equivalent, if not superior, while allowing a greater flexibility needed when examining more complicated models. (C) 2010 Elsevier B.V. All rights reserved.","Pastorello, S.; Rossi, E.",2010,10.1016/j.csda.2010.02.001,,wos,"This paper proposes an efficient importance sampling (EIS) method for maximum likelihood estimation (MLE) of stochastic differential equations (SDEs) when the transition density function is unknown. The EIS method is evaluated through Monte Carlo experiments using diffusion processes and compared to an alternative importance sampling (IS) strategy, demonstrating its effectiveness and flexibility for complex models.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:53:47.200356
bf8c440f1d08b343,"Elliptical Capital Asset Pricing Models: Formulation, Diagnostics, Case Study with Chilean Data, and Economic Rationale","The capital asset pricing model (CAPM) is often based on the Gaussianity or normality assumption. However, such an assumption is frequently violated in practical situations. In this paper, we introduce the symmetric CAPM considering distributions with lighter or heavier tails than the normal distribution. These distributions are symmetric and belong to the family of elliptical distributions. We pay special attention to the family members related to the normal, power-exponential, and Student-t cases, with the power-exponential distribution being particularly considered, as it has not been explored widely. Based on these cases, the expectation-maximization algorithm can be used to facilitate the estimation of model parameters utilizing the maximum likelihood method. In addition, we derive the leverage and local influence methods to carry out diagnostics in the symmetric CAPM. We conduct a detailed case study to apply the obtained results estimating the systematic risk of the financial assets of a Chilean company with real data. We employ the Akaike information criterion to conclude that the studied models provide better results than the CAPM under Gaussianity.",,2023,10.3390/math11061394,,proquest,"This paper proposes symmetric Capital Asset Pricing Models (CAPM) that accommodate elliptical distributions, which have lighter or heavier tails than the normal distribution. It focuses on power-exponential and Student-t distributions, using the expectation-maximization algorithm for parameter estimation and leverage/local influence methods for diagnostics. A case study with Chilean financial data demonstrates that these models outperform the standard Gaussian CAPM.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:53:50.903345
fd197540678bf733,"Emerging markets’ resource booms and busts, borrowing risk and regime change","Resource booms create real sector and credit expansion in resource-rich countries; however it can also give rise to over-borrowing. If a resource bust hits, the affected economies contract through declining export revenues, and possibly face increased default risk. Thus, both booms and busts can create macroeconomic instability. Using a dynamic growth model, we model regime changes which reveal nonlinear effects of debt on the economy, depending on the level of leveraging. We find a change from stable to unstable dynamics if the external debt to capital ratio rises above a certain threshold. Risk premia are introduced highlighting the state-dependent borrowing costs for the dynamic paths. We study excess debt and over-leveraging as deviations from sustainable ratios. We find country-specific risk premia that are likely associated with booms and busts for the given debt assessment. Our empirical estimates suggest that certain oil-exporting countries are at a heightened risk for debt crises. © 2017 Elsevier B.V., All rights reserved.","Nyambuu, U.; Semmler, W.",2017,10.1016/j.strueco.2017.02.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014406799&doi=10.1016%2Fj.strueco.2017.02.001&partnerID=40&md5=93c2c5125aae33db8872245de3e2f76d,scopus,"This paper uses a dynamic growth model to explore how resource booms and busts in emerging markets affect borrowing risk and can lead to regime changes in economic dynamics. It finds that exceeding a certain external debt to capital ratio threshold can destabilize the economy, and introduces risk premia to account for state-dependent borrowing costs. The study suggests that certain oil-exporting countries face a heightened risk of debt crises.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:53:54.113646
36465bfe50fa4423,Engineering viable foot-and-mouth disease viruses with increased thermostability as a step in the development of improved vaccines,"We have rationally engineered foot-and-mouth disease virus to increase its stability against thermal dissociation into subunits without disrupting the many biological functions needed for its infectivity. Amino acid side chains located near the capsid intersubunit interfaces and either predicted or found to be dispensable for infectivity were replaced by others that could establish new disulfide bonds or electrostatic interactions between subunits. Two engineered viruses were normally infectious, genetically stable, and antigenically indistinguishable from the natural virus but showed substantially increased stability against irreversible dissociation. Electrostatic interactions mediated this stabilizing effect. For foot-and-mouth disease virus and other viruses, some evidence had suggested that an increase in virion stability could be linked to an impairment of infectivity. The results of the present study show, in fact, that virion thermostability against dissociation into subunits may not be selectively constrained by functional requirements for infectivity. The thermostable viruses obtained, and others similarly engineered, could be used for the production, using current procedures, of foot-and-mouth disease vaccines that are less dependent on a faultless cold chain. In addition, introduction of those stabilizing mutations in empty (nucleic acid-free) capsids could facilitate the production of infection-risk-free vaccines against the disease, one of the economically most important animal diseases worldwide. Copyright © 2008, American Society for Microbiology. All Rights Reserved. © 2009 Elsevier B.V., All rights reserved.; MEDLINE® is the source for the MeSH terms of this document.","Mateo, R.; Luna, E.; Rincón, V.; Mateu, M.G.",2008,10.1128/jvi.01553-08,https://www.scopus.com/inward/record.uri?eid=2-s2.0-57349125715&doi=10.1128%2FJVI.01553-08&partnerID=40&md5=312eebb857432143e3d20a48dc5ffa60,scopus,"This study describes the engineering of foot-and-mouth disease viruses (FMDV) to enhance their thermostability. By introducing specific amino acid changes, the researchers created FMDV variants that are more resistant to thermal dissociation without compromising infectivity or antigenicity. These thermostable viruses could lead to improved FMDV vaccines that are less reliant on cold chain storage and potentially safer if used as empty capsids.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:53:55.628128
8132ab240b3a2bd6,Enhancing Customer Service Efficiency: Automating Responses to Customer Queries using Natural Language Processing and Radial Basis Function Neural Network (RBFNN),"The insurance sector is progressively embracing Artificial Intelligence (AI) and Natural Language Processing (NLP) to enhance customer service and streamline operations. This research offers a comprehensive framework that seamlessly integrates a chatbot system, empowered by advanced natural language processing techniques, with a Radial Basis Function Neural Network (RBFNN). In this approach, a chatbot serves as the primary user interface, facilitating easy and efficient communication regarding insurance policies and claims. Natural language processing algorithms are employed to interpret user queries, extract vital information, and generate structured responses. However, the key innovation lies in the application of the RBFNN, which is adapted to model and predict various aspects of insurance documents, including policy terms, premium calculations, and claim procedures. The RBFNN's ability to capture intricate data patterns significantly enhances the accuracy and efficiency of document generation. The combined approach accelerates document creation, reduces errors, and enhances the overall customer experience in the insurance domain. The performance of the proposed technique is evaluated in the Python platform and compared with existing approaches. Empirical results and comparisons with traditional methods illustrate the advantages in terms of accuracy and efficiency. The RBFNN achieved an average accuracyof99% across the five folds. This means that the RBFNN was able to correctly generate insurance documents for 99% of the customers in the test set, on average. © 2024 Elsevier B.V., All rights reserved.","Kolambe, S.A.; Kaur, P.",2024,10.62441/nano-ntp.v20is6.64,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203091771&doi=10.62441%2Fnano-ntp.v20iS6.64&partnerID=40&md5=7bed1d5ec424827f558477f89ed58e15,scopus,"This research introduces a framework for automating customer service in the insurance sector by integrating a chatbot with NLP and a Radial Basis Function Neural Network (RBFNN). The NLP interprets queries, and the RBFNN models insurance documents (policies, premiums, claims) to enhance accuracy and efficiency in document generation. The system achieved 99% accuracy in generating insurance documents.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:54:00.308687
64f45a55163d6b93,Equity Return Dispersion and Stock Market Volatility: Evidence from Multivariate Linear and Nonlinear Causality Tests,"We employ bivariate and multivariate nonlinear causality tests to document causality from equity return dispersion to stock market volatility and excess returns, even after controlling for the state of the economy. Expansionary (contractionary) market states are associated with a low (high) level of equity return dispersion, indicating asymmetries in the relationship between return dispersion and economic conditions. Our findings indicate that both return dispersion and business conditions are valid joint forecasters of stock market volatility and excess returns and that return dispersion possesses incremental information regarding future stock return dynamics beyond that which can be explained by the state of the economy.",,2019,10.3390/su11020351,,proquest,"This study uses nonlinear causality tests to show that equity return dispersion influences stock market volatility and excess returns. It finds that market conditions affect return dispersion asymmetrically and that both return dispersion and economic conditions can predict stock market volatility and excess returns, with return dispersion offering additional predictive information.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:54:04.959627
f74524ca4a843b41,Equity/bond yield correlation and the FED model: evidence of switching behaviour from the G7 markets,"This paper considers how the strength and nature of the relation between the equity and bond yield varies with the level of the real bond yield. We demonstrate that at low levels of the real bond yield, the correlation between the equity and bond yields turns negative. This arises as the lower bond yield implies heightened macroeconomic risk (e.g. deflation and economic stagnation) and causes equity and bond prices to move in opposite directions. The FED model relies on a positive relation for its success in predicting future returns. Thus, we argue that the mixed empirical evidence regarding the FED model arises due to this switch in correlation behaviour. We present supportive evidence for the switching relation and its link to the level of the bond yield using linear and nonlinear smooth transition panel regression techniques for the G7 markets. The results presented here should be of interest to market practitioners who may wish to use the FED model to aid market timing decisions and for academics interested in understanding the interrelations between markets. © 2018 Elsevier B.V., All rights reserved.","Humpe, A.; McMillan, D.G.",2018,10.1057/s41260-018-0091-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052958299&doi=10.1057%2Fs41260-018-0091-x&partnerID=40&md5=da878cf9fc2d0e5c1d3d00c3aa2fbdb2,scopus,"This paper investigates the relationship between equity and bond yields, finding that it becomes negative at low real bond yield levels due to heightened macroeconomic risk. This switching behavior is proposed as an explanation for the mixed empirical evidence on the FED model's predictive power. The study uses smooth transition panel regression techniques for G7 markets to support these findings.",True,True,True,gemini-2.5-flash-lite,Ulrik,M,Not ML enough? Need more than abstract,2025-10-13T15:55:43.834103
c621221de8365a99,Estimating Interest Rate Curves by Support Vector Regression,"A model that seeks to estimate an interest rate curve should have two desirable capabilities in addition to the usual characteristics required from any function-estimation model: it should incorporate the bid-ask spreads of the securities from which the curve is extracted and restrict the curve shape. The goal of this article is to estimate interest rate curves by using Support Vector Regression (SVR), a method derived from the Statistical Learning Theory developed by Vapnik (1995). The motivation is that SVR features these extra capabilities at a low estimation cost. The SVR is specified by a loss function, a kernel function and a smoothing parameter. SVR models the daily U.S. dollar interest rate swap curves, from 1997 to 2001. As expected from a priori and sensibility analyses, the SVR equipped with the kernel generating a spline with an infinite number of nodes was the best performing SVR. Comparing this SVR with other models, it achieved the best cross-validation interpolation performance in controlling the bias-variance trade-off and generating the lowest error considering the desired accuracy fixed by the bid-ask spreads.","Monteiro, Andre d'Almeida",2010,10.1080/07474938.2010.481998,,wos,"This article estimates interest rate curves using Support Vector Regression (SVR), a method that incorporates bid-ask spreads and restricts curve shape. The SVR model, particularly with a spline-generating kernel, demonstrated superior performance in cross-validation, controlling bias-variance trade-off and minimizing error compared to other models.",True,False,False,gemini-2.5-flash-lite,Ulrik,M,,2025-10-13T15:56:09.388375
8407ab83849bf0fa,Estimating dynamic equilibrium models using mixed frequency macro and financial data,"We provide a framework for inference in dynamic equilibrium models including financial market data at daily frequency, along with macro series at standard lower frequency. Our formulation of the macro finance model in continuous time conveniently accounts for the difference in observation frequency. We suggest the use of martingale estimating functions (MEF) to infer the structural parameters of the model directly through a nonlinear scheme. This method is compared to regression-based methods and the generalized method of moments (GMM). We illustrate our approaches by estimating various versions of the AK-Vasicek model with mean-reverting interest rates. We provide asymptotic theory and Monte Carlo evidence on the small sample behavior of the estimators and report empirical estimates using 30 years of US macro and financial data. (C) 2016 Elsevier B.V. All rights reserved.","Christensen, Bent Jesper; Posch, Olaf; van der Wel, Michel",2016,10.1016/j.jeconom.2016.04.005,,wos,"This paper proposes a framework for estimating dynamic equilibrium models using mixed-frequency macro and financial data. It utilizes continuous-time modeling and martingale estimating functions (MEF) for parameter inference, comparing this approach to regression-based methods and GMM. The authors illustrate their methods with versions of the AK-Vasicek model and provide empirical estimates using US data.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:56:21.667245
753a88b9bf9f6fc4,Estimating latent asset-pricing factors,"We develop an estimator for latent factors in a large-dimensional panel of financial data that can explain expected excess returns. Statistical factor analysis based on Principal Component Analysis (PCA) has problems identifying factors with a small variance that are important for asset pricing. We generalize PCA with a penalty term accounting for the pricing error in expected returns. Our estimator searches for factors that can explain both the expected return and covariance structure. We derive the statistical properties of the new estimator and show that our estimator can find asset-pricing factors, which cannot be detected with PCA, even if a large amount of data is available. Applying the approach to portfolio data we find factors with Sharpe-ratios more than twice as large as those based on conventional PCA and with smaller pricing errors.",,2020,10.1016/j.jeconom.2019.08.012,,proquest,"This paper proposes a new estimator for latent factors in financial data that aims to improve upon Principal Component Analysis (PCA) for asset pricing. The estimator incorporates a penalty term to account for pricing errors, allowing it to identify factors with small variance that are important for explaining expected excess returns and the covariance structure. The authors demonstrate that their method can uncover factors missed by PCA and show superior performance in an application to portfolio data, yielding factors with higher Sharpe ratios and lower pricing errors.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:56:49.064161
cecb8e178cdb3ad6,Estimating stochastic discount factor models with hidden regimes: Applications to commodity pricing,"We develop new likelihood-based methods to estimate factor-based Stochastic Discount Factors (SDF) that may accommodate Hidden Markov dynamics in the factor loadings. We use these methods to investigate whether it is possible to find a SDF that jointly prices the cross-section of eight U.S. portfolios of stocks, Treasuries, corporate bonds, and commodities. In particular, we test a range of possible different specification of the SDF, including single-state and Hidden Markov models and compare their statistical and pricing performances. In addition, we assess whether and to which extent a selection of these models replicates the observed moments of the return series, and especially correlations. We report that regime-switching models clearly outperform single-state ones both in term of statistical and pricing accuracy. However, while a four-state model is selected by the information criteria, a two-state three-factor full Vector Autoregression model outperforms the others as far as the pricing accuracy is concerned. © 2017 Elsevier B.V., All rights reserved.","Giampietro, M.; Guidolin, M.; Pedio, M.",2018,10.1016/j.ejor.2017.07.045,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029533759&doi=10.1016%2Fj.ejor.2017.07.045&partnerID=40&md5=290458cda6fa18cfc85c520063b195a2,scopus,"This paper proposes new likelihood-based methods to estimate Stochastic Discount Factor (SDF) models with hidden regimes, applying them to commodity pricing. The study investigates whether these models can jointly price various U.S. asset portfolios (stocks, Treasuries, corporate bonds, commodities) and compares the performance of single-state versus Hidden Markov models. Regime-switching models demonstrate superior statistical and pricing accuracy, with a two-state, three-factor model showing the best pricing performance.",True,True,True,gemini-2.5-flash-lite,Ulrik,M,Portfolio of only bonds contained? Need more than abstract,2025-10-13T15:57:47.601827
d06548d8a3fc3d66,Estimation and empirical evaluation of the time-dependent Extended-CIR term structure model,"Empirical study of 25 years US Treasury bills data shows that even when the spot interest rate remains fixed, its volatility varies significantly over time. Constant-coefficient models cannot capture these changes as they give rise to time-homogeneous distributions. Maximum likelihood fitting of a one-factor time-dependent Extended-CIR model of the term structure, whose closed-form solution was previously obtained by the author, shows that it can capture these changes, as well as achieve significantly higher likelihood value. It is shown that exploitation of the closed-form solutions substantially improves the accuracy and efficiency of Monte Carlo simulations over high-order discretization algorithms. It is also shown that the feasibility of exact one-to-one calibration of the model to any continuous yield curve allows valuation of bond options significantly more accurately and efficiently.",Y. MAGHSOODI,2000,10.1093/imaman/11.3.161,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8132325,ieeexplore,"This paper empirically evaluates a time-dependent Extended-CIR model for the term structure of interest rates using 25 years of US Treasury bills data. The model captures time-varying volatility, outperforming constant-coefficient models. The study also demonstrates the efficiency of using closed-form solutions for Monte Carlo simulations and bond option valuation.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:57:53.363251
e3fc14003bf395e3,Estimation of Parameters in Mean-Reverting Stochastic Systems,"Stochastic differential equation (SDE) is a very important mathematical tool to describe complex systems in which noise plays an important role. SDE models have been widely used to study the dynamic properties of various nonlinear systems in biology, engineering, finance, and economics, as well as physical sciences. Since a SDE can generate unlimited numbers of trajectories, it is difficult to estimatemodel parameters based on experimental observationswhichmay represent only one trajectory of the stochastic model. Although substantial research efforts have been made to develop effective methods, it is still a challenge to infer unknown parameters in SDE models from observations that may have large variations. Using an interest rate model as a test problem, in this work we use the Bayesian inference and Markov Chain Monte Carlo method to estimate unknown parameters in SDE models.","Tian, Tianhai; Zhou, Yanli; Wu, Yonghong; Ge, Xiangyu",2014,10.1155/2014/317059,,wos,"This paper proposes using Bayesian inference and Markov Chain Monte Carlo methods to estimate parameters in mean-reverting stochastic systems, particularly when dealing with limited observational data from a single trajectory. The authors test their approach on an interest rate model.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:58:18.744763
fd910f31509a0f0d,European options in a nonlinear incomplete market model with default,"We study the superhedging prices and the associated superhedging strategies for European options in a nonlinear incomplete market model with default. The underlying market model consists of one risk-free asset and one risky asset, whose price may admit a jump at the default time. The portfolio processes follow nonlinear dynamics with a nonlinear driver f. By using a dynamic programming approach, we first provide a dual formulation of the seller's (superhedging) price for the European option as the supremum, over a suitable set of equivalent probability measures Q ∈ Q, of the fevaluation/expectation under Q of the payoff. We also establish a characterization of the seller's (superhedging) price as the initial value of the minimal supersolution of a constrained backward stochastic differential equation with default. Moreover, we provide some properties of the terminal profit made by the seller, and some results related to replication and no-arbitrage issues. Our results rely on first establishing a nonlinear optional and a nonlinear predictable decomposition for processes which are Ef-strong supermartingales under Q for all Q ∈ Q. © 2020 Elsevier B.V., All rights reserved.","Grigorova, M.; Quenez, M.-C.; Sulem, A.",2020,10.1137/20m1318018,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091823497&doi=10.1137%2F20M1318018&partnerID=40&md5=2cdc28d979b26bd118cd3f70ddad0322,scopus,"This paper investigates superhedging prices and strategies for European options within a nonlinear, incomplete market model that incorporates default risk. The model features a risk-free asset and a risky asset that can jump upon default, with nonlinear dynamics driven by a function 'f'. Using dynamic programming, the authors derive a dual formulation for the seller's superhedging price as the supremum of expected payoffs under various equivalent probability measures. They also characterize this price as the initial value of a minimal supersolution to a constrained backward stochastic differential equation with default. The study includes analysis of terminal profits, replication, and no-arbitrage conditions, building upon nonlinear optional and predictable decomposition theorems for specific types of supermartingales.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:58:32.768972
cedfa0a421c3207f,Evaluation of the influence of surface structure on tribological properties of the solid–liquid interface: Analytical and experimental assessment,"Nowadays, multiple strategies have been suggested to improve product efficiency on the basis of risk free techniques. Owing to the vast applications of the structured surface in many industrial sectors, considerable attention has been paid by many scholars to improve the surface performance aspects by studying their solid–liquid interface characterizations. In the current study, a new technique is introduced to manufacture a functional surface with water repellency feature through grinding process. Based on the solid–liquid interface evaluations of the modified surface, by structuring the surface, the contact angle increases from 35° (untreated surface) to 127° for structured surface. Therefore, the reinforced surface showed hydrophobicity with a 263% improvement for a scratch area fraction more than 75%. Formation of air pads trapped in the vacant space of the scratches was the main cause to enhance contact angle for structured surface. Since air molecules have very low inclination to chemical bonding with water molecules, the water droplet did not penetrate the scratches space and contact angle enhanced. A new analytical model for predicting the solid–liquid surface property was simultaneously developed by interaction of the kinematics of the grinding technique with single diamond and the basic wettability theory of the Cassie-Baxter. Therefore, the effect of all input parameters on the output results was studied in terms of achieving the best solid–liquid interaction performance through expanded model. The optimal values were calculated and the proposed structured surface was manufactured during the grinding process. According to the value of the static contact angle measured during experimental tests (127°) and its analytical value (123°), less than 4% error was observed between the results, which showed the high accuracy of the equation expanded on the present work. © 2023 Elsevier B.V., All rights reserved.","Musavi, S.H.; Razfar, M.; Domiri Ganji, D.D.",2023,10.1016/j.molliq.2023.122967,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170069308&doi=10.1016%2Fj.molliq.2023.122967&partnerID=40&md5=f2510f436420d6846dc300fecee68675,scopus,"This study introduces a new technique using a grinding process to create a functional, water-repellent surface. The structured surface demonstrated increased hydrophobicity, with a contact angle improving from 35° to 127°. This enhancement is attributed to air pads trapped in the surface's scratches. An analytical model was developed to predict solid-liquid surface properties based on the grinding kinematics and Cassie-Baxter wettability theory, showing good agreement with experimental results.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:58:36.219195
ac8f1b6ca53d639a,Evolving Fuzzy-GARCH Approach for Financial Volatility Modeling and Forecasting,"Volatility modeling and forecasting play a key role in asset allocation, risk management, derivatives pricing and policy making. The purpose of this paper is to develop an evolving fuzzy-GARCH modeling approach for stock market asset returns forecasting. The method addresses GARCH volatility modeling within the framwork of evolving fuzzy systems. This hybrid methodology aims to account for time-varying volatility, from GARCH approach, as well as volatility clustering and nonlinear time series identification, from evolving fuzzy systems, which use time-varying data streams to continuously and simultaneously adapt the structure and functionality of fuzzy models. The motivation is to improve model performance as new data is input through gradual model construction, inducing model adaptation and refinement without catastrophic forgetting while keeping current model useful. An empirical application includes the forecasting of S&P 500 and Ibovespa indexes by the evolving fuzzy-GARCH against traditional GARCH-family models and a fuzzy GJR-GARCH methodology. The results indicate the high potential of the evolving fuzzy-GARCH model to forecast stock returns volatility, which outperforms GARCH-type models and showed comparable forecasts with fuzzy GJR-GARCH methodology.","Maciel, Leandro; Gomide, Fernando; Ballini, Rosangela",2016,10.1007/s10614-015-9535-2,,wos,"This paper proposes an evolving fuzzy-GARCH model for stock market volatility forecasting, combining GARCH's time-varying volatility with evolving fuzzy systems' ability to adapt to nonlinear time series and data streams. The model aims to improve forecasting by continuously adapting without forgetting past information. Empirical results on S&P 500 and Ibovespa indexes suggest the evolving fuzzy-GARCH model outperforms traditional GARCH models and is comparable to fuzzy GJR-GARCH.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:58:47.005008
bee113618fd74452,Examining the myths of connected and autonomous vehicles: Analysing the pathway to a driverless mobility paradigm,"Connected and autonomous vehicles (CAVs) could become the most powerful mobility intervention in the history of human race; possibly greater than the conception of the wheel itself or the shift from horse-carriages to automobiles. Despite CAVs' likely traffic safety, economic, environmental, social inclusion and network performance benefits their full-scale implementation may not be as predictable, uncomplicated, acceptable and risk-free as it is often communicated by a large share of automotive industries, policy-makers and transport experts. Framing an 'unproven', 'disruptive' and 'life-changing' intervention, primarily based on its competitive advantages over today's conventional automobile technologies, may create misconceptions, overreaching expectations and room for errors that societies need to be cautious about. This article 'tests' eleven myths referring to an overly optimistic CAVs' development and adoption timeline. This approach highlights unresolved issues that need to be addressed before an inescapable CAV-based mobility paradigm transition takes place and provides relevant policy recommendations on how to achieve that. © 2020 Elsevier B.V., All rights reserved.","Nikitas, A.; Tchouamou Njoya, E.T.; Dani, S.",2019,10.1504/ijatm.2019.098513,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063507634&doi=10.1504%2FIJATM.2019.098513&partnerID=40&md5=7076e763a81cf64f2fa696878081f9af,scopus,"This article examines optimistic myths surrounding the development and adoption of connected and autonomous vehicles (CAVs). It challenges the predictable, uncomplicated, acceptable, and risk-free implementation often communicated by industry and policymakers. By testing eleven myths about CAV timelines, the article highlights unresolved issues and offers policy recommendations for a transition to a CAV-based mobility paradigm.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:58:48.960583
5405d96dfae218a6,Experience rating of risk premium for Esscher premium principle,"In this article, a new method is introduced under the Bayesian framework to derive the credibility estimator of risk premiums based on the Esscher premium principle. This new estimator offers desirable statistical properties, making it more useful and practical compared to existing estimators. Additionally, Bayesian models for policy portfolios are established, and empirical Bayes methods are employed to estimate the structural parameters. The empirical Bayesian estimation of risk premiums is also discussed in detail. The convergence rate and goodness of the proposed estimators are verified through simulations. The results demonstrate the effectiveness and accuracy of the new estimator and its superior performance compared to other existing methods. Finally, an empirical analysis is conducted using real insurance data, which further confirms the applicability and reliability of the proposed credibility estimator and its superiority in practical insurance applications. © 2024 Elsevier B.V., All rights reserved.","Zhang, Y.; Wen, L.",2024,10.1080/03610926.2023.2286192,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178100660&doi=10.1080%2F03610926.2023.2286192&partnerID=40&md5=41e426440e05e0182b9e7d5f4d9127c3,scopus,"This article introduces a new Bayesian framework for deriving a credibility estimator of risk premiums based on the Esscher premium principle. It establishes Bayesian models for policy portfolios, employs empirical Bayes methods for parameter estimation, and discusses empirical Bayesian estimation of risk premiums. Simulations verify the estimators' convergence and goodness, showing superior performance compared to existing methods. An empirical analysis using real insurance data confirms the practical applicability and reliability of the proposed estimator.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:58:57.271624
9342c5885c2e100c,Experimental Evidence on Socioeconomic Differences in Risk‐Taking and Risk Premiums,"Using a route choice experiment with embedded travel time variability, this study empirically estimates car commuters’ risk attitudes and taste preferences within a nonlinear mixed logit model. In addition to the identified overall risk‐taking behaviour, we find that risk attitudes covary with some sociodemographic characteristics, that is, older commuters are more risk‐taking than young ones and higher‐income commuters are less risk‐taking than low‐income ones. The implications of accounting for systematic risk attitude heterogeneity for valuing travellers’ willingness to pay for travel time improvement are also discussed.",,2020,10.1111/1475-4932.12544,,proquest,"This study uses a route choice experiment to estimate car commuters' risk attitudes and taste preferences using a nonlinear mixed logit model. It finds that older commuters are more risk-taking than younger ones, and higher-income commuters are less risk-taking than lower-income ones. The study also discusses the implications of this risk attitude heterogeneity for valuing travel time improvements.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:59:01.788219
c6c0fac67ecede1f,Exploration of Stock Portfolio Investment Construction Using Deep Learning Neural Network,"To study the intelligent and efficient stock portfolio in China’s financial market, based on the relevant theories such as deep learning (DL) neural network (NN) and stock portfolio, this study selects 111 stable stocks from the constituent stocks of the China Security Index (CSI) 300 from January 1, 2018, to December 31, 2021, as the research samples. Then, it analyzes these research samples and imports the relevant data of 111 stocks into the DL NN model. The corresponding prediction results of stock prices are obtained. Finally, the stock portfolio model based on DL NN is compared with the data results of the Shanghai Stock Exchange (SSE) 50 Index and CSI 500 Index. The results show that the closing prices of the selected 111 stocks are relatively stable and fluctuate up and down around the horizontal axis, and the positive and negative returns are relatively balanced, roughly between −5% and 5%. There is a phenomenon of fluctuation aggregation to a certain extent. Comparing the prediction results of different models reveals that the prediction results of model c are closest to the actual stock price trend. Comparing the relevant returns of the proposed stock portfolio with other stocks uncovers that the annualized return of the stock portfolio based on the DL NN model is 47.44%. The sharp ratio is 1.52, the maximum pullback is 18.15%, the monthly excess return is 3.11%, and the information ratio is 0.82. Compared with other indexes, the proposed stock portfolio shows the best results. Therefore, the proposal of the stock portfolio based on DL NN provides a theoretical basis for the development of the financial field in the future.",,2022,10.1155/2022/7957097,,proquest,"This study constructs a stock portfolio using a deep learning neural network model with 111 stable stocks from the China Security Index (CSI) 300 between 2018 and 2021. The model's predictions were compared to actual stock prices and benchmark indices (SSE 50 Index and CSI 500 Index). The deep learning-based portfolio achieved an annualized return of 47.44% with a Sharpe ratio of 1.52, outperforming other indices.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:59:11.290605
728df2bee0b1fd08,Exploring Low-Risk Anomalies: A Dynamic CAPM Utilizing a Machine Learning Approach,"Low-risk pricing anomalies, characterized by lower returns in higher-risk stocks, are prevalent in equity markets and challenge traditional asset pricing theory. Previous studies primarily relied on linear regression methods, which analyze a limited number of factors and overlook the advantages of machine learning in handling high-dimensional data. This study aims to address these anomalies in the Chinese market by employing machine learning techniques to measure systematic risk. A large dataset consisting of 770 variables, encompassing macroeconomic, micro-firm, and cross-effect factors, was constructed to develop a machine learning-based dynamic capital asset pricing model. Additionally, we investigated the differences in factors influencing time-varying beta between state-owned enterprises (SOEs) and non-SOEs, providing economic explanations for the black-box issues. Our findings demonstrated the effectiveness of random forest and neural networks, with the four-layer neural network performing best and leading to a substantial rise in the excess return of the long–short portfolio, up to 0.36%. Notably, liquidity indicators emerged as the primary drivers influencing beta, followed by momentum. Moreover, our analysis revealed a shift in variable importance during the transition from SOEs to non-SOEs, as liquidity and momentum gradually replaced fundamentals and valuation as key determinants. This research contributes to both theoretical and practical domains by bridging the research gap in incorporating machine learning methods into asset pricing research. © 2023 Elsevier B.V., All rights reserved.","Wang, J.; Chen, Z.",2023,10.3390/math11143220,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166206513&doi=10.3390%2Fmath11143220&partnerID=40&md5=d85880f568724fa7255d579695735817,scopus,"This study applies machine learning (random forest and neural networks) to a dynamic CAPM model using a large dataset of 770 variables to analyze low-risk anomalies in the Chinese equity market. It investigates time-varying betas, particularly differences between SOEs and non-SOEs, finding liquidity and momentum to be key drivers. The machine learning approach significantly improved the performance of a long-short portfolio.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:59:19.645428
3fbafc43043d6b52,Failure Propagation in SAP MultiBank Payment Batches Due to Unsynchronized Secure Channel Negotiations,"In SAP MultiBank systems, the payment batch processing failures are usually due to out-of-sync secure channel negotiations between the corporate SAP treasury systems and the banking interfaces that are integrated and connected. This research looks into the failure timing impacts of secure channel handshake intervals such as the time-to-first-byte, SSL certificate validation delays, and out-of-sync cryptographic negotiations occurring asynchronously. Using transaction logs, synthetic datasets, and real-world data, we construct a failure propagation framework that models transaction execution disruptions across various API types and geographical endpoints. The research confirms that there is a strong dependency between the level of channel desynchronization and the average payment failure rate with retry latencies and the volume of batches serving as extreme multipliers. Through recovery strategy analysis based on manual realignments, scheduled syncs, and AI anomaly driven adaptive predictions, we quantify the changes in batch stability and the integrity of transmitted data. The findings illustrate that diverse systems require synchronous coordinated negotiation protocols for secure cryptographic negotiation per transaction, stressing the treasury teams provide seamless payment failure continuity, enhanced compliance standards, and robust compliance standards for interbank integration. © 2025 Elsevier B.V., All rights reserved.","Jamithireddy, N.S.",2025,10.58346/jisis.2025.i2.036,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012485585&doi=10.58346%2FJISIS.2025.I2.036&partnerID=40&md5=4f31951178fd939d4f4e5b7ce6ed7171,scopus,"This research investigates failures in SAP MultiBank payment batches caused by unsynchronized secure channel negotiations between SAP treasury systems and banking interfaces. It models failure propagation using transaction logs and real-world data, confirming a strong link between channel desynchronization and payment failure rates. The study also analyzes recovery strategies, including AI-driven predictions, to improve batch stability and data integrity, emphasizing the need for synchronous negotiation protocols.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:59:22.316129
a940e3bbceaea481,False Safe Haven Assets: Evidence From the Target Volatility Strategy Based on Recurrent Neural Network,"This paper examines which safe haven assets should be used when improving out-of-sample portfolio performance. We define a market state with recurrent neural network (RNN) volatility predictions and construct an investment strategy that dynamically combines equity, cash, and safe havens. The equity is allocated by targeting the volatility, and investing in safe havens depends on the predicted market state. We consider the S&P500 index with 13 safe haven assets, such as long-term government bonds, commodities, gold, and other precious metals. Other indices, NIKKEI225, NIFTY50, and STOXX50, are examined for robustness. With analysis conducted over a 20-year sample period, we find that RNN delivers sound predictions to construct the volatility targeting strategy. Among considered assets, only long-term Treasury bonds act as a safe haven and improve the strategy performance. Other considered assets have no such potential. Our findings are relevant to portfolio managers and investors actively managing portfolio risk. © 2021 Elsevier B.V., All rights reserved.","Kaczmarek, T.; Be̜dowska-Sójka, B.; Grobelny, P.; Perez, K.",2022,10.1016/j.ribaf.2021.101610,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122282703&doi=10.1016%2Fj.ribaf.2021.101610&partnerID=40&md5=19f8d4a3c02c1effd32fe5951dcc2048,scopus,"This paper uses a Recurrent Neural Network (RNN) to predict market states and construct a volatility targeting strategy. The strategy dynamically combines equity, cash, and safe haven assets, with a focus on long-term Treasury bonds as the only effective safe haven among 13 considered assets. The analysis, conducted over 20 years using S&P500 and other indices, confirms the RNN's predictive accuracy and the limited safe haven potential of other assets.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:59:36.205935
f0af41484ecdd8f7,Flexible inflation targeting and stock market volatility: Evidence from emerging market economies,"Since the recent financial crisis, inflation targeting has been considered as one of the causes of the authorities’ unresponsiveness to the buildup of financial instability. Related research has either emphasized the effects of the central bank instrument and/or outcome or exclusively the impact of a unique central bank institutional characteristic, but never all of them as a core part of a unified framework. We fulfill this gap by providing evidence on whether the stock market volatility from Flexible Inflation Targeting (FIT) countries is less than volatility from non-FIT countries. Using data on a large set of emerging and employing causal inference methods, we examine the impact of FIT on stock market volatility. The results demonstrate that FIT is effective in containing volatility. By anchoring market operators’ expectations, FIT shapes the risk premium, which compensates for inflation uncertainty by lowering its main component, i.e. uncertainty, hence eventually bringing down the stock market volatility. © 2023 Elsevier B.V., All rights reserved.","Dridi, I.; Boughrara, A.",2023,10.1016/j.econmod.2023.106420,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165012437&doi=10.1016%2Fj.econmod.2023.106420&partnerID=40&md5=aefbb3defb36a70add814f54d2335234,scopus,"This study investigates whether Flexible Inflation Targeting (FIT) reduces stock market volatility in emerging economies. Using causal inference methods on a large dataset, the research finds that FIT is effective in containing volatility by anchoring expectations and reducing uncertainty, thereby lowering the risk premium.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:59:46.293938
3d1b3ebf3347f4b5,Fluctuations and Forecasting of Carbon Price Based on A Hybrid Ensemble Learning GARCH-LSTM-Based Approach: A Case of Five Carbon Trading Markets in China,"Carbon trading risk management and policy making require accurate forecasting of carbon trading prices. Based on the sample of China’s carbon emission trading pilot market, this paper firstly uses the Augmented Dickey–Fuller test and Autoregressive conditional heteroscedasticity model to test the stationarity and autocorrelation of carbon trading price returns, uses the Generalized Autoregressive Conditional Heteroscedasticity family model to analyze the persistence, risk and asymmetry of carbon trading price return fluctuations, and then proposes a hybrid prediction model neural network (generalized autoregressive conditional heteroscedasticity–long short-term memory network) due to the shortcomings of GARCH models in carbon price fluctuation analysis and prediction. The model is used to predict the carbon trading price. The results show that the carbon trading pilots have different degrees of volatility aggregation characteristics and the volatility persistence is long, among which only the Shanghai and Beijing carbon trading markets have risk premiums. The other pilot returns have no correlation with risks, and the fluctuations of carbon trading prices and returns are asymmetrical. The prediction results of different models show that the root mean square error (RMSE) of Hubei, Shenzhen and Shanghai carbon trading pilots based on the GARCH-LSTM model is significantly lower than that of the single GARCH model, and the RMSE values are reduced by 0.0006, 0.2993 and 0.0151, respectively. The RMSE in the three pilot markets improved by 0.0007, 0.3011 and 0.0157, respectively, compared to the standalone LSTM model. At the same time, compared with the single model, the GARCH-LSTM model significantly increased the R^2 value in Hubei (0.2000), Shenzhen (0.7607), Shanghai (0.0542) and Beijing (0.0595). Therefore, compared with other models, the GARCH-LSTM model can significantly improve the prediction accuracy of carbon price and provide a new idea for scientifically predicting the fluctuation of financial time series such as carbon price.",,2024,10.3390/su16041588,,proquest,"This paper proposes a hybrid GARCH-LSTM model to forecast carbon trading prices in five Chinese markets. The study analyzes price return volatility, risk premiums, and asymmetry. Results indicate that the GARCH-LSTM model significantly improves prediction accuracy compared to single GARCH or LSTM models, with notable improvements in RMSE and R^2 values for Hubei, Shenzhen, Shanghai, and Beijing markets.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T15:59:51.836439
8fb8a050541580b5,Forecasting Yield Curves with Survey Information,"In recent years, affine term structure models have provided alternatives to the expectations hypothesis and have become very popular in the finance literature. In particular, the widely accepted dynamic Nelson-Siegel model employs ingenious measures of the level, slope, and curvature of the yield curve that captured the attention of Francis and Hua. They supplement the dynamic Nelson-Siegel model with the Federal Reserve's Survey of Professional Forecasters data. Because these data utilize information from dozens of professional forecasters who study numerous macroeconomic variables, the author's wanted to see if this information-rich supplementary data could be used to improve the interest rate forecasting models for out-of-sample forecasts for Treasury bond maturities ranging from three months to 10 years that extend from three months to one year into the future.","Francis, Jack Clark; Hua, Jian",2012,10.3905/jpm.2012.38.3.149,,wos,"This study enhances the dynamic Nelson-Siegel model by incorporating the Federal Reserve's Survey of Professional Forecasters data to improve out-of-sample interest rate forecasts for Treasury bonds. The goal is to leverage the information-rich survey data to predict bond yields for maturities ranging from three months to 10 years, with forecasts extending one year into the future.",False,True,True,gemini-2.5-flash-lite,Ulrik,N,Could be useful in Part 1,2025-10-13T16:00:40.731591
fd8a58d650cc3e18,Forecasting and trading credit default swap indices using a deep learning model integrating Merton and LSTMs,"Using macroeconomic and financial conditions to forecast credit default swap (CDS) spreads is a challenging task. In this paper, we propose the Merton-LSTM model, a modified LSTM model formed by integrating with the Merton determinants model, to forecast the CDS indices. We provide the rigorous math behind the Merton-LSTM model, which demonstrates that by leveraging the nonlinear learning ability of LSTM with increased model capacity, the Merton-LSTM model is expected to learn the inherent association between the Merton determinants and CDS spreads. Further, the Merton-LSTM model is compared with the machine learning models LSTM, gated recurrent unit (GRU), multilayer perceptron network (MLP), support vector machine (SVM) and a typical sto-chastic series model in forecasting the two most liquid five-year CDS indices, North America High Yield index (CDX.NA.HY) and North America Investment Grade index (CDX.NA.IG) through the root mean squared error (RMSE) and the Diebold-Mariano test. The comparison results show that the RMSEs of the Merton-LSTM model are the lowest (6.2570-27.2000 for CDX.NA.HY and 1.3168-6.4772 for CDX.NA.IG) compared to other competitive models. The superiority of the Merton-LSTM model in forecasting performance is highlighted in long-term prediction even with a forecasting horizon extended to 28 days. Simulated trading with different thresholds and horizons is conducted in this study. We find that the Merton-LSTM trading strategy yields the highest annualized Sharpe ratios and lowest maximum losses at most thresholds and horizons, highlighting the economic significance of the proposed model.","Mao, Weifang; Zhu, Huiming; Wu, Hao; Lu, Yijie; Wang, Haidong",2023,10.1016/j.eswa.2022.119012,,wos,"This paper introduces the Merton-LSTM model, a hybrid deep learning approach combining the Merton determinants model with LSTMs, to forecast Credit Default Swap (CDS) indices. The model demonstrates superior forecasting accuracy compared to traditional machine learning and time series models, particularly for longer prediction horizons. Furthermore, a simulated trading strategy based on the Merton-LSTM model shows promising economic significance with high Sharpe ratios and low maximum losses.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:00:51.043920
9169d6d7b0d2309e,Forecasting carbon emissions future prices using the machine learning methods,"Due to the uncertainty surrounding the coupling and decoupling of natural gas, oil, and energy commodity futures prices, the current study seeks to investigate the interactions between energy commodity futures, oil price futures, and carbon emission futures from a forecasting perspective with implications for environmental sustainability. We employed daily data on natural gas futures prices, crude oil futures prices, carbon futures prices, and Dow Jones energy commodity futures prices from January 2018 to October 2021. For empirical analysis, we applied machine learning tools including traditional multiple linear regression (MLR), artificial neural network (ANN), support vector regression (SVR), and long short-term memory (LSTM). The machine learning analysis provides two key findings. First, the nonlinear frameworks outperform linear models in developing the relationships between future oil prices (crude oil and heating oil) and carbon emission futures prices. Second, the machine learning findings establish that when oil prices and natural gas prices display extreme movement, carbon emission futures prices react nonlinearly. Understanding the nonlinear dynamics of extreme movements can help policymakers design climate and environmental policies, as well as adjust natural gas and oil futures prices. We discuss important implications to sustainable development goals mainly SDG 7 and SDG 12.","Shahzad, Umer; Sengupta, Tuhin; Rao, Amar; Cui, Lianbiao",2024,10.1007/s10479-023-05188-7,,wos,"This study forecasts carbon emission futures prices by examining the interactions with natural gas, oil, and energy commodity futures prices using machine learning methods (MLR, ANN, SVR, LSTM). The findings indicate that nonlinear models outperform linear ones, and carbon emission futures prices react nonlinearly to extreme movements in oil and natural gas prices. The research has implications for environmental sustainability, climate policies, and sustainable development goals (SDG 7 and SDG 12).",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:00:53.240519
bd6374063056c122,Forecasting equity risk premium: The role of investor concern on oil price volatility,"We explore the impact of investor concern to oil price volatility on Chinese equity risk premium by constructing an investor oil price volatility concern index (IOPVC) using Baidu Index. Our analysis demonstrates that IOPVC is a strong predictor of equity risk premium, with a negative correlation to future returns. Robustness checks, including the use of different data sources, various prediction windows, and differing levels of risk aversion, confirm that the relationship between IOPVC and equity risk premium is reliable. Furthermore, our analysis reveals that IOPVC is a leading indicator of forthcoming economic scenarios and exerts a significant influence on investor risk aversion.","Li, Dakai",2025,10.1016/j.ribaf.2025.102990,,wos,This study investigates the relationship between investor concern about oil price volatility and the Chinese equity risk premium. The authors construct an index (IOPVC) using Baidu Index data and find it to be a significant negative predictor of future equity returns. The findings are robust across various checks and suggest that IOPVC also acts as a leading indicator for economic conditions and influences investor risk aversion.,False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:00:54.966287
b6b619d5ca55a0f5,Forecasting exchange rate: A bibliometric and content analysis,"The study aims to present a systematic overview of the research in the field of exchange rate projection models through bibliometric techniques and content analysis. First, 775 articles published in journals within the scope of the international Web of Science database from 1966 to May 2021 were analyzed through bibliometric techniques. Second, a selected sample of 69 articles was analyzed through a detail content analysis to identify hot topics and new avenues of interest in the field. The research findings suggest that the scientific production on the subject is in wide development. New approaches have been incorporated, such as neural networks, requiring a broad perspective by the researcher in the evaluation of the empirical results.","Vasconcelos, Camila de Souza; Hadad Jr, Eli",2023,10.1016/j.iref.2022.09.006,,wos,"This study provides a bibliometric and content analysis of research on exchange rate forecasting models, examining 775 articles from 1966-2021. It identifies emerging trends like neural networks and emphasizes the need for a broad perspective in evaluating empirical results.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:01:15.397549
5c20933515d8c65b,Forecasting gold price using machine learning methodologies,"This study investigates the potential of advanced Machine Learning (ML) methodologies to predict fluctuations in the price of gold. The study employs data from leading global stock indices, the S&P500 VIX volatility index, major commodity futures, and 10-year bond yields from the US, Germany, France, and Japan. Lagged values of these features up to 10 previous days are also used. Four machine learning models are used: Random Forest, Gradient Boosted Regression Trees (GBRT), and Extreme Gradient Boosting (XGBoost), to forecast future gold prices. The study finds that the most influential stocks indices for prediction are one-day lagged data of ASX, S&P500, TA35, IBEX, and AEX, as well as U.S. and Japan bonds yields and delayed data of gas and silver. Furthermore, the study's models identify that one-day lagged VIX score and our VIX dummy variable have a significant impact on gold price, indicating that economic uncertainty affects gold prices. The results suggest that incorporating various financial indicators and moving averages can be a powerful tool for predicting future gold prices. GBRT and XGBoost can be valuable models for making informed decisions about gold investments. © 2023 Elsevier B.V., All rights reserved.","Cohen, G.; Aiche, A.",2023,10.1016/j.chaos.2023.114079,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171768860&doi=10.1016%2Fj.chaos.2023.114079&partnerID=40&md5=242166c0eb01ccf4ae2e69b83f662f2b,scopus,"This study explores the use of Random Forest, GBRT, and XGBoost machine learning models to forecast gold prices, utilizing data from global stock indices, the VIX, commodity futures, and bond yields. It identifies key influential factors such as lagged stock indices, bond yields, and VIX scores, suggesting that economic uncertainty impacts gold prices. The findings indicate that GBRT and XGBoost are valuable for gold investment predictions.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:01:25.777905
fa405ec7825ac3fb,Forecasting government bond spreads with heuristic models: evidence from the Eurozone periphery,"This study investigates the predictability of European long-term government bond spreads through the application of heuristic and metaheuristic support vector regression (SVR) hybrid structures. Genetic, krill herd and sine–cosine algorithms are applied to the parameterization process of the SVR and locally weighted SVR (LSVR) methods. The inputs of the SVR models are selected from a large pool of linear and non-linear individual predictors. The statistical performance of the main models is evaluated against a random walk, an Autoregressive Moving Average, the best individual prediction model and the traditional SVR and LSVR structures. All models are applied to forecast daily and weekly government bond spreads of Greece, Ireland, Italy, Portugal and Spain over the sample period 2000–2017. The results show that the sine–cosine LSVR is outperforming its counterparts in terms of statistical accuracy, while metaheuristic approaches seem to benefit the parameterization process more than the heuristic ones.",,2019,10.1007/s10479-018-2808-0,,proquest,"This study explores the predictability of European government bond spreads using hybrid Support Vector Regression (SVR) models enhanced with genetic, krill herd, and sine-cosine algorithms. The models were tested on daily and weekly data for Greece, Ireland, Italy, Portugal, and Spain from 2000-2017. The sine-cosine LSVR model demonstrated superior statistical accuracy, suggesting that metaheuristic approaches improve parameterization.",True,True,True,gemini-2.5-flash-lite,Ulrik,M,Unsure about forecasting horizon,2025-10-13T16:02:08.752555
1317143c8a3a95de,Forecasting interest rate swap spreads using domestic and international risk factors: evidence from linear and non-linear models,"This paper explores the ability of factor models to predict the dynamics of US and UK interest rate swap spreads within a linear and a non-linear framework. We reject linearity for the US and UK swap spreads in favour of a regime-switching smooth transition vector autoregressive (STVAR) model, where the switching between regimes is controlled by the slope of the US term structure of interest rates. We compare the ability of the STVAR model to predict swap spreads with that of a non-linear nearest-neighbours model as well as that of linear AR and VAR models. We find some evidence that the non-linear models predict better than the linear ones. At short horizons, the nearest-neighbours (NN) model predicts better than the STVAR model US swap spreads in periods of increasing risk conditions and UK swap spreads in periods of decreasing risk conditions. At long horizons, the STVAR model increases its forecasting ability over the linear models, whereas the NN model does not outperform the rest of the models. Copyright John Wiley & Sons. Reproduced with permission. An electronic version of this article is available online at http://www.interscience.wiley.com",,2007,10.1002/for.1048,,proquest,"This paper investigates the prediction of US and UK interest rate swap spreads using linear and non-linear factor models. A regime-switching smooth transition vector autoregressive (STVAR) model, triggered by the US term structure slope, is found to be superior to linear AR and VAR models, especially at longer horizons. A non-linear nearest-neighbours (NN) model shows better short-term prediction for US swap spreads during increasing risk and UK swap spreads during decreasing risk.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:02:21.473577
4ac39d877a1b7094,Forecasting macroeconomy based on the term structure of credit spreads: Evidence from China,"This article establishes an original methodology to forecast macroeconomy based on the term structure of credit spreads. It combines the traditional Svensson model with genetic algorithms to obtain the interest rate term structures of government bonds and corporate bonds and calculates credit spreads as their differences. And this article defines three factors of the term structure of credit spreads: level, slope and curvature. Based on these three factors and several macroeconomic variables, VAR models are developed and tested to forecast macroeconomic variables. The empirical results confirm that VAR models can predict the changes of China's macroeconomy well, which indicates that the term structure of credit spreads contains information of future changes of macroeconomic variables. We believe this result has significant implications for macroeconomy policy-makers. © 2013 Copyright Taylor and Francis Group, LLC. © 2013 Elsevier B.V., All rights reserved.","Zhou, R.; Wang, X.; Tong, G.",2013,10.1080/13504851.2013.806778,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883325066&doi=10.1080%2F13504851.2013.806778&partnerID=40&md5=eafa30b532af4735b80691807774aefd,scopus,"This study develops a novel method to forecast the macroeconomy using the term structure of credit spreads. It integrates the Svensson model with genetic algorithms to derive term structures for government and corporate bonds, calculating credit spreads. Three factors (level, slope, curvature) from these spreads, along with macroeconomic variables, are used in VAR models for forecasting. Empirical results show these models effectively predict China's macroeconomic changes, suggesting credit spread term structures hold predictive information for policymakers.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:02:32.085349
4eb235a93e4df864,Forecasting market trends with neural networks,"Neural networks are just one of the many technologies that are giving businesses a competitive edge.  Neural networks (NN) are a branch of artificial intelligence which has generated considerable interest across many disciplines during the past few years.  An NN is a nonlinear type of model which receives its inspiration from the neural architecture of the human brain.  Three sample neural networks are presented:  1.  real estate assessment, 2.  credit application evaluation, and 3.  Treasury Bill rate forecasting.",,1999,none,,proquest,"This article discusses the application of neural networks (NNs) as a competitive business tool, drawing inspiration from the human brain's neural architecture. It presents three sample NN applications: real estate assessment, credit application evaluation, and Treasury Bill rate forecasting.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T16:02:45.368920
8459fc80a83ccbd0,Forecasting nonlinear green bond yields in China: Deep learning for improved accuracy and policy awareness,"This study develops a convolutional neural network bidirectional long short-term memory model with an attention mechanism to forecast yields in China's green bond market. The model incorporates macroeconomic indicators, financial variables, policy factors, and issuer heterogeneity to enhance predictive accuracy. Empirical results show the model outperforms traditional approaches in point forecasting. It also offers superior robustness under identical confidence levels, increasing its utility for risk management and policy assessment in green finance. It is a practical tool for regulators, investors, and issuers. © 2025 Elsevier B.V., All rights reserved.","Wang, L.; Wang, Y.; Wang, J.; Yu, L.",2025,10.1016/j.frl.2025.107889,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009696841&doi=10.1016%2Fj.frl.2025.107889&partnerID=40&md5=3f3d8b8a179e9671678fa81f21beab95,scopus,"This study utilizes a deep learning model (CNN-BiLSTM with attention) to forecast yields in China's green bond market, incorporating macroeconomic, financial, policy, and issuer-specific factors. The model demonstrates superior accuracy and robustness compared to traditional methods, offering a practical tool for risk management and policy assessment in green finance.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:02:48.647531
6af741a2238a82fe,"Forecasting realized volatility: HAR against Principal Components Combining, neural networks and GARCH","This paper examines whether nonlinear models, like Principal Components Combining, neural networks and GARCH are more accurate on realized volatility forecasting than the Heterogeneous Autoregressive (HAR) model. The answer is no. The realized volatility property of persistence is too important to leave out of a realized volatility forecasting model. However, the Principal Components Combining model is ranked very close to HAR. Analysis is implemented in seven US financial markets: spot equity, spot foreign exchange rates, exchange traded funds, equity index futures, US Treasury bonds futures, energy futures, and commodities options. © 2016 Elsevier B.V., All rights reserved.","Vortelinos, D.I.",2017,10.1016/j.ribaf.2015.01.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925263796&doi=10.1016%2Fj.ribaf.2015.01.004&partnerID=40&md5=221cb713631134e38331665696f3cf0c,scopus,"This paper compares the forecasting accuracy of nonlinear models (Principal Components Combining, neural networks, GARCH) against the Heterogeneous Autoregressive (HAR) model for realized volatility. The study finds that the HAR model, which captures the persistence property of realized volatility, outperforms the nonlinear models. The analysis covers seven US financial markets. The Principal Components Combining model showed performance close to HAR.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:02:53.776246
547e3e2a7c69aaf4,Forecasting the European Monetary Union equity risk premium with regression trees,"This paper investigates whether classification and regression trees ensemble algorithms such as bagging, random forests and boosting improve on traditional parametric models for forecasting the equity risk premium. In particular, we work with European Monetary Union (EMU) data for the period from its foundation in 2000 to 2020. The paper first compares the monthly out-of-sample forecasting ability of multiple economic and technical variables using univariate linear regression models and regression tree techniques. The results obtained suggest that regression trees do not show better forecasting ability than a first-order autoregressive benchmark model and univariate linear regressions. The paper then analyses asset allocation strategies with regression trees and checks whether these can select the best economic pre-dictors to form dynamic portfolios composed of two assets: a risk-free asset and an equity index. The results indicate that trading strategies built with two or three economic predictors selected with boosting and random forest algorithms can generate economic value for a risk-averse investor with a quadratic utility function. © 2022 Elsevier B.V., All rights reserved.","Cortés-Sánchez, D.; Soriano-Felipe, P.",2022,10.21314/jor.2022.035,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138497197&doi=10.21314%2FJOR.2022.035&partnerID=40&md5=1675b21b61b962828b2cd173adb7b029,scopus,"This paper explores the use of regression tree ensemble algorithms (bagging, random forests, boosting) for forecasting the European Monetary Union's equity risk premium from 2000-2020. It compares their forecasting ability against traditional linear models and analyzes asset allocation strategies. While regression trees did not outperform linear models in forecasting, strategies using predictors selected by boosting and random forest algorithms showed economic value for risk-averse investors.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:03:07.411544
db8470eac8d63910,Forecasting the Volatility of US Oil and Gas Firms With Machine Learning,"Forecasting the realized volatility of oil and gas firms is of interest to investors and practitioners trading on the energy spot and derivative markets. In this paper, we assess whether several machine learning (ML) techniques can offer superior forecasts compared to HAR models for predicting realized volatility at the firm level. Moreover, we investigate whether economically motivated variables and technical indicators contain valuable information for forecasting firm volatility beyond those contained in various volatility factors previously identified in the literature. Our results demonstrate that certain ML techniques provide superior forecasting accuracy compared to the benchmark model. Additionally, we identify variables such as the 1‐month treasury bill and the aggregate VIX index as significant drivers of realized firm volatility in the oil and gas industry.",,2025,10.1002/for.3245,,proquest,"This paper evaluates the effectiveness of machine learning (ML) techniques in forecasting the realized volatility of US oil and gas firms, comparing them against traditional HAR models. It also explores the predictive power of economically motivated variables and technical indicators. The study finds that certain ML methods outperform the benchmark and identifies the 1-month treasury bill and aggregate VIX index as significant predictors of firm volatility.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:03:09.857928
84691e655de528a2,Forecasting the equity risk premium: The role of technical indicators,"Academic research relies extensively on macroeconomic variables to forecast the U.S. equity risk premium, with relatively little attention paid to the technical indicators widely employed by practitioners. Our paper fills this gap by comparing the predictive ability of technical indicators with that of macroeconomic variables. Technical indicators display statistically and economically significant in-sample and out-of-sample predictive power, matching or exceeding that of macroeconomic variables. Furthermore, technical indicators and macroeconomic variables provide complementary information over the business cycle: technical indicators better detect the typical decline in the equity risk premium near business-cycle peaks, whereas macroeconomic variables more readily pick up the typical rise in the equity risk premium near cyclical troughs. Consistent with this behavior, we show that combining information from both technical indicators and macroeconomic variables significantly improves equity risk premium forecasts versus using either type of information alone. Overall, the substantial countercyclical fluctuations in the equity risk premium appear well captured by the combined information in technical indicators and macroeconomic variables. © 2014 Elsevier B.V., All rights reserved.","Neely, C.J.; Rapach, D.E.; Tu, J.; Zhou, G.",2014,10.1287/mnsc.2013.1838,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897701069&doi=10.1287%2Fmnsc.2013.1838&partnerID=40&md5=e863e6e4d1820309d93770b620ce4674,scopus,"This paper investigates the predictive power of technical indicators for the U.S. equity risk premium, comparing them to macroeconomic variables. The findings indicate that technical indicators offer significant in-sample and out-of-sample predictive capabilities, comparable to or better than macroeconomic variables. The study also reveals that combining both types of indicators enhances forecasting accuracy, particularly in capturing cyclical fluctuations of the equity risk premium.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:03:11.559175
43806516a814d135,Forecasting the stock risk premium: A new statistical constraint,"We develop a new statistical constraint to improve the stock return forecasting performance of predictive models. This constraint uses a new objective function that combines the Huber loss function with the Ridge penalty. Out‐of‐sample results indicate that our constraint improves the predictive ability of the univariate models. The constrained univariate models significantly outperform the historical average benchmark model assuming no predictability. The forecast improvement based on the new constraint is also evident for multivariate information methods including forecast combination and diffusion index. The model is capable of capturing time‐varying risk which serves as the potential economic explanation of the improved return predictability. Our results are robust to different evaluation subsamples, validation sample lengths, and different risk aversion coefficients.",,2023,10.1002/for.2984,,proquest,"This paper introduces a novel statistical constraint for stock return forecasting, combining Huber loss and Ridge penalty. The constraint enhances the predictive performance of univariate and multivariate models, outperforming historical averages and capturing time-varying risk. Results are robust across various evaluation settings.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:03:13.674964
c0db7e92ec868ec7,Foreign Residency Rights and Corporate Bond Yield Spreads,"We investigate the effect of ultimate controllers' foreign residency rights on corporate bond yield spreads. Using data on Chinese listed firms from 2010 to 2021, this study reveals a positive association between foreign residency rights and corporate bond yield spreads. The positive relationship is robust across different measures of foreign residency rights, estimation methods and after considering potential endogeneity issues. We propose two potential channels for the positive effect of foreign residency rights on corporate bond yield spreads: increasing firms' earnings management and taking more risk. Further, stronger external governance and internal governance alleviate the positive effects of foreign residency rights on corporate bond yield spreads. Additional analyses indicate that ultimate controllers with overseas residency rights are associated with more bond covenants, higher bank loan spreads and shorter loan maturity. Overall, our results indicate that corporate bondholders are fully aware of the expropriation risk created by controllers' foreign residency rights. Thus, investors and regulators in emerging markets should pay attention to controllers' foreign residency rights. © 2025 Elsevier B.V., All rights reserved.","Su, Z.-Q.; Zhu, Y.; Jin, H.; Wu, M.",2025,10.1002/ijfe.70029,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012620539&doi=10.1002%2Fijfe.70029&partnerID=40&md5=e5ab7afd2b6ee1f120a929042e541067,scopus,"This study examines how the foreign residency rights of ultimate controllers affect corporate bond yield spreads in Chinese listed firms from 2010-2021. It finds a positive association, suggesting increased earnings management and risk-taking. Stronger governance mitigates this effect. The findings highlight that bondholders recognize the expropriation risk associated with these rights, suggesting attention from investors and regulators in emerging markets.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:03:15.630966
11fabc255e24d79e,Functional shocks to inflation expectations and real interest rates and their macroeconomic effects,"This paper applies a recently developed method (Inoue and Rossi, 2021) to estimate functional inflation expectations and ex-ante real interest rate shocks, and then examines their macroeconomic effects in the context of a Functional Vector Autoregressive model with exogenous variables (Functional VARX). Monthly data from January 1998 to May 2023 for the US, the UK and the euro area are used for the analysis. The estimated impulse responses show significant effects of the functional shocks on both inflation and output. In addition, threshold functional local projections indicate that the effects are nonlinear and depend on central bank credibility. Further, inflation expectations shocks have similar effects to supply (demand) ones when they are driven by long-term (short-term) changes. In the presence of an inverted (steepening) real interest rate term structure, the effects are inflationary (deflationary) and expansionary (recessionary). Finally, the responses of inflation, output and the policy rate are driven primarily by the slope and curvature factors of the term structure shocks, which contain important information not captured by traditional scalar shocks.",,2024,10.1007/s10290-024-00538-4,,proquest,"This paper estimates functional inflation expectations and real interest rate shocks using a Functional VARX model with US, UK, and euro area data from 1998-2023. It finds significant macroeconomic effects of these shocks on inflation and output, with nonlinearities dependent on central bank credibility. The study highlights the importance of term structure factors in driving these responses.",True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:03:35.085444
b6874ce0d132be04,"Funding shortages, expectations, and forward rate risk premium",This paper estimates term risk premium and expected future spot rates embedded in Treasury forward rates to study the impact of short-term funding shortages on these quantities. Our approach is consistent with dynamic equilibrium models and avoids the arbitrage-free dynamic inconsistency problems exhibited by traditional methods. We find that short-term funding shortages in money markets affect both expectations of spot rates and forward rate risk premium for all maturity forward rates. The leverage ratio of intermediaries (primary dealers) significantly affects term risk premium but not expectations of future spot rates. Yield curve inversion has no impact on the forward rate curve's evolution.,"Jarrow, Robert; Lamichhane, Sujan",2022,10.1080/14697688.2022.2057352,,wos,"This paper estimates the term risk premium and expected future spot rates from Treasury forward rates, investigating the influence of short-term funding shortages. The methodology aligns with dynamic equilibrium models, circumventing arbitrage-free dynamic inconsistency issues. Findings indicate that funding shortages impact both expectations and risk premiums across all maturities. The leverage ratio of primary dealers influences term risk premium but not future spot rate expectations. Yield curve inversions do not affect the forward rate curve's progression.",False,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:04:08.486384
853f428121b4ba0c,Futures Open Interest and Speculative Pressure Dynamics via Bayesian Models of Long-Memory Count Processes,"In this work, we develop time series regression models for long-memory count processes based on the generalized linear Gegenbauer autoregressive moving average (GLGARMA) framework. We present a comprehensive Bayesian formulation that addresses both in-sample and out-of-sample forecasting within a broad class of generalized count time series regression models. The GLGARMA framework supports various count distributions, including Poisson, negative binomial, generalized Poisson, and double Poisson distributions, offering the flexibility to capture key empirical characteristics such as underdispersion, equidispersion, and overdispersion in the data. We connect the counting process to a time series regression framework through a link function, which is associated with a stochastic linear predictor incorporating the family of long-memory GARMA models. This linear predictor is central to the model's formulation, requiring careful specification of both the GLGARMA Bayesian likelihood and the resulting posterior distribution. To model the stochastic error terms driving the linear predictor, we explore two approaches: parameter-driven and observation-driven frameworks. For model estimation, we adopt a Bayesian approach under both frameworks, leveraging advanced sampling techniques, specifically the Riemann manifold Markov chain Monte Carlo (MCMC) methods implemented via R-Stan. To demonstrate the practical utility of our models, we conduct an empirical study of open interest dynamics in US Treasury Bond Futures. Our Bayesian models are used to forecast speculative pressure, a crucial concept for understanding market behavior and agent actions. The analysis includes 136 distinct time series from the US Commodity Futures Trading Commission (CFTC), encompassing futures-only and futures-and-options data across four US government-issued fixed-income securities. Our findings indicate that the proposed Bayesian GLGARMA models outperform existing state-of-the-art models in forecasting open interest and speculative pressure. These improvements in forecast accuracy directly enhance portfolio performance, underscoring the practical value of our approach for bond futures portfolio construction. This work advances both the methodology for modeling long-memory count processes and its application in financial econometrics, particularly in improving the forecasting of speculative pressure and its impact on investment strategies. © 2025 Elsevier B.V., All rights reserved.","Yan, H.; Peters, G.; Bagnarosa, G.; Chan, J.",2025,10.1002/for.70001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009700778&doi=10.1002%2Ffor.70001&partnerID=40&md5=72ceb973c96f77374b0a2198f1f0c781,scopus,"This paper introduces Bayesian time series regression models for long-memory count processes using the GLGARMA framework. It offers flexibility in count distributions and error term modeling. The models are applied to forecast speculative pressure in US Treasury Bond Futures using CFTC data, demonstrating superior performance over existing models and potential for improved portfolio construction.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T16:04:47.929321
31f65a4ef29b519a,Futures price modeling under exchange rate volatility and its multi-period semi-variance portfolio selection,"Considering the stochastic exchange rate, a four-factor futures model with the underling asset, convenience yield, instantaneous risk-free interest rate and exchange rate, is established. These processes follow jump-diffusion processes (Weiner process and Poisson process). The corresponding partial differential equation (PDE) with terminal boundary condition of the model is drawn. The general solution with parameters of the above PDE is derived. The parameters are estimated by using the weight least squares approach with historical data for special cases. For the objective of risk assessment, downside risk has impacted on the practitioner's view of risk apparently. Variance is substituted by semi-variance. Moreover, one period portfolio selection is extended to multi-period. A class of multi-period semi-variance model is formulated. A hybrid genetic algorithm, which makes use of the position displacement strategy of the particle swarm optimiser as a mutation operation, is applied to solve the multi-period semi-variance model. Finally, in order to demonstrate the effectiveness of the theoretical models and numerical methods, fuel futures in the Shanghai exchange market is selected to be an example. © 2010 Elsevier B.V., All rights reserved.","Yan, W.; Li, S.",2009,10.1080/00207720902985385,https://www.scopus.com/inward/record.uri?eid=2-s2.0-75649121144&doi=10.1080%2F00207720902985385&partnerID=40&md5=76b4efe53044da4e6519f0e46370cf28,scopus,"This paper develops a four-factor futures price model incorporating exchange rate volatility, jump-diffusion processes for asset price, convenience yield, interest rate, and exchange rate. It derives a general solution for the corresponding PDE and estimates parameters using weighted least squares. The study extends portfolio selection to multiple periods using a semi-variance objective and a hybrid genetic algorithm. The model's effectiveness is demonstrated with fuel futures data from the Shanghai exchange.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:04:55.640506
b391e6771a6ea657,G-PINNs: A Bayesian-Optimized GRU-Enhanced Physics-Informed Neural Network for Advancing Short Rate Model Predictions,"Interest rate modeling plays a crucial role in financial risk management, derivative pricing, and economic forecasting. To address the challenges of capturing complex stochastic dynamics, this study proposes a novel Bayesian-Optimized GRU-Enhanced Physics-Informed Neural Network (G-PINNs) architecture, integrated with the Hull–White (HW) short-rate model, to improve the prediction accuracy of yield forecasting, zero-coupon bond (ZCB) pricing, and option pricing. The proposed framework effectively models time dependent variations and stochastic behavior in interest rate dynamics by leveraging Gated Recurrent Units (GRU) for sequential pattern recognition and Physics Informed Neural Networks (PINNs) to enforce financial constraints through partial differential equations (PDEs) of the HW model. For empirical validation, US treasury yield data from April 2020 to March 2025 is utilized. To achieve the best optimal hyperparameters to enhance both predictive accuracy and training efficiency, Bayesian Optimization (BO) is employed for hyperparameter tuning. The proposed model outperforms Vanilla PINNs as evidenced by higher R2 values and reduced error metrics (MAE, MSE, RMSE, Max & Min error, MSLE, Huber loss, MedAE) in yield prediction, ZCB pricing, and option pricing, as indicated by the numerical results. Furthermore, the results are statistically validated through the paired t-test, which confirms that the G-PINNs model's performance improvement is significant and not a consequence of random variation. Also, 5-fold cross-validation is performed to ensure robust and unbiased model evaluation across different data splits. © 2025 Elsevier B.V., All rights reserved.","Rani, I.; Kumar Verma, C.K.",2025,10.1016/j.enganabound.2025.106396,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011519011&doi=10.1016%2Fj.enganabound.2025.106396&partnerID=40&md5=f568c88dee94315797af2ea970c71c42,scopus,"This study introduces G-PINNs, a Bayesian-Optimized GRU-Enhanced Physics-Informed Neural Network, to improve short-rate model predictions for yield forecasting, zero-coupon bond pricing, and option pricing. The model integrates GRU for sequential data and PINNs to enforce financial constraints from the Hull-White model. Using US treasury yield data, G-PINNs demonstrated superior performance over Vanilla PINNs, with statistically significant improvements confirmed by paired t-tests and cross-validation.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T16:05:02.444126
9c9a62d1d4915359,"GDP Forecasting: Machine Learning, Linear or Autoregression?","This paper compares the predictive power of different models to forecast the real U.S. GDP. Using quarterly data from 1976 to 2020, we find that the machine learning K-Nearest Neighbour (KNN) model captures the self-predictive ability of the U.S. GDP and performs better than traditional time series analysis. We explore the inclusion of predictors such as the yield curve, its latent factors, and a set of macroeconomic variables in order to increase the level of forecasting accuracy. The predictions result to be improved only when considering long forecast horizons. The use of machine learning algorithm provides additional guidance for data-driven decision making.","Maccarrone, Giovanni; Morelli, Giacomo; Spadaccini, Sara",2021,10.3389/frai.2021.757864,,wos,"This paper compares the predictive power of machine learning (KNN) and traditional time series models for forecasting real U.S. GDP using quarterly data from 1976-2020. The KNN model outperformed traditional methods, especially for long forecast horizons, and the inclusion of predictors like the yield curve and macroeconomic variables improved accuracy. The study suggests machine learning offers valuable guidance for data-driven decision-making.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:05:22.851271
3495aca6d5866e34,Gaussian scale mixture model for estimating volatility as a function of economic factor,"In this paper the scale mixture of Gaussian distribution is used to model the stock return data in financial market. There are many volatility models and forecasting methods. Some of the models are Historical volatility models, Implied volatility models, Autoregressive Conditional Heteroskedasticity models, models based on Artificial Neural Network. All these models are direct models. In these models the influence of economic factors like price level uncertainty, riskless rate of interest, the equity risk premium and the ratio of expected profit to expected revenue for the economy are not taken into account. Here the volatility parameter 'σ' is treated as a function of an economic factor. The main economic factor considered is the ratio of expected profit to expected revenue. Economic ratio is assumed to follow the exponential distribution. The resultant distribution is fitted to Dow Jones Industrial Average (DJIA) data by estimating the parameters. It is observed that this mixture distribution is a better fit than the GARCH fit. © 2016 Elsevier B.V., All rights reserved.","Seethalakshmi, R.; Saavithri, V.; Vijayabanu, C.",2014,10.5829/idosi.wasj.2014.32.06.783,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975509067&doi=10.5829%2Fidosi.wasj.2014.32.06.783&partnerID=40&md5=0af32d633e8e0428f18b827b74333b0b,scopus,"This paper proposes a Gaussian scale mixture model to estimate stock return volatility, treating volatility as a function of economic factors, specifically the ratio of expected profit to expected revenue. The model is fitted to Dow Jones Industrial Average (DJIA) data and shows a better fit than the GARCH model.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:05:39.396644
246c475ec932cfd5,Global market factors that impact Baltic Dry Index,"The Baltic Dry Index is used as a strategic tool by shipping companies to monitor the daily movement of freight rates for the transportation of bulk cargoes on predetermined routes for the different types of bulk carriers. Therefore, the management of shipping companies pays great attention to the factors that can contribute to the prediction of the price movement of the Baltic Dry Index. Main goal of this paper is to explore if stock market indices of United States of America (S&P 500 stock index) and China (Shanghai stock exchange Composite index), 10 Year bond yield, CRB index, WTI Crude oil and Gold as global market factors, but also as leading macroeconomic global indicators, have impact on movement of BDI. We explored period from January 1, 2003 to December 31, 2021, with monthly data for which the multiple linear regression method was used to analyse mentioned global market factors impact on BDI. The research found that the movement of S&P 500 and SSECI stock indices and CRB index had a positive impact on the movement of BDI, while the movement of Gold and WTI crude oil had negative impact on BDI for the observed period. The scientific contribution of this paper is manifested through observation and exploring relationship of mentioned global market factors with BDI, previous papers observed shorter time period and included macroeconomic indicators which are lagging, together with some global market factors. © 2023 Elsevier B.V., All rights reserved.","Pepur, P.; Peronja, I.; Laća, S.",2022,10.31217/p.36.2.8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144355072&doi=10.31217%2Fp.36.2.8&partnerID=40&md5=477b721368b0945e8012ecc7dd331876,scopus,"This paper investigates the impact of global market factors, including US and Chinese stock indices, bond yields, the CRB index, WTI crude oil, and gold, on the Baltic Dry Index (BDI) from 2003 to 2021. Using multiple linear regression, the study found that S&P 500, SSECI, and CRB index movements positively influenced the BDI, while gold and WTI crude oil had a negative impact. The research contributes by analyzing a longer time period and including global market factors alongside macroeconomic indicators.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:05:43.175630
703481e0f3994ee0,"Good volatility, bad volatility, and the cross section of cryptocurrency returns","This paper examines the predictability of realized volatility measures (RVM), especially the realized signed jumps (RSJ), on future volatility and returns. We confirm the existence of volatility persistence and future volatility is more strongly related to the volatility of past positive returns than to that of negative returns in the cryptocurrency market. RSJ-sorted cryptocurrency portfolios yield statistically and economically significant differences in the subsequent portfolio returns. After controlling for cryptocurrency market characteristics and existing risk factors, the differences remain significant. The investor attention explains the predictability of realized jump risk in future cryptocurrency returns.","Zhang, Zehua; Zhao, Ran",2023,10.1016/j.irfa.2023.102712,,wos,"This paper investigates the predictive power of realized volatility measures, particularly realized signed jumps (RSJ), on future cryptocurrency returns and volatility. It finds that future volatility is more influenced by past positive returns than negative ones, and RSJ-sorted portfolios show significant return differences. Investor attention is identified as a factor explaining this predictability.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:05:45.538886
f274dfa7538c8887,Government Bonds of the CIS Countries: Integration Dynamics of Debt Markets in the Context of External Instability,"The paper examines development specifics of government bond markets in the CIS countries. The sample includes Russia, Kazakhstan, Uzbekistan and Azerbaijan, since only these countries, among the CIS members, possess enough government bonds included in the global debt market. The relevance of the study is due to the increasing financial uncertainty, which attracts attention to relatively reliable means of public debt; the need to understand the functioning of debt markets against the background of anti -Russian sanctions and the increasing influence of the State. The aim of the work is to empirically verify the connectivity, integration and predictability of the government bond markets of Russia, Kazakhstan, Uzbekistan and Azerbaijan. Empirical data include daily refinancing rates of national central banks, indices of total government bond yields, G -spreads of international bonds of the countries in relation to the conditionally risk -free US bond yield curve for 2019-2023. The effects of market development features are divided into local, regional and global, such as the reaction to COVID-19 and anti -Russian sanctions after 2022. We use the following methods: dynamics analysis, correlation, factor and regression analysis. The novelty of the research lies in introducing new empirical data into scientific discourse, testing a methodology that allows us to assess the interaction of monetary policies and the functioning of government bond markets, common features and differences in the behavior of these markets before and after the imposition of sanctions against the Russian financial system. We conclude that the integration of the considered markets within the CIS is violated, which poses risks to the effective economic development of the region. We consider the relatively developed and integrated, but poorly predictable markets of Russia and Kazakhstan. Unlike Russia, Kazakhstan has more connectivity regarding its monetary policy, government bond yields and risks. The yield of Azerbaijan's government bonds is influenced by a more developed market of Kazakhstan, especially in terms of risk assessment, but the market itself is developed poorly. Uzbekistan's market is even less integrated and developed.","Romashkina, G. f.; Andrianov, K. v.; Yukhtanova, Yu. A.",2024,10.15838/esc.2024.2.92.8,,wos,"This study analyzes the government bond markets of Russia, Kazakhstan, Uzbekistan, and Azerbaijan, focusing on their integration and predictability amidst external instability. Using daily data from 2019-2023, including refinancing rates, bond yield indices, and G-spreads, the research employs correlation, factor, and regression analyses to assess market connectivity. Findings indicate a violation of integration within the CIS region, with Russia and Kazakhstan exhibiting relatively developed but poorly predictable markets. Kazakhstan's monetary policy shows greater connectivity than Russia's. Azerbaijan's bond yields are influenced by Kazakhstan's market, though Azerbaijan's market is less developed. Uzbekistan's market is the least integrated and developed. The study highlights the impact of events like COVID-19 and anti-Russian sanctions on these markets.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:05:50.691771
48a52c4662bbacda,"Heterogeneity, dividends and complex dynamics in asset pricing; 投资者异质性、分红与资产价格的复杂动态","A lot of empirical researches have shown that the dividend policy can affect investor trading behaviors and price volatility. Different types of Investors may response differently to the dividend policy. For instance, individual investors are insensitive to the dividend policy, while the institutional investors usually prefer to the stocks with stable dividend. Some studies have provided evidences that the unstable dividend may lead to great fluctuations of stock price. In this paper, we attempt to develop a theoretical model based on investor behaviors, and investigate the impacts of dividend policy on price dynamics. In real financial markets, investors are heterogeneous and have asymmetric information. They make trading decisions based on the information they observe and take different trading strategies. Some investors may buy the stock and care about the dividend. Some others may trade based on the fundamentals of the stock. They estimate the fundamental value and buy the stock when the price is below the fundamental value. In this paper, investors are assumed to be boundedly rational, and their behaviors are modeled with the heterogenous agent model. In the model, we consider two types of trading strategies, i. e., the fundamental strategy and the technical strategy. These strategies reflect the heterogeneous expectations of investors. Investors choose between the two strategies according to their performance. The better performance one strategy has, the higher probability the strategy is chosen. The strategy switching mechanism is expressed by the logit response function. It can also depict the dynamics of investor fractions in the market. The price is generated through the trading behaviors of investors. We model the price adjustment process based on the aggregate excess demand. When the aggregate excess demand is positive, the price increases, and vice versa. In Section 1, we establish the model and derive a nonlinear dynamical system, which can characterize the evolutionary dynamics of stock price and investor structure. As it shows, the dynamical system involves a variety of parameters such as investor risk appetites, the level of bounded rationality, market liquidity, trading costs, dividend, fundamental value, and risk-free rate. Using the analysis of dynamical system, we study the impacts of these factors on asset pricing and volatility. In Section 2, we investigate the equilibrium of the dynamical system with mathematical analysis. In the case with rational and homogeneous investors, the equilibrium price equals to the intrinsic value which is determined by dividends. Furthermore, we solve the equilibrium in the case with bounded rational and heterogeneous investors. The equilibrium price is a weighted average of the estimated fundamental value and the intrinsic value. When the estimated fundamental value is equal to the intrinsic value, the equilibrium price is the same as the rational equilibrium price. We study the difference between the estimated fundamental value and the intrinsic value, and analyze its impacts on asset pricing and investor structure. The fraction of fundamentalists in the market is positively correlated with the absolute difference between the estimated fundamental value and the intrinsic value. Moreover, by using the Schur-Cohn criterion, we solve the stability conditions for the equilibrium. The stability conditions are determined by the parameters such as market liquidity, risk appetites and the deviation of the fundamental value from the intrinsic value. To guarantee the stability conditions, the difference between the estimated fundamental value and the intrinsic value should be neither too great nor too small. In Section 3, the simulation analysis is implemented. Under different parameter settings, we investigate the stability region, the bifurcation diagram and the phase portrait. When the stability conditions are not satisfied, the periodic and chaotic dynamics can be observed. The results of this study can explain the empirical findings of previous literatures. If the dividend policy is unstable, the volatility of dividend is great. Then, according to our study, investors would have less demand for stocks, and fundamentalists would take a small proportion in the market. This reflects institutional investors’ preference for dividend policy. In addition, if the dividend policy is unstable, the estimated fundamental value might deviate greatly from the intrinsic value, and the stability conditions cannot be satisfied. As a result, the price might fluctuate greatly. Then, the market might collapse. The findings provide some significant implications for understanding the complex phenomena in financial markets, making dividends policy and implementing market regulations. When companies formulate dividend policies, they should consider investors′ fundamental valuations of stocks, and should not make dividends too low or too high. In addition, market regulators can take measures to promote the disclosure of information, guide investors to have a reasonable valuation of stocks, so as to reduce market instability. © 2024 Elsevier B.V., All rights reserved.","Qingbin, G.; Diao, D.",2024,10.13587/j.cnki.jieem.2024.03.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193751502&doi=10.13587%2Fj.cnki.jieem.2024.03.004&partnerID=40&md5=3e73a674019bd1a2b77639a59c3d526c,scopus,"This paper develops a theoretical model of asset pricing based on heterogeneous agents with bounded rationality. It investigates the impact of dividend policy on price dynamics, considering two trading strategies: fundamental and technical. The model incorporates factors like investor risk appetites, liquidity, and trading costs. Analysis of the resulting nonlinear dynamical system reveals that unstable dividend policies can lead to increased price volatility and potentially market collapse. The study suggests implications for dividend policy formulation and market regulation.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:06:05.873144
24c473804012a63d,Heterogeneous beliefs with information processing capacity constraints and asset pricing in a monetary economy,"This paper proposes a monetary model to explore the influences of heterogeneous beliefs and information processing capacity constraints on the dynamics of asset prices. The capacity constraints not only influence the estimations of the capacity constrained investor, but also generate persistent disagreements among the investors. The model implies that reducing the levels of capacity constraints can alleviate the influences of heterogeneous beliefs and helps to stabilize financial markets. The model also reveals that introducing heterogeneous beliefs about both real and nominal sectors not only leads the stock with low monetary policy exposure to have significantly higher average return than the stock with high monetary policy exposure, but also can explain the mixed results about the relationship between the volatility and the risk premium of the aggregate stock market.","Wang, Hailong; Hu, Duni",2024,10.1016/j.najef.2024.102143,,wos,This paper develops a monetary model to investigate how heterogeneous beliefs and constraints on information processing capacity affect asset prices. It suggests that these constraints create lasting disagreements among investors and that easing them can stabilize markets. The model also shows that incorporating heterogeneous beliefs about both real and nominal sectors can explain differences in stock returns based on monetary policy exposure and reconcile mixed findings on the relationship between stock market volatility and risk premium.,False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:06:08.886729
983957a87777ab21,How Much Can Machines Learn Finance from Chinese Text Data?,"How much can we learn finance directly from text data? This paper presents a new framework for learning textual data based on the factor augmentation model and sparsity regularization, called the factor-augmented regularized model for prediction (FarmPredict), to let machines learn financial returns directly from news. FarmPredict allows the model itself to extract information directly from articles without predefined information, such as dictionaries or pretrained models as in most studies. Using unsupervised learned factors to augment the predictors would benefit our method with a ""doublerobust""feature: that the machine would learn to balance between individual words or text factors/topics. It also avoids the information loss of factor regression in dimensionality reduction. We apply our model to the Chinese stock market with a large proportion of retail investors by using Chinese news data to predict financial returns. We show that positive sentiments scored by our FarmPredict approach from news generate on average 83 basic points (bps) stock daily excess returns, and negative news has an adverse impact of 26 bps on the days of news announcements, where both effects can last for a few days. This asymmetric effect aligns well with the short-sale constraints in the Chinese equity market. The result shows that the machine-learned prediction does provide sizeable predictive power with an annualized return of 54% at most with a simple investment strategy. Compared with other statistical and machine learning methods, FarmPredict significantly outperforms them on model prediction and portfolio performance. Our study demonstrates the far-reaching potential of using machines to learn text data. © 2024 Elsevier B.V., All rights reserved.","Zhou, Y.; Fan, J.; Xue, L.",2024,10.1287/mnsc.2022.01468,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201264430&doi=10.1287%2Fmnsc.2022.01468&partnerID=40&md5=86523d9245d5c88bd1b6868500e9f558,scopus,"This paper introduces FarmPredict, a novel framework using factor augmentation and sparsity regularization to enable machines to learn financial returns directly from Chinese news text data. Unlike previous methods, FarmPredict extracts information without predefined dictionaries or models. The study demonstrates that positive news sentiment predicts an average of 83 bps daily excess stock returns, while negative news has an adverse impact of 26 bps, with effects lasting several days. The model achieves up to 54% annualized return with a simple strategy and outperforms other statistical and machine learning methods in prediction and portfolio performance, highlighting the potential of machine learning in text data analysis.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:06:25.140751
585f44403016e47b,How do zero-coupon inflation swaps predict inflation rates in the euro area? Evidence of efficiency and accuracy on 1-year contracts,"This paper examines the risk-neutral efficient market hypothesis for inflation swap markets in the euro area from 2005.10 to 2014.07. Overall, we conclude that 1-year zero-coupon inflation swap rates are unbiased predictors of inflation rates. Further, there is no empirical evidence of an inflation risk premium and the assumption of rationality seems to hold. Definitely, these inferences encourage the reading of inflation expectations embedded in short-term inflation swaps. Additionally, we compare the predictive ability of inflation swaps with other measures of inflation expectations. The in-sample results show that, in contrast with surveys, market-based measures are able to accurately forecast inflation rates. In turn, based on an out-of-sample analysis, a straightforward econometric model dominates other sources. Therefore, a combined analysis that uses different sources contributes to a more robust view of future inflation rates.","Ribeiro, Pedro Pires; Curto, Jose Dias",2018,10.1007/s00181-017-1268-8,,wos,"This paper investigates the efficiency and accuracy of 1-year zero-coupon inflation swaps in predicting euro area inflation rates from 2005 to 2014. It finds that these swap rates are unbiased predictors, with no evidence of an inflation risk premium, suggesting rationality in the market. The study also compares inflation swaps with other expectation measures, concluding that market-based measures, particularly through a simple econometric model, offer accurate inflation forecasts.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:06:32.078977
4ad7c5f96fa212c7,How informative are variance risk premium and implied volatility for Value-at-Risk prediction? International evidence,"The aim of this paper is to examine the information embedded in the implied volatility index and the variance risk premium in terms of quantifying market risk for developed and emerging stock markets. The backtesting results indicate that incorporating the relative variance risk premium into the GARCH model, greatly enhances the forecasts of one-day-ahead Value-at-Risk (VaR) for a long trading position in developed markets, while the standard GARCH is the most relevant specification in capturing risk in emerging markets. Results are found to be robust against distressed financial markets and alternative measures of the variance risk premium. Moreover, the empirical evidence shows that the superior performance of these models cannot completely reduce the scope of implied volatility as a risk management tool. Including implied volatility into the GARCH model incurs substantial savings in terms of efficient regulatory capital provisions. (C) 2019 Board of Trustees of the University of Illinois. Published by Elsevier Inc. All rights reserved.","Slim, Skander; Dahmene, Meriam; Boughrara, Adel",2020,10.1016/j.qref.2019.08.006,,wos,"This paper investigates the predictive power of implied volatility and variance risk premium for Value-at-Risk (VaR) in developed and emerging stock markets. It finds that the variance risk premium improves VaR forecasts in developed markets when incorporated into a GARCH model, while the standard GARCH model is sufficient for emerging markets. Implied volatility also proves valuable for risk management and efficient regulatory capital provisions.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:06:36.345209
72c1d3b4cb2ecc1d,How to fly to safety without overpaying for the ticket,"For most active investors treasury bonds (govs) provide diversification and thus reduce the risk of a portfolio. These features of govs become particularly desirable in times of elevated risk which materialize in the form of the flight-To-safety (FTS) phenomenon. The FTS for govs provides a shelter during market turbulence and is exceptionally beneficial for portfolio drawdown risk reduction. However, what if the unsatisfactory expected return from treasuries discourages higher bonds allocations? This research proposes a solution to this problem with Deep Target Volatility Equity-Bond Allocation (DTVEBA) that dynamically allocate portfolios between equity and treasuries. The strategy is driven by a state-of-The-Art recurrent neural network (RNN) that predicts next-day market volatility. An analysis conducted over a twelve year out-of-sample period found that with DTVEBA an investor may reduce treasury allocation by two (three) times to get the same Sharpe (Calmar) ratio and overper-forms the S&P500 index by 43% (115%). © 2023 Elsevier B.V., All rights reserved.","Kaczmarek, T.; Grobelny, P.",2023,10.18559/ebr.2023.2.738,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168003715&doi=10.18559%2Febr.2023.2.738&partnerID=40&md5=234075bf4afac4ab4e8170ed913b55f1,scopus,"This research introduces Deep Target Volatility Equity-Bond Allocation (DTVEBA), a dynamic portfolio allocation strategy between equities and treasuries. It utilizes a recurrent neural network (RNN) to predict market volatility, aiming to improve portfolio risk reduction and returns, outperforming the S&P500 index.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:07:09.264129
6a24a503b3d75e11,"Human health risk assessment for exposure to BTEXN in an urban aquifer using deterministic and probabilistic methods: A case study of Chennai city, India","The aquifer in Tondiarpet, Chennai, had been severely contaminated with petroleum fuels due to an underground pipeline leakage. Groundwater samples were analyzed quarterly for priority pollutants such as benzene, toluene, ethylbenzene, xylenes, and naphthalene (BTEXN) using purge and trap gas chromatography and mass spectrometer from 2016 to 2018. The maximum concentrations of BTEXN in groundwater at the site were found to be greater than the permissible limits significantly. Among the five sampling locations (MW1, MW2, MW3, MW4, and MW5), mean BTEXN levels were found to be higher near MW2, confirming the source location of petroleum leakage. Human health risk assessment was carried out using deterministic and probabilistic methods for exposure to BTEXN by oral and dermal exposure pathways. Risk analysis indicated that mean cancer and non-cancer risks were many times higher than the allowable limits of 1E-06 and 1 respectively in all age groups (children, teens, and adults), implying the adverse health effects. Oral exposure is predominately contributing (60-80%) to the total health risk in comparison to the dermal exposure route. Variability and uncertainty were addressed using the Monte Carlo simulations and the resultant minimum, maximum, 5th, 95th, and mean percentile risks were predicted. Under the random exposure conditions to BTEXN, it was estimated that the risk would become unacceptable for >98.7% of the exposed population. Based on the sensitivity analysis, exposure duration, and ingestion rate are the crucial variables contributing significantly to the health risk. As part of the risk management, preliminary remediation goals for the study site were estimated, which require >99% removal of the BTEXN contamination for risk-free exposures. It is suggested that the residents of Tondiarpet shouldn't utilize the contaminated groundwater mainly for oral ingestion to lower the cancer incidence related to exposure to BTEXN.The aquifer in Tondiarpet, Chennai, had been severely contaminated with petroleum fuels due to an underground pipeline leakage. Groundwater samples were analyzed quarterly for priority pollutants such as benzene, toluene, ethylbenzene, xylenes, and naphthalene (BTEXN) using purge and trap gas chromatography and mass spectrometer from 2016 to 2018. The maximum concentrations of BTEXN in groundwater at the site were found to be greater than the permissible limits significantly. Among the five sampling locations (MW1, MW2, MW3, MW4, and MW5), mean BTEXN levels were found to be higher near MW2, confirming the source location of petroleum leakage. Human health risk assessment was carried out using deterministic and probabilistic methods for exposure to BTEXN by oral and dermal exposure pathways. Risk analysis indicated that mean cancer and non-cancer risks were many times higher than the allowable limits of 1E-06 and 1 respectively in all age groups (children, teens, and adults), implying the adverse health effects. Oral exposure is predominately contributing (60-80%) to the total health risk in comparison to the dermal exposure route. Variability and uncertainty were addressed using the Monte Carlo simulations and the resultant minimum, maximum, 5th, 95th, and mean percentile risks were predicted. Under the random exposure conditions to BTEXN, it was estimated that the risk would become unacceptable for >98.7% of the exposed population. Based on the sensitivity analysis, exposure duration, and ingestion rate are the crucial variables contributing significantly to the health risk. As part of the risk management, preliminary remediation goals for the study site were estimated, which require >99% removal of the BTEXN contamination for risk-free exposures. It is suggested that the residents of Tondiarpet shouldn't utilize the contaminated groundwater mainly for oral ingestion to lower the cancer incidence related to exposure to BTEXN.",,2020,10.1016/j.envpol.2020.114814,,proquest,"This study assesses the human health risks associated with BTEXN contamination in an urban aquifer in Chennai, India, resulting from a petroleum pipeline leak. Groundwater analysis revealed BTEXN concentrations exceeding permissible limits. Both deterministic and probabilistic methods were employed to evaluate cancer and non-cancer risks from oral and dermal exposure across different age groups. The findings indicate significantly elevated risks, with oral exposure being the primary contributor. Monte Carlo simulations were used to address uncertainty, predicting unacceptable risks for over 98.7% of the exposed population under random exposure conditions. Sensitivity analysis identified exposure duration and ingestion rate as key risk factors. Remediation goals suggest over 99% BTEXN removal is needed for safe exposure. Residents are advised against using the contaminated groundwater for oral ingestion.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:07:13.823393
b1f77f14c23e3395,Impact of Wind Electricity Forecasts on Bidding Strategies,"The change in the generation mix from conventional electricity sources to renewables has important implications for bidding behaviour and may have an impact on prices. The main goal of this work is to discover the role played by expected wind production, together with other relevant factors, in explaining the day-ahead market price through a data panel model. The Spanish market, given the huge increase in wind generation observed in the last decade, has been chosen for this study as a paradigmatic example. The results obtained suggest that wind power forecasts are a new key determinant for supply market participants when bidding in the day-ahead market. We also provide a conservative quantification of the effect of such trading strategies on marginal prices at an hourly level for a specific year in the sample. The consequence has been an increase in marginal price to levels higher than what could be expected in a context with notable wind penetration. Therefore, the findings of this work are of interest to practitioners and regulators and support the existence of a wind risk premium embedded in electricity prices to compensate for the uncertainty of wind production.","Ballester, Cristina; Furio, Dolores",2017,10.3390/su9081318,,wos,"This study investigates the impact of wind electricity forecasts on bidding strategies in the Spanish day-ahead electricity market. Using a data panel model, it finds that wind power forecasts are a significant factor for market participants' bidding behavior, leading to higher marginal prices due to a 'wind risk premium' that compensates for production uncertainty.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:07:19.200548
2bf3df700a0b5572,Implied Filtering Densities on the Hidden State of Stochastic Volatility,"Abstract: We formulate and analyse an inverse problem using derivative prices to obtain an implied filtering density on volatility’s hidden state. Stochastic volatility is the unobserved state in a hidden Markov model (HMM) and can be tracked using Bayesian filtering. However, derivative data can be considered as conditional expectations that are already observed in the market, and which can be used as input to an inverse problem whose solution is an implied conditional density on volatility. Our analysis relies on a specification of the martingale change of measure, which we refer to as separability. This specification has a multiplicative component that behaves like a risk premium on volatility uncertainty in the market. When applied to SPX options data, the estimated model and implied densities produce variance-swap rates that are consistent with the VIX volatility index. The implied densities are relatively stable over time and pick up some of the monthly effects that occur due to the options’ expiration, indicating that the volatility-uncertainty premium could experience cyclic effects due to the maturity date of the options. © 2015 Elsevier B.V., All rights reserved.","Fuertes, C.; Papanicolaou, A.",2014,10.1080/1350486x.2014.891357,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926101307&doi=10.1080%2F1350486X.2014.891357&partnerID=40&md5=3c8204565e0f0de1bea8624f18a14859,scopus,"This paper presents an inverse problem using derivative prices to infer an implied filtering density on the hidden state of stochastic volatility. It utilizes a hidden Markov model (HMM) and Bayesian filtering, treating derivative data as observed conditional expectations. The model, when applied to SPX options data, yields variance-swap rates consistent with the VIX index and shows stable implied densities that capture monthly effects related to option expiration, suggesting cyclic effects in the volatility-uncertainty premium.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:07:21.623814
53eaa29638130e5b,Implied volatility surface predictability: The case of commodity markets,"Recent literature seek to forecast implied volatility derived from equity, index, foreign exchange, and interest rate options using latent factor and parametric frameworks. Motivated by increased public attention borne out of the financialization of futures markets in the early 2000s, we investigate if these extant models can uncover predictable patterns in the implied volatility surfaces of the most actively traded commodity options between 2006 and 2016. Adopting a rolling out-of-sample forecasting framework that addresses the common multiple comparisons problem, we establish that, for energy and precious metals options, explicitly modeling the term structure of implied volatility using the Nelson-Siegel factors produces the most accurate forecasts. © 2019 Elsevier B.V., All rights reserved.","Kearney, F.; Shang, H.L.; Sheenan, L.",2019,10.1016/j.jbankfin.2019.105657,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072749898&doi=10.1016%2Fj.jbankfin.2019.105657&partnerID=40&md5=725a9ef86c2c5b30331c554ee665baeb,scopus,"This study investigates the predictability of implied volatility surfaces in commodity markets (energy and precious metals options) between 2006 and 2016. It adapts existing latent factor and parametric frameworks from equity and FX markets, finding that modeling the term structure of implied volatility using Nelson-Siegel factors yields the most accurate out-of-sample forecasts.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:07:31.688839
5f39172024a62f24,Improving CAT bond pricing models via machine learning,"Enhanced machine learning methods provide an encouraging alternative to forecast asset prices by extending or generalizing the possible model specifications compared to conventional linear regression methods. Even if enhanced methods of machine learning in the literature often lead to better forecasting quality, this is not clear for small asset classes, because in small asset classes enhanced machine learning methods may potentially over-fit the in-sample data. Against this background, we compare the forecasting performance of linear regression models and enhanced machine learning methods in the market for catastrophe (CAT) bonds. We use linear regression with variable selection, penalization methods, random forests and neural networks to forecast CAT bond premia. Among the considered models, random forests exhibit the highest forecasting performance, followed by linear regression models and neural networks. © 2020 Elsevier B.V., All rights reserved.","Götze, T.; Gürtler, M.; Witowski, E.",2020,10.1057/s41260-020-00167-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089556740&doi=10.1057%2Fs41260-020-00167-0&partnerID=40&md5=43b235afab54d4b10b4bcae23c45d2d9,scopus,"This study compares the forecasting performance of linear regression models and enhanced machine learning methods (random forests, neural networks) in the market for catastrophe (CAT) bonds. Random forests showed the best forecasting performance, outperforming linear regression and neural networks.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:08:00.774171
8a92241a88c5f917,Improving Quality of Long-Term Bond Price Prediction Using Artificial Neural Networks,"Purpose: The aim of this paper is to propose nonlinear autoregressive neural network which can improve quality of bond price forecasting.Methodology/Approach: Due to the complex nature of market information that influence bonds, artificial intelligence could be accurate, robust and fast choice of bond price prediction method.Findings: Our results have reached a coefficient of determination higher than 95% in the training, validation and testing sets. Moreover, we proposed the nonlinear autoregressive network with external inputs using 50 year interest-rate swaps denominated in EUR and volatility index VIX as two external variables.Research Limitation/Implication: Our sample of daily prices between 4th January 2016 and 13th January 2021 (totally 1,270 trading days) suggest that both Levenberg-Marquardt and Scaled conjugate gradient learning algorithms achieved excellent results.Originality/Value of paper: Despite the fact that both learning algorithms achieved satisfying outcomes, implementation of an independent variable into the autoregressive neural network environment had no significant impact on prediction ability of the model.Category: Research paper","Verner, Robert; Tkac, Michal, Sr.; Tkac, Michal, Jr.",2021,10.12776/qip.v25i1.1532,,wos,"This paper proposes a nonlinear autoregressive neural network to improve long-term bond price forecasting, achieving a coefficient of determination over 95%. The study uses daily bond prices from 2016-2021 and explores the impact of external variables like interest-rate swaps and the VIX index, finding no significant improvement from their inclusion.",True,False,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T16:08:17.943361
17c70911a878167b,Incorporating Markov decision process on genetic algorithms to formulate trading strategies for stock markets,"With the arrival of low interest rates, investors entered the stock market to seek higher returns. However, the stock market proved volatile, and only rarely could investors gain excess returns when trading in real time. Most investors use technical indicators to time the market. However the use of technical indicators is associated with problems, such as indicator selection, use of conflicting versus similar indicators. Investors thus have difficulty relying on technical indicators to make stock market investment decisions. This research combines Markov decision process and genetic algorithms to propose a new analytical framework and develop a decision support system for devising stock trading strategies. This investigation uses the prediction characteristics and real-time analysis capabilities of the Markov decision process to make timing decisions. The stock selection and capital allocation employ string encoding to express different investment strategies for genetic algorithms. The parallel search capabilities of genetic algorithms are applied to identify the best investment strategy. Additionally, when investors lack sufficient money and stock, the architecture of this study can complete the transaction via credit transactions. The experiments confirm that the model presented in this research can yield higher rewards than other benchmarks. © 2017 Elsevier B.V., All rights reserved.","Chang, Y.-H.; Lee, M.-S.",2017,10.1016/j.asoc.2016.09.016,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994403308&doi=10.1016%2Fj.asoc.2016.09.016&partnerID=40&md5=7f450fb3552c013c98635d476b9fe7e5,scopus,"This research proposes a new framework combining Markov decision process and genetic algorithms to develop a decision support system for stock trading strategies. It uses the Markov decision process for timing decisions and genetic algorithms for stock selection and capital allocation, aiming to identify the best investment strategy and achieve higher rewards than benchmarks.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:08:29.290449
049416f83ae200ea,"Indian equity options: Smile, risk premiums, and efficiency","We study the pricing of equity options in India which is one of the world's largest options markets. Our findings are supportive of market efficiency: A parsimonious smile-adjusted Black model fits option prices well, and the implied volatility (IV) has incremental predictive power for future volatility. However, the risk premium embedded in IV for Single Stock Options appears to be higher than in other markets. The study suggests that even a very liquid market with substantial participation of global institutional investors can have structural features that lead to systematic departures from the behavior of a fully rational market while being microefficient.","Jain, Sonali; Varma, Jayanth R.; Agarwalla, Sobhesh Kumar",2019,10.1002/fut.21971,,wos,"This study examines Indian equity options, finding evidence of market efficiency with a Black model fitting prices well and implied volatility predicting future volatility. However, it notes a potentially higher risk premium in Indian Single Stock Options compared to other markets, suggesting that even liquid markets can exhibit systematic deviations from rational behavior.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:08:31.728010
cf9e82b6c1d97962,Industry bubbles and unexpected consumption shocks: A cross-sectional explanation of stock returns under recursive preferences,"Assuming an environment with rational and informed agents, where investors exhibit recursive preferences and make their economic decisions embedding industry bubbles into their information sets, we study to what extent unexpected consumption shocks can proxy for revisions in expected consumption growth and, consequently, explain the cross-sectional behavior of stock returns. Our results show that unexpected consumption shocks help forecast future consumption growth, allowing the Epstein-Zin model to satisfactorily explain the equity risk premium of different anomaly portfolios on the Tokyo Stock Exchange. Furthermore, our model provides a better understanding on the dynamics of consumption and its relationship to stock returns. © 2023 Elsevier B.V., All rights reserved.","Rojo-Suárez, J.; Alonso-Conde, A.B.; Lago-Balsalobre, R.",2024,10.1016/j.iref.2023.07.086,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169004311&doi=10.1016%2Fj.iref.2023.07.086&partnerID=40&md5=d9b4ad7092203f77787e79d262f307c7,scopus,"This study investigates how unexpected consumption shocks can explain the cross-sectional behavior of stock returns within the framework of the Epstein-Zin model, incorporating industry bubbles and recursive preferences. The findings suggest that these shocks are effective predictors of future consumption growth and can account for the equity risk premium across various anomaly portfolios on the Tokyo Stock Exchange, thereby enhancing the understanding of consumption-stock return dynamics.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:08:34.683475
07ccec1141e89737,Institutional investor attention and stock market volatility and liquidity: international evidence,"In this paper, we examine the influence of the daily institutional investor attention to particular stocks on stock volatility and liquidity. The institutional investor attention is measured from the number of times that users of Bloomberg terminal, who are mostly institutional investors, search for or read articles on a specific stock. Relying on a large international dataset of approximately a million daily observations over the period 2011-2020 from nine countries (Canada, France, Germany, Japan, Russia, South Korea, Switzerland, the UK, and the US), we find that this recent measure of institutional investor attention has a strong positive effect on stock volatility and liquidity. Confirmed by a battery of robustness tests, our findings suggest that this continuous barometer of attention by institutional investors can be used by financial practitioners to predict future stock volatility and liquidity.","El Ouadghiri, Imane; Erragragui, Elias; Jaballah, Jamil; Peillex, Jonathan",2022,10.1080/00036846.2022.2036689,,wos,"This study investigates how institutional investor attention, measured by Bloomberg terminal searches, impacts stock market volatility and liquidity across nine countries from 2011-2020. The findings indicate a significant positive relationship, suggesting this attention metric can predict future stock volatility and liquidity.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:08:38.553897
7cad7bb9373c17b7,Integrated methodology for estimating zero-coupon yield curves: Evidence from Turkish government nominal bonds,"This study estimates the zero-coupon yield curves for Turkish government nominal bonds from February 2005 to June 2022 using the Nelson–Siegel–Svensson parametric model. We implement a weighting scheme in the objective function, where squared pricing errors are weighted by the inverse of the square root of the bond duration. This weighting scheme strikes a better balance between the short- and long-maturity bonds during the optimization process. Moreover, by employing four nonlinear optimization algorithms and three parameter initialization approaches, we aim to prevent premature convergence to local optima and improve the quality of fit. Our integrated methodology yields reasonably low in-sample root mean squared error values for price errors and offers clear guidance and a framework for researchers in constructing zero-coupon yield curves. © 2025 Elsevier B.V., All rights reserved.","Paçcı, M.Ü.; Okay, N.",2025,10.1016/j.bir.2025.05.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006716439&doi=10.1016%2Fj.bir.2025.05.003&partnerID=40&md5=89e8caa6f97eab08251fe089078164ce,scopus,This study estimates zero-coupon yield curves for Turkish government nominal bonds from February 2005 to June 2022 using the Nelson–Siegel–Svensson parametric model. It incorporates a novel weighting scheme in the objective function and employs multiple optimization techniques to enhance the accuracy and robustness of the yield curve estimation. The methodology aims to provide a reliable framework for constructing zero-coupon yield curves.,False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:08:54.964481
c98db5fb581ab79d,Integrated prediction of green bond return under the dual risks of climate change and energy crisis,"Prediction of bond return is a classic problem in financial area, providing an important basis for portfolio construction and risk management. The sustainable investment attribute of green bonds has been favored by investors, so that green bonds have become an important component for major asset allocation. However, due to the specific investment focus of green bonds, investors' return expectations are influenced not only by traditional corporate bond factors, but also by related factors such as climate change and energy transition. Against the backdrop of increasingly severe climate risks and the global energy crisis, this paper analyses the volatility characteristics of China's green bonds at multiple time scales, and introduces exogenous variables such as returns of the alternative financial assets, climate risks and returns of energy markets for prediction. Based on the LSTM model, the volatility of green bond yield at different time scales is separately predicted using optimal exogenous variable before integration. It is found that the new integrated prediction model can significantly improve the forecasting performance compared to traditional single LSTM models and simple decomposition-integrated models. Further, both climate risks and energy markets variables have a significant improvement effect on predicting green bond in low-frequency item, while energy markets variables also have a better predictive effect on trend items. Building on the use of only LSTM model, it could be further enhanced by integrating more algorithms to select the best single model for each component, further improve the prediction accuracy and provide a more effective quantitative tool for investment decision-making and risk management in related fields.","Nie, Qimiao; Chen, Siying; Chen, Yiming; Hu, Yiguo",2023,10.3389/fenvs.2023.1336867,,wos,"This paper develops an integrated prediction model for green bond returns, incorporating climate change and energy crisis risks. Using an LSTM model, it analyzes volatility at multiple time scales and integrates exogenous variables like alternative asset returns, climate risks, and energy market returns. The model shows improved forecasting performance compared to traditional methods, with climate and energy variables significantly impacting low-frequency and trend components.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:08:59.477816
6b96cc3b210ad231,Intelligent Optimization Based Multi-Factor Deep Learning Stock Selection Model and Quantitative Trading Strategy,"With the rapid development of financial research theory and artificial intelligence technology, quantitative investment has gradually entered people's attention. Compared with traditional investment, the advantage of quantitative investment lies in quantification and refinement. In quantitative investment technology, quantitative stock selection is the foundation. Without good stock selection ability, the effect of quantitative investment will be greatly reduced. Therefore, this paper builds an effective multi-factor stock selection model based on intelligent optimization algorithms and deep learning and proposes corresponding trading strategies based on this. First of all, this paper selects 26 effective factors of financial indicators, technical indicators and public opinion to construct the factor database. Secondly, a Gated Recurrent Unit (GRU) neural network based on the Cuckoo Search (CS) optimization algorithm is used to build a stock selection model. Finally, a quantitative investment strategy is designed, and the proposed multi-factor deep learning stock selection model based on intelligent optimization is applied to practice to test its effectiveness. The results show that the quantitative trading strategy based on this model achieved a Sharpe ratio of 127.08%, an annualized rate of return of 40.66%, an excess return of 13.13% and a maximum drawdown rate of -17.38% during the back test period. Compared with other benchmark models, the proposed stock selection model achieved better back test performance.","Wang, Jujie; Zhuang, Zhenzhen; Feng, Liu",2022,10.3390/math10040566,,wos,"This paper proposes a multi-factor stock selection model using a GRU neural network optimized by the Cuckoo Search algorithm. The model incorporates 26 factors from financial, technical, and public opinion data. A quantitative trading strategy based on this model demonstrated strong performance in backtesting, outperforming benchmark models.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:09:08.577958
04ea9823b9217dee,Intelligent forecasting in bitcoin markets,"This paper examines the effectiveness of Artificial Intelligence (AI) in predicting Bitcoin's price movements. To achieve this, we developed two distinct trading strategies and compared their performance against each other and the traditional Buy and Hold (B&H) strategy. Over the period from January 2018 to September 2023, we found that the strategy optimized by ChatGPT 01-Preview, which integrates multiple technical indicators and sentiment analysis into a weighted composite index, delivered an exceptional total return of 944.85 %. The second strategy, that is using Extreme Gradient Boosting (XGBoost) technique achieved a total return of 189.05 %. The AI strategy's excess return of 755.8 % over the XGBoost strategy highlights the significant advantage of AI particularly in utilizing diverse data sources, such as social media, to predict Bitcoin's price trends more effectively than relying solely on economic data. Both trading strategies significantly outperformed the traditional B&H strategy, which returned 73.08 % over the same period. Furthermore, we found that AI has an advantage during periods of high Bitcoin price volatility. © 2024 Elsevier B.V., All rights reserved.","Cohen, G.; Aiche, A.",2025,10.1016/j.frl.2024.106487,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209232540&doi=10.1016%2Fj.frl.2024.106487&partnerID=40&md5=73aba1a778a03fbc9a4a154ac9f78596,scopus,"This paper investigates the efficacy of AI in predicting Bitcoin price movements, comparing two AI-driven trading strategies (one using ChatGPT 01-Preview and the other XGBoost) against the Buy and Hold strategy. The ChatGPT-optimized strategy yielded a 944.85% return, significantly outperforming XGBoost (189.05%) and Buy and Hold (73.08%), especially during volatile periods and by integrating diverse data sources like social media.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:13:01.804979
9e2b52f34baf3156,Interest Rate Model With Investor Attitude and Text Mining,"This paper develops and estimates an interest rate model with investor attitude factors, which are extracted by a text mining method. First, we consider two contrastive attitudes (optimistic versus conservative) towards uncertainties about Brownian motions driving economy, develop an interest rate model, and obtain an empirical framework of the economy consisting of permanent and transitory factors. Second, we apply the framework to a bond market under extremely low interest rate environment in recent years, and show that our three-factor model with level, steepening and flattening factors based on different investor attitudes is capable of explaining the yield curve in the Japanese government bond (JGB) markets. Third, text mining of a large text base of daily financial news reports enables us to distinguish between steepening and flattening factors, and from these textual data we can identify events and economic conditions that are associated with the steepening and flattening factors. We then estimate the yield curve and three factors with frequencies of relevant word groups chosen from textual data in addition to observed interest rates. Finally, we show that the estimated three factors, extracted only from the bond market data, are able to explain the movement in stock markets, in particular Nikkei 225 index.",S. Nakatani; K. G. Nishimura; T. Saito; A. Takahashi,2020,10.1109/access.2020.2992477,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9086462,ieeexplore,"This paper develops an interest rate model incorporating investor attitudes derived from text mining. It proposes a three-factor model (level, steepening, flattening) to explain the Japanese government bond yield curve, distinguishing between optimistic and conservative investor attitudes. Text mining of financial news helps identify factors associated with specific economic conditions. The model's factors, derived from bond market data, also show explanatory power for stock market movements, specifically the Nikkei 225 index.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T16:13:16.138063
ae189095c8b70524,Interest rate prediction: a neuro-hybrid approach with data preprocessing,"The following research implements a differential evolution-based fuzzy-type clustering method with a fuzzy inference neural network after input preprocessing with regression analysis in order to predict future interest rates, particularly 3-month T-bill rates. The empirical results of the proposed model is compared against nonparametric models, such as locally weighted regression and least squares support vector machines, along with two linear benchmark models, the autoregressive model and the random walk model. The root mean square error is reported for comparison.","Mehdiyev, Nijat; Enke, David",2014,10.1080/03081079.2014.883386,,wos,"This study proposes a neuro-hybrid model using differential evolution-based fuzzy-type clustering and a fuzzy inference neural network, preceded by regression analysis, to forecast 3-month T-bill interest rates. The model's performance is evaluated against nonparametric and linear benchmark models using root mean square error.",True,False,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T16:13:30.852177
2f9cd73a4b3f546d,Interest rate spreads as predictors of German inflation and business cycles,"We have studied the comparative performance of a number of interest rate spreads as predictors of the German inflation and business cycle in the post-Bretton Woods era. The two-regime Markov-switch model that we used as a nonlinear filter allows the dynamic behavior of the economy to vary between expansions and recessions in terms of duration and volatility. We found that the bank term structure, the public term structure, and the spread based on the call rate predicted all recessions with a comfortable lead, although they lagged some of the recoveries by a few months. The bank-public spread generates a series of false signals, and missed completely the upturn in the mid-1970s, but detected the last two recoveries with an average lead of nearly 12 months. The source of the predictive power of interest rate spreads lies in the information they contain not only about monetary policy, but also about an assortment of general macroeconomic shocks. The filter probabilities from three of the interest rate differentials also foreshadowed the long swings in the German inflation rate remarkably well, with a lead time of 2-4 years without any false signals. © International Institute of Forecasters. © 2017 Elsevier B.V., All rights reserved.","Ivanova, D.; Lahiri, K.; Seitz, F.",2000,10.1016/s0169-2070(99)00029-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0010061067&doi=10.1016%2FS0169-2070%2899%2900029-1&partnerID=40&md5=7b914d1774858e720fa00fff034fe499,scopus,"This study investigates the predictive power of various interest rate spreads for German inflation and business cycles in the post-Bretton Woods era. Using a two-regime Markov-switch model, the research indicates that certain spreads (bank term structure, public term structure, call rate spread) effectively predict recessions, while others show mixed results for recoveries. The predictive ability is attributed to the information these spreads hold about monetary policy and macroeconomic shocks. Additionally, some interest rate differentials accurately foreshadowed long swings in German inflation.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:13:35.839418
ad94029bc09772d2,Introduction to m-m processes,"In this paper, we introduce a new type of nonlinear model, called the min-max model, and analyze its properties for a pair of series. The stability conditions of this system are given for a nonlinearly integrated bivariate series. Under these stability conditions, the difference between the two series exhibits threshold-type nonlinearity. It is possible to construct a threshold error correction model from the min-max processes. Neglected nonlinearity tests are applied, both to the univariate series and to the bivariate system, in order to detect nonlinearity, and it turns out that the tests using the bivariate series have better power. We apply the min-max model to U.S. Treasury bills and commercial paper interest rates. The spread of these interest rates shows threshold-type nonlinearity, and this model outperforms a linear model in terms of its predictability for out-of-sample data. © 2005 Elsevier B.V. All rights reserved. © 2008 Elsevier B.V., All rights reserved.","Granger, C.W.J.; Hyung, N.",2006,10.1016/j.jeconom.2004.09.013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-28244490968&doi=10.1016%2Fj.jeconom.2004.09.013&partnerID=40&md5=9e94f88585e6c3c302b12e0c1abef8a6,scopus,"This paper introduces a novel min-max nonlinear model for analyzing pairs of series, focusing on stability conditions and threshold-type nonlinearity in the difference between series. It demonstrates that this model can be used to construct threshold error correction models and that nonlinearity tests are more powerful when applied to bivariate series. The model is applied to U.S. Treasury bills and commercial paper interest rates, showing its effectiveness in predicting out-of-sample data and outperforming linear models.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:13:48.079015
533240a828b01136,Investor Attention and Stock Returns,"We propose an investor attention index based on proxies in the literature and find that it predicts the stock market risk premium significantly, both in sample and out of sample, whereas every proxy individually has little predictive power. The index is extracted using partial least squares, but the results are similar by the scaled principal component analysis. Moreover, the index can deliver sizable economic gains for mean-variance investors in asset allocation. The predictive power of the investor attention index stems primarily from the reversal of temporary price pressure and from the stronger forecasting ability for high-variance stocks.",,2022,10.1017/s0022109021000090,,proquest,"This study develops an investor attention index using proxies from existing literature. The index, derived through partial least squares or scaled principal component analysis, significantly predicts the stock market risk premium, outperforming individual proxies. It also offers economic benefits for investors in asset allocation, primarily due to the reversal of temporary price pressure and improved forecasting for high-variance stocks.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:13:49.505442
85c477dfff28cf7e,Investor Sentiment and Bond Risk Premia: Evidence from China,"This article shows the statistical signi?cance of a set of variables related to market sentiment and uses them to predict the risk premium embedded in China's sovereign bonds. We construct a composite index of market-wide investor sentiment as a linear combination of proxies for a degree of market participation and risk appetite of investors. Further, we show that these sentiment-related factors can be summarized in a single-return forecasting factor, similar in a spirit of Cochrane and Piazzesi (2005). Our empirical results show that this sentiment factor has predictive power beyond that contained in the yield curve and macroeconomic variables, and this predictability is robust for out-of-sample testing. In addition, the predictive power of the sentiment factor shows relevance during the 2008 global financial crisis, indicating that the forecasting ability of investor sentiment is mainly derived by a sentiment-induced flight-to-quality.","Lee, Kiryoung; Kim, Minki",2019,10.1080/1540496x.2018.1466276,,wos,"This study constructs a composite index of investor sentiment in China's sovereign bond market, combining proxies for market participation and risk appetite. This sentiment index is shown to predict bond risk premia, outperforming traditional yield curve and macroeconomic variables, particularly during the 2008 financial crisis, suggesting a flight-to-quality effect.",False,True,True,gemini-2.5-flash-lite,Ulrik,M,"Abstract not enough to know how investor sentiment was gauged, but 2019",2025-10-13T16:14:38.294924
5c62e0f1a86ccf3e,Investor attention: Can google search volumes predict stock returns?,"This paper investigates the role of investor attention in predicting future stock market returns for Brazilian stocks using Google Search Volume (GSV). We tested whether lagged variations in GSV are followed by changes in excess returns by testing 57 stocks from the Ibovespa using weekly search data from Google Brazil from 2014 to 2018. Similar to previous research on the U.S. market, we found that increases in GSV are followed by lower excess returns. Additionally, we show that the more traded a stock is, the higher the effect. This is consistent with the hypothesis that higher individual investor attention leads to lower subsequent returns, suggesting that increasing popularity causes stock prices to deviate from their fundamental value. © 2021 Elsevier B.V., All rights reserved.","Yoshinaga, C.; Rocco, F.",2020,10.15728/bbr.2020.17.5.3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100415030&doi=10.15728%2Fbbr.2020.17.5.3&partnerID=40&md5=d2051069c272e875c103600f36b929cb,scopus,"This study examines if Google Search Volume (GSV) can predict stock market returns for Brazilian stocks. Using weekly GSV data for 57 Ibovespa stocks from 2014-2018, the research found that increased GSV was followed by lower excess returns, especially for more traded stocks. This supports the idea that high investor attention can cause stock prices to deviate from their fundamental value.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:14:42.690330
3e4b27043ebffa04,Investors' and Central Bank's Uncertainty Embedded in Index Options,"Shocks to equity options' implied volatility are followed by persistently lower short-term rates. Shocks to puts' over calls' out-of-the-money implied volatilities (P/C) are followed by persistently higher rates. Stock and Treasury bond implied volatilities, which measure market and policy uncertainty, are countercyclical, while P/C, which measures downside risk, is procyclical. An equilibrium model in which investors and the central bank learn about composite regimes of economic and policy variables explains these dynamics, linking them to a learning-based, forward-looking Taylor rule. Survey data support our model's predictions on the effect of uncertainty on the level and fluctuations of implied volatilities.","David, Alexander; Veronesi, Pietro",2014,10.1093/rfs/hhu024,,wos,"This paper investigates how investor and central bank uncertainty, as reflected in equity options' implied volatility, influences short-term interest rates. It finds that shocks to implied volatility lead to lower rates, while shocks to the ratio of put to call implied volatilities (P/C) lead to higher rates. The study proposes an equilibrium model incorporating learning about economic and policy variables to explain these dynamics, supported by survey data on uncertainty's impact on implied volatilities.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:14:44.790782
1a7da81a013d9178,Is There an On-the-Run Premium in TIPS?,"In the U.S. Treasury market, the most recently issued, or so-called on-the-run, security typically trades at a price above those of more seasoned but otherwise comparable securities. This difference is known as the on-the-run premium. In this paper, yield spreads between pairs of Treasury Inflation-Protected Securities (TIPS) with both matching and nearly-matching maturities but of separate vintages are analyzed. Adjusting for differences in conventional liquidity premiums, values of embedded deflation options, and coupon rates, the results show a small, insignificant premium on recently issued TIPS, which leads us to conclude that there is no on-the-run premium in the TIPS market.","Christensen, Jens H. E.; Lopez, Jose A.; Shultz, Patrick J.",2020,10.1142/s201013922050007x,,wos,"This paper analyzes yield spreads between Treasury Inflation-Protected Securities (TIPS) of different vintages. After adjusting for liquidity premiums, deflation options, and coupon rates, the study finds a small, insignificant premium on recently issued TIPS, concluding that there is no on-the-run premium in the TIPS market.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:14:52.874233
f4e21d42f7de9c14,Jumps and time-varying correlations in daily foreign exchange rates,"This paper extends the multivariate latent factor ARCH model approach of Diebold and Nerlove (Journal of Applied Econometrics 4 (1989) 1) as a parsimonious alternative that pays particular attention to time series properties of daily foreign exchange rates such as jumps and to changing volatilities in both the common and country-specific factors. Using seven major daily dollar exchange rates from January 1 1992 to December 31 1996, this paper finds evidence of significant time-varying correlations and the country-specific variances. Consistent with the finding of Alexius and Sellin (1997) (A latent factor model of European exchange rate risk premia. Manuscript, The Economic Research Institute, Stockholm School of Economics), the two factor model appears to be a reasonable description of the major exchange rates. © 2001 Elsevier Science Ltd. © 2005 Elsevier Science B.V., Amsterdam. All rights reserved.","Chang, K.-H.; Kim, M.-J.",2001,10.1016/s0261-5606(01)00007-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041825343&doi=10.1016%2FS0261-5606%2801%2900007-9&partnerID=40&md5=fcf9dd0391f4978033d3a52d2a2777fc,scopus,"This paper extends the multivariate latent factor ARCH model to analyze daily foreign exchange rates, focusing on jumps and time-varying volatilities in common and country-specific factors. The study uses seven major dollar exchange rates from 1992-1996 and finds evidence of significant time-varying correlations and country-specific variances, suggesting a two-factor model is a reasonable description of these exchange rates.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:14:57.089816
a0a865e10fc2c0c7,LASSO-Type Penalties for Covariate Selection and Forecasting in Time Series,"This paper studies some forms of LASSO-type penalties in time series to reduce the dimensionality of the parameter space as well as to improve out-of-sample forecasting performance. In particular, we propose a method that we call WLadaLASSO (weighted lag adaptive LASSO), which assigns not only different weights to each coefficient but also further penalizes coefficients of higher-lagged covariates. In our Monte Carlo implementation, the WLadaLASSO is superior in terms of covariate selection, parameter estimation precision and forecasting, when compared to both LASSO and adaLASSO, especially for a higher number of candidate lags and a stronger linear dependence between predictors. Empirical studies illustrate our approach for US risk premium and US inflation forecasting with good results. Copyright © 2016 John Wiley & Sons, Ltd. © 2022 Elsevier B.V., All rights reserved.","Konzen, E.; Ziegelmann, F.A.",2016,10.1002/for.2403,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958818333&doi=10.1002%2Ffor.2403&partnerID=40&md5=2a5fa664844d07fe52cdbc5e3abfda81,scopus,"This paper introduces WLadaLASSO, a novel LASSO-type penalty for time series analysis that enhances covariate selection and forecasting by weighting coefficients and penalizing higher-lagged covariates. It outperforms standard LASSO and adaLASSO in simulations, particularly with many lags and correlated predictors. The method is demonstrated on US risk premium and inflation forecasting.",True,False,True,gemini-2.5-flash-lite,Ulrik,M,,2025-10-13T16:15:07.237392
ec5f21caa1e911a1,Language Models Fine-Tuning for Automatic Format Reconstruction of SEC Financial Filings,"The analysis of financial reports is a crucial task for investors and regulators, especially the mandatory annual reports (10-K) required by the SEC (Securities and Exchange Commission) that provide crucial information about a public company in the American stock market. Although SEC suggests a specific document format to standardize and simplify the analysis, in recent years, several companies have introduced their own format and organization of the contents, making human-based and automatic knowledge extraction inherently more difficult. In this research work, we investigate different Neural language models based on Transformer networks (Bidirectional recurrence-based, Autoregressive-based, and Autoencoders-based approaches) to automatically reconstruct an SEC-like format of the documents as a multi-class classification task with 18 classes at the sentence level. In particular, we propose a Bidirectional fine-tuning procedure to specialize pre-trained language models on this task. We propose and make the resulting novel transformer model, named SEC-former, publicly available to deal with this task. We evaluate SEC-former in three different scenarios: 1) in terms of topic detection performances; 2) in terms of document similarity (TF-IDF Bag-of-words and Doc2Vec) achieved with respect to original and trustable financial reports since this operation is leveraged for portfolio optimization tasks; and 3) testing the model in a real use-case scenario related to a public company that does not respect the SEC format but provides a human-supervised reference to reconstruct it.",G. Lombardo; G. Trimigno; M. Pellegrino; S. Cagnoni,2024,10.1109/access.2024.3370444,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10445214,ieeexplore,"This research explores the use of Transformer-based neural language models, specifically SEC-former, to automatically reconstruct SEC-like financial filing formats. The study investigates Bidirectional, Autoregressive, and Autoencoder approaches, fine-tuning them for a multi-class classification task at the sentence level. The model's performance is evaluated based on topic detection, document similarity, and a real-world use case involving a company with a non-standard format.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:15:10.490946
0bd417484ae81bb2,Likelihood inference for dynamic linear models with Markov switching parameters: on the efficiency of the Kim filter,"The Kim filter (KF) approximation is widely used for the likelihood calculation of dynamic linear models with Markov regime-switching parameters. However, despite its popularity, its approximation error has not yet been examined rigorously. Therefore, this study investigates the reliability of the KF approximation for maximum likelihood (ML) and Bayesian estimations. To measure the approximation error, we compare the outcomes of the KF method with those of the auxiliary particle filter (APF). The APF is a numerical method that requires a longer computing time, but its numerical error can be sufficiently minimized by increasing simulation size. According to our extensive simulation and empirical studies, the likelihood values obtained from the KF approximation are practically identical to those of the APF. Furthermore, we show that the KF method is reliable, particularly when regimes are persistent and sample size is small. From the Bayesian perspective, we show that the KF method improves the efficiency of posterior simulation. This study contributes to the literature by providing evidence to justify the use of the KF method in both ML and Bayesian estimations.","Kim, Young Min; Kang, Kyu Ho",2019,10.1080/07474938.2018.1514027,,wos,"This study evaluates the accuracy of the Kim filter (KF) approximation for dynamic linear models with Markov switching parameters, comparing it to the auxiliary particle filter (APF). The findings indicate that the KF approximation is highly reliable, producing likelihood values virtually identical to the APF, especially when regimes are persistent and sample sizes are small. The research also demonstrates that the KF method enhances the efficiency of posterior simulations in Bayesian estimations, thus justifying its use in both maximum likelihood and Bayesian contexts.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:15:17.197164
dbc0a172a842c869,Likelihood-based specification analysis of continuous-time models of the short-term interest rate,"An extensive collection of continuous-time models of the short-term interest rate is evaluated over data sets that have appeared previously in the literature. The analysis, which uses the simulated maximum likelihood procedure proposed by Durham and Gallant (2002), provides new insights regarding several previously unresolved questions. For single factor models, I find that the volatility, not the drift, is the critical component in model specification. Allowing for additional flexibility beyond a constant term in the drift provides negligible benefit. While constant drift would appear to imply that the short rate is nonstationary, in fact, stationarity is volatility-induced. The simple constant elasticity of volatility model fits weekly observations of the three-month Treasury bill rate remarkably well but is easily rejected when compared with more flexible volatility specifications over daily data. The methodology of Durham and Gallant can also be used to estimate stochastic volatility models. While adding the latent volatility component provides a large improvement in the likelihood for the physical process, it does little to improve bond-pricing performance. (C) 2003 Elsevier B.V. All rights reserved.","Durham, GB",2003,10.1016/s0304-405x(03)00207-1,,wos,"This paper evaluates continuous-time models of short-term interest rates using simulated maximum likelihood. It finds that volatility is more critical than drift for model specification and that a simple constant elasticity of volatility model fits weekly Treasury bill rate data well, but is rejected by daily data. Stochastic volatility models improve likelihood but not bond-pricing performance.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:15:23.020177
23cd22560c926a1e,Limited information-processing capacity and asymmetric stock correlations,"Through an orthogonalized impulse-response analysis, I studied the relationship between the variance risk premium, market variance and stock correlations in the French stock market from September 2002 through September 2006, using high-frequency data-based measures. Variance risk premium is estimated using realized variances and index options-implied variances and used as a state vector to proxy investors perceived uncertainty. I found that a shock to variance risk premium causes long-lasting increases in the market variance pointing to the limitedness of investors information-processing capacity. At the same time, the shock generates consecutive increases in realized correlations between individual stocks and the market portfolio. I propose this as a possible explanation for the asymmetric/counter-cyclic behaviour of stock correlations. © 2019 Elsevier B.V., All rights reserved.","Ceylan, O.",2015,10.1080/14697688.2013.808374,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929133348&doi=10.1080%2F14697688.2013.808374&partnerID=40&md5=4cdf28a6de9803f2ca275da5d8c0647a,scopus,"This study investigates the link between the variance risk premium, market variance, and stock correlations in the French stock market using high-frequency data. The findings suggest that shocks to the variance risk premium lead to prolonged increases in market variance and consecutive rises in stock-market correlations, potentially explaining the asymmetric behavior of stock correlations and highlighting limitations in investors' information processing capacity.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:15:25.634391
1c7ef051f405988d,Linear regression versus backpropagation networks to predict: Quarterly stock market excess returns,"This paper compares a linear model to predict quarterly stock market excess returns to several backpropagation networks. Research findings suggest that quarterly stock market returns are to some extent predictable, but only marginal attention has been paid to possible nonlinearities in the return generating process. The paper discusses input selection, elaborates on how to generate out-of-sample predictions to estimate generalization performance, motivates the choice for a particular network, examines backpropagation training, and evaluates network performance. The out-of-sample predictions are used to calculate several performance metrics, and to determine added value when applying a straightforward tactical asset allocation policy. A nonparametric test is selected to evaluate generalization behavior, and sensitivity analysis examines the selected network's qualitative behavior. Strong nonlinear effects appear to be absent, but the proposed backpropagation network generates an asset allocation policy that outperforms the linear model. © 1996 Kluwer Academic Publishers. © 2018 Elsevier B.V., All rights reserved.","Hiemstra, Y.",1996,10.1007/bf00115692,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0043266837&doi=10.1007%2FBF00115692&partnerID=40&md5=44c0893012d125f91ad203a8be14cb41,scopus,"This paper compares linear models with backpropagation networks for predicting quarterly stock market excess returns. While strong nonlinear effects were not found, the backpropagation network outperformed the linear model in an asset allocation policy. The study discusses input selection, out-of-sample prediction, network training, and performance evaluation.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:15:28.920105
b7b3d42a192ae0ce,Linear-price term structure models,"We characterize the term structure models in which the zero-coupon prices are linear functions of underlying factors. These models are called Linear-price Term Structure Models (LTSM). We provide two types of LTSM where the observable factors predict regimes which are not observed by the investor. These hidden regimes are represented by a Markov chain, which features either an exogenous, or an endogenous dynamics. We illustrate the possible term structure patterns, their evolutions, in particular their ability to stay close to a zero lower bound. © 2013 Elsevier B.V. © 2023 Elsevier B.V., All rights reserved.","Gouriéroux, C.; Monfort, A.",2013,10.1016/j.jempfin.2013.07.004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883523553&doi=10.1016%2Fj.jempfin.2013.07.004&partnerID=40&md5=e34fe3bdc2f523b56b4b64e14ceb551c,scopus,"This paper introduces Linear-price Term Structure Models (LTSM) where zero-coupon prices are linear functions of underlying factors. It presents two types of LTSM with unobserved Markov chain regimes (exogenous or endogenous dynamics) and illustrates term structure patterns, their evolution, and their ability to approach a zero lower bound.",False,True,True,gemini-2.5-flash-lite,Ulrik,M,Maybe not ML enough?,2025-10-13T16:16:12.405863
28798acb3ba870d9,Local lagged adapted generalized method of moments: An innovative estimation and forecasting approach and its applications,"In this work, an attempt is made to apply the Local Lagged Adapted Generalized Method of Moments (LLGMM) to estimate state and parameters in stochastic differential dynamic models. The development of LLGMM is motivated by parameter and state estimation problems in continuous-time nonlinear and non-stationary stochastic dynamic model validation problems in biological, chemical, engineering, energy commodity markets, financial, medical, military, physical sciences and social sciences. The byproducts of this innovative approach (LLGMM) are the balance between model specification and model prescription of continuous-time dynamic process and the development of discrete-time interconnected dynamic model of local sample mean and variance statistic process (DTIDMLSMVSP). Moreover, LLGMM is a dynamic non-parametric method. The DTIDMLSMVSP is an alternative approach to the GARCH(1,1) model, and it provides an iterative scheme for updating statistic coefficients in a system of generalized method of moment/observation equations. Furthermore, applications of LLGMM to energy commodities price, U.S. Treasury Bill interest rate and the U.S.-U.K. foreign exchange rate data strongly exhibit its unique role, scope and performance, in particular, in forecasting and confidence-interval problems in applied statistics. © 2019 Elsevier B.V., All rights reserved.","Otunuga, O.M.; Ladde, G.S.; Ladde, N.G.",2019,10.1515/jtse-2016-0024,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060695794&doi=10.1515%2Fjtse-2016-0024&partnerID=40&md5=40c6e24628aa2141e4d8b7306439ce99,scopus,"This paper introduces the Local Lagged Adapted Generalized Method of Moments (LLGMM), a novel non-parametric approach for estimating states and parameters in continuous-time nonlinear and non-stationary stochastic dynamic models. LLGMM is presented as an alternative to GARCH(1,1) for modeling local sample mean and variance statistics and offers an iterative scheme for updating coefficients. The method's effectiveness is demonstrated through applications in energy commodities prices, U.S. Treasury Bill interest rates, and U.S.-U.K. foreign exchange rates, particularly highlighting its performance in forecasting and confidence interval estimation.",True,True,True,gemini-2.5-flash-lite,Ulrik,M,Maybe not ML enough?,2025-10-13T16:17:17.426872
2097fbf52b7eeb1d,Long-range facility planning based on dynamic programming for optimum combined cost and probability paths,"Dynamic programming (DP)-based planning algorithms have been shown to be valuable tools since they provide a basis for sampling, enumeration, and optimization of options for long-range deployment of facilities. Previous applications of DP to optimize pipeline long-range facility planning problems based on either the least-cost path for the facility or the most-probable path for noncost constraints have been documented in the literature. Such applications, however, are faced with a challenge in selecting the optimum facility deployment path, as the least-cost path does not always necessarily coincide with the most-probable path. As a result, the selection of a path that combines both features has to be achieved through a subjective compromise and in a rather arbitrary manner. In the present paper, two new DP methods have been developed which are based on the concept of combining cost and probability to give a single-objective probability-adjusted cost. One method incorporated the probability of each arc in the DP architecture using a variation of the Black-Scholes partial differential equation. The solution of the resulting equation gave a probability-adjusted arc cost dependent on the year (or stage) the cost incurred, the overall probability of all constraints associated with this arc, and the risk-free rate. The other method was based on simply dividing the present value of each arc cost by its probability to give a single probability-adjusted cost. Both approaches were applied to a complex DP architecture composed of 10 stages and 10 different options at each stage in which all options were available at every stage in a directed manner. The optimum paths from the new approaches were compared to the least-cost options, and most-probable options, and were found to combine the two features. Finally, all options from all methods were found to lie on a Pareto front obtained from a multiobjective genetic algorithm. © 2010 ASCE. © 2011 Elsevier B.V., All rights reserved.","Botros, K.K.; Tchir, W.J.; Henderson, J.F.; Chmilar, B.",2010,10.1061/(asce)ps.1949-1204.0000052,https://www.scopus.com/inward/record.uri?eid=2-s2.0-82355181547&doi=10.1061%2F%28ASCE%29PS.1949-1204.0000052&partnerID=40&md5=3cd46f312ce4b7a4fd1f3059e79dc975,scopus,"This paper presents two novel dynamic programming (DP) methods for long-range facility planning that combine cost and probability into a single objective. These methods address the limitation of previous DP approaches that focused solely on least-cost or most-probable paths. The first method integrates arc probabilities into the DP framework using a Black-Scholes equation variation, yielding a probability-adjusted arc cost. The second method calculates probability-adjusted arc cost by dividing arc cost by its probability. Both methods were tested on a complex DP architecture and demonstrated the ability to find paths that balance cost and probability, outperforming methods that consider only one factor. The results were also compared to a multiobjective genetic algorithm, showing the optimized paths lie on the Pareto front.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:17:21.004098
08bba97ee6005b87,MARKET MANIPULATION: A SURVEY,"Despite the significant attention that market manipulation has received in recent years many aspects of it are poorly understood. This article identifies from the theoretical and empirical literature what we do and do not know about market manipulation, and suggests directions for future research. We know that manipulation is possible and that it occurs in a wide variety of markets and circumstances. In contrast, we know little about how often manipulation occurs, its effects and how it responds to regulation. Suggested approaches for future research on these issues include: (1) collecting more comprehensive data sets of manipulation cases; (2) using detection controlled estimation methods to overcome sample selection and partial observability problems and (3) conducting controlled experiments. This article also constructs a novel and broad taxonomy of the different types of market manipulation and discusses approaches to defining manipulation.","Putnins, Talis J.",2012,10.1111/j.1467-6419.2011.00692.x,,wos,"This survey paper reviews the literature on market manipulation, identifying what is known and unknown about its occurrence, effects, and regulatory responses. It proposes future research directions, including data collection, advanced estimation methods, and controlled experiments, and offers a taxonomy of manipulation types.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:17:22.744131
a4339a705a7fa1f2,Machine learning models and cost-sensitive decision trees for bond rating prediction,"Since the outbreak of the financial crisis, the major global credit rating agencies have implemented significant changes to their methodologies to assess the sovereign credit risk. Therefore, bond rating prediction has become an interesting potential for investors and financial institutions. Previous research studies in this field have applied traditional statistical methods to develop models which provide prediction accuracy. However, no overall distinguished methods have been used in predicting bond ratings. Moreover, recent studies have suggested ensembles of classifiers that may be used in bond rating prediction. This article proposes an improved machine learning aimed to predict the rating of financial bonds. We empirically compare the classifiers ranging from logistic regression and discriminant analysis to nonparametric classifiers, such as support vector machine, neural networks, the cost-sensitive decision tree algorithm and deep neural networks. Three real-world bond rating data sets were selected to check the effectiveness and the viability of the set of the classifiers. The experimental results confirm that data mining methods can represent an alternative to the traditional prediction models of bond rating. © 2020 Elsevier B.V., All rights reserved.","Ben Jabeur, S.B.; Saadaoui, A.; Sghaier, A.; Aloui, R.",2020,10.1080/01605682.2019.1581405,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064715076&doi=10.1080%2F01605682.2019.1581405&partnerID=40&md5=e3791d5826922a1e07d61ea236e0eb79,scopus,"This article proposes an improved machine learning approach for predicting financial bond ratings, comparing various classifiers including logistic regression, support vector machines, neural networks, cost-sensitive decision trees, and deep neural networks. The study uses three real-world bond rating datasets to evaluate the effectiveness of these methods, suggesting that data mining techniques can serve as an alternative to traditional prediction models.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:17:28.302539
592ae86c1ecb9d0b,Macro Factors and Bond Returns in China,"As a central issue in macro-finance studies, the spanning hypothesis has always been the focus of research. Previous studies have focused on whether this hypothesis holds true in developed markets, while paying little attention to that in emerging markets. Because of their unique monetary systems, governments in most emerging markets play a key role in bond returns. This study identifies macroeconomic factors for forecasting excess returns in emerging government bond markets under spanning hypothesis. We find that in previous research, government intervention factors employed in excess returns forecasting have no additional predictive ability, as they are already incorporated in current yields. Using dynamic factor analysis, we find that macroeconomic information, including pure macroeconomic activities and financial factors, has robust incremental predictive power for in-sample and out-of-sample bond excess returns. © 2022 Elsevier B.V., All rights reserved.","Li, X.; Yang, B.; Su, Y.; Qi, Y.; An, Y.",2022,10.1080/1540496x.2021.1941860,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109852085&doi=10.1080%2F1540496X.2021.1941860&partnerID=40&md5=4b6119268539038cc29dbe316dc7106a,scopus,"This study investigates the spanning hypothesis in emerging government bond markets, identifying macroeconomic factors that forecast excess returns. It finds that while government intervention factors are already incorporated in current yields, macroeconomic activities and financial factors demonstrate robust incremental predictive power for bond excess returns, both in-sample and out-of-sample.",False,True,True,gemini-2.5-flash-lite,Ulrik,M,How is identification done? Check for ML outside abstract,2025-10-13T16:17:50.554855
0798f3bbdbaff551,Macroeconomic Models for Monetary Policy: A Critical Review from a Finance Perspective,"We provide a critical review of macroeconomic models used for monetary policy at central banks from a finance perspective. We review the history of monetary policy modeling, survey the core monetary models used by major central banks, and construct an illustrative model for those readers who are unfamiliar with the literature. Within this framework, we highlight several important limitations of current models and methods, including the fact that local-linearization approximations omit important nonlinear dynamics, yielding biased impulse-response analysis and parameter estimates. We also propose new features for the next generation of macrofinancial policy models, including a substantial role for the financial sector, the government balance sheet, and unconventional monetary policies; heterogeneity, reallocation, and redistribution effects;the macroeconomic impact of large nonlinear risk premium dynamics; time-varying uncertainty; financial sector and systemic risks; imperfect product market and markups; and further advances in solution, estimation, and evaluation methods for dynamic quantitative structural models. © 2020 Elsevier B.V., All rights reserved.","Dou, W.W.; Lo, A.W.; Muley, A.; Uhlig, H.",2020,10.1146/annurev-financial-012820-025928,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097430621&doi=10.1146%2Fannurev-financial-012820-025928&partnerID=40&md5=6c6933942ee847d97a6763f19dbc34d1,scopus,"This paper critically reviews macroeconomic models used for monetary policy by central banks, focusing on their limitations from a finance perspective. It highlights issues with local-linearization approximations and proposes enhancements for future models, including a greater role for the financial sector, government balance sheet, unconventional policies, heterogeneity, and nonlinear risk dynamics.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:17:58.579346
f8d976b8b744af6c,"Macroeconomic attention, economic policy uncertainty, and stock volatility predictability","This study adopts the newly constructed macroeconomic attention indices (MAI) and category-specific economic policy uncertainty (EPU) indices to predict stock volatility. Principal component analysis (PCA), scaled PCA (sPCA), and partial least squares (PLS) are used to extract the principal components from indicators. The results show that the combination of MAI and EPU indices can obtain additional information for predicting stock market volatility. In addition, the comprehensive index containing all indicator information (F-t(All)) has the strongest short-term forecasting ability, whereas the MAI show the most substantial forecasting ability in long-term forecasting.","Ma, Feng; Guo, Yangli; Chevallier, Julien; Huang, Dengshi",2022,10.1016/j.irfa.2022.102339,,wos,"This study uses macroeconomic attention indices (MAI) and economic policy uncertainty (EPU) indices to predict stock volatility. It employs Principal Component Analysis (PCA), scaled PCA (sPCA), and Partial Least Squares (PLS) for component extraction. The findings indicate that combining MAI and EPU improves stock market volatility prediction. A comprehensive index (F-t(All)) shows strong short-term forecasting ability, while MAI demonstrates superior long-term forecasting power.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:18:09.088371
8e03ef7073e5ba57,Markov switching models in empirical finance,"I review the burgeoning literature on applications of Markov regime switching models in empirical finance. In particular, distinct attention is devoted to the ability of Markov Switching models to fit the data, filter unknown regimes and states on the basis of the data, to allow a powerful tool to test hypotheses formulated in light of financial theories, and to their forecasting performance with reference to both point and density predictions. The review covers papers concerning a multiplicity of subfields in financial economics, ranging from empirical analyses of stock returns, the term structure of default-free interest rates, the dynamics of exchange rates, as well as the joint process of stock and bond returns. Copyright © 2011 by Emerald Group Publishing Limited. © 2013 Elsevier B.V., All rights reserved.","Guidolin, M.",2011,10.1108/s0731-9053(2011)000027b004,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872420543&doi=10.1108%2FS0731-9053%282011%29000027B004&partnerID=40&md5=f6c892890a65c56195475aa0f9c3021c,scopus,"This paper reviews the application of Markov regime switching models in empirical finance, focusing on their ability to fit data, filter regimes, test hypotheses, and their forecasting performance for stock returns, interest rates, exchange rates, and joint stock/bond returns.",True,True,True,gemini-2.5-flash-lite,Ulrik,Review,,2025-10-13T16:18:24.087982
3a1e5fe8c3d33851,Maximum likelihood estimation of non-affine volatility processes,"In this paper we develop a new estimation method for extracting non-affine latent stochastic volatility and risk premia from measures of model-free realized and risk-neutral integrated volatility. We estimate non-affine models with nonlinear drift and constant elasticity of variance and we compare them to the popular square-root stochastic volatility model. Our empirical findings are: (1) the square-root model is misspecified; (2) the inclusion of constant elasticity of variance and nonlinear drift captures stylized facts of volatility dynamics and (3) the square-root stochastic volatility model is explosive under the risk-neutral probability measure. All rights reserved, Elsevier",,2011,10.1016/j.jempfin.2010.10.006,,proquest,"This paper introduces a novel method for estimating non-affine latent stochastic volatility and risk premia using realized and risk-neutral integrated volatility measures. The study compares non-affine models with constant elasticity of variance and nonlinear drift against the square-root stochastic volatility model, finding the latter to be misspecified and potentially explosive under the risk-neutral measure. The proposed models better capture volatility dynamics.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:18:28.184785
6e7428a05a102988,"Measurement error, skewness, and risk analysis: Coping with the long tail of the distribution","Probabilistic risk analyses often construct multistage chance trees to estimate the joint probability of compound events. If random measurement error is associated with some or all of the estimates, we show that resulting estimates of joint probability may be highly skewed. Joint probability estimates based on the analysis of multistage chance trees are more likely than not to be below the true probability of adverse events, but will sometimes substantially overestimate them. In contexts such as insurance markets for environmental risks, skewed distributions of risk estimates amplify the ""winner's curse"" so that the estimated risk premium for low-probability events is likely to be lower than the normative value. Skewness may result even in unbiased estimators of expected value from simple lotteries, if measurement error is associated with both the probability and pay-off terms. Further, skewness may occur even if the error associated with these two estimates is symmetrically distributed. Under certain circumstances, skewed estimates of expected value may result in risk-neutral decisionmakers exhibiting a tendency to choose a certainty equivalent over a lottery of equal expected value, or vice versa. We show that when distributions of estimates of expected value are positively skewed, under certain circumstances it will be optimal to choose lotteries with nominal values lower than the value of apparently superior certainty equivalents. Extending the previous work of Goodman (1960), we provide an exact formula for the skewness of products. © 2008 Elsevier B.V., All rights reserved.","Mumpower, J.L.; McClelland, G.",2002,10.1111/0272-4332.00027,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036093310&doi=10.1111%2F0272-4332.00027&partnerID=40&md5=e208b86abcf5d91cfe313e6fa5828657,scopus,"This paper discusses how measurement error in probabilistic risk analyses can lead to skewed estimates of joint probabilities, particularly for low-probability events. It explains that these skewed estimates can affect decision-making in contexts like insurance markets and can even cause risk-neutral individuals to make suboptimal choices. The authors provide a formula for calculating the skewness of products, extending previous work.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:18:30.163269
97f84ada8039939e,Measuring ESG risk premia with contingent claims,"We propose a contingent claims approach for estimating ESG risk premia from market information and market participants' decisions. To this end, we infer the asset value dynamics via the structural model of Merton [1974, On the Pricing of Corporate Debt: The Risk Structure of Interest Rates. Journal of Finance 29: 449-470.] for a large panel of S&P 500 firms using an estimation algorithm that utilizes the information embedded in stock market prices, CDS spreads, and default probabilities. We find a statistically significant relationship between the ESG score and the volatility and drift terms of the asset value process, suggesting that ESG factors are structurally connected to the value of the firm. We establish a mapping between ESG scores and the cost of equity and debt as implied by firm's contingent claims, and derive estimates of the ESG risk premium across different ESG and leverage profiles. In addition, we break down the ESG risk premia by industry, and demonstrate how practitioners can adjust the weighed average cost of capital of ESG laggard firms for valuation and decision making purposes.","Michopoulos, Ioannis; Bougias, Alexandros; Episcopos, Athanasios; Livanis, Efstratios",2025,10.1080/1351847x.2024.2394550,,wos,"This paper proposes a contingent claims approach to estimate ESG risk premia using market data and participant decisions. It applies Merton's structural model to S&P 500 firms, incorporating stock prices, CDS spreads, and default probabilities. The study finds a link between ESG scores and asset value dynamics, implying ESG factors influence firm value. It derives ESG risk premia and shows how to adjust the cost of capital for ESG laggard firms.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:18:31.625366
50f2b2d275365f3b,Measuring Economic Uncertainty in China†,"This study develops a new economic uncertainty (EU) index based on Chinese newspapers to address the media coverage bias of existing measures. We investigate how the EU affects China’s macroeconomy. Our results suggest that the EU reduces aggregate output. We find that uncertainty predicts fluctuations in economic activity and actual economic activity also predicts EU, but nonlinearly. Furthermore, we show that uncertainty in the United States leads to uncertainty in China, implying that negative EU on the Chinese economy is coming from the U.S. Finally, we conduct some asset-pricing tests, showing that EU can predict stock returns and commands risk premium. Our results are helpful for both researchers and policymakers to stabilize the economy and financial markets in China. © 2022 Elsevier B.V., All rights reserved.","Pan, W.-F.; Wang, X.; Wang, S.",2022,10.1080/1540496x.2021.1873764,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100533968&doi=10.1080%2F1540496X.2021.1873764&partnerID=40&md5=0e68f4835371abb9317f7969560367ff,scopus,"This study introduces a new economic uncertainty (EU) index for China, derived from newspaper coverage, to mitigate biases in existing measures. It examines the impact of this EU index on China's macroeconomy, finding that increased uncertainty reduces aggregate output. The research also reveals that uncertainty predicts economic activity, and vice versa, with a nonlinear relationship. Additionally, it demonstrates a spillover effect from US uncertainty to China, suggesting external factors influence China's economic uncertainty. The study further explores the predictive power of EU on stock returns and its associated risk premium, offering insights for economic and financial market stabilization.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:18:44.630961
a0ae28c3f6db31b0,Measuring contagion effects between crude oil and Chinese stock market sectors,"The role of cross-market linkages in the occurrence of tail events in stock and energy markets has not yet been fully understood in the contagion literature. This paper investigates the contagion from oil prices to Chinese stock sectors by considering differences between extreme positive returns and extreme negative returns. We compute time-varying cut-offs by employing a generalized Pareto distribution (GPD) function to estimate excess returns. We then use a multinomial logit (MNL) model to examine the probability of Chinese stock sector co-exceedances associated with oil price exceedances. Our results indicate that, compared to common domestic factors, the contagion between oil price and stock sectors is relatively weak, but never negligible. We argue that faced with volatile oil prices during turbulent periods, the existence of any contagion weakens the benefits of portfolio diversification related to oil and Chinese stock sector investment. Based on our findings, investors holding a portfolio of oil and Chinese sector stocks should pay special attention to the extreme changes in crude oil prices and adopt hedging measures to protect their portfolio from extreme shocks to oil markets. © 2018 Elsevier B.V., All rights reserved.","Fang, S.; Egan, P.",2018,10.1016/j.qref.2017.11.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034079456&doi=10.1016%2Fj.qref.2017.11.010&partnerID=40&md5=d7590a7aff8c4cc31d0bc45a65327a35,scopus,"This paper investigates the contagion effects between crude oil prices and Chinese stock market sectors, distinguishing between extreme positive and negative returns. Using a generalized Pareto distribution (GPD) to estimate excess returns and a multinomial logit (MNL) model to analyze co-exceedances, the study finds that contagion is relatively weak but present. The authors suggest that investors should be aware of extreme oil price changes and consider hedging strategies.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:18:46.116884
19c588a05711d2d3,Measuring the Level and Uncertainty of Trend Inflation,"Firmly anchored inflation expectations are widely viewed as playing a central role for the conduct of monetary policy. This paper presents estimates of trend inflation, based on information contained in monthly data on realized inflation, survey expectations, and the term structure of interest rates. In order to assess whether inflation expectations are anchored, a timevarying volatility of trend shocks is estimated as well. While there is some commonality in inflation- and survey-based estimates of trend inflation, yield-based trend estimates embed a highly persistent component orthogonal to trend inflation. Trimmed-mean inflation rates and survey forecasts are most indicative of trend inflation.","Mertens, Elmar",2016,10.1162/rest_a_00549,,wos,"This paper estimates trend inflation using monthly data on realized inflation, survey expectations, and the term structure of interest rates. It also estimates time-varying volatility of trend shocks to assess inflation expectations anchoring. Trimmed-mean inflation rates and survey forecasts are found to be most indicative of trend inflation, while yield-based estimates include a persistent component orthogonal to trend inflation.",False,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:18:59.646176
e60825a4816e6116,Medical Extended Reality for Radiology Education and Training,"Medical extended reality (MXR), encompassing augmented reality, virtual reality, and mixed reality (MR), presents a novel paradigm in radiology training by offering immersive, interactive, and realistic learning experiences in health care. Although traditional educational tools in the field of radiology are essential, it is necessary to capitalize on the innovative and emerging educational applications of extended reality (XR) technologies. At the most basic level of learning anatomy, XR has been extensively used with an emphasis on its superiority over conventional learning methods, especially in spatial understanding and recall. For imaging interpretation, XR has fostered the concepts of virtual reading rooms by enabling collaborative learning environments and enhancing image analysis and understanding. Moreover, image-guided interventions in interventional radiology have witnessed an uptick in XR utilization, illustrating its effectiveness in procedural training and skill acquisition for medical students and residents in a safe and risk-free environment. However, there remain several challenges and limitations for XR in radiology education, including technological, economic, and ergonomic challenges and and integration into existing curricula. This review explores the transformative potential of MXR in radiology education and training along with insights on the future of XR in radiology education, forecasting advancements in immersive simulations, artificial intelligence integration for personalized learning, and the potential of cloud-based XR platforms for remote and collaborative training. In summation, MXR's burgeoning role in reshaping radiology education offers a safer, scalable, and more efficient training model that aligns with the dynamic healthcare landscape.Medical extended reality (MXR), encompassing augmented reality, virtual reality, and mixed reality (MR), presents a novel paradigm in radiology training by offering immersive, interactive, and realistic learning experiences in health care. Although traditional educational tools in the field of radiology are essential, it is necessary to capitalize on the innovative and emerging educational applications of extended reality (XR) technologies. At the most basic level of learning anatomy, XR has been extensively used with an emphasis on its superiority over conventional learning methods, especially in spatial understanding and recall. For imaging interpretation, XR has fostered the concepts of virtual reading rooms by enabling collaborative learning environments and enhancing image analysis and understanding. Moreover, image-guided interventions in interventional radiology have witnessed an uptick in XR utilization, illustrating its effectiveness in procedural training and skill acquisition for medical students and residents in a safe and risk-free environment. However, there remain several challenges and limitations for XR in radiology education, including technological, economic, and ergonomic challenges and and integration into existing curricula. This review explores the transformative potential of MXR in radiology education and training along with insights on the future of XR in radiology education, forecasting advancements in immersive simulations, artificial intelligence integration for personalized learning, and the potential of cloud-based XR platforms for remote and collaborative training. In summation, MXR's burgeoning role in reshaping radiology education offers a safer, scalable, and more efficient training model that aligns with the dynamic healthcare landscape.",,2024,10.1016/j.jacr.2024.05.006,,proquest,"This review explores the use of Medical Extended Reality (MXR), including AR, VR, and MR, in radiology education and training. It highlights MXR's potential for anatomy learning, imaging interpretation, and interventional radiology procedures, while also acknowledging challenges like technological and integration issues. The review forecasts future advancements such as AI integration and cloud-based platforms for remote training, suggesting MXR offers a safer, scalable, and efficient training model.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:19:01.873783
465b71f382fbc310,Merchant Commodity Storage and Term-Structure Model Error,"Merchant operations involves valuing and hedging the cash flows of commodity- and energy-conversion assets as real options based on stochastic models that inevitably embed model error. In this paper we quantify how empirically calibrated model errors concerning the futures term structure affect the valuation and hedging of natural gas storage. We find that even small model errors-on the order of 1%-2% of the empirical futures price variance-can have a disproportionate impact on storage valuation and hedging. In particular, theoretically equivalent hedging strategies have very different sensitivities to model error, with one natural strategy exhibiting potentially catastrophic performance in the presence of small model errors. We propose effective approaches to mitigate the negative effect of futures term-structure model error on hedging, also taking into account futures contract illiquidity, and provide theoretical justification for some of these approaches. Beyond commodity storage, our analysis has relevance for other real and financial options that depend on futures term-structure dynamics, as well as for inventory, production, and capacity investment policies that rely on demand-forecast term structures.","Secomandi, Nicola; Lai, Guoming; Margot, Francois; Scheller-Wolf, Alan; Seppi, Duane J.",2015,10.1287/msom.2015.0518,,wos,"This paper quantifies the impact of empirically calibrated model errors in futures term structure on the valuation and hedging of natural gas storage. It finds that even small errors can significantly affect storage valuation and hedging, leading to potentially catastrophic performance for certain hedging strategies. The study proposes mitigation approaches and discusses broader relevance for other options and investment policies.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:19:09.232025
048eafcb2e26ee95,Minimax and Biobjective Portfolio Selection Based on Collaborative Neurodynamic Optimization,"Portfolio selection is one of the important issues in financial investments. This article is concerned with portfolio selection based on collaborative neurodynamic optimization. The classic Markowitz mean–variance (MV) framework and its variant mean conditional value-at-risk (CVaR) are formulated as minimax and biobjective portfolio selection problems. Neurodynamic approaches are then applied for solving these optimization problems. For each of the problems, multiple neural networks work collaboratively to characterize the efficient frontier by means of particle swarm optimization (PSO)-based weight optimization. Experimental results with stock data from four major markets show the performance and characteristics of the collaborative neurodynamic approaches to the portfolio optimization problems.",M. -F. Leung; J. Wang,2021,10.1109/tnnls.2019.2957105,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8948344,ieeexplore,"This article presents a neurodynamic optimization approach for portfolio selection, addressing both minimax and biobjective formulations based on Markowitz mean-variance and mean conditional value-at-risk frameworks. It utilizes collaborative neural networks and particle swarm optimization to identify efficient frontiers, with experimental validation on stock market data.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:19:11.354020
43f035f3fb505552,Misaligned expectations and bond term premium measures☆,"This paper shows that inflation expectations and those embedded in short-term interest rate expectations as reported in the Survey of Professional Forecasters show evidence of misaligned expectations. This misalignment seems to have been substantial in recent times, featuring a low correlation between inflation and the policy rate. This empirical evidence motivates an alternative explanation, based on uncertainty rather than risk, of the bond term premium measures found in the literature. This paper estimates an expectational term premium driven by misaligned short-term interest rate expectations from a behavioral DSGE model that introduces model uncertainty by assuming adaptive learning with discretionary beliefs. The estimated 10-year expectational term premium shares important features with the corresponding term premium measures obtained using no-arbitrage affine term structure models. Thus, the expectational term premium is sizable, highly persistent, mildly countercyclical, and highly correlated with those term premium measures in the most recent period studied. In short, a potential misalignment of short-term interest expectations with inflation expectations provides an important channel for explaining the bond premium lately.","Vazquez, Jesus",2025,10.1016/j.najef.2025.102442,,wos,"This paper investigates misaligned inflation and short-term interest rate expectations, particularly in recent times, suggesting this misalignment impacts bond term premium measures. It proposes an alternative explanation based on uncertainty rather than risk, estimating an expectational term premium using a behavioral DSGE model with adaptive learning and discretionary beliefs. The estimated term premium exhibits characteristics similar to those derived from no-arbitrage affine term structure models, indicating its significance, persistence, and countercyclicality, and its correlation with recent term premium measures. The misalignment of short-term interest expectations with inflation expectations is presented as a key factor in explaining recent bond premium behavior.",False,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:19:29.701720
6e6b601cc5aa10eb,Model of corporate bond spread based on improved neural network,"The reasons for credit spreads can be divided into enterprise-specific non-systematic risks and widespread macroeconomic systemic risks. The previous traditional research mainly focused on the perspective of unsystematic risk. However, at present, more and more scholars are beginning to focus on systemic risks. Based on the neural network algorithm, this paper constructs an improved neural network-based corporate bond spread model to explore the impact of macro systemic risks on credit spreads. Based on the multi-factor no-arbitrage model, the linear relationship between the credit spread and the risk premium of each factor is obtained. At the same time, based on previous research results and observations of the current market reality, this paper identifies five important macroeconomic factors: actual economic output factors, inflation factors, stock market volatility factors, stock market return factors and inter-bank funding factors. The research results show that the model constructed in this paper has excellent performance.","Luo, Qiaoshun; Liu, Xinping",2021,10.3233/jifs-189497,,wos,"This paper proposes an improved neural network model to analyze corporate bond spreads, focusing on the impact of macroeconomic systemic risks. It incorporates five key macroeconomic factors and demonstrates the model's strong performance.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:19:34.357920
0e4008aea258c83e,Modeling Health Data Using Machine Learning Techniques Applied to Financial Management Predictions,"Health management has steadily improved in performance and accuracy using IT technology. Hospitals and health institutions hold an enormous number of data in their software applications, which can be used with Big Data methodologies to extract useful information. One of the most challenging aspects of health institutional management is financial management; billing prediction is a key aspect to maintain a predictable service level for patients, avoiding unpleasant surprises and anticipating treasury management. Using patient data from public patient databases and applying a machine learning approach, this article offers a model that helps to make more precise and detailed financial plans.",,2022,10.3390/app122312148,,proquest,This article proposes a machine learning model to improve financial management in healthcare institutions by predicting billing. It utilizes patient data from public databases to create more accurate financial plans.,True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:19:36.022521
a4e215a81aa0f6ae,Modelling and forecasting interest rates during stages of the economic cycle: A knowledge-discovery approach,"Modelling the structure of risk-free rates and their relation to other economic and financial variables during different stages of the economic cycles has attracted much interest from both the theoretical and practical perspectives. The previous literature has emphasized the deployment of expert systems and knowledge-discovery approaches motivated by the need to address the limitations of the econometric models. However, it has failed to address the interpretability aspects and, more importantly, the need to provide methodological support that allows the deployment of such techniques in a more systematic way. This approach entails the definition of a process that includes the usual steps taken by experts to address similar problems and allows the relative merits of different techniques in relation to common goals and objectives to be gauged. This paper addresses the interpretability and the lack of methodological support by proposing a knowledge-discovery methodology that includes a minimal common number of steps to model, analyse, evaluate and deploy different non-linear techniques and models. Furthermore, the interpretability is addressed through the use of open-box techniques, such as decision trees. The proposed methodology helps to discover and describe hidden patterns, allowing for the study and characterization of economic cycles, and economic cycle stages, as well as the description of the historic relationships between interest rates and other relevant economic variables. These patterns can also be used in the forecasting of economic cycle stages, interest rates and other related variables of concern. The output of the methodology can provide actionable information for market agents, such as monetary authorities, financial institutions, and individual investors, as well as for the academic community, to increase further the knowledge and understanding of financial markets, thus enriching and complementing existing financial theories. © 2015 Elsevier B.V., All rights reserved.","Díaz, D.; Theodoulidis, B.; Dupouy, C.",2016,10.1016/j.eswa.2015.09.010,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945251489&doi=10.1016%2Fj.eswa.2015.09.010&partnerID=40&md5=295b07c4bfb60217b7e945fbddbf99e7,scopus,"This paper proposes a knowledge-discovery methodology to model, analyze, evaluate, and deploy non-linear techniques for understanding interest rate behavior across economic cycles. It emphasizes interpretability using open-box methods like decision trees and aims to uncover hidden patterns for forecasting economic cycles and interest rates, providing actionable insights for various market participants and academics.",True,False,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T16:20:44.116606
3e25d963775485c0,Modelling financial time series with threshold nonlinearity in returns and trading volume,"This paper investigates the effect of past returns and trading volumes on the temporal behaviour of international market returns. We propose a class of nonlinear threshold time-series models with generalized autoregressive conditional heteroscedastic disturbances. Using Bayesian approach, an implementation of Markov chain Monte Carlo procedure is used to obtain estimates of unknown parameters. The proposed family of models incorporates changes in log of volumes in the sense of regime changes and asymmetric effects on the volatility functions. The results show that when differences of log volumes are involved in the system of log return and volatility models, an optimum selection can be achieved. In all the five markets considered, both mean and variance equations involve volumes in the best models selected. Our best models produce higher posterior-odds ratios than that in Gerlach et al.'s (Phys. A Statist. Mech. Appl. 2006; 360:422-444) models, indicating that our return-volume partition of regimes can offer extra gain in explaining return-volatility term structure.",,2007,10.1002/asmb.674,,proquest,"This paper proposes and implements a class of nonlinear threshold time-series models to analyze the relationship between past returns, trading volumes, and international market returns. Using a Bayesian approach with Markov chain Monte Carlo, the models incorporate regime changes and asymmetric effects related to trading volume. The findings indicate that including trading volume differences in the models improves the explanation of return-volatility dynamics across five markets.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:20:55.149818
79f5b96bb6a44999,Mortgage prepayment with an uncertain holding period,"A discrete-time-option pricing model is developed to value a mortgage and its embedded prepayment option when the effective life of the mortgage is a random variable with a probability distribution of known parameters. The model can be applied when the borrower's ex ante expectation of his tenure follows any probability distribution bounded to the left at zero. The Gamma distribution is used to illustrate the model.The pricing model is further applied to determine the conditions under which financially motivated prepayment is optimal. The results show that the certainty model understates the Interest Rate Differential needed to justify prepayment (IRD) for short Expected Holding Period (EHP) borrowers and overstates the IRD for long EHP borrowers. When the EHP is relatively long, the certainty model provides relatively good estimates of IRD during the beginning years of the mortgage life. Under most other conditions, the estimates of the certainty holding period model are biased.","Yang, TT; Maris, BA",1996,10.1007/bf00132266,,wos,"This paper develops a discrete-time-option pricing model for mortgages with embedded prepayment options, considering an uncertain borrower holding period. It applies the Gamma distribution to illustrate the model and analyzes conditions for financially motivated prepayment. The model reveals biases in the certainty model's Interest Rate Differential (IRD) estimates, particularly for borrowers with short or long Expected Holding Periods (EHP).",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:20:56.664218
0bb5683df1b01809,Multi-Factor Cox-Ingersoll-Ross Models of the Term Structure: Estimates and Tests from a Kalman Filter Model,"This paper presents a method for estimating multi-factor versions of the Cox-Ingersoll-Ross (1985b) model of the term structure of interest rates. The fixed parameters in one, two, and three factor models are estimated by applying an approximate maximum likelihood estimator in a state-space model using data for the U.S. treasury market. A nonlinear Kalman filter is used to estimate the unobservable factors. Multi-factor models are necessary to characterize the changing shape of the yield curve over time, and the statistical tests support the case for two and three factor models. A three factor model would be able to incorporate random variation in short term interest rates, long term rates, and interest rate volatility. © 2008 Elsevier B.V., All rights reserved.","Chen, R.-R.; Scott, L.",2003,10.1023/a:1024736903090,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037491892&doi=10.1023%2FA%3A1024736903090&partnerID=40&md5=4be8316ed69eeed051871feea9eb16d0,scopus,"This paper estimates multi-factor Cox-Ingersoll-Ross models for the term structure of interest rates using a Kalman filter and U.S. treasury data. It finds that two and three-factor models are statistically supported, with a three-factor model allowing for variations in short-term rates, long-term rates, and volatility.",True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:21:08.739558
bbe5ad1518e05078,Multiple yield curve modeling and forecasting using deep learning,"This manuscript introduces deep learning models that simultaneously describe the dynamics of several yield curves. We aim to learn the dependence structure among the different yield curves induced by the globalization of financial markets and exploit it to produce more accurate forecasts. By combining the self-attention mechanism and nonparametric quantile regression, our model generates both point and interval forecasts of future yields. The architecture is designed to avoid quantile crossing issues affecting multiple quantile regression models. Numerical experiments conducted on two different datasets confirm the effectiveness of our approach. Finally, we explore potential extensions and enhancements by incorporating deep ensemble methods and transfer learning mechanisms. © 2024 Elsevier B.V., All rights reserved.","Richman, R.; Scognamiglio, S.",2024,10.1017/asb.2024.26,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207006861&doi=10.1017%2Fasb.2024.26&partnerID=40&md5=af5466c8f0a797c696cf7812ccb4d0ea,scopus,"This paper presents deep learning models for simultaneous modeling and forecasting of multiple yield curves, leveraging the dependence structure between them. It combines self-attention and nonparametric quantile regression to generate point and interval forecasts, addressing quantile crossing issues. The approach is validated empirically on two datasets and discusses extensions with ensemble methods and transfer learning.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T16:21:26.456343
cbb317c157af2d69,Multitrend Conditional Value at Risk for Portfolio Optimization,"Trend representation has been attracting more and more attention recently in portfolio optimization (PO) via machine learning methods. It adopts concepts and phenomena from the field of empirical and behavioral finance when little prior knowledge is obtained or strict statistical assumptions cannot be guaranteed. It is used mostly in estimating the expected asset returns, but hardly in measuring risk. To fill this gap, we propose a novel multitrend conditional value at risk (MT-CVaR), which embeds multiple trends and their influences in CVaR. Besides, we propose a novel PO model with this MT-CVaR as the risk metric and then design a solving algorithm based on the interior point method to compute the portfolio. Extensive experiments on six benchmark datasets from diverse financial markets with different frequencies show that MT-CVaR achieves the state-of-the-art investing performance and risk management.",Z. -R. Lai; C. Li; X. Wu; Q. Guan; L. Fang,2024,10.1109/tnnls.2022.3183891,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9805693,ieeexplore,"This paper introduces a novel Multitrend Conditional Value at Risk (MT-CVaR) for portfolio optimization, incorporating multiple trends and their impacts into CVaR. A new portfolio optimization model using MT-CVaR as the risk metric is proposed, with a solution algorithm based on the interior point method. Experiments on benchmark datasets demonstrate MT-CVaR's effectiveness in investing performance and risk management.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:21:29.290411
f7635ac88ef7da8e,Mutual Fund Liquidity Transformation and Reverse Flight to Liquidity,"We identify fixed-income mutual funds as an important contributor to the unusually high selling pressure in liquid asset markets during the COVID-19 crisis. We show that mutual funds experienced pronounced investor outflows amplified by their liquidity transformation. In meeting redemptions, funds followed a pecking order by first selling their liquid assets, including Treasuries and high-quality corporate bonds, which generated the most concentrated selling pressure in these markets. Overall, the estimated price impact of mutual funds was sizable at a third of the increase in Treasury yields and a quarter of the increase in corporate bond yields during the COVID-19 crisis.","Ma, Yiming; Xiao, Kairong; Zeng, Yao",2022,10.1093/rfs/hhac007,,wos,"This study investigates the role of fixed-income mutual funds in exacerbating selling pressure in liquid asset markets during the COVID-19 crisis. It highlights how investor outflows, amplified by the funds' liquidity transformation, led to the sale of liquid assets like Treasuries and corporate bonds, significantly impacting yields. The paper quantifies the price impact of these sales on Treasury and corporate bond yields.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:21:31.007452
038b53d4cdf820ae,Navigating Inflation Challenges: AI-Based Portfolio Management Insights,"After 2010, the consumer price index fell to a low level in the EU. In the euro area, it remained low between 2010 and 2020. The European Central Bank has even had to take action against the emergence of deflation. The situation changed significantly in 2021. Inflation jumped to levels not seen for 40 years in the EU. Our study aims to use artificial intelligence to forecast inflation. We also use artificial intelligence to forecast stock index changes. Based on the forecasts, we propose portfolio reallocation decisions to protect against inflation. The forecasting literature does not address the importance of structural breaks in the time series, which, among other things, can affect both the pattern recognition and prediction capabilities of various machine learning models. The novelty of our study is that we used the Zivot–Andrews unit root test to determine the breakpoints and partitioned the time series into training and testing datasets along these points. We then examined which database partition gives the most accurate prediction. This information can be used to re-balance the portfolio. Two different AI-based prediction algorithms were used (GRU and LSTM), and a hybrid model (LSTM–GRU) was also included to investigate the predictability of inflation. Our results suggest that the average error of the inflation forecast is a quarter of that of the stock market index forecast. Inflation developments have a fundamental impact on equity and government bond returns. If we obtain a reliable estimate of the inflation forecast, we have time to rebalance the portfolio until the inflation shock is incorporated into government bond returns. Our results not only support investment decisions at the national economy level but are also useful in the process of rebalancing international portfolios.",,2024,10.3390/risks12030046,,proquest,"This study utilizes AI (GRU, LSTM, and LSTM-GRU models) to forecast inflation and stock index changes, incorporating structural breaks identified by the Zivot-Andrews unit root test. The goal is to inform portfolio reallocation decisions to mitigate inflation risks, suggesting that inflation forecasts are more accurate than stock market index forecasts and can aid in rebalancing both national and international portfolios.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:21:33.018107
eddff9ceb55591e5,Network Centrality and Managerial Market-Timing Ability,"We document that long-run excess returns following announcements of share buyback authorizations and insider purchases are a U-shaped function of firm centrality in the input-output trade-flow network. These results conform to a model of investors endowed with a large but finite capacity for analyzing firms. Additional links weaken insiders' informational advantage in peripheral firms (simple firms whose cash flows depend on few economic links), provided investors' capacity is large enough, but eventually amplify that advantage in central firms (firms with many links) as a result of investors' limited capacity. These findings shed light on the sources of managerial market-timing ability.","Evgeniou, Theodoros; Peress, Joel; Vermaelen, Theo; Yue, Ling",2022,10.1017/s0022109021000016,,wos,"This study investigates the relationship between a firm's centrality in the input-output trade-flow network and managerial market-timing ability, specifically concerning share buyback authorizations and insider purchases. The findings suggest that long-run excess returns exhibit a U-shaped pattern based on firm centrality, explained by a model where investors have limited capacity for analyzing firms. Increased network links can weaken or amplify insiders' informational advantage depending on firm centrality and investor capacity.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:33:23.183181
11848a5aa1999a9c,Neural Ordinary Differential Equation Networks for Fintech Applications Using Internet of Things,"The Internet of Things (IoT) technology is becoming increasingly pivotal in the financial services sector, with a growing number of algorithms being employed in high-frequency trading. High-frequency prediction in financial time series prediction presents a promising avenue of research. From convolutional neural networks to recurrent neural networks, deep learning have demonstrated exceptional capabilities in capturing the nonlinear characteristics of stock markets, thereby achieving high performance in stock index prediction. In this article, we employ ODE-LSTM model for high-frequency price forecasting, predicting stock price data across various time scales, including 1-, 5-, and 30-min frequencies. This approach introduces a novel concept, wherein the long short-term memory (LSTM) model is integrated with Neural ordinary differential equations (ODEs) to manage the hidden state and augment model interpretability. Over the course of 7 months, we achieved a 41.79% excess return on a simulated trading platform, with a daily average excess return of 0.30%, showcasing the commendable performance of our model and strategy.",J. Li; W. Chen; Y. Liu; J. Yang; D. Zeng; Z. Zhou,2024,10.1109/jiot.2024.3376748,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10472330,ieeexplore,"This article proposes an ODE-LSTM model, integrating Neural Ordinary Differential Equations with LSTM, for high-frequency stock price forecasting using IoT data. The model demonstrated strong performance, achieving a 41.79% excess return over 7 months on a simulated trading platform.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:33:28.448262
4717510223fcce48,News Media and Attention Spillover across Energy Markets: A Powerful Predictor of Crude Oil Futures Prices,"We develop two news-based investor attention measures from the news trends function of the Bloomberg terminal and investigate their predictive power for returns on crude oil futures contracts with various maturities. Our main results after controlling for relevant macroeconomic variables show that the Oil-based Institutional Attention Index is useful in predicting oil futures returns, especially during price downturn periods, while the forecasting accuracy is further improved when the Commodity Market Institutional Attention Index is used. This forecasting accuracy decreases, however, with the maturity of oil futures contracts. Moreover, we find some evidence of Granger-causality and regime-dependent interactions between investor attention measures and oil futures returns. Finally, variable selection algorithms matter before making predictions since they create the best forecasting results in many cases considered. These findings are important for informed traders and policymakers to better understand the price dynamics of the oil markets.","Cepni, Oguzhan; Duc Khuong Nguyen; Sensoy, Ahmet",2022,10.5547/01956574.43.si1.ocep,,wos,"This study develops two news-based investor attention measures to predict crude oil futures returns. The Oil-based Institutional Attention Index and the Commodity Market Institutional Attention Index show predictive power, particularly during price downturns and for shorter-term futures contracts. The research also highlights the importance of variable selection algorithms for forecasting accuracy and suggests implications for traders and policymakers.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:33:33.899673
636a11ccd9e2eab8,"Nominal US Treasuries Embed Liquidity Premiums, Too","A novel arbitrage-free model of nominal U.S. Treasuries that decomposes yields into frictionless expected rates, frictionless term premiums, and liquidity premiums produces four key results from Jan. 1987 to Aug. 2023. First, liquidity loadings are larger than for the slope and higher-order principal components. Second, the countercyclicality of required nominal Treasury returns owes to liquidity, if anything, not frictionless term premiums. Third, Federal Reserve large-scale asset purchases generally work through expected rates and frictionless term premiums, not liquidity premiums. Fourth, given similar estimates using TIPS, inflation expectations are less moored around the Federal Reserve's price objectives than other models say.","Durham, J. Benson",2025,10.1017/s0022109023001345,,wos,"This paper introduces a new arbitrage-free model for nominal U.S. Treasuries, separating yields into frictionless expected rates, frictionless term premiums, and liquidity premiums. The model reveals that liquidity premiums are significant, countercyclical returns are driven by liquidity rather than frictionless term premiums, Federal Reserve asset purchases primarily affect expected rates and frictionless term premiums, and inflation expectations are less anchored than previously thought. The analysis spans from January 1987 to August 2023.",False,True,False,gemini-2.5-flash-lite,Ulrik,M,See how model is built,2025-10-13T16:34:04.170773
63afa8c0f2631f86,Non-linear and asymmetric linkages between real growth in the Euro area and global financial market conditions: new evidence,"This paper deals with transition mechanisms through which financial market conditions affect real economic growth in the Euro area. The informational content of financial variables for predicting real economic growth is assessed, allowing for asymmetric responses to shocks. A nonlinear framework is developed based on a smooth transition model for which the effects of shocks can vary across business cycles when financial indicators modify both the endogenous and state variables. Global financial variables are shown to significantly affect real growth in the Euro area, particularly during periods of recession. Changes in stock market index and yield slope have asymmetric effects on real growth. In recessionary periods, the slope of the US yield curve does not have a significant impact on growth in the Euro area. All rights reserved, Elsevier",,2012,10.1016/j.econmod.2012.01.008,,proquest,"This paper investigates how global financial market conditions influence real economic growth in the Euro area, employing a nonlinear, asymmetric framework. It finds that financial variables significantly impact Euro area growth, especially during recessions, with stock market index changes and yield slope exhibiting asymmetric effects. The US yield curve's slope, however, shows no significant impact on Euro area growth during recessions.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:34:12.248766
6d1f179bacc01371,Non-linearities in the relationship of agricultural futures prices,"The movement of food prices remains a controversial issue owing to the intense rise in volatility that has been observed in recent years. Agricultural futures markets have experienced a similar pattern and simplistic linear models seem to be no longer reliable when analysing their functions. Against this background, this study contributes to the literature by adopting a non-linear smooth transition approach to examine the relationship between prices for first and second nearby futures contracts of seven agricultural commodities. Our main objective is to distinguish between contango and backwardation regimes when analysing the relationship between the futures spread and changes in the first nearby futures price. Our findings reveal that a linear framework neglects important dynamics, as futures prices adjust only under specific circumstances, and that the predictive power of the futures spread is much stronger during backwardation regimes.","Beckmann, Joscha; Czudaj, Robert",2014,10.1093/erae/jbt015,,wos,"This study uses a non-linear smooth transition approach to analyze the relationship between first and second nearby futures contracts for seven agricultural commodities. It aims to differentiate between contango and backwardation regimes and finds that linear models are insufficient, with futures prices adjusting only under specific circumstances and the futures spread being a stronger predictor during backwardation regimes.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:34:16.613764
44636fa0fc84cad0,Nonlinear adjustments in deviations from the law of one price for wholesale hog prices,"This article applies the Band-Threshold Autoregression (Band-TAR) model to investigate whether the law of one price (LOOP) holds in Taiwanese wholesale hog markets during the period from May 1987 through December 2003. We find evidence of a nonlinear mean reversion in deviations from the LOOP for relative hog prices. Our empirical study confirms the presence of thresholds and provides strong evidence in support of the view that the regional hog markets have been tightly integrated in Taiwan and that the wholesale hog market in Taiwan is an efficient market economy. Furthermore, the estimated half-lives from the nonlinear generalized impulse response analysis are as short as four months.","Chen, Pei-Fen; Lee, Chien-Chiang",2008,10.1111/j.1574-0862.2008.00320.x,,wos,"This study uses a Band-Threshold Autoregression (Band-TAR) model to examine the law of one price (LOOP) in Taiwanese wholesale hog markets. The findings indicate nonlinear mean reversion in deviations from the LOOP for relative hog prices, suggesting tight integration and efficiency in these markets. The estimated half-lives for adjustments are as short as four months.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:34:19.369166
df4201d91d38dc14,Nonlinear dynamics in foreign exchange rates,"This paper investigates whether the behavior of real and nominal foreign exchange rates as well as interest rates are governed by nonlinear dynamics; it also explores whether observed deviations from parity conditions exhibit nonlinear dependence. Standard statistical tests for randomness, such as autocorrelation tests, have low power against a large class of deterministic, nonlinear processes. Discerning nonrandomness of innovations in exchange rates is important for a variety of reasons. For example, many models of international asset pricing assume exchange rates to follow a random walk. Furthermore, nonlinear patterns in deviations from various exchange rate parities have implications for the existence of a time-varying foreign exchange risk premium. With the use of the BDS statistic and a correlation dimension analysis, this paper's primary findings are that (1) foreign exchange markets have become increasingly complex and therefore less amenable to forecasting over time; (2) although forward exchange risk premia are statistically significant and display a deterministic structure, this structure is complex and therefore not easily discernible; and (3) innovations in real exchange rates are consistent with a Purchasing Power Parity equilibrium. © 1999 Elsevier Science Inc. © 2018 Elsevier B.V., All rights reserved.","Mahajan, A.; Wagner, A.J.",1999,10.1016/s1044-0283(99)00002-2,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042597353&doi=10.1016%2FS1044-0283%2899%2900002-2&partnerID=40&md5=3947c7aa0039abb36b482bdda7e1902f,scopus,"This paper investigates nonlinear dynamics in foreign exchange rates, interest rates, and deviations from parity conditions. Using BDS statistic and correlation dimension analysis, it finds that foreign exchange markets have become more complex and less predictable over time. While forward exchange risk premia show a deterministic structure, it is complex. Innovations in real exchange rates are consistent with Purchasing Power Parity equilibrium.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:34:22.389096
f8be887256aa2835,Nonlinear error correction model and multiple-threshold cointegration,"As an extension of linear cointegration, threshold cointegration has been a vibrant research topic in finance and statistics. Existing estimation procedures of threshold cointegration are usually based on the threshold vector error correction model (TVECM); however, only one threshold cointegration is considered. In this paper, we investigate estimation of the multiple-threshold cointegration that is more widely used in application. Two proposed methods, the LSE and the Smoothed LSE are studied, via the multiple-regime TVECM. The convergence rate of the LSE is obtained and the limiting distribution of the smoothed LSE is developed. To assess the performance of these estimators, a simulation study was conducted, in which the results support the asymptotic theories. As an example, we study the term structure of interest rates by a two-threshold cointegration model. © 2023 Elsevier B.V., All rights reserved.","Wang, M.; Chan, N.H.; Yau, C.Y.",2016,10.5705/ss.2014.219t,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011856669&doi=10.5705%2Fss.2014.219t&partnerID=40&md5=777e1a0aa7630414aad0d4e9f0221332,scopus,"This paper proposes and analyzes estimation methods for multiple-threshold cointegration, extending the existing threshold vector error correction model (TVECM) which typically considers only one threshold. Two methods, Least Squares Estimation (LSE) and Smoothed LSE, are studied for the multiple-regime TVECM. The paper provides theoretical results on the convergence rate of LSE and the limiting distribution of Smoothed LSE, supported by simulation studies. An empirical application to the term structure of interest rates using a two-threshold cointegration model is presented.",True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:34:31.435292
ba14e9af00683956,Nonlinear mean reversion in stock prices,"This paper provides new evidence on the time-series predictability of stock market returns by introducing a test of nonlinear mean reversion. The performance of extreme daily returns is evaluated in terms of their power to predict short- and long-horizon returns on various stock market indices and size portfolios. The paper shows that the speed of mean reversion is significantly higher during the large falls of the market. The parameter estimates indicate a negative and significant relation between the monthly portfolio returns and the extreme daily returns observed over the past one to eight months. Specifically, in a quarter in which the minimum daily return is -2% the expected excess return is 37 basis points higher than in a month in which the minimum return is only -1%. This result holds for the value-weighted and equal-weighted stock market indices and for each of the size decile portfolios. The findings are also robust to different sample periods, different indices, and investment horizons. All rights reserved, Elsevier",,2008,10.1016/j.jbankfin.2007.05.013,,proquest,"This paper investigates nonlinear mean reversion in stock prices, demonstrating that extreme daily returns predict future returns, with faster mean reversion occurring after large market declines. The study finds a significant negative relationship between monthly portfolio returns and extreme daily returns over several months, indicating that larger negative daily returns lead to higher expected excess returns. These findings are robust across different market indices, portfolio types, and time periods.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:35:02.110794
08f7e1c21ff490c4,Nonlinear predictability of stock returns using financial and economic variables,"Inspired by the linear predictability and nonlinearity found in the finance literature, this article examines the nonlinear predictability of the excess returns. The relationship between the excess returns and the predicting variables is recursively modeled by a neural-network model, which is capable of performing flexible nonlinear functional approximation. The nonlinear neural-network model is found to have better in-sample fit and out-of-sample forecasts compared to its linear counterpart. Moreover, the switching portfolio based on the recursive neural-network forecasts generates higher profits with lower risks than both the buy-and-hold market portfolio and the switching portfolio based on linear recursive forecasts. © 2017 Elsevier B.V., All rights reserved.","Qi, M.",1999,10.1080/07350015.1999.10524830,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033435319&doi=10.1080%2F07350015.1999.10524830&partnerID=40&md5=5168aa09c44a851bad6e254e59934493,scopus,"This article investigates the nonlinear predictability of stock returns using a neural network model, which demonstrates superior in-sample fit and out-of-sample forecasts compared to linear models. The study also shows that a switching portfolio based on these nonlinear forecasts yields higher profits with lower risks.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:35:04.022944
412b7080ec4282c9,Nonlinear structural estimation of corporate bond liquidity,"We estimate the term structure of corporate bond liquidity premiums using a dual estimation technique. Our estimates reveal that the term structures of the liquidity premiums were positively sloped and concave for each category of creditworthiness and in three economic epochs. As the macroeconomy transitioned from a pre-crisis to a crisis period, liquidity premiums elevated across time to maturity for both investment grade and speculative grade bonds. With the migration of the financial system from stress to relative calm, the premiums on both grades of debt declined for all maturities.",,2025,10.1007/s11156-024-01323-y,,proquest,"This study estimates the term structure of corporate bond liquidity premiums using a dual estimation technique. The findings indicate that these premiums are positively sloped and concave across different creditworthiness categories and economic periods. Liquidity premiums increased during economic crises and decreased during periods of financial stability, affecting both investment-grade and speculative-grade bonds across all maturities.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:35:05.559671
00fd43d7d419402b,Objective Black-Litterman views through deep learning: A novel hybrid model for enhanced portfolio returns,"The Black-Litterman Model is a sophisticated approach to portfolio optimization that integrates investor views with market data. However, the model's effectiveness is highly dependent on the quality of its inputs and is often challenged by subjective or biased views. Recent advancements in deep learning have enabled the generation of more objective, data-driven views, significantly enhancing the model's accuracy and reliability. In this study, we propose a novel CGL-BL Model, which employs a hybrid deep learning approach—CEEMDAN-GLSTM-LSTM (CGL)—to generate investor views. The CGL model leverages the CEEMDAN algorithm for return-based time series decomposition, a Genetic Algorithm-optimized LSTM network to enhance prediction accuracy, and an additional LSTM network for nonlinear aggregation of prediction results. The proposed CGL-BL model was evaluated on both the SSE 50 Index in China and the DJIA in the United States. Empirical results show that the proposed CGL-BL model outperforms all benchmark portfolios in terms of excess return, Sharpe ratio, and maximum drawdown when applied with a short-term rebalancing strategy on the SSE 50 Index and a medium-to-long-term strategy on the DJIA, demonstrating strong potential for practical application in financial markets. © 2025 Elsevier B.V., All rights reserved.","Su, X.; Lu, K.; Yen, J.",2026,10.1016/j.eswa.2025.128868,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009900832&doi=10.1016%2Fj.eswa.2025.128868&partnerID=40&md5=b27f0493fa3bcfd8ab0088a189292bd7,scopus,"This study introduces a novel hybrid model, CGL-BL, that combines deep learning (CEEMDAN-GLSTM-LSTM) with the Black-Litterman model to generate objective investor views for portfolio optimization. The model was tested on the SSE 50 Index and DJIA, showing improved performance over benchmarks in excess return, Sharpe ratio, and maximum drawdown.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:35:16.720443
7bff3f5daef33b24,Oil volatility risk and stock market volatility predictability: Evidence from G7 countries,"Academic research relies extensively on stock market information to forecast oil volatility, with relatively little attention paid to the reverse evidence. Our paper fills this gap by investigating the predictive ability of oil volatility risk to forecast stock market volatility. Using oil volatility risk premium (oil VRP) as the predictor, we find that oil VRP does exhibit statistically and economically significant in-sample and out-of-sample forecasting power for G7 countries, even controlling for some popular macroeconomic variables. These findings are robust when using alternative proxies for volatilities of stock and oil. Furthermore, the strength of the predictive evidence is substantial during relatively high and low level of stock market, while is substantially higher for recessions vis-á-vis expansions. Oil VRP can also contains additional information for predicting a series of macroeconomic variables, which serves as an available explanation for its forecasting ability. © 2017 Elsevier B.V., All rights reserved.","Feng, J.; Wang, Y.; Yin, L.",2017,10.1016/j.eneco.2017.09.023,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033474517&doi=10.1016%2Fj.eneco.2017.09.023&partnerID=40&md5=a075dd9efe8a8e5ec98bf304a551f6af,scopus,"This paper investigates the predictive ability of oil volatility risk for stock market volatility in G7 countries. It finds that oil volatility risk premium (oil VRP) has statistically and economically significant forecasting power for stock market volatility, even after controlling for macroeconomic variables. The predictive power is stronger during recessions and at high/low stock market levels. Oil VRP also contains information for predicting macroeconomic variables.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:35:21.902759
3ca42c57cf880dd3,On credit spread change of Chinese corporate bonds: credit risk or asset allocation effect?,"Purpose – Credit spread change is a key issue for investors to earn the excess return from corporate bonds. Generally, there are two kinds of different effects that support the changing of credit spread: asset allocation effect and credit risk change effect. The existing literature based on US data supports credit spread change is driven by credit risk change; however, this issue based on Chinese market data has not been investigated clearly. This paper seeks to address this issue. Design/methodology/approach – The authors adopt Markov regime switching model to investigate the changing mode of the credit spread in the Chinese bond market. They select three kinds of variables: the credit risk variables, the asset allocation variables and the liquidity condition variables. With ML estimators, the authors can find the changing mode and further they study the relationship between the regime switching and some observed variables, such as macro economy variables and turnover of stock market. Findings – The authors find it is driven by asset allocation effect in most time and by credit risk change only in shorter period. Empirical results show that the switching of dominance from one effect to another isn't closely related with macro-economy variables, but related with the turnover of stock market. Practical implications – These results indicate that in China the credit risk of corporate bonds is relatively low and the corporate bonds are still auxiliary asset for investors. Originality/value – In this paper, the authors have the following two contributions: first, they discuss the asset allocation effect in the Chinese bond market and introduce the stock market variables and bank credit variable to describe the asset allocation effect; second, based on Chinese bond market data, they find different findings from the existing literature about US and European bond markets, showing that the changing of credit spread is mostly related with asset allocation effect but not credit risk change. © 2017 Elsevier B.V., All rights reserved.","Cui, C.; Liu, H.; Zhang, Y.",2013,10.1108/cfri-02-2012-0020,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015670143&doi=10.1108%2FCFRI-02-2012-0020&partnerID=40&md5=702c717b284c0dcc395735c4a2685d52,scopus,"This paper investigates the drivers of credit spread changes in the Chinese corporate bond market, distinguishing between asset allocation and credit risk effects. Using a Markov regime switching model and ML estimators, the study finds that asset allocation effects dominate most of the time, with credit risk playing a lesser role. The switching between these effects is linked to stock market turnover rather than macroeconomic variables. The findings suggest that Chinese corporate bonds are primarily an auxiliary asset with relatively low credit risk.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:35:23.642208
6c8e3fca2c525e30,On estimability of parsimonious term structure models: An experiment with the Nelson-Siegel specification,"This study addresses operational issues in estimation of parsimonious term structure models. When using price errors, objective function in term structure estimation is a nonlinear function of the model parameters. This necessarily entails using numerical optimization techniques for estimation, which brings to fore the issue of (sensitivity of final results to) the choice of initialization of the optimization routine. This study assesses the sensitivity of the final objective function value and the final parameter vector to the choice of the 'initial guess' during the estimation of the popular Nelson-Siegel model. It turns out that there exist regions in the shape of the objective function where a slight change in (seemingly reasonable) initial vector takes one far from optimum. Choice of the (range of) 'best' starting vector turns out to be an empirical matter. Grid search is recommended. One must first get to a subset of initial values that results in the objective function value near a minimum and then assess the sensitivity of the final parameter vector to those relevant (subset of) initial values. The study illustrates the process using a typical trading day's data. © 2012 Copyright Taylor and Francis Group, LLC. © 2012 Elsevier B.V., All rights reserved.","Virmani, V.",2012,10.1080/13504851.2012.657343,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863492248&doi=10.1080%2F13504851.2012.657343&partnerID=40&md5=759a05b89376f52765cdf960acd72789,scopus,"This study investigates the estimation challenges of parsimonious term structure models, specifically the Nelson-Siegel model, by examining the sensitivity of parameter estimation to initial guesses in numerical optimization. It highlights the non-linear nature of the objective function and recommends a grid search approach to identify optimal starting vectors and assess parameter sensitivity, illustrated with a trading day's data.",True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:35:29.741418
a174f9343be6fc86,On filtering in Markovian term structure models: An approximation approach,"We consider a parametrization of the Heath-Jarrow-Morton (HJM) family of term structure of interest rate models that allows a finite-dimensional Markovian representation of the stochastic dynamics. This parametrization results from letting the volatility function depend on time to maturity and on two factors: the instantaneous spot rate and one fixed-maturity forward rate. Our main purpose is an estimation methodology for which we have to model the observations under the historical probability measure. This leads us to consider as an additional third factor the market price of interest rate risk, that connects the historical and the HJM martingale measures. Assuming that the information comes from noisy observations of the fixed-maturity forward rate, the purpose is to estimate recursively, on the basis of this information, the three Markovian factors as well as the parameters in the model, in particular those in the volatility function. This leads to a nonlinear filtering problem, for the solution of which we describe an approximation methodology, based on time discretization and quantization. We prove the convergence of the approximate filters for each of the observed trajectories. © 2005 Elsevier Science B.V., Amsterdam. All rights reserved.","Chiarella, C.; Pasquali, S.; Runggaldier, W.J.",2001,10.1239/aap/1011994030,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035710457&doi=10.1239%2Faap%2F1011994030&partnerID=40&md5=354532f209d840951e8d6199d8470815,scopus,This paper proposes an approximation methodology for estimating parameters in a Markovian representation of the Heath-Jarrow-Morton (HJM) term structure of interest rate models. The approach involves time discretization and quantization to address a nonlinear filtering problem arising from noisy observations of a fixed-maturity forward rate. The goal is to recursively estimate the model's Markovian factors and volatility parameters.,False,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:35:46.585313
f54835efc01a2af6,On modeling IPO failure risk,"This paper offers a novel framework, combining firm operational risk, IPO pricing risk, and market risk, to model IPO failure risk. By analyzing nearly a thousand variables, we observe that prior IPO failure risk models have suffered from a major missing-variable problem. Evidence reveals several key new firm-level determinants, e.g., the volatility operating performance, the size of its accounts payable, pretax income to common equity, total short-term debt, and a few macroeconomic variables such as treasury bill rate, and book-to-market of the DJIA index. These findings have major economic implications. The total value loss from not predicting the imminent failure of an IPO is significantly lower with this proposed model compared to other established models. The IPO investors could have saved around $18billion over the period between 1994 and 2016 by using this model. © 2022 Elsevier B.V., All rights reserved.","Colak, G.; Fu, M.; Hasan, I.",2022,10.1016/j.econmod.2022.105790,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124421011&doi=10.1016%2Fj.econmod.2022.105790&partnerID=40&md5=f16401aacf4f384db51620d5c6763e73,scopus,"This paper introduces a new framework to model IPO failure risk by integrating operational, pricing, and market risks. It identifies key firm-level and macroeconomic determinants, suggesting that previous models suffered from missing variables. The proposed model demonstrates significant improvements in predicting IPO failures, potentially saving investors substantial amounts.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:35:48.731253
ad0a338018943161,On the nonlinear predictability of stock returns using financial and economic variables,"In a recent article by Qi, neural networks trained by Bayesian regularization were used to predict excess returns on the S&P 500. The article concluded that the switching portfolio based on the recursive neural-network forecasts generates higher accumulated wealth with lower risks than that based on linear regression. Unfortunately, attempts to replicate the results were unsuccessful. Replicated results using the same software, approach and data detailed by Qi indicate that, in fact, the switching portfolio based on the recursive neural-network forecasts generates lower accumulated wealth with higher risks than that based on linear regression. © 2005 Elsevier Science B.V., Amsterdam. All rights reserved.","Racine, J.",2001,10.1198/073500101681019927,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035638655&doi=10.1198%2F073500101681019927&partnerID=40&md5=2f633ec6cfbf429ce536720d0c842b79,scopus,"This article attempts to replicate the findings of Qi (2005) regarding the nonlinear predictability of stock returns using neural networks. The authors found that their replication efforts were unsuccessful, and the neural network approach actually performed worse than linear regression in terms of accumulated wealth and risk.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:35:52.166463
cc726ef76b042dc2,On the nonlinear specifications of short-term interest rate behavior: Evidence from euro-currency markets,"This paper presents a coherent nonlinear interest rate model that incorporates the dynamics of the error correction specification into the traditional term structure model. The joint tests based on six Euro-Currency rates indicate that the linear specification should be rejected. The estimated equation suggests that the linear components - the change of the long-term interest rate and the error correcting term are highly significant. The nonlinear components involving the higher order of the independent variables, the cross products, the lagged error squares, and/or the ARCH effect also present significant explanatory power for predicting short-term Euro-Currency rate changes, confirming the non-linear specifications. © 1999 Kluwer Academic Publishers,. © 2018 Elsevier B.V., All rights reserved.","Chiang, T.C.; Jeanette Chiang, J.I.N.",1999,10.1023/a:1008302525246,https://www.scopus.com/inward/record.uri?eid=2-s2.0-53149100134&doi=10.1023%2FA%3A1008302525246&partnerID=40&md5=7fbdb4800e1097cff8e0bd382f9120ca,scopus,"This paper proposes a nonlinear interest rate model for short-term Euro-currency rates, integrating error correction dynamics into traditional term structure models. Empirical tests on six Euro-Currency rates reject linear specifications, showing significant explanatory power for both linear and nonlinear components, including higher-order terms, cross-products, lagged error squares, and ARCH effects, in predicting short-term rate changes.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:35:55.203339
23e04bea77ea6c28,On the significance testing of fuzzy regression applied to the CAPM: Canadian commodity futures evidence,"This paper is written with two congruent objectives. The first is to develop a framework for individual tests of significance of a fuzzy regression model by employing a simple probabilistic estimation procedure. The proposed test, based on two-phase fuzzy regression estimates, is simple and robust. The capital asset pricing model (CAPM), with induction of price limits, serves as the essential component of our analysis, due to its ability to illuminate and determine the risk premiums in a commodity futures market. The second objective is to estimate and test for the significance of the systematic risk of Canadian commodity futures and to illustrate the benefits of the significancetesting approach. Copyright © 2013 Inderscience Enterprises Ltd. © 2020 Elsevier B.V., All rights reserved.","Smimou, K.",2013,10.1504/ijams.2013.053710,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877272226&doi=10.1504%2FIJAMS.2013.053710&partnerID=40&md5=b1910293cf57fa1c92dc80288a597b51,scopus,"This paper proposes a framework for testing the significance of fuzzy regression models, applying it to the Capital Asset Pricing Model (CAPM) within the context of Canadian commodity futures. The authors aim to estimate and test the significance of systematic risk in this market, highlighting the benefits of their proposed testing approach.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:35:57.438885
429dc98f1a74b78f,Optimal Time Varying Parameters in Yield Curve Modeling and Forecasting: A Simulation Study on BRICS Countries,"The term structure of interest rates is a fundamental decision-making tool for various economic activities. Despite the huge number of contributions in the field, the development of a reliable framework for both fitting and forecasting under various market conditions (either stable or very volatile) still remains a topical issue. Motivated by this problem, this study introduces a methodology relying on optimal time-varying parameters for three and five factor models in the Nelson-Siegel class that can be employed for an effective in-sample fitting and out-of-sample forecasting of the term structure. In detail, for the in-sample fitting we discussed a two-step estimation procedure leading to optimal models parameters and evaluated the performances of this approach in terms of flexibility and fitting accuracy gains. For what it concerns the forecasting, we suggest an approach overcoming the well-known issue between the stability of factor models' parameters and the optimal dynamic decay terms. To such aim, we use either autoregressive or machine learning techniques as local data generating processes based on the optimal parameters time series derived in the in-line fitting step. The so-obtained values are then employed to get day-ahead predictions of the yield curve. We assessed the proposed framework on daily spot rates of the BRICS (Brazil, Russia, India, China and South Africa) bond market. The experimental analysis illustrated that (i) time-varying parameters ensure a significant boost in the models fitting power and a more faithful representation of the yield curves dynamics; (ii) the proposed approach provides also stable and accurate predictions.","Castello, Oleksandr; Resta, Marina",2025,10.1007/s10614-024-10619-z,,wos,"This study proposes a methodology using optimal time-varying parameters for Nelson-Siegel class models to improve yield curve fitting and forecasting. It employs a two-step estimation for in-sample fitting and utilizes autoregressive or machine learning techniques for out-of-sample forecasting, tested on BRICS countries' bond market data. The results show that time-varying parameters enhance fitting power and prediction accuracy.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T16:36:26.375440
61ddf22073d6a62b,Optimal asset allocation and nonlinear return predictability from the dividend-price ratio,"We study non-linear predictability of stock returns arising from the dividend-price ratio and its implications for asset allocation decisions. Using data from five countries — U.S., U.K., France, Germany and Japan — we find empirical evidence supporting non-linear and time-varying models for the equity risk premium. Building on this, we examine several model specifications that can account for non-linear return predictability, including Markov switching models, regression trees, random forests and neural networks. Although in-sample return regressions and portfolio allocation results support the use of non-linear predictability models, the out-of-sample evidence is notably weaker, highlighting the difficulty in exploiting non-linear predictability in real time. © 2025 Elsevier B.V., All rights reserved.","Ghezzi, F.; Sarkar, A.; Pedersen, T.Q.; Timmermann, A.",2025,10.1007/s10479-024-06332-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001086702&doi=10.1007%2Fs10479-024-06332-7&partnerID=40&md5=dd0ef7ddf17b2e69e5c4a37d7cf1969f,scopus,"This study investigates non-linear predictability of stock returns using the dividend-price ratio across five countries. It explores various non-linear models like Markov switching, regression trees, random forests, and neural networks. While in-sample results show promise for non-linear models in return prediction and asset allocation, out-of-sample performance is less convincing, indicating challenges in real-time application.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:36:30.543031
b2464947594c2bc5,Optimal credit allocation under regime uncertainty with sensitivity analysis,"We consider the problem of credit allocation in a regime-switching model. The global evolution of the credit market is driven by a benchmark, the drift of which is given by a two-state continuous-time hidden Markov chain. We apply filtering techniques to obtain the diffusion of the credit assets under partial observation and show that they have a specific excess return with respect to the benchmark. The investor performs a simple mean-variance allocation on credit assets. However, returns and variance matrix have to be computed by a numerical method such as Monte Carlo, because of the dynamics of the system and the non-linearity of the asset prices. We use the theory of Dirichlet forms to deal with the uncertainty on the excess returns. This approach provides an estimation of the bias and the variance of the optimal allocation, and return. We propose an application in the case of a sectorial allocation with Credit Default Swaps (CDS), fully calibrated with observable data or direct input given by the portfolio manager. Reprinted by permission of World Scientific Publishing",,2015,10.1142/s0219024915500028,,proquest,"This paper addresses credit allocation in a regime-switching model where the credit market's evolution is influenced by a two-state hidden Markov chain. It uses filtering techniques to analyze credit asset diffusion and their excess returns relative to a benchmark. The study employs mean-variance allocation and discusses the necessity of numerical methods like Monte Carlo for calculating returns and variance due to the system's dynamics. It also applies Dirichlet form theory to manage uncertainty in excess returns, providing bias and variance estimations for optimal allocation. An application involving sectorial allocation with Credit Default Swaps (CDS) is presented, calibrated with observable data or portfolio manager inputs.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:36:37.069915
7ce39ff7ea9cbb6e,Optimal supplier testing and tolerance strategies for genetically modified (GM) wheat,"AbstractA stochastic optimization model was developed to determine optimal testing strategies, costs, and risks for dual marketing of genetically modified (GM) and non-GM wheat in an export supply chain. The optimal testing strategy is derived that minimizes disutility of additional system costs due to testing and quality loss. Cost components were estimated including those related to testing, quality loss, and a risk premium to induce shippers to undertake dual marketing as opposed to handling only non-GM crops. Uncertainties were incorporated for adventitious presence and commingling, variety declaration, and test accuracy. Sensitivities were performed for effects of variety risks and declaration, penalty differentials, buyer tolerances, risk aversion, and GM adoption. Results indicate testing and segregation can be performed at a relatively low cost and risk to buyers.",,2007,10.1111/j.1574-0862.2007.00175.x,,proquest,"This study develops a stochastic optimization model to find the best strategies for testing and managing risks in a dual-market supply chain for genetically modified (GM) and non-GM wheat. The model aims to minimize costs associated with testing, quality loss, and a risk premium for shippers. It accounts for uncertainties in GM presence, commingling, variety declaration, and test accuracy. The findings suggest that testing and segregation can be cost-effective and low-risk for buyers.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:36:38.831195
4c6402a19fd533ec,Option Pricing Under a Stochastic Interest Rate and Volatility Model with Hidden Markovian Regime-Switching,"In this paper we discuss an option pricing problem in a hidden Markovian regime-switching model with a stochastic interest rate and volatility. Regime switches are attributed to structural changes in an hidden economic environment and are described by a continuous-time, finite-state, unobservable Markov chain. The model is then applied to the valuation of a standard European option. By means of the standard separation principle, filtering and option valuation problems are separated. Robust filters for the hidden states of the economy and their robust filtered estimates of unknown parameters from the expectation maximization algorithm are presented based on standard techniques in filtering theory. Then an explicit expression of a conditional characteristic function relevant to option pricing is presented and the valuation of the option is discussed using the inverse Fourier transformation approach. Using the limiting behavior of the conditional characteristic function, an efficient implementation of the transform inversion integral is considered. Numerical experiments are given to illustrate the flexibility of filtering algorithms and the significance of regime-switching in option pricing.","Zhu, Dong-Mei; Lu, Jiejun; Ching, Wai-Ki; Siu, Tak-Kuen",2019,10.1007/s10614-017-9754-9,,wos,"This paper presents an option pricing model incorporating hidden Markovian regime-switching, stochastic interest rates, and volatility. It separates filtering and option valuation, develops robust filters using the expectation maximization algorithm, and derives an explicit expression for the conditional characteristic function. The valuation is performed using inverse Fourier transformation, with numerical experiments demonstrating the model's flexibility and the impact of regime-switching.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:36:42.619949
e89217d91d1107e3,Option price sensitivities through fuzzy numbers,"The main motivation in using fuzzy numbers in finance lies in the need for modelling the uncertainty and vagueness that are implicit in many situations. However, the fuzzy approach should not be considered as a substitute for the probabilistic approach but rather as a complementary way to describe the model peculiarities. Here, we consider, in particular, the Black and Scholes model for option pricing, and we show that the fuzzification of some key parameters enables a sensitivity analysis of the option price with respect to the risk-free interest rate, the final value of the underlying stock price, the volatility, and also better forecasts (see Thavaneswaran etaaal. (2009) for details). The sensitivities with respect to the variables of the model are represented by different letters of the Greek alphabet and they play an important role in the definition of the shape of the fuzzy option price.",,2011,10.1016/j.camwa.2010.11.024,,proquest,"This paper explores the use of fuzzy numbers to model uncertainty in option pricing, specifically within the Black-Scholes framework. It demonstrates how fuzzifying key parameters allows for a sensitivity analysis of option prices concerning interest rates, stock prices, and volatility, offering a complementary approach to probabilistic methods.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:36:44.697903
fc9d1d735105cd33,Option-Based Estimation of the Price of Coskewness and Cokurtosis Risk,"We show that the prices of risk for factors that are nonlinear in the market return can be obtained using index option prices. The price of coskewness risk corresponds to the market variance risk premium, and the price of cokurtosis risk corresponds to the market skewness risk premium. Option-based estimates of the prices of risk lead to reasonable values of the associated risk premia. An analysis of factor models with coskewness risk indicates that the new estimates of the price of risk improve the models' performance compared with regression-based estimates.",,2021,10.1017/s002210902000023x,,proquest,"This paper proposes a method to estimate the prices of coskewness and cokurtosis risk using index option prices. It demonstrates that these prices of risk can be derived from the market variance risk premium and market skewness risk premium, respectively. The study finds that option-based estimates yield reasonable risk premia and improve the performance of factor models compared to regression-based estimates.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:36:47.803046
624b406f55b3ee95,Option-implied correlation between iTraxx Europe Financials and Non-Financials Indexes: A measure of spillover effect in European debt crisis,"This paper proposes an analytic method to estimate the option-implied correlation embedded in options on the iTraxx Europe CDS indexes. The option-implied correlation is suggested as a measure of the spill-over effect of default risk between the financial and corporate sectors in Europe. In particular, the correlation between the iTraxx Financials and Non-Financials sub-indexes is estimated from options on the iTraxx Main Index, which is considered as a basket option with the two sub-indexes being its underlyings. The abrupt changes of the realized correlation anticipated information of the corresponding option prices. The sovereign default risk, funding liquidity risk, level of risk aversion, and equity market performance are identified to be significant determinants of the option-implied correlation, implying interdependence amongst various markets during the European debt crisis. (C) 2013 Elsevier B.V. All rights reserved.","Hui, Cho-Hoi; Lo, Chi-Fai; Lau, Chun-Sing",2013,10.1016/j.jbankfin.2013.05.030,,wos,"This paper introduces a method to calculate option-implied correlation between iTraxx Europe Financials and Non-Financials indexes, using options on the iTraxx Main Index. This implied correlation serves as a metric for default risk spillover between European financial and corporate sectors. The study identifies sovereign default risk, funding liquidity risk, risk aversion, and equity market performance as key drivers of this correlation, highlighting market interdependencies during the European debt crisis.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:37:10.790449
b3a10d9772e08e18,"Oracle Properties, Bias Correction, and Bootstrap Inference for Adaptive Lasso for Time Series M-Estimators","We derive new theoretical results on the properties of the adaptive least absolute shrinkage and selection operator (adaptive lasso) for possibly nonlinear time series models. In particular, we investigate the question of how to conduct inference on the parameters given an adaptive lasso model. Central to this study is the test of the hypothesis that a given adaptive lasso parameter equals zero, which therefore tests for a false positive. To this end, we introduce a recentered bootstrap procedure and show, theoretically and empirically through extensive Monte Carlo simulations, that the adaptive lasso can combine efficient parameter estimation, variable selection, and inference in one step. Moreover, we analytically derive a bias correction factor that is able to significantly improve the empirical coverage of the test on the active variables. Finally, we apply the adaptive lasso and the recentered bootstrap procedure to investigate the relation between the short rate dynamics and the economy, thereby providing a statistical foundation (from a model choice perspective) for the classic Taylor rule monetary policy model.","Audrino, Francesco; Camponovo, Lorenzo",2018,10.1111/jtsa.12270,,wos,"This paper presents theoretical results for the adaptive lasso in time series models, focusing on inference for parameters and hypothesis testing. It introduces a recentered bootstrap procedure and a bias correction factor to improve parameter estimation, variable selection, and inference. The method is applied to analyze the relationship between short-term interest rates and the economy, providing a statistical basis for the Taylor rule.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:37:38.249489
f2eb271685e466d0,PARAMETRIC SPECIFICATION TEST FOR NONLINEAR AUTOREGRESSIVE MODELS,"The paper considers testing parametric assumptions on the conditional mean and variance functions for nonlinear autoregressive models. To this end, we compare the kernel density estimate of the marginal density of the process with a convolution-type density estimate. It is shown that, interestingly, the latter estimate has a parametric (root n) rate of convergence, thus substantially improving the classical kernel density estimates whose rates of convergence are much inferior. Our results are confirmed by a simulation study for threshold autoregressive processes and autoregressive conditional heteroskedastic processes.","Kim, Kun Ho; Zhang, Ting; Wu, Wei Biao",2015,10.1017/s0266466614000681,,wos,"This paper proposes a parametric specification test for nonlinear autoregressive models by comparing kernel density estimates of the marginal density with a convolution-type density estimate. The convolution-type estimate achieves a parametric rate of convergence, outperforming classical kernel estimates. The method is validated through simulations on threshold autoregressive and autoregressive conditional heteroskedastic processes.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:37:46.957350
f6f95c3a073ff11d,Parameter Estimations of Heston Model Based on Consistent Extended Kalman Filter,"Heston model is widely applied to financial institutions, while there still exist difficulties in estimating the parameters and volatilities of this model. In this paper, the pseudo Maximum Likelihood Estimation and consistent extended Kalman filter (PMLE-CEKF) are implemented synchronously to estimate the Heston model. For parameter estimations, PMLE for the state equation and the measurement equation of the Heston model are conducted independently. For volatility estimations, the consistent extended Kalman filter (CEKF) algorithm is introduced to ensure the volatility to be well evaluated. Additionally, the estimation results of the Heston model are compared between PMLE-CEKF and PMLE-EKF algorithm. The numerical simulations illustrate that PMLE-CEKF algorithm works more efficiently than PMLE-EKF algorithm. Application of the PMLE-CEKF to S&P 500 shows the utility of the proposed algorithm. (C) 2017, IFAC (International Federation of Automatic Control) Hosting by Elsevier Ltd. All rights reserved.","Wang, Ximei; He, Xingkang; Zhao, Yanlong; Zuo, Zhiqiang",2017,10.1016/j.ifacol.2017.08.1850,,wos,"This paper implements a synchronous approach using Pseudo Maximum Likelihood Estimation (PMLE) and a Consistent Extended Kalman Filter (CEKF) to estimate parameters and volatilities of the Heston model, a model commonly used in financial institutions. The study compares the PMLE-CEKF algorithm with the PMLE-EKF algorithm, demonstrating the former's superior efficiency through numerical simulations and an application to the S&P 500 index.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:37:52.192206
dde88ce8c7f12863,Physical vs. Transition climate risks: Asymmetric effects on stock return predictability,"This paper examines the predictive role of two dominant climate risk categories-physical and transition risks-in forecasting U.S. equity market risk premiums. The results reveal a pronounced asymmetry: physical climate risk significantly and negatively predicts stock returns both in-sample and out-of-sample, whereas transition climate risk demonstrates insignificant forecasting ability. This superior performance of physical risk delivers greater economic gains to investors and remains robust even after controlling for widely used economic predictors. However, its predictability is state-dependent, weakening during economic disruptions and strengthening following the COP21 Agreement. Further analysis shows that the cash flow and sentiment channels potentially drive the strong predictability of physical risk. Overall, our findings underscore the importance of incorporating physical climate risk into equity return forecasting models, offering actionable insights for financial decision-making processes.","Zhou, Mingtao; Ma, Yong",2025,10.1016/j.irfa.2025.104266,,wos,"This study investigates the predictive power of physical and transition climate risks on U.S. equity market risk premiums. It finds that physical climate risk significantly predicts stock returns, while transition climate risk does not. The predictability of physical risk is state-dependent and potentially driven by cash flow and sentiment channels, offering insights for financial decision-making.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:37:54.495898
f103b6f4fbd0108a,Portfolio Selection and Optimization through Neural Networks and Markowitz Model: A Case of Pakistan Stock Exchange Listed Companies,"This paper used artificial neural networks (ANNs) time series predictor for approximating returns of Pakistan Stock Exchange (PSX) listed 100 companies. These projected returns are then substituted into expected returns in the Markowitz’s Mean Variance (MV) portfolio Model. For comparison empirical data used is closing prices of PSX listed stocks, Karachi Inter Bank Offer Rates (KIBOR) as risk free rate and KSE-all share index as benchmark. The Portfolio returns are compared for two datasets by employing various constraints like budget, transaction costs, and turnover constraints. The value of portfolios is measured through Sharpe ratio and Information ratio. Both Sharpe and Information ratios support use of ANNs as return predictor and optimisation tool over simple MV model implemented for empirical data as well as predicted data. ANNs framework performed better in both Long and Short positions and its portfolio returns are significantly higher as compared with MV.",,2019,10.26710/reads.v5i1.354,,proquest,"This paper applies Artificial Neural Networks (ANNs) to predict stock returns for companies listed on the Pakistan Stock Exchange (PSX). These predicted returns are then integrated into the Markowitz Mean Variance (MV) portfolio optimization model. The study compares the performance of portfolios constructed using ANNs with those using the standard MV model, considering various constraints and using Sharpe and Information ratios for evaluation. The results indicate that ANNs perform better as a return predictor and optimization tool, yielding significantly higher portfolio returns.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:37:57.825565
df698990aeb42d1d,Portfolio optimization in the presence of tail correlation,"We investigate the relative performance of optimal versus naive portfolio strategies. The accepted status on this question is that naive diversification outperforms optimal strategies. We revisit this question using U.S. data for equity, Treasury bonds, Gold and Crude Oil between 2002 and 2022 by analyzing the portfolio of investors displaying constant relative risk aversion who also consider tail behavior in the dynamics of assets. We use moment generating functions applied to non-Gaussian processes to obtain accurate model estimation as well as an efficient control variate for the utility maximization problem. Our results show that risk-averse investors that are aware of tail dynamics consistently outperform the most standard portfolio strategies. In particular, highly risk-averse investors substantially outperform the so-called naive 1/N portfolio in both pre-COVID-19 and post-COVID-19 periods. Thus, true portfolio diversification requires considering both the complexity of asset dynamics and realistic risk aversion structures. © 2023 Elsevier B.V., All rights reserved.","Ben Abdelaziz, F.; Chibane, M.",2023,10.1016/j.econmod.2023.106235,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149471432&doi=10.1016%2Fj.econmod.2023.106235&partnerID=40&md5=35edc3923027f51972407c1948146451,scopus,"This study compares optimal and naive portfolio strategies, challenging the notion that naive diversification is superior. Using US equity, Treasury bonds, Gold, and Crude Oil data from 2002-2022, the research incorporates tail correlation and constant relative risk aversion. The findings indicate that risk-averse investors considering tail dynamics achieve better performance than standard strategies, particularly outperforming the 1/N portfolio in both pre- and post-COVID-19 periods. The study emphasizes the importance of accounting for asset dynamics complexity and realistic risk aversion for effective diversification.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:37:59.836155
1fbbbf6449f5cb97,"Predictability and pricing efficiency in forward and spot, developed and emerging currency markets","We study the predictability of forward and spot exchange rates of currencies of emerging and developed economies from 1994 to 2016. Our purpose is to shed light on the efficiency of currency markets and how and why it has evolved over this time. For the currencies of emerging economies, our analysis of rates of return on forward contracts finds some evidence of excess-predictability, especially in the earlier parts of the sample period, consistent with the view that this portion of the foreign exchange market has only become efficient in recent times. When we turn our attention to excess-returns computed from spot exchange rates and spot interest rates, however, we find much less predictability. In particular, over our full sample period, we find no evidence of excess-predictability, in contrast with the results reported by Hsu et al. (2016) but in agreement with Kuang et al. (2014). The different predictability of spot excess-returns and rates of return on forward contracts is a manifestation of the widespread violation of covered interest parity which emerged with the onset of the 2008 financial crisis. © 2020 Elsevier B.V., All rights reserved.","Poti, V.; Levich, R.; Conlon, T.",2020,10.1016/j.jimonfin.2020.102223,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087713148&doi=10.1016%2Fj.jimonfin.2020.102223&partnerID=40&md5=694062d698f7310f40c42b54960ef8e1,scopus,"This study investigates the predictability of forward and spot exchange rates for emerging and developed economies from 1994 to 2016 to understand currency market efficiency. It found some evidence of excess predictability in emerging market forward contracts, particularly earlier in the sample, suggesting increasing efficiency over time. Predictability was lower for spot exchange rates and spot interest rates, with no evidence of excess predictability over the full sample. This difference is attributed to violations of covered interest parity following the 2008 financial crisis.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:38:07.356627
52ddf32cfa8a6bc0,Predictability of sugar futures: evidence from the Indian commodity market,"Purpose – The forecasting power of commodity futures is a matter of intensive research as evidenced by a number of related publications. The purpose of this paper is to illustrate how advanced forecasting techniques improve the predictability of sugar futures in the Indian commodity market. Design/methodology/approach – The forward premium is estimated using ordinary least square regression technique. Different linear and nonlinear models are used to forecast the sugar future spot prices from the futures prices. The forecasting accuracy of each pair of models is then compared by estimating the corresponding Diebold-Mariano test statistics. Findings – From the estimated forward premiums, it is found that there is more volatility toward the date of maturity for a three-month horizon compared to six-month, and 12-month horizons. It is established that the futures prices of sugar, when used in a model, are able to generate better forecasts for the future spot prices. Moreover, the forecasting accuracy is found to be better for a shorter futures horizon. Research limitations/implications – The present study is restricted only to sugar. If sufficient data are available, the same study could be extended to other commodities as well. The findings imply that technical traders would benefit by using advanced forecasting techniques along with futures prices of sugar to determine the expected future spot prices. Practical implications – The findings in this paper suggest that though simple statistical models may be adopted to relate future spot prices to futures prices, more accurate prediction of the price behavior is possible with advanced forecasting methods like the artificial neural network. Social implications – The findings will help market participants such as traders to be better informed about the future spot prices and hence get a better deal. Originality/value – This is one of the first investigations to assess the predictability of commodity futures by employing advanced forecasting techniques.",,2015,10.1108/afr-02-2014-0002,,proquest,"This paper investigates the predictability of sugar futures in the Indian commodity market using advanced forecasting techniques. It compares linear and nonlinear models to forecast sugar future spot prices from futures prices, finding that futures prices improve forecasts, especially for shorter horizons. The study suggests technical traders can benefit from these advanced methods.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:38:10.183825
27f7eabc787858e0,Predictable variation and profitable trading of US equities: A trading simulation using neural networks,"A switching rule conditioned on out-of-sample one-step-ahead predictions of returns is used to establish investment positions in either stocks or Treasury bills. The economic significance of any discernible patterns of predictability is assessed by incorporating transaction costs in the simulated trading strategies. We find that ANN models produce switching signals that could have been exploited by investors in an out-of-sample context to achieve superior cumulative and risk-adjusted returns when compared to either regression or a simple buy-and-hold strategy in the market indices. The robustness of these results across a large number of stock market indices is encouraging. Scope and purpose A large body of evidence has accumulated suggesting that stock returns are predictable by means of publicly available information on a number of financial and macroeconomic variables with an important business cycle component. Previous research has, for the most part, relied on standard statistical techniques (e.g., regression analysis) with unduly restrictive assumptions presumed to hold in the underlying data-generating process. This paper reexamines the evidence regarding predictable variation in US stock returns using both artificial neural network (ANN) and regression, and compares simulated trading results obtained from ANN models with those obtained from regression. (C) 2000 Elsevier Science Ltd. All rights reserved.; A switching rule conditioned on out-of-sample one-step-ahead predictions of returns is used to establish investment positions in either stocks or Treasury bills. The economic significance of any discernible patterns of predictability is assessed by incorporating transaction costs in the simulated trading strategies. We find that ANN models produce switching signals that could have been exploited by investors in an out-of-sample context to achieve superior cumulative and risk-adjusted returns when compared to either regression or a simple buy-and-hold strategy in the market indices. The robustness of these results across a large number of stock market indices is encouraging. © 2004 Elsevier Science B.V., Amsterdam. All rights reserved.","Motiwalla, L.; Wahab, M.",2000,10.1016/s0305-0548(99)00148-3,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034046387&doi=10.1016%2FS0305-0548%2899%2900148-3&partnerID=40&md5=fc139aa19f3bbf2ee1db63ecc6efa633,scopus,"This study investigates predictable variations in US stock returns using Artificial Neural Networks (ANNs) and regression analysis. A trading simulation incorporating transaction costs demonstrates that ANN models can generate profitable trading signals, outperforming regression and buy-and-hold strategies in terms of cumulative and risk-adjusted returns. The findings suggest that ANNs can exploit predictable patterns in stock returns more effectively than traditional methods.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:38:13.972781
314959b9aa6feaf1,Predicting Chinese bond risk premium with machine learning,This paper investigates whether bond yield curve and macroeconomic factors have nonlinear relationships with bond risk premia in the Chinese bond market. We apply machine learning approaches to forecast Chinese treasury bond one-year holding period excess returns. Our results show that the bond yield curve has significant nonlinear predictive relationships with bond risk premia. We find evidence that ‘monetary policy’ and ‘tax’ macroeconomic groups have stronger nonlinear relationships with risk premia while ‘invest’ macroeconomic factors matter more for bonds with longer maturities. This paper provides statistical evidence for a significant relationship between expected bond risk premia and several economic drivers including range of forecast of GDP and bond volatility variables. We further document the economic values of our forecasting results by showing they can generate statistically higher certain equivalent values than those from the benchmark forecast.,,2025,10.1080/1351847x.2024.2446719,,proquest,"This study uses machine learning to predict Chinese treasury bond risk premia, finding significant nonlinear relationships with the yield curve and macroeconomic factors like monetary policy and tax. The model's economic value is demonstrated through higher certain equivalent values compared to benchmarks.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T16:38:22.590584
2c07afa57f6fdf97,Predicting Future Earnings Changes Using Machine Learning and Detailed Financial Data,"We use machine learning methods and high‐dimensional detailed financial data to predict the direction of one‐year‐ahead earnings changes. Our models show significant out‐of‐sample predictive power: the area under the receiver operating characteristics curve ranges from 67.52% to 68.66%, significantly higher than the 50% of a random guess. The annual size‐adjusted returns to hedge portfolios formed based on the prediction of our models range from 5.02% to 9.74%. Our models outperform two conventional models that use logistic regressions and small sets of accounting variables, and professional analysts’ forecasts. Analyses suggest that the outperformance relative to the conventional models stems from both nonlinear predictor interactions missed by regressions and the use of more detailed financial data by machine learning.",,2022,10.1111/1475-679x.12429,,proquest,"This study employs machine learning and detailed financial data to predict one-year-ahead earnings changes, achieving significant out-of-sample predictive power (AUC 67.52%-68.66%) and generating positive hedge portfolio returns (5.02%-9.74%). The models outperform conventional methods and analyst forecasts, attributed to capturing nonlinear interactions and utilizing richer financial data.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:38:29.333845
d40c4143dfb51f9e,Predicting Stock Jumps and Crashes Using Options,"This paper investigates the informativeness of option-implied volatility and Greeks in forecasting extreme stock returns. Using a large data set of U.S. stocks and options from 1996 to 2022 and employing Light Gradient-Boosting Machine as a machine learning algorithm, we show that option characteristics, particularly implied volatility and delta, are strong predictors of extreme returns. The long-short portfolio utilizing option variables significantly outperforms a benchmark using only stock characteristics, suggesting that options provide information beyond what can be inferred from stock characteristics. Put options are revealed to be more informative than call options, and crashes are easier to predict than jumps.","Andreou, Panayiotis C.; Han, Chulwoo; Li, Nan",2025,10.1002/fut.22609,,wos,"This study explores the use of option-implied volatility and Greeks to predict extreme stock returns (jumps and crashes). Utilizing a Light Gradient-Boosting Machine on a large dataset from 1996-2022, the research demonstrates that option characteristics, especially implied volatility and delta, are effective predictors. The findings indicate that options offer valuable information beyond stock characteristics, with put options being more predictive than call options, and crashes being more predictable than jumps.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:38:30.952980
9d7d055063aef573,Predicting bank inactivity: A comparative analysis of machine learning techniques for imbalanced data,"This study compares the predictive accuracy of a set of machine learning models coupled with three resampling techniques (Random Undersampling, Random Oversampling, and Synthetic Minority Oversampling Technique) in predicting bank inactivity. Our sample includes listed banks in EU-28 member states between 2011 and 2019. We employed 23 financial ratios comprising capital adequacy, asset quality, management capability, earnings, liquidity, and sensitivity indicators. The empirical findings established that XGBoost performs exceptionally well as a classifier in predicting bank inactivity, particularly when considering a one-year time frame before the event. Furthermore, our findings indicate that random forest with Synthetic Minority Oversampling Technique demonstrates the highest predictive accuracy two years prior to inactivity, while XGBoost with Random Oversampling outperforms other methods three years in advance. Furthermore, the empirical results emphasize the significance of management capability and loan quality ratios as key factors in predicting bank inactivity. Our findings present important policy implications.HighlightsBank inactivity predictive accuracy of machine learning techniques with resampling techniques is analyzed.Data on banks in the EU-28 member states between 2011 and 2019 are used.XGBoost performs exceptionally well one year before inactivity.Random Forest with Synthetic Minority Oversampling is the best classifier two years before inactivity.XGBoost with Random Oversampling outperforms other methods three years before inactivity.",,2025,10.1007/s10479-024-06018-0,,proquest,"This study compares machine learning models (XGBoost, Random Forest) with resampling techniques to predict bank inactivity using financial ratios from EU-28 banks (2011-2019). XGBoost was best one year prior, Random Forest with SMOTE two years prior, and XGBoost with Random Oversampling three years prior. Management capability and loan quality ratios were key predictors.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:38:38.131345
992e33dba092f9dd,Predicting corporate bankruptcy using the framework of Leland-Toft: evidence from U.S.,"In this paper, we evaluate an alternative approach for bankruptcy prediction that measures the financial healthiness of firms that have coupon-paying debts. The approach is based on the framework of Leland, H. and Toft, K.B. [Optimal capital structure, endogenous bankruptcy and the term structure of credit spreads. J. Financ., 1996, 51, 987–1019], which is an extension of a widely-used model; the Black–Scholes–Merton model. Using U.S. public firms between 1995 and 2014, we show that the Leland-Toft approach is more powerful than Black–Scholes–Merton in a variety of tests. Moreover, extending popular but also contemporary corporate bankruptcy models with the probability of bankruptcy derived from the Leland-Toft model, such as Altman, E. [Financial ratios, discriminant analysis and the prediction of corporate bankruptcy. J. Financ., 1968, 23, 589–609], Ohlson, J.A. [Financial ratios and the probabilistic prediction of bankruptcy. J. Account. Res., 1980, 18, 109–131] and Campbell, J. Y., Hilscher, J. and Szilagyi, J. [In search of distress risk. J. Financ., 2008, 63, 2899–2939], yields models with improved performance. One of our tests, for example, shows that banks using these extended models, achieve superior economic performance relative to other banks. Our results are consistent under a comprehensive out-of-sample framework. © 2020 Elsevier B.V., All rights reserved.","Charalambous, C.; Martzoukos, S.H.; Taoushianis, Z.",2020,10.1080/14697688.2019.1667519,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074765488&doi=10.1080%2F14697688.2019.1667519&partnerID=40&md5=b15d939b006661b2bf31cd24674df7cd,scopus,"This paper evaluates an alternative approach for bankruptcy prediction using the Leland-Toft framework, which extends the Black-Scholes-Merton model. The study uses U.S. public firms from 1995-2014 and demonstrates that the Leland-Toft approach outperforms the Black-Scholes-Merton model. Incorporating the Leland-Toft probability of bankruptcy into existing models like Altman, Ohlson, and Campbell et al. also improves their performance. The findings are robust under out-of-sample testing, with banks using these extended models showing superior economic performance.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:38:39.742863
3bb815ed509032e9,Predicting risk premium under changes in the conditional distribution of stock returns,"The goal of this paper is to assess time-variation in asset returns while considering the whole conditional distribution. We use a quantile regression framework and quarterly data for the U.S., and show that the probabilistic distribution of expectations about future stock returns changes in response to variation in commonly used explanatory variables. Moreover, our results support the idea that lower quantiles are less stable than upper quantiles, thus, suggesting that asset pricing models are particularly accurate in capturing the expectations that less risk-averse agents have about future returns. © 2017 Elsevier B.V., All rights reserved.","Sousa, J.; Sousa, R.M.",2017,10.1016/j.intfin.2017.09.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030168894&doi=10.1016%2Fj.intfin.2017.09.002&partnerID=40&md5=302310729f73705e6b4efcc18f0ecccc,scopus,"This paper uses quantile regression and quarterly U.S. data to assess time-variation in asset returns by considering the entire conditional distribution. It demonstrates that the probabilistic distribution of expectations about future stock returns changes in response to variations in explanatory variables. The findings suggest that lower quantiles are less stable than upper quantiles, implying that asset pricing models are more accurate for expectations of less risk-averse agents.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:38:45.338466
cc4a38ac36cf4d52,Predicting tanker freight rates using parsimonious variables and a hybrid artificial neural network with an adaptive genetic algorithm,"Short-term prediction of tanker freight rates (TFRs) is strategically important to stakeholders in the oil shipping industry. This study develops a hybrid TFR prediction model based on an artificial neural network (ANN) and an adaptive genetic algorithm (AGA). The AGA adaptively searches satisficing network parameters such as input delay size. The ANN iteratively optimizes a prediction network considering parsimonious variables and time-lag effects as predictors. Three parsimonious variables (crude oil price, fleet productivity and bunker price) are selected by a stepwise regression of TFR variables. The article compares the performance of its hybrid model with two traditional approaches (regression and moving average), as well as with the findings of existing ANN studies. The results of our model (root mean squared error (RMSE)= 11.2 WS) are not only significantly superior to the regression approach (RMSE = 21.6 WS) and the moving average approach (RMSE = 17.5 WS), but are even slightly superior to the results of existing ANN studies (RMSE = 14.6 WS-15.8 WS).","Eslami, Payman; Jung, Kihyo; Lee, Daewon; Tjolleng, Amir",2017,10.1057/mel.2016.1,,wos,"This study proposes a hybrid model combining an Artificial Neural Network (ANN) with an Adaptive Genetic Algorithm (AGA) to predict tanker freight rates (TFRs). The model utilizes parsimonious variables like crude oil price, fleet productivity, and bunker price, and demonstrates superior performance compared to regression, moving average, and existing ANN studies.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:38:50.987031
33fcf9fe6ddb79f7,Prediction of US 30‐years‐treasury‐bonds movement and trading entry point using the robust 1DCNN‐BiLSTM‐XGBoost algorithm,"This article presents a novel algorithm that accurately predicts market trends and identifies trading entry points for US 30‐year Treasury bonds. The proposed method employs a hybrid approach, integrating a 1‐dimensional convolutional neural network (1DCNN), long‐short term memory (LSTM), and XGBoost algorithms. The 1DCNN is used to learn local and short‐term patterns, while LSTM is employed to capture both short and long‐term dependencies. Furthermore, we have implemented an algorithm that utilizes hull moving average (HMA) and simple moving average (SMA) crossover data to detect trading entry points and major trends in the market. The combination of the SMA–HMA crossover algorithm and predictions provided by the 1DCNN‐BiLSTM‐XGBoost algorithm yields exceptional results in terms of prediction accuracy and profitability. Additionally, these integrated techniques effectively filter out noise and mitigate false breakouts, which are often observed with US 30‐year Treasury bonds. In the field of financial time series prediction, the effectiveness of 1DCNN and LSTM in identifying trading entry points and market perturbations has not been comprehensively studied. Therefore, our work fills this gap by demonstrating through experiments that the proposed 1DCNN‐BiLSTM‐XGBoost algorithm, in combination with moving average crossovers, effectively reduces noise and market perturbations. This leads to the precise identification of trading entry points and accurate recognition of trend signals for US 30‐year Treasury bonds. We demonstrate through experiments that our proposed approach achieves an average root mean squared error of 0.0001 and an R‐square value of 0.9999, highlighting its promise as a method for predicting market trends and trading entry points for US 30‐year Treasury bonds.",,2024,10.1111/exsy.13459,,proquest,"This study introduces a novel algorithm combining 1DCNN, BiLSTM, and XGBoost, along with Hull Moving Average (HMA) and Simple Moving Average (SMA) crossovers, to predict US 30-year Treasury bond market trends and identify trading entry points. The approach effectively captures short and long-term patterns, filters noise, and mitigates false breakouts, achieving high prediction accuracy with an RMSE of 0.0001 and R-square of 0.9999.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T16:39:22.163944
60d9172998b8c2be,Prediction of long-term government bond yields using statistical and artificial intelligence methods,"This chapter investigates the use of different artificial intelligence and classical techniques for forecasting the monthly yield of the US 10-year Treasury bonds from a set of four economic indicators. The task is particularly challenging due to the sparseness of the data samples and the complex interactions amongst the variables. At the same time, it is of high significance because of the important and paradigmatic role played by the US market in the world economy. Four data-driven artificial intelligence approaches are considered: a manually built fuzzy logic model, a machine learned fuzzy logic model, a self-organising map model, and a multi-layer perceptron model. Their prediction accuracy is compared with that of two classical approaches: a statistical ARIMA model and an econometric error correction model. The algorithms are evaluated on a complete series of end-month US 10-year Treasury bonds yields and economic indicators from 1986:1 to 2004:12. In terms of prediction accuracy and reliability, the best results are obtained by the three parametric regression algorithms, namely the econometric, the statistical, and the multi-layer perceptron model. Due to the sparseness of the learning data samples, the manual and the automatic fuzzy logic approaches fail to follow with adequate precision the range of variations of the US 10-year Treasury bonds. For similar reasons, the self-organising map model performs unsatisfactorily. Analysis of the results indicates that the econometric model has a slight edge over the statistical and the multi-layer perceptron models. This suggests that pure data-driven induction may not fully capture the complicated mechanisms ruling the changes in interest rates. Overall, the prediction accuracy of the best models is only marginally better than the prediction accuracy of a basic one-step lag predictor. This result highlights the difficulty of the modelling task and, in general, the difficulty of building reliable predictors for financial markets. © 2014 Springer International Publishing Switzerland. © 2016 Elsevier B.V., All rights reserved.","Castellani, M.; Dos Santos, E.A.",2014,10.1007/978-3-319-01866-9_11,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958526206&doi=10.1007%2F978-3-319-01866-9_11&partnerID=40&md5=5bd2589979558156e7b4404cf22ec603,scopus,"This study compares statistical and artificial intelligence methods for forecasting US 10-year Treasury bond yields. It evaluates fuzzy logic, self-organizing maps, multi-layer perceptrons, ARIMA, and error correction models using monthly data from 1986-2004. The best performing models were parametric regression algorithms (econometric, statistical, and multi-layer perceptron), though the econometric model showed a slight advantage. The study notes the difficulty of financial market prediction, with even the best models offering only marginal improvements over a simple one-step lag predictor.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T16:39:27.475845
5957d41f05f017e9,Predictive trading strategy for physical electricity futures,"This article presents an original predictive strategy, based on a new mid-term forecasting model, to be used for trading physical electricity futures. The forecasting model is used to predict the average spot price, which is used to estimate the Risk Premium corresponding to electricity futures trade operations with a physical delivery. A feed-forward neural network trained with the extreme learning machine algorithm is used as the initial implementation of the forecasting model. The predictive strategy and the forecasting model only need information available from electricity derivatives and spot markets at the time of negotiation. In this paper, the predictive trading strategy has been applied successfully to the Iberian Electricity Market (MIBEL). The forecasting model was applied for the six types of maturities available for monthly futures in the MIBEL, from 1 to 6 months ahead. The forecasting model was trained with MIBEL price data corresponding to 44 months and the performances of the forecasting model and of the predictive strategy were tested with data corresponding to a further 12 months. Furthermore, a simpler forecasting model and three benchmark trading strategies are also presented and evaluated using the Risk Premium in the testing period, for comparative purposes. The results prove the advantages of the predictive strategy, even using the simpler forecasting model, which showed improvements over the conventional benchmark trading strategy, evincing an interesting hedging potential for electricity futures trading. © 2020 Elsevier B.V., All rights reserved.","Monteiro, C.; Fernandez-Jimenez, L.A.; Ramírez-Rosado, I.J.",2020,10.3390/en13143555,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090803020&doi=10.3390%2Fen13143555&partnerID=40&md5=d51d140d7458a000e4c17bee11df1825,scopus,"This paper introduces a novel predictive trading strategy for physical electricity futures, utilizing a mid-term forecasting model based on a feed-forward neural network trained with the extreme learning machine algorithm. The model predicts average spot prices to estimate the Risk Premium for futures trades. The strategy, applied to the Iberian Electricity Market, uses only derivative and spot market data. Results demonstrate the strategy's advantages and hedging potential, outperforming benchmark strategies.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:39:30.250849
9e5453d40cead624,Price Forecast of Treasury Bond Market Yield: Optimize Method Based on Deep Learning Model,"Accurate forecasting of the treasury bond market is beneficial for financial institutions to formulate investment research strategies and for national managers to build a modern financial system. This paper integrates the ideas of improved multivariate time series sampling and deep learning prediction model structure optimization, and proposes an optimized deep learning model framework under the LASSO-SMLR-PCA machine learning method. Through the LASSO and SMLR methods, the multicollinearity of the multivariate time series is reduced and the variables with insignificant correlation coefficients are eliminated. Then, the PCA method is used for dimensionality reduction and reconstruction, and finally, the LSTM deep learning model with Bayesian optimized hyperparameters is used to achieve rolling time prediction of the treasury bond market yield price. The empirical results show that the optimized deep learning model performs excellently in terms of evaluation indicators for treasury bond yield price forecasting, with accurate curve fitting, efficient model structure, and stable and effective practical application.",W. Ping; Y. Hu; L. Luo,2024,10.1109/access.2024.3519438,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10806713,ieeexplore,"This paper proposes an optimized deep learning model framework, integrating multivariate time series sampling and model structure optimization, using LASSO-SMLR-PCA methods to reduce multicollinearity and dimensionality, followed by a Bayesian-optimized LSTM model for treasury bond market yield price forecasting. Empirical results demonstrate the model's excellent performance in accuracy, curve fitting, and practical application.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,,2025-10-13T16:39:33.527293
6414f68f51ea9ec4,Pricing Deflation Risk with US Treasury Yields,"We use an arbitrage-free term structure model with spanned stochastic volatility to determine the value of the deflation protection option embedded in Treasury inflation-protected securities. The model accurately prices the deflation protection option prior to the financial crisis when its value was near zero; at the peak of the crisis in late 2008 when deflationary concerns spiked sharply; and in the post-crisis period. During 2009, the average value of this option at the 5-year maturity was 41 basis points on a par-yield basis. The option value is shown to be closely linked to overall market uncertainty as measured by the VIX, especially during and after the 2008 financial crisis.","Christensen, Jens H. E.; Lopez, Jose A.; Rudebusch, Glenn D.",2016,10.1093/rof/rfv029,,wos,"This paper utilizes an arbitrage-free term structure model with spanned stochastic volatility to price the deflation protection option within US Treasury Inflation-Protected Securities. The model's accuracy is demonstrated across different periods, including pre-crisis, the peak of the 2008 financial crisis, and the post-crisis era. The value of the deflation protection option is found to be closely correlated with market uncertainty, particularly the VIX, especially around the 2008 crisis.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:39:36.205663
eb633e8b54bef901,Pricing the volatility risk premium with a discrete stochastic volatility model,"Investors’ decisions on capital markets depend on their anticipation and preferences about risk, and volatility is one of the most common measures of risk. This paper proposes a method of estimating the market price of volatility risk by incorporating both conditional heteroscedasticity and nonlinear effects in market returns, while accounting for asymmetric shocks. We develop a model that allows dynamic risk premiums for the underlying asset and for the volatility of the asset under the physical measure. Specifically, a nonlinear in mean time series model combining the asymmetric autoregressive conditional heteroscedastic model with leverage (NGARCH) is adapted for modeling return dynamics. The local risk-neutral valuation relationship is used to model investors’ preferences of volatility risk. The transition probabilities governing the evolution of the price of the underlying asset are adjusted for investors’ attitude towards risk, presenting the asset returns as a function of the risk premium. Numerical studies on asset return data show the significance of market shocks and levels of asymmetry in pricing the volatility risk. Estimated premiums could be used in option pricing models, turning options markets into volatility trading markets, and in measuring reactions to market shocks. © 2021 Elsevier B.V., All rights reserved.","Šimović, P.; Tafro, A.",2021,10.3390/math9172038,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114048678&doi=10.3390%2Fmath9172038&partnerID=40&md5=b61140065f8e83e82fbeffb2d275f40c,scopus,"This paper proposes a method to estimate the market price of volatility risk using a discrete stochastic volatility model that incorporates conditional heteroscedasticity, nonlinear effects, and asymmetric shocks. It adapts a nonlinear time series model (NGARCH) for return dynamics and uses local risk-neutral valuation to model investor preferences for volatility risk. The model adjusts transition probabilities for risk premiums, showing that market shocks and asymmetry are significant in pricing volatility risk. The estimated premiums can be used in option pricing and for measuring reactions to market shocks.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:39:41.754746
873e33706d751e55,Projected polynomial autoregression for prediction of stationary time series,"Polynomial autoregressions are usually considered to be unrealistic models for time series. However, this paper shows that they can successfully be used when the purpose of the time series study is to provide forecasts. A projection scheme inspired from projection pursuit regression and feedforward artificial neural networks is used in order to avoid an explosion of the number of parameters when considering a large number of lags. The estimation of the parameters of the projected polynomial autoregressions is a non-linear least-squares problem. A consistency result is proved. A simulation study shows that the naive use of the common final prediction error criterion is inappropriate to identify the best projected polynomial autoregression. An explanation of this phenomenon is given and a correction to the criterion is proposed. An important feature of the polynomial predictors introduced in this paper is their simple implementation, which allows for automatic use. This is illustrated with real data for the three-month US Treasury Bill. © 2017 Elsevier B.V., All rights reserved.","de Luna, X.",1998,10.1080/02664769822756,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032459211&doi=10.1080%2F02664769822756&partnerID=40&md5=134c8744849f235aaae3661b345458cd,scopus,"This paper proposes projected polynomial autoregressions for time series forecasting, addressing the issue of parameter explosion with a projection scheme. It demonstrates the method's applicability with real data from US Treasury Bills and suggests a corrected prediction error criterion for model selection.",True,True,True,gemini-2.5-flash-lite,Ulrik,Y,Yes but old,2025-10-13T16:40:18.910619
2278b01d1d5eb032,Pseudo-True SDFs in Conditional Asset Pricing Models,"This article is motivated by the need to bridge some gap between modern asset pric-ing theory and recent developments in econometric methodology. While asset pric-ing theory enhances the use of conditional pricing models, econometric inference of conditional models can be challenging due to misspecification or weak identifica-tion. To tackle the case of misspecification, we utilize the conditional Hansen and Jagannathan (1997) (HJ) distance as studied by Gagliardini and Ronchetti (2016), but we set the focus on interpretation and estimation of the pseudo-true value defined as the argument of the minimum of this distance. While efficient Generalized Method of Moments (GMM) has no meaning for estimation of a pseudo-true value, the HJ-distance not only delivers a meaningful loss function, but also features an additional advantage for the interpretation and estimation of man-aged portfolios whose exact pricing characterizes the pseudo-true pricing kernel (stochastic discount factor (SDF)). For conditionally affine pricing kernels, we can display some managed portfolios which are well-defined independently of the pseudo-true value of the parameters, although their exact pricing is achieved by the pseudo-true SDF. For the general case of nonlinear SDFs, we propose a smooth minimum distance (SMD) estimator (Lavergne and Patilea, 2013) that avoids a focus on specific directions as in the case of managed portfolios. Albeit based on kernel smoothing, the SMD approach avoids instabilities and the resulting need of trim-ming strategies displayed by classical local GMM estimators when the density func-tion of the conditioning variables may take arbitrarily small values. In addition, the fact that SMD may allow fixed bandwidth asymptotics is helpful regarding the curse of dimensionality. In contrast with the true unknown value for a well-specified model, the estimated pseudo-true value, albeit defined in a time-invariant (uncondi-tional) way, may actually depend on the choice of the state variables that define fun-damental factors and their scaling weights. Therefore, we may not want to be overly parsimonious about the set of explanatory variables. Finally, following Antoine and Lavergne (2014), we show how SMD can be further robustified to deal with weaker identification contexts. Since SMD can be seen as a local extension of the method of jackknife GMM (Newey and Windmeijer, 2009), we characterize the Gaussian asymptotic distribution of the estimator of the pseudo-true value using classical U-statistic theorems.","Antoine, Bertille; Proulx, Kevin; Renault, Eric",2020,10.1093/jjfinec/nby017,,wos,"This paper addresses the challenge of estimating conditional asset pricing models, particularly when misspecification or weak identification is present. It focuses on the concept of the pseudo-true value, defined as the minimizer of the conditional Hansen-Jagannathan (HJ) distance. The authors propose a smooth minimum distance (SMD) estimator, which is robust to issues like small density values of conditioning variables and can handle weaker identification contexts. The SMD estimator is shown to have Gaussian asymptotic distribution properties.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:40:21.490715
7eace64f85144252,"Public attention, sentiment and the default of Silicon Valley Bank","We assess the interplay between public attention and trading of the Silicon Valley Bank (SVB) stock before its default on March 10, 2023. Based on intra-day data in 15-min intervals, we estimate SVB market excess returns and match these with intra-day measures of investor attention based on the relative number of tweets and Google searches. Wavelet analysis reveals bilateral lead–lag patterns between both series and demonstrates that a higher level of attention led to a significant decrease in SVB returns. Thereby, the results provide evidence that Twitter sentiment and media attention ultimately fueled and accelerated the crash dynamics of Silicon Valley Bank. Economically, Twitter provides information at lower costs and higher effectiveness than newspapers and allows direct communication without potential distortions from media bias or timing lags in reporting. Hence, individuals can coordinate and communicate their run beliefs at a much faster pace, emphasizing the importance for financial stability. © 2023 Elsevier B.V., All rights reserved.","Bales, S.; Burghof, H.-P.",2024,10.1016/j.najef.2023.102026,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174724134&doi=10.1016%2Fj.najef.2023.102026&partnerID=40&md5=bbf65da12d42f5e1e21b99d3d0426f1b,scopus,"This study examines the relationship between public attention (measured by tweets and Google searches) and the trading of Silicon Valley Bank (SVB) stock leading up to its default. Using intra-day data, the analysis found that increased attention was associated with decreased SVB stock returns, suggesting that social media sentiment and media attention accelerated the bank's collapse. The authors highlight the efficiency of platforms like Twitter for rapid information dissemination and coordination of 'run beliefs', underscoring implications for financial stability.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:40:25.481949
f61f9aaf4b3a4dc3,Public debt stabilization: the relevance of policymakers' time horizons,"Policymakers are stuck in time. Political short-termism, policy myopia, policy short-sightedness, and similar words have been coined to emphasize the present-centric policy thinking. Politics tends to produce short time horizons, and as a result, policymakers often fail to use present opportunities to mitigate future harms. Focusing on fiscal and monetary strategic interactions, given different separate decision makers, our paper aims to explore the effects of policymakers' time horizons on debt stabilization. To formalize our ideas, we use the novel concept of Nonlinear-model-predictive-control Feedback Nash Equilibrium (NFNE) and find that present-centric policy thinking and decision horizons matters under several dimensions.","Di Bartolomeo, Giovanni; Di Pietro, Marco; Saltari, Enrico; Semmler, Willi",2018,10.1007/s11127-018-0584-7,,wos,"This paper investigates how policymakers' short-term perspectives affect public debt stabilization, using a novel Nonlinear-model-predictive-control Feedback Nash Equilibrium (NFNE) framework. It explores the fiscal and monetary strategic interactions and concludes that present-centric policy thinking significantly impacts debt stabilization.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:40:28.039654
771da80fe19611dc,Quasi-likelihood estimation of a threshold diffusion process,"The threshold diffusion process, first introduced by Tong (1990), is a continuous-time process satisfying a stochastic differential equation with a piecewise linear drift term and a piecewise smooth diffusion term, e.g., a piecewise constant function or a piecewise power function. We consider the problem of estimating the (drift) parameters indexing the drift term of a threshold diffusion process with continuous-time observations. Maximum likelihood estimation of the drift parameters requires prior knowledge of the functional form of the diffusion term, which is, however, often unavailable. We propose a quasi-likelihood approach for estimating the drift parameters of a two-regime threshold diffusion process that does not require prior knowledge about the functional form of the diffusion term. We show that, under mild regularity conditions, the quasi-likelihood estimators of the drift parameters are consistent. Moreover, the estimator of the threshold parameter is super consistent and weakly converges to some non-Gaussian continuous distribution. Also, the estimators of the autoregressive parameters in the drift term are jointly asymptotically normal with distribution the same as that when the threshold parameter is known. The empirical properties of the quasi-likelihood estimator are studied by simulation. We apply the threshold model to estimate the term structure of a long time series of US interest rates. The proposed approach and asymptotic results can be readily lifted to the case of a multi-regime threshold diffusion process.",,2015,10.1016/j.jeconom.2015.03.038,,proquest,"This paper proposes a quasi-likelihood estimation method for threshold diffusion processes, which are continuous-time processes with piecewise linear drift and piecewise smooth diffusion terms. The method estimates drift parameters without requiring prior knowledge of the diffusion term's functional form. The estimators are shown to be consistent, with the threshold parameter estimator being super consistent and the autoregressive parameter estimators being asymptotically normal. The approach is demonstrated through simulations and applied to US interest rate term structure estimation, with potential for extension to multi-regime processes.",True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:40:53.135067
4ca5e1c5b38940ea,Rational overoptimism and limited liability,"Is excessive risk-taking in credit cycles driven by incentives or biased beliefs? I propose a framework suggesting that the two are actually related and, specifically, that procyclical overoptimism can arise rationally from risk-taking incentives. I show that when firms and banks have a limited liability payoff structure, they have lower incentives to pay attention to the aggregate conditions that generate risk. This leads to systematic underestimation of the accumulation of risk during economic booms and overoptimistic beliefs. As a result, agents lend and borrow excessively, further increasing downside risk. Credit cycles driven by this new “uninformed” risk-taking are consistent with existing evidence such as high credit and low-risk premia predicting a higher probability of crises and negative returns for banks. My model suggests that regulating incentives can decrease overoptimistic beliefs and thus mitigate boom-and-bust cycles. © 2024 Elsevier B.V., All rights reserved.","Gemmi, L.",2024,10.1016/j.jmoneco.2023.11.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176101825&doi=10.1016%2Fj.jmoneco.2023.11.002&partnerID=40&md5=7c53bdf5beda43dd6dbaec5930afffaf,scopus,"This paper proposes a framework where rational overoptimism arises from risk-taking incentives, particularly in the presence of limited liability for firms and banks. This leads to underestimation of aggregate risk, excessive lending/borrowing, and boom-bust cycles. The model suggests that regulating incentives can mitigate these cycles.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:40:54.987482
0eff708fe81a1f18,Recursive bayesian estimation in forward price models implied by fair pricing,"In this paper we describe a recursive Bayesian algorithm for the estimation of forward price models. The forward price is modeled within the benchmark framework for a forward price volatility function which includes a stochastic variable; a forward price with a liquidly traded maturity. A relationship between the bond price, the spot price and certain forward prices is stated. We set up the stochastic real world dynamics for these discretely compounded market observed forward prices. We propose a dynamic Bayesian estimation algorithm for a Monte Carlo time-discretized version of the resulting forward prices dynamics. The parameter to be estimated is a vector consisting of the forward price volatility parameters and the benchmarked bond price volatility parameters. © 2010 World Scientific Publishing Company. © 2010 Elsevier B.V., All rights reserved.","El Qalli, Y.",2010,10.1142/s0219024910005784,https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952516296&doi=10.1142%2FS0219024910005784&partnerID=40&md5=5245caaa7c31ebe7cd25a2cde564d272,scopus,"This paper presents a recursive Bayesian algorithm for estimating forward price models, incorporating a stochastic volatility function and a liquidly traded maturity. It establishes a relationship between bond prices, spot prices, and forward prices, and proposes a dynamic Bayesian estimation algorithm for a Monte Carlo time-discretized version of the forward price dynamics. The parameters estimated include forward price volatility and benchmarked bond price volatility.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:41:07.211469
32ae7d077ced29f9,Reducing Waiting Times to Improve Patient Satisfaction: A Hybrid Strategy for Decision Support Management,"Patient satisfaction and operational efficiency are critical in healthcare. Long waiting times negatively affect patient experience and hospital performance. Addressing these issues requires accurate system time predictions and actionable strategies. This paper presents a hybrid framework combining predictive modeling and optimization to reduce system times and enhance satisfaction, focusing on registration, vitals, and doctor consultation. We evaluated three predictive models: multiple linear regression (MLR), log-transformed regression (LTMLR), and artificial neural networks (ANN). The MLR model had the best performance, with an (Formula presented.) of 0.93, an MAE of 7.29 min, and an RMSE of 9.57 min. MLR was chosen for optimization due to its accuracy and efficiency, making it ideal for implementation. The hybrid framework combines the MLR model with a simulation-based optimization system to reduce waiting and processing times, considering resource constraints like staff and patient load. Simulating various scenarios, the framework identifies key bottlenecks and allocates resources effectively. Reducing registration and doctor consultation wait times were identified as primary areas for improvement. Efficiency factors were applied to optimize waiting and processing times. These factors include increasing staff during peak hours, improving workflows, and automating tasks. As a result, registration wait time decreased by 15%, vitals by 20%, and doctor consultation by 25%. Processing times improved by 10–15%, leading to an average reduction of 22.5 min in total system time. This paper introduces a hybrid decision support system that integrates predictive analytics with operational improvements. By combining the MLR model with simulation, healthcare managers can predict patient times and test strategies in a risk-free, simulated environment. This approach allows real-time decision-making and scenario exploration without disrupting operations. This methodology highlights how reducing waiting times has a direct impact on patient satisfaction and hospital operational efficiency, offering an applicable solution that does not require significant structural changes. The results are practical and implementable in resource-constrained healthcare environments, allowing for optimized staff management and patient flow. © 2024 Elsevier B.V., All rights reserved.","Morales, J.; Silva-Aravena, F.; Sáez, P.",2024,10.3390/math12233743,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211951995&doi=10.3390%2Fmath12233743&partnerID=40&md5=e8a747b3971e274a71c35b49e1f544cf,scopus,"This paper presents a hybrid decision support system that combines predictive modeling (specifically, multiple linear regression, log-transformed regression, and artificial neural networks) with simulation-based optimization to reduce patient waiting times in healthcare settings. The study found that MLR performed best for prediction and was integrated into the optimization framework. The system identified registration and doctor consultation wait times as key areas for improvement. By implementing strategies such as increasing staff during peak hours and improving workflows, the system achieved significant reductions in waiting and processing times, leading to an average decrease of 22.5 minutes in total system time and a direct impact on patient satisfaction and operational efficiency. The approach is practical, implementable in resource-constrained environments, and allows for risk-free scenario testing.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:41:10.384984
abbff00861afe4d6,Reducing the cost of capital to finance the energy transition in developing countries,"Climate stabilization requires the mobilization of substantial investments in low- and zero-carbon technologies, especially in emerging and developing economies. However, access to stable and affordable finance varies dramatically across countries. Models used to evaluate the energy transition do not differentiate regional financing costs and therefore cannot study risk-sharing mechanisms for renewable electricity generation. In this study, we incorporated the empirically estimated cost of capital differentiated by country and technology into an ensemble of five climate–energy–economy models. We quantified the additional financing cost of decarbonization borne by developing regions and explored policies of risk premium convergence across countries. We found that alleviating financial constraints benefits both climate and equity as a result of more renewable and affordable energy in the developing world. This highlights the importance of fair finance for energy availability, affordability and sustainability, as well as the need to include financial considerations in model-based assessments.Fair finance in the energy sector is modelled in five climate–energy–economy models. The results show that convergence costs of capital could improve energy availability, affordability and sustainability in developing countries, thereby increasing the international equity of the energy transition.",,2024,10.1038/s41560-024-01606-7,,proquest,"This study incorporates country- and technology-specific costs of capital into climate-energy-economy models to analyze the financing of the energy transition in developing countries. It quantifies the additional financing costs faced by developing regions and explores policies for risk premium convergence. The findings suggest that alleviating financial constraints benefits both climate and equity by promoting more affordable and accessible renewable energy in the developing world, emphasizing the need to include financial considerations in model-based assessments.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:41:12.183747
fcef337c3b0fa757,Renewable integration and energy storage management and conversion in grid systems: A comprehensive review,"The dynamic behaviours of battery energy storage systems (BESSs) make their cutting-edge technology for power grid applications. A BESS must have a Battery Management System (BMS) for dependable, efficient, and risk-free operation. With an emphasis on BESSs and the control strategies for their state-of-charge (SoC) balancing, this article thoroughly reviews energy storage systems (ESSs) on a grid scale. It delves into the future of grid-scale BESSs and the function of ESS, focusing on Li-ion battery systems and drawing attention to the essential features and integration hurdles of Li-ion cells. This review examines the many sides, specifically the cost-benefit analysis, operational efficiencies, and financial incentives that push people to use ESSs. To further improve energy storage and utilization, the article delves into managing hybrid storage systems, which combine photovoltaics (PV), batteries, and supercapacitors. Innovative solutions and technological advancements are the main focus of this examination of current trends in power conversion systems (PCS) associated with BESSs. Finally, future developments in energy storage technology are discussed and how they could solve current problems while making the grid more stable and reliable.","Ahmad, Ashraf Bani; Ooi, Chia Ai; Ali, Omer; Charin, Chanuri; Maharum, Siti Marwangi Mohamad; Swadi, Mahmood; Salem, Mohamed",2025,10.1016/j.egyr.2025.02.008,,wos,"This review comprehensively examines grid-scale battery energy storage systems (BESSs), focusing on Battery Management Systems (BMS), State-of-Charge (SoC) balancing, and Li-ion battery integration. It discusses cost-benefit analyses, operational efficiencies, financial incentives, and the management of hybrid storage systems (PV, batteries, supercapacitors). The review also covers power conversion systems (PCS) and future developments for grid stability and reliability.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:41:13.706738
73fcf163344c10da,Research on Financial Stock Market Prediction Based on the Hidden Quantum Markov Model,"Quantum finance, as a key application scenario of quantum computing, showcases multiple significant advantages of quantum machine learning over traditional machine learning methods. This paper first aims to overcome the limitations of the hidden quantum Markov model (HQMM) in handling continuous data and proposes an innovative method to convert continuous data into discrete-time sequence data. Second, a hybrid quantum computing model is developed to forecast stock market trends. The model was used to predict 15 stock indices from the Shanghai and Shenzhen Stock Exchanges between June 2018 and June 2021. Experimental results demonstrate that the proposed quantum model outperforms classical algorithmic models in handling higher complexity, achieving improved efficiency, reduced computation time, and superior predictive performance. This validation of quantum advantage in financial forecasting enables the practical deployment of quantum-inspired prediction models by investors and institutions in trading environments. This quantum-enhanced model empowers investors to predict market regimes (bullish/bearish/range-bound) using real-time data, enabling dynamic portfolio adjustments, optimized risk controls, and data-driven allocation shifts.",,2025,10.3390/math13152505,,proquest,"This paper proposes a hybrid quantum computing model for stock market trend forecasting, addressing limitations of the hidden quantum Markov model (HQMM) in handling continuous data by converting it to discrete-time sequences. The model was tested on 15 stock indices from Chinese exchanges and showed superior performance compared to classical models in terms of efficiency, computation time, and predictive accuracy. The authors suggest this quantum-enhanced model can be practically deployed by investors for market regime prediction and portfolio management.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:41:21.658945
da3315d9fa0074d1,Revisiting asset co-movement: Does network topology really matter?,"Asset co-movement has garnered increasing attention from researchers in both traditional finance and emerging interdisciplinary disciplines. However, there is limited knowledge regarding the consistency of market-wide co-movement proxies constructed based on these two perspectives. Employing Fama–French industry portfolios as samples, we construct market-wide co-movement proxies in terms of R2-based and network-based approaches. We further examine if and how market-wide co-movement is priced using supervised principal analysis (SPCA) proposed by Giglio et al. (2021). Our findings include: First, most topological properties are highly correlated with the R2-based proxies. Second, the risk-premium estimates by the SPCA range from 90 bps to 130 bps per month, depending on the size of the latent factors considered. Furthermore, most co-movement proxies are linked to the characteristics regarding asset fundamentals. However, the associated R2 values remain around only 15%, highlighting the challenges in hedging the risks associated with market-wide co-movement in equity markets. © 2023 Elsevier B.V., All rights reserved.","Shi, H.-L.; Chen, H.",2023,10.1016/j.ribaf.2023.102064,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169609130&doi=10.1016%2Fj.ribaf.2023.102064&partnerID=40&md5=552d46f0a087e1821531a343302ab073,scopus,"This study investigates asset co-movement using both R2-based and network-based approaches with Fama-French industry portfolios. It examines whether market-wide co-movement is priced using supervised principal analysis (SPCA). The findings indicate a strong correlation between topological properties and R2-based proxies, with risk-premium estimates ranging from 90 to 130 bps per month. While co-movement proxies are linked to asset fundamentals, R2 values are low, suggesting challenges in hedging related risks.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:41:27.339945
950e074ff9401528,Risk aversion and the yield of corporate debt,"This paper develops a model to estimate the implied default probability of corporate bonds. The model explicitly considers the risk averse behavior of investors to provide a more precise framework for estimating the implied default probability. A Kalman filter method is used to estimate time-varying risk premium associated with the investor's risk aversion. The results of nonlinear regressions indicate that previous risk-neutrality models consistently overestimate the implied default rates of corporate bonds. The results also suggest that investors may have been adequately compensated for investment in risky bonds. © 2017 Elsevier B.V., All rights reserved.","Wu, C.; Yu, C.-H.",1996,10.1016/0378-4266(94)00099-9,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030100137&doi=10.1016%2F0378-4266%2894%2900099-9&partnerID=40&md5=d3ffd14c6e4c6ebb72f65d65b6f2180e,scopus,"This paper presents a model to estimate the implied default probability of corporate bonds, incorporating investor risk aversion. It uses a Kalman filter for time-varying risk premiums and finds that risk-neutrality models overestimate default rates. The study suggests investors are compensated for holding risky bonds.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:41:30.288131
81e929d489f783c5,Risk premia and seasonality in commodity futures,We develop and estimate a multifactor affine model of commodity futures that allows for stochastic seasonality. We document the existence of stochastic seasonal fluctuations in commodity futures and that properly accounting for the cost‐of‐carry curve requires at least three factors. We estimate the model using data on heating oil futures and analyze the contribution of the factors to risk premia. Correctly specifying seasonality as stochastic is important to avoid erroneously assigning those fluctuations to other risk factors. We also estimate a nonlinear version of the model that imposes the zero lower bound on interest rates and find similar results.,,2018,10.1002/jae.2631,,proquest,"This paper proposes a multifactor affine model for commodity futures, incorporating stochastic seasonality. The model requires at least three factors to accurately represent the cost-of-carry curve. The study finds that stochastic seasonality is crucial for avoiding misattribution of fluctuations to other risk factors. A nonlinear version of the model, accounting for the zero lower bound on interest rates, yields similar results.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:41:32.146194
e46cdb87f9172c01,Risks and risk premiums of GE corn: A macromarketing framework,"It has been more than two decades since genetic engineered (GE) corn has been introduced in the United States and Spain. Despite the wide scale adoption of GE corn, (92% of planted acreage in the US in 2017), biodiversity conservation, environmental protection goals, and food safety continue to surface as potential risk factors. We developed a macromarketing framework to provide a linkage between the consumers, producers, and societal impacts of GE corn. An empirical Arbitrage Pricing Model (APT) was used to quantify risks and risk premiums associated with GE corn production. The risk premium deduced from the APT model provides a measure of intrinsic compensation for taking on higher or lower risks by participants in the marketing system. An Auto-Regressive Distributed Lag (ARDL) regression estimation of the APT model reveals that GE causes corn prices to go down due to increase supply, but significantly reduced the risk premium for producing corn in the United States. GE corn also provided environmental beneficial outcomes by reducing the use of fertilizers.",,2022,10.1016/j.ecolecon.2022.107560,,proquest,"This paper uses a macromarketing framework and an Arbitrage Pricing Model (APT) to analyze the risks and risk premiums associated with GE corn production in the US. The study found that GE corn increases supply, lowers prices, and significantly reduces the risk premium for producers, while also offering environmental benefits through reduced fertilizer use.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:41:34.548100
016ee04e5aa868c2,Robust analysis of default intensity,"The problem of robust estimation and multivariate outlier detection of the term structure of default intensity is considered. Both the multivariate Vasicek and CIR models, embedding the Kalman filter algorithm in a forward search context, are used to estimate default intensity. The focus is not on the estimation of credit models including jumps, but on the automatic detection of masked multiple outliers in multivariate time series. Both simulated and real market credit spread time series are analyzed. In order to make inference on outliers, confidence envelopes which are virtually independent of the estimated parameters are introduced. The output is not only a unique default intensity term structure curve, as often used in the financial literature, but a robust confidence interval within which default intensity is likely to stay. © 2010 Elsevier B.V. All rights reserved. © 2012 Elsevier B.V., All rights reserved.","Bellini, T.; Riani, M.",2012,10.1016/j.csda.2011.03.007,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052729228&doi=10.1016%2Fj.csda.2011.03.007&partnerID=40&md5=c461a0037e44f8f1bb762976a3665485,scopus,"This paper addresses robust estimation and multivariate outlier detection for the term structure of default intensity, utilizing both Vasicek and CIR models with a Kalman filter within a forward search framework. The primary focus is on identifying masked multiple outliers in multivariate time series, rather than on credit models with jumps. The study analyzes both simulated and real market credit spread data, introducing confidence envelopes for outlier inference that are largely parameter-independent. The outcome provides a robust confidence interval for default intensity, moving beyond the single default intensity term structure curve often seen in financial literature.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:41:40.012734
11277b48778899ce,Robust out-of-sample inference,"This paper presents analytical, empirical and simulation results concerning inference about the moments of nondifferentiable functions of out-of-sample forecasts and forecast errors. Special attention is given to the measurement of a model's predictive ability using the test of equal mean absolute error. Tests for equal mean absolute error and mean square error are used to evaluate predictions of excess returns to the S & P 500 composite. Simulations indicate that appropriately constructed tests for equal mean absolute error can provide more accurately sized and more powerful tests than inappropriately constructed tests for equal mean absolute error and mean square error. © 2000 Elsevier Science S.A. All rights reserved. © 2017 Elsevier B.V., All rights reserved.","McCracken, M.W.",2000,10.1016/s0304-4076(00)00022-1,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0001909961&doi=10.1016%2FS0304-4076%2800%2900022-1&partnerID=40&md5=92f2aa5d4aad4c137b65fa13fd612370,scopus,"This paper discusses methods for making inferences about the moments of out-of-sample forecasts and forecast errors, particularly for nondifferentiable functions. It focuses on evaluating predictive ability using tests for equal mean absolute error and mean square error, with an application to predicting excess returns for the S&P 500. Simulations suggest that well-constructed tests for equal mean absolute error are superior to other methods.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:41:45.747689
1a226116b97cd3c2,Robust portfolio choice with limited attention,"This paper investigates a robust portfolio selection problem with the agent’s limited attention. The agent has access to a risk-free asset and a stock in a financial market. But she does not observe perfectly the expected return rate of the stock so she has to estimate this key parameter before making decisions. Besides the general observable financial information, the agent can also acquire a news signal process whose accuracy depends on the agent’s attention. We assume that the agent pays limited attention on the signal and she does not trust her estimation model. So it is necessary to consider model ambiguity in this paper as well. The agent maximizes the expected utility of her terminal wealth under the worst-case scenario. Under this setting, we derive the robust optimal strategy explicitly. In the presence of the attention and ambiguity aversion, the myopic term of the strategy, the hedging term of the strategy and the worst-case scenario are all changed. We find that more attention makes the variance of the estimated return smaller. The numerical examples also show that a more attentive agent has a better estimation of the unobservable parameter and is more confident on her estimation. Consequently, the worst-case scenario deviates less from the reference model, which implies a higher expected return rate under the worst-case scenario, thus invests more in the stock © 2023 Elsevier B.V., All rights reserved.","Ma, Y.; Li, Z.",2023,10.3934/era.2023186,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159911737&doi=10.3934%2FERA.2023186&partnerID=40&md5=f806efd2b7aacacd69a68d507fee36c1,scopus,"This paper examines a robust portfolio selection problem where the agent has limited attention and faces model ambiguity. The agent must estimate the stock's expected return rate using observable financial information and a news signal whose accuracy depends on attention. The agent maximizes expected utility under a worst-case scenario, leading to an explicitly derived robust optimal strategy. Increased attention reduces the variance of the estimated return, improves parameter estimation, and leads to a less deviated worst-case scenario, resulting in higher investment in the stock.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:41:47.385106
9d05ef274491439a,SVM-Based Techniques for Predicting Cross-Functional Team Performance: Using Team Trust as a Predictor,"Due to the characteristics of cross-functional teams, trust is crucial for cross-functional teams to enhance performance. However, as a significant factor, trust had been neglected in previous team performance models. In this paper, we investigate whether trust can be used as a predictor of cross-functional team performance by proposing a prediction model. The inputs of the model are both team structural and contextual (SC) factors, and project process (PP) factors, which are two major sources that form team trust. The output of the model is different levels of team performance, which consists of internal performance and external performance. The support vector machine techniques are used to establish the model. Results show that prediction accuracy is high (84.95%) when using both SC and PP factors as inputs, while PP factors have better prediction accuracy than SC factors on team performance and internal performance. It is suggested that team trust can be used as a good predictor of cross-functional team performance. In practice, this paper presents a better understanding of the relationship between trust and performance in cross-functional teams, and thus, enhances practitioners' managerial skills. It also gives reference for managers to dynamically control and predict team performance during project period.",L. Zhang; X. Zhang,2015,10.1109/tem.2014.2380177,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004820,ieeexplore,"This paper proposes a prediction model using Support Vector Machine (SVM) techniques to predict cross-functional team performance. The model utilizes team structural and contextual factors, along with project process factors, as inputs to predict internal and external team performance. Results indicate high prediction accuracy (84.95%) and suggest that team trust is a significant predictor.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:42:08.772998
031c94725788365c,Satellite-detected gain in built-up area as a leading economic indicator,"Leading indicators of future economic activity include measures such as new housing starts, managers purchasing index, money supply, and bond yields. Such macroeconomic and financial indicators hold predictive power in signaling recessionary periods. However, many indicators are constrained by the fact that data are often published with some delay and are subject to constant revision (Bandholz and Funke 2003, Huanget al 2018, Orphanides 2003). In this research, we propose a leading indicator derived from satellite imagery, the expansion of anthropogenic bare ground. Satellite-detected gain in built-up area, a major land cover and land use (LCLU) outcome of anthropogenic bare ground gain (ABGG), provides an inexpensive, consistent, and near-real-time indicator of global and regional macroeconomic change. Our panel data analysis across four major regions of the world from 2001 to 2012 shows that the logarithm of total ABGG, mostly owing to its major LCLU outcome, the expansion of built-up land in either year t, t - 1 or t - 2, significantly correlated with the year t logarithm of gross domestic product (GDP, de-trended by Hodrick-Prescott filter). Global ABGG between 2001 and 2012 averaged 7875 km(2) yr(-1), with a peak gain of 11 875 (+/- 2014 km(2) at the 95% confidence interval) in 2006, prior to the 2007-2008 global financial crisis. The curve of global ABGG or its major LCLU outcome of built-up area in year t - 1 accords well with that of the de-trended logarithm of the global GDP in year t. Given the 40 year archive of free satellite data, a growing satellite constellation, advances in machine learning, and scalable methods, this study suggests that analyses of ABGG as a whole or its LCLU outcomes can provide valuable information in near-real time for socioeconomic research, development planning, and economic forecasting.","Ying, Qing; Hansen, Matthew C.; Sun, Laixiang; Wang, Lei; Steininger, Marc",2019,10.1088/1748-9326/ab443e,,wos,"This research proposes using satellite-detected built-up area expansion as a near-real-time leading economic indicator. The study analyzes panel data from 2001-2012 across four major regions, finding a significant correlation between the gain in built-up area and the de-trended logarithm of GDP. The authors suggest that satellite data analysis can provide valuable information for economic forecasting.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:42:20.159766
58ae8ef2afebef3f,Semiparametric inference in a GARCH-in-mean model,"A new semiparametric estimator for an empirical asset pricing model with general nonparametric risk-return tradeoff and GARCH-type underlying volatility is introduced. Based on the profile likelihood approach, it does not rely on any initial parametric estimator of the conditional mean function, and it is under stated conditions consistent, asymptotically normal, and efficient, i.e., it achieves the semiparametric lower bound. A sampling experiment provides finite sample comparisons with the parametric approach and the iterative semiparametric approach with parametric initial estimate of Conrad and Mammen (2008). An application to daily stock market returns suggests that the risk-return relation is indeed nonlinear. (C) 2011 Elsevier B.V. All rights reserved.","Christensen, Bent Jesper; Dahl, Christian M.; Iglesias, Emma M.",2012,10.1016/j.jeconom.2011.09.028,,wos,"This paper introduces a new semiparametric estimator for an asset pricing model that incorporates a nonparametric risk-return tradeoff and GARCH-type volatility. The estimator is shown to be consistent, asymptotically normal, and efficient. Empirical results suggest a nonlinear risk-return relationship in stock market returns.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:42:22.642944
33528ceaf46b6df9,"Sensitivity, moment conditions, and the risk-free rate in Yogo (2006)","In this paper, we show that results presented in the seminal paper by Yogo, A Consumption Based Explanation of Expected Stock Returns, cannot be replicated. We find different estimates for the parameters and we obtain values of over-identified statistics that being much larger than those in the original paper indicate rejection of the durable consumption asset pricing model. By careful inspection of Yogo's replication files, we were able to track down the inconsistency to a coding bug. The rejection of the durable model is exemplified by its inability to simultaneously explain the risk-free rate and excess stock returns. © 2018 Elsevier B.V., All rights reserved.","Borri, N.; Ragusa, G.",2017,10.1561/104.00000050,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047126663&doi=10.1561%2F104.00000050&partnerID=40&md5=2e80cdf8a809220a2a0c9a68c39d3f9e,scopus,This paper identifies a coding bug in Yogo (2006) that leads to different parameter estimates and rejection of the durable consumption asset pricing model. The corrected model fails to explain both the risk-free rate and excess stock returns simultaneously.,False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:42:23.731188
8952329c631edb64,Sentiment spillover effects for US and European companies,"The fast-growing literature on news analytics provides evidence that financial markets are partially driven by sentiments. In contrast with previous studies that have almost exclusively focused on the direct effects of the news related to single companies or sectors, we investigate the time-varying dynamics of news’ cross-industry influences for a set of US and European stocks over a period of 10 years. The graphical Granger causality of the news sentiments-excess return networks is estimated by applying the adaptive lasso. We find significant spillover effects and show the importance of sentiments related to certain sectors for the whole cross-section of stocks. © 2019 Elsevier B.V., All rights reserved.","Audrino, F.; Tetereva, A.",2019,10.1016/j.jbankfin.2019.07.022,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070492911&doi=10.1016%2Fj.jbankfin.2019.07.022&partnerID=40&md5=a82745431816b9d30c291b182aa0c89b,scopus,"This study investigates the time-varying dynamics of news sentiment's cross-industry influences on US and European stocks over 10 years, using graphical Granger causality and adaptive lasso to identify significant spillover effects and the importance of sector-specific sentiments.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:42:33.517960
17b1f4e7dc5f6e24,Sequential Monte Carlo Methods to Train Neural Network Models,"We discuss a novel strategy for training neural networks using sequential Monte Carlo algorithms and propose a new hybrid gradient descent/sampling importance resampling algorithm (HySIR). In terms of computational time and accuracy, the hybrid SIR is a clear improvement over conventional sequential Monte Carlo techniques. The new algorithm may be viewed as a global optimization strategy that allows us to learn the probability distributions of the network weights and outputs in a sequential framework. It is well suited to applications involving on-line, nonlinear, and nongaussian signal processing. We show how the new algorithm outperforms extended Kalman filter training on several problems. In particular, we address the problem of pricing option contracts, traded in financial markets. In this context, we are able to estimate the one-step-ahead probability density functions of the options prices.",J. F. G. d. Freitas; M. Niranjan; A. H. Gee; A. Doucet,2000,10.1162/089976600300015664,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6790037,ieeexplore,"This paper introduces a novel strategy for training neural networks using sequential Monte Carlo algorithms, specifically a hybrid gradient descent/sampling importance resampling algorithm (HySIR). HySIR improves upon conventional sequential Monte Carlo methods in terms of computational time and accuracy. It functions as a global optimization strategy for learning probability distributions of network weights and outputs in a sequential framework, suitable for online, nonlinear, and non-Gaussian signal processing. The authors demonstrate its superiority over extended Kalman filter training on various problems, including option pricing in financial markets, where it estimates one-step-ahead probability density functions of option prices.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:42:40.274917
809a91c999a43a8c,Short term forecasting with support vector machines and application to stock price prediction,"Forecasting a stock price movement is one of the most difficult problems in finance. The reason is that financial time series are complex, non stationary. Furthermore, it is also very difficult to predict this movement with parametric models. Instead of parametric models, we propose two techniques, which are data driven and non parametric. Based on the idea that excess returns would be possible with publicly available information, we developed two models in order to forecast the short term price movements by using technical indicators. Our assumption is that the future value of a stock price depends on the financial indicators although there is no parametric model to explain this relationship. This relationship comes from the technical analysis. Comparison shows that support vector regression (SVR) out performs the multi layer perceptron (MLP) networks for a short term prediction in terms of the mean square error. If the risk premium is used as a comparison criterion, then the SVR technique is as good as the MLP method or better.",,2008,10.1080/03081070601068595,,proquest,"This study proposes two non-parametric, data-driven models, including Support Vector Regression (SVR), to forecast short-term stock price movements using technical indicators. SVR demonstrated superior performance compared to Multi-Layer Perceptron (MLP) networks in terms of mean square error for short-term prediction.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:42:44.619198
c82a5d7d6b70548d,Simplicity and Risk,"I introduce and test for preference for simplicity in choice under risk. I characterize the theory axiomatically, and derive its properties and unique predictions relative to canonical models. By designing and running theoretically motivated experiments, I document that people value simplicity in ways not fully captured by existing models that study risk premia in financial markets. Participants' risk premia increase as complexity increases, holding moments fixed; their dominance violations increase in complexity; their behavior is predicted by simplicity's characterizing axiom; and their complexity aversion is heterogeneous in cognitive ability. None of expected utility theory, cumulative prospect theory, prospect theory, rational inattention, sparsity, salience, or probability weighting that differs by number of outcomes fully capture the experimental findings. I generalize the underlying theory to additionally capture broader measures of complexity, including obfuscation, computation, and language effects.",,2025,10.1111/jofi.13417,,proquest,"This paper introduces and empirically tests a theory of preference for simplicity in choice under risk. Experiments show that participants value simplicity, with risk premia increasing and dominance violations increasing with complexity. Existing models like expected utility theory and cumulative prospect theory do not fully capture these findings. The theory is generalized to include broader measures of complexity.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:42:51.616734
f8146118cc97279a,Simulation-based estimation of contingent-claims prices,"A new methodology is proposed to estimate theoretical prices of financial contingent claims whose values are dependent on some other underlying financial assets. In the literature, the preferred choice of estimator is usually maximum likelihood (ML). ML has strong asymptotic justification but is not necessarily the best method in finite samples. This paper proposes a simulation-based method. When it is used in connection with ML, it can improve the finite-sample performance of the ML estimator while maintaining its good asymptotic properties. The method is implemented and evaluated here in the Black-Scholes option pricing model and in the Vasicek bond and bond option pricing model. It is especially favored when the bias in ML is large due to strong persistence in the data or strong nonlinearity in pricing functions. Monte Carlo studies show that the proposed procedures achieve bias reductions over ML estimation in pricing contingent claims when ML is biased. The bias reductions are sometimes accompanied by reductions in variance. Empirical applications to U.S. Treasury bills highlight the differences between the bond prices implied by the simulation-based approach and those delivered by ML. Some consequences for the statistical testing of contingent-claim pricing models are discussed. Reprinted by permission of Oxford University Press",,2009,10.1093/rfs/hhp009,,proquest,"This paper proposes a simulation-based methodology to estimate theoretical prices of financial contingent claims, aiming to improve upon the finite-sample performance of Maximum Likelihood (ML) estimators. The method is applied to option pricing models (Black-Scholes) and bond pricing models (Vasicek), showing bias reduction compared to ML, especially in cases of strong persistence or nonlinearity. Empirical applications to U.S. Treasury bills highlight differences in implied bond prices.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:42:59.085745
0e58fa6aadafd7b6,Sovereign CDS Spread and Term Structure Forecasting Based on Neural Network,"The article aims to forecast credit risk for BRICS countries using daily credit default swaps (CDS) spreads obtained from Datastream data base from 2018 to 2023. Our approach consists, first, of forecasting the CDS spread in order to estimate the forecasted CDS term structure. The general regression neural network (GRNN) is used to predict the CDS spread. By checking the accuracy of the prediction, the results show that the GRNN model can be recommended as an effective forecasting tool for CDS spread. Second, the predicted spreads are used to estimate the forecasted CDS term structure using the Nelson–Siegel model. The results show that for Russia, overall, the CDS spreads in the long term are less than those in the short term, which implies that the future outlook is more optimistic, given the events that occurred during the study period, but it still retains the highest level of credit risk compared to other countries. Unlike Brazil, India and South Africa, the future outlook is more pessimistic. For China, the term structure is unstable; in the short term, there is a tendency to reduce the risk, but for longer horizons, the risk will increase. Thus, BRICS countries have different risk profiles depending on investment horizons. The study’s findings help policymakers in developing tailored risk management strategies for BRICS countries and guide investors in making informed credit investment decisions. The use of advanced forecasting tools like GRNN and Nelson–Siegel models emphasizes the importance of sophisticated techniques in enhancing financial market resilience. © 2024 Elsevier B.V., All rights reserved.","Abid, A.; Souissi, N.",2024,10.1177/09721509241276952,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206434819&doi=10.1177%2F09721509241276952&partnerID=40&md5=e2af5a9387b092f3129034c1c1b3e1d7,scopus,"This study forecasts credit risk for BRICS countries using daily Credit Default Swap (CDS) spreads from 2018-2023. A General Regression Neural Network (GRNN) is employed to predict CDS spreads, demonstrating its effectiveness as a forecasting tool. The predicted spreads are then used with the Nelson–Siegel model to estimate the forecasted CDS term structure. The analysis reveals distinct risk profiles and future outlooks for BRICS countries based on investment horizons, offering insights for policymakers and investors.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:43:14.312053
77a29933a035a55b,Sovereign bond yield spreads and market sentiment and expectations: Empirical evidence from Euro area countries,"The paper investigates the determinants of sovereign bond yield spreads in the Euro area and extends the models commonly used in empirical analyses by focusing on the impact of market expectations and behavioral factors.Using monthly panel data for ten European countries over the period 2000-2012, the analysis adopts a pooled mean-group approach to estimate non-stationary dynamic models of spreads determinants, allowing for country heterogeneities in short-run dynamics.Results show that the behavioral indicators considered, proxies of consumer and market sentiment and expectations, strongly affect spreads behavior, especially during the crisis. Specific attention is also paid to check the robustness of the estimated effects of behavioral indicators and to assess the impact of global financial crisis on the determinants of government bond rate differentials. © 2024 Elsevier B.V., All rights reserved.","Aristei, D.; Duccio Martelli, D.",2014,10.1016/j.jeconbus.2014.08.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927125445&doi=10.1016%2Fj.jeconbus.2014.08.001&partnerID=40&md5=2e2df8bfd63ae330adfe189e467f28ee,scopus,"This paper examines the factors influencing sovereign bond yield spreads in Euro area countries, incorporating market sentiment and expectations. Using monthly panel data from 2000-2012 and a pooled mean-group approach, the study finds that behavioral indicators, representing consumer and market sentiment, significantly impact spreads, particularly during crises. The research also assesses the robustness of these effects and the influence of the global financial crisis.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:43:25.443002
ee3869d724e9f558,Specification tests for nonlinear dynamic models,"We propose a new adequacy test and a graphical evaluation tool for nonlinear dynamic models. The proposed techniques can be applied in any set-up where parametric conditional distribution of the data is specified and, in particular, to models involving conditional volatility, conditional higher moments, conditional quantiles, asymmetry, Value at Risk models, duration models, diffusion models, etc. Compared to other tests, the new test properly controls the nonlinear dynamic behaviour in conditional distribution and does not rely on smoothing techniques that require a choice of several tuning parameters. The test is based on a new kind of multivariate empirical process of contemporaneous and lagged probability integral transforms. We establish weak convergence of the process under parameter uncertainty and local alternatives. We justify a parametric bootstrap approximation that accounts for parameter estimation effects often ignored in practice. Monte Carlo experiments show that the test has good finite-sample size and power properties. Using the new test and graphical tools, we check the adequacy of various popular heteroscedastic models for stock exchange index data.","Kheifets, Igor L.",2015,10.1111/ectj.12040,,wos,"This paper introduces a new adequacy test and graphical tool for nonlinear dynamic models, applicable to various parametric conditional distribution models including those with conditional volatility, quantiles, and Value at Risk. The test controls for nonlinear dynamics without smoothing, uses a multivariate empirical process, and is supported by bootstrap approximation and Monte Carlo simulations. It is applied to heteroscedastic models for stock index data.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:43:35.342053
ff04be79fa6dba3b,Stochastic Gradient Descent in Continuous Time,"Stochastic gradient descent in continuous time (SGDCT) provides a computationally efficient method for the statistical learning of continuous-time models, which are widely used in science, engineering, and finance. The SGDCT algorithm follows a (noisy) descent direction along a continuous stream of data. SGDCT performs an online parameter update in continuous time with the parameter updates theta(t) satisfying a stochastic differential equation. We prove that lim(t ->infinity) del(g) over bar(theta(t)) = 0, where (g) over bar is is a natural objective function for the estimation of the continuous-time dynamics. The convergence proof leverages ergodicity by using an appropriate Poisson equation to help describe the evolution of the parameters for large times. For certain continuous-time problems, SGDCT has some promising advantages compared to a traditional stochastic gradient descent algorithm. This paper mainly focuses on applications in finance, such as model estimation for stocks, bonds, interest rates, and financial derivatives. SGDCT can also be used for the optimization of high-dimensional continuous time models, such as American options. As an example application, SGDCT is combined with a deep neural network to price high-dimensional American options (up to 100 dimensions).","Sirignano, Justin; Spiliopoulos, Konstantinos",2017,10.1137/17m1126825,,wos,"This paper introduces Stochastic Gradient Descent in Continuous Time (SGDCT), an efficient method for learning continuous-time models used in various fields like finance. SGDCT updates parameters in continuous time following a stochastic differential equation and is proven to converge. It offers advantages over traditional SGD for certain problems, particularly in finance for estimating models of stocks, bonds, interest rates, and derivatives. An example application combines SGDCT with deep neural networks for pricing high-dimensional American options.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:44:03.016881
08cd3cdeb999b4d8,Stochastic interest rates in the analysis of energy investments: Implications on economic performance and sustainability,"A systematic impact assessment of stochastic interest and inflation rates on the analysis of energy investments is presented. A real-options algorithm has been created for this task. Constant interest rates incorporating high risk premium have been extensively used for economic calculations, within the framework of traditional direct cash flow methods, thus favouring immediate, irreversible investments in the expense of, sometimes, insubstantially low anticipated yields. In this article, not only incomes and expenses but also interest and inflation rates are considered stochastically evolving according to specific probabilistic models. The numerical experiments indicated that the stochastic interest rate forecasts fluctuate in such low levels that may signal delayed investment entry in favour of higher expected yields. The implementation of stochastically evolving interest rates in energy investment analysis may have a controversial effect on sustainability. Displacements of inefficient plants may be significantly delayed, thus prolonging high CO sub(2) emission rates. Under the current CO sub(2) allowance prices or their medium-term forecasts, this situation may not be improved and flexible policy interventions may be necessitated.",,2010,10.1016/j.apenergy.2009.11.033,,proquest,"This paper presents a systematic impact assessment of stochastic interest and inflation rates on energy investments using a real-options algorithm. It argues that traditional methods using constant interest rates may favor immediate investments, while stochastic modeling suggests delayed investment entry due to fluctuating low interest rates. This can have controversial effects on sustainability, potentially delaying the displacement of inefficient plants and prolonging high CO2 emissions, necessitating policy interventions.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:44:06.955882
09fa231c7b4e23cf,Stock Selection Using Machine Learning Based on Financial Ratios,"Stock prediction has garnered considerable attention among investors, with a recent focus on the application of machine learning techniques to enhance predictive accuracy. Prior research has established the effectiveness of machine learning in forecasting stock market trends, irrespective of the analytical approach employed, be it technical, fundamental, or sentiment analysis. In the context of fiscal year-end selection, the decision may initially seem straightforward, with December 31 being the apparent choice, as discussed by B. Kamp in 2002. The primary argument for a uniform fiscal year-end centers around comparability. When assessing the financial performance of two firms with differing fiscal year-ends, substantial shifts in the business environment during non-overlapping periods can impede meaningful comparisons. Moreover, when two firms merge, the need to synchronize their annual reporting often results in shorter or longer fiscal years, complicating time series analysis. In the US S&P stock market, misaligned fiscal years lead to variations in report publication dates across different industries and market segments. Since the financial reporting dates of US S&P companies are determined independently by each listed entity, relying solely on these dates for investment decisions may prove less than entirely reliable and impact the accuracy of return prediction models. Hence, our interest lies in the synchronized fiscal year of the TW stock market, leveraging machine learning models for fundamental analysis to forecast returns. We employed four machine learning models: Random Forest (RF), Feedforward Neural Network (FNN), Gated Recurrent Unit (GRU), and Financial Graph Attention Network (FinGAT). We crafted portfolios by selecting stocks with higher predicted returns using these machine learning models. These portfolios outperformed the TW50 index benchmarks in the Taiwan stock market, demonstrating superior returns and portfolio scores. Our study’s findings underscore the advantages of using aligned financial ratios for predicting the top 20 high-return stocks in a mid-to-long-term investment context, delivering over 50% excess returns across the four models while maintaining lower risk profiles. Using the top 10 high-return stocks produced over 100% relative returns with an acceptable level of risk, highlighting the effectiveness of employing machine learning techniques based on financial ratios for stock prediction.",,2023,10.3390/math11234758,,proquest,"This study investigates the use of machine learning models (Random Forest, FNN, GRU, FinGAT) to predict stock returns in the Taiwan stock market, utilizing synchronized financial ratios. The developed portfolios based on predicted returns outperformed the TW50 index, demonstrating the effectiveness of this approach for mid-to-long-term investment and highlighting the benefits of aligned financial reporting for predictive accuracy.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:44:10.082071
0c6ee7d2bea7d19d,Stock Trading Strategy Based on Multi-Scale Deep Reinforcement Learning and Price Movement Prediction,"Owing to the dynamic and complex properties of the stock market, generating a stable and highly profitable trading strategy is a challenge. Therefore, in this paper, a novel trading strategy is proposed, grounded in multi-scale deep reinforcement learning and stock price trend prediction, with supervised learning and reinforcement learning unified within a unified framework. Our proposed method is separated into three stages. First, a novel network was designed to predict stock price movement (upward, stationary, or downward) with 67.34% accuracy by combining the strengths of Convolutional Neural Network and Long-Short Term Memory. Second, leveraging the trained trend prediction network, states were enhanced with daily and weekly stock information, and multi-scale and backbone network modules were employed for effective feature extraction. Finally, a Double Deep Q-Network algorithm based on the augmented state was adopted to learn robust trading strategies. This study also contributes to the theoretical advancement of stock price prediction models by introducing a hybrid CNN-LSTM architecture for trend prediction and a multi-scale feature extraction framework for improved decision-making. Experimental results across six U.S. financial assets demonstrate that a notable accuracy of 67.34% for price trend prediction is achieved by our Convolutional Neural Network-Long-Short Term Memory network. Furthermore, the proposed trading strategy outperforms other deep reinforcement learning algorithms, yielding an average annualized return of 44.47%. By comparison, the PPO model achieves 37.60%, the TDQN model achieves 13.38%, the DQN-vanilla model achieves 28.71%, and the DQN-pattern model achieves 22.21%. These results validate the efficacy of the approach, showcasing substantial excess returns. © 2025 Elsevier B.V., All rights reserved.","Huang, Y.; Cui, K.; Lu, X.",2025,10.1142/s0219622025500737,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012223869&doi=10.1142%2FS0219622025500737&partnerID=40&md5=d6dec46fc1f5507e9743879f2357481f,scopus,"This paper proposes a novel stock trading strategy using multi-scale deep reinforcement learning and price movement prediction. It combines CNN-LSTM for trend prediction (67.34% accuracy) and a Double Deep Q-Network for strategy learning. The strategy achieved an average annualized return of 44.47%, outperforming other deep reinforcement learning algorithms.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:44:12.429171
b637484b643b9a37,Stock investment strategy combining earnings power index and machine learning,"We propose an intermediate-term stock investment strategy based on fundamental analysis and machine learning. The approach uses predictors from the Earnings Power Index (EPI) as input variables derived from cross-sectional and time-series data from a company's financial statements. The analytical methods of machine learning allow us to validate the link between financial factors and excess returns directly. We then select stocks for which returns are likely to increase at the time of the next disclosed financial statement. To verify the proposed approach's usefulness, we use company data listed publicly on the Korean stock market from 2013 to 2019. We examine the profitability of trading strategy based on ten machine-learning techniques by forming long, short, and hedge portfolios with three different measures. As a result, most portfolios, including EPI-related variables, present positive returns regardless of the period. Especially, the neural network of the two layers with sigmoid function presents the best performance for the period of 3 months and 6 months, respectively. Our results show that incorporating machine learning is useful for mid-term stock investment. Further research into the possible convergence of financial statement analysis and machine-learning techniques is warranted. © 2022 Elsevier B.V., All rights reserved.","Jun, S.Y.; Kim, D.S.; Jung, S.Y.; Jun, S.G.; Kim, J.W.",2022,10.1016/j.accinf.2022.100576,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138051303&doi=10.1016%2Fj.accinf.2022.100576&partnerID=40&md5=c12843ef5be8986f6a9785fb0232e51f,scopus,"This study proposes a stock investment strategy using the Earnings Power Index (EPI) and machine learning. It analyzes financial statement data to predict stock returns and tests the strategy on Korean stock market data from 2013-2019 using ten machine learning techniques. The results indicate that incorporating machine learning with EPI variables is beneficial for intermediate-term stock investment, with a two-layer neural network showing the best performance.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:44:14.132863
357b115e59209cb9,Stock selection with random forest: An exploitation of excess return in the Chinese stock market,"In recent years, a variety of research fields, including finance, have begun to place great emphasis on machine learning techniques because they exhibit broad abilities to simulate more complicated problems. In contrast to the traditional linear regression scheme that is usually used to describe the relationship between the stock forward return and company characteristics, the field of finance has experienced the rapid development of tree-based algorithms and neural network paradigms when illustrating complex stock dynamics. These nonlinear methods have proved to be effective in predicting stock prices and selecting stocks that can outperform the general market. This article implements and evaluates the robustness of the random forest (RF) model in the context of the stock selection strategy. The model is trained for stocks in the Chinese stock market, and two types of feature spaces, fundamental/technical feature space and pure momentum feature space, are adopted to forecast the price trend in the long run and the short run, respectively. It is evidenced that both feature paradigms have led to remarkable excess returns during the past five out-of-sample period years, with the Sharpe ratios calculated to be 2.75 and 5 for the portfolio net value of the multi-factor space strategy and momentum space strategy, respectively. Although the excess return has weakened in recent years with respect to the multi-factor strategy, our findings point to a less efficient market that is far from equilibrium.In recent years, a variety of research fields, including finance, have begun to place great emphasis on machine learning techniques because they exhibit broad abilities to simulate more complicated problems. In contrast to the traditional linear regression scheme that is usually used to describe the relationship between the stock forward return and company characteristics, the field of finance has experienced the rapid development of tree-based algorithms and neural network paradigms when illustrating complex stock dynamics. These nonlinear methods have proved to be effective in predicting stock prices and selecting stocks that can outperform the general market. This article implements and evaluates the robustness of the random forest (RF) model in the context of the stock selection strategy. The model is trained for stocks in the Chinese stock market, and two types of feature spaces, fundamental/technical feature space and pure momentum feature space, are adopted to forecast the price trend in the long run and the short run, respectively. It is evidenced that both feature paradigms have led to remarkable excess returns during the past five out-of-sample period years, with the Sharpe ratios calculated to be 2.75 and 5 for the portfolio net value of the multi-factor space strategy and momentum space strategy, respectively. Although the excess return has weakened in recent years with respect to the multi-factor strategy, our findings point to a less efficient market that is far from equilibrium.",,2019,10.1016/j.heliyon.2019.e02310,,proquest,"This study evaluates the Random Forest (RF) model for stock selection in the Chinese market, utilizing both fundamental/technical and momentum feature spaces. The RF model demonstrated significant excess returns over a five-year out-of-sample period, with Sharpe ratios of 2.75 and 5 for the respective strategies, suggesting market inefficiency.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:44:17.095911
86f133ebdc5eaa79,Strategy and tactics in public debt management,"We examine the public debt management problem with respect to the maturity mix of new issues in a mean-variance framework. After identifying the main determinants of the long-run target (strategy), we focus on which interest rate conditions allow for a temporary deviation (tactics). The study is partly motivated by the apparent window of opportunity to issue more heavily at longer maturities given the recent historically low yields. We show that the room for long tactical positions on the long-term bond is actually narrower than predicted by rules of thumb based on Sharpe-like ratios. Once the model is augmented to embed real world features such as no price-taking and transaction costs, the scope for tactical position shrinks further. We discuss the model results and its implications in terms of the principal agent dilemma (government vs. debt manager); the paper also explores the financial stability implications arising from public debt issuance choices. All in all, our findings provide a rationale for the degree of caution often shown by many public debt managers in fulfilling their mandate. (C) 2015 Society for Policy Modeling. Published by Elsevier Inc. All rights reserved.","Dottori, Davide; Manna, Michele",2016,10.1016/j.jpolmod.2015.12.003,,wos,"This paper analyzes public debt management, focusing on the maturity mix of new debt issues within a mean-variance framework. It distinguishes between long-run strategy (target maturity mix) and short-term tactics (deviations based on interest rate conditions). The study finds that the opportunity for tactical issuance at longer maturities, despite historically low yields, is narrower than commonly assumed, especially when considering real-world factors like non-price-taking behavior and transaction costs. The findings also touch upon principal-agent issues and financial stability implications, suggesting a rationale for the cautious approach often adopted by debt managers.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:44:19.107557
c38e480a7ebbb97e,Strongly-typed genetic programming and fuzzy inference system: An embedded approach to model and generate trading rules,"Generating trading signals is an interesting topic and a hard problem to solve. This work uses fuzzy inference system (FIS) and strongly typed genetic programming (STGP) to generate trading rules for the US stock market, a framework that we call FISTGP. The two embedded models have not been widely evaluated in financial applications, and according to the literature, their combination could improve forecasting performance. The fitness function used to train the STGP model is based on accuracy, optimizing the buy and sell signals, taking a different approach to the classic optimization of return–risk ratio. The rules are generated in a FIS framework, and the final signal depends on the amount of information that the investor relies on. The model is suited to each investor as a recommendation of when to change portfolio composition according to his or her particular criteria. Ternary rules are generated based on an economic interpretation, considering the risk-free rate as a part of more demanding rules. The model is applied to 90 of the most traded and active stocks in the US stock market. This approach generates important recommendations and delivers useful information to investors. The results show that the proposed model outperforms the Buy and Hold (B&H) strategy by 28.62% in the test period, considering excesses of return, with almost the same risk (1.28% higher). The other base models underperform in comparison to the B&H, with the proposed model also outperforming them. © 2020 Elsevier B.V., All rights reserved.","Michell, K.; Kristjanpoller R., W.",2020,10.1016/j.asoc.2020.106169,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079842746&doi=10.1016%2Fj.asoc.2020.106169&partnerID=40&md5=7d044e5fcb41907b98487380158cfe03,scopus,"This study introduces FISTGP, a novel framework combining Fuzzy Inference System (FIS) and Strongly Typed Genetic Programming (STGP) to generate trading rules for the US stock market. Unlike traditional methods optimizing return-risk ratio, FISTGP uses an accuracy-based fitness function. The generated rules are interpretable and adaptable to individual investor criteria, incorporating the risk-free rate. Applied to 90 active US stocks, FISTGP demonstrated a 28.62% excess return compared to the Buy and Hold strategy with comparable risk, outperforming other base models.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:44:26.238168
24e3321504f74b62,Structural Laplace Transform and Compound Autoregressive Models,"This paper presents a new general class of compound autoregressive (Car) models for non-Gaussian time series. The distinctive feature of the class is that Car models are specified by means of the conditional Laplace transforms. This approach allows for simple derivation of the ergodicity conditions and ensures the existence of forecasting distributions in closed form, at any horizon. The last property is of particular interest for applications to finance and economics that investigate the term structure of variables and/or of their nonlinear transforms. The Car class includes a number of time-series models that already exist in the literature, as well as new models introduced in this paper. Their applications are illustrated by examples of portfolio management, term structure and extreme risk analysis.",,2006,10.1111/j.1467-9892.2006.00479.x,,proquest,"This paper introduces a new class of compound autoregressive (Car) models for non-Gaussian time series, defined using conditional Laplace transforms. This method simplifies the derivation of ergodicity conditions and provides closed-form forecasting distributions, which are valuable for financial and economic applications involving term structures and nonlinear transformations. The Car class encompasses existing and novel time-series models, with applications demonstrated in portfolio management, term structure analysis, and extreme risk assessment.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,Yes but old,2025-10-13T16:45:14.337485
fdcb4bf37f076de6,Structural break threshold VARs for predicting us recessions using the spread,"This paper proposes a model to predict recessions that accounts for non-linearity and a structural break when the spread between long- and short-term interest rates is the leading indicator. Estimation and model selection procedures allow us to estimate and identify time-varying non-linearity in a VAR. The structural break threshold VAR (SBTVAR) predicts better the timing of recessions than models with constant threshold or with only a break. Using real-time data, the SBTVAR with spread as leading indicator is able to anticipate correctly the timing of the 2001 recession. Copyright (c) 2006 John Wiley & Sons, Ltd.","Galvao, Ana Beatriz C.",2006,10.1002/jae.840,,wos,"This paper introduces a Structural Break Threshold Vector Autoregression (SBTVAR) model to predict US recessions using the interest rate spread as a leading indicator. The model accounts for non-linearity and structural breaks, outperforming simpler models in predicting recession timing. It successfully anticipated the 2001 recession using real-time data.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:45:23.328898
60815d5382594062,Structure of the intact ppar-γ-rxr-α nuclear receptor complex on dna,"This article develops critical values to test the null hypothesis of a unit root against the alternative of stationarity with asymmetric adjustment. Specific attention is paid to threshold and momentum threshold autoregressive processes. The standard Dickey–Fuller tests emerge as a special case. Within a reasonable range of adjustment parameters, the power of the new tests is shown to be greater than that of the corresponding Dickey–Fuller test. The use of the tests is illustrated using the term structure of interest rates. It is shown that the movements toward the long-run equilibrium relationship are best estimated as an asymmetric process. © 1998 Taylor & Francis Group, LLC. © 2017 Elsevier B.V., All rights reserved.","Enders, W.; Granger, C.W.J.",1998,10.1080/07350015.1998.10524769,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032345729&doi=10.1080%2F07350015.1998.10524769&partnerID=40&md5=22eda4c7422cb3f9079f6babe2f18cb9,scopus,"This article develops critical values for testing unit roots against stationarity with asymmetric adjustment, focusing on threshold and momentum threshold autoregressive processes. It shows that the power of these new tests is greater than standard Dickey-Fuller tests within a certain parameter range and illustrates their use with the term structure of interest rates, suggesting asymmetric processes for movements toward long-run equilibrium.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:45:29.891652
a252363c576b1816,Systematic Pricing and Trading of Municipal Bonds,"In this article, the authors propose a systematic approach for pricing and trading municipal bonds that leverages the feature-rich information available at the individual bond level. Based on the proposed pricing framework, they estimate several models using ridge regression and Kalman filtering. In their empirical work, they show that the models compare favorably in pricing accuracy to those available in the literature. In addition, the models can quickly adapt to changing market conditions. Incorporating the pricing models into relative value trading strategies, the authors demonstrate that the resulting portfolios generate significant excess returns and positive alpha relative to the Vanguard Long-Term Tax-Exempt Fund, one of the largest mutual funds in the municipal space. © 2022 Elsevier B.V., All rights reserved.","Kolm, P.N.; Purushothaman, S.",2022,10.3905/jfds.2021.1.079,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127392362&doi=10.3905%2Fjfds.2021.1.079&partnerID=40&md5=0d3f3669aec2fa0af60630b8e7f93f28,scopus,"This article presents a systematic method for pricing and trading municipal bonds using individual bond data and advanced modeling techniques like ridge regression and Kalman filtering. The proposed models demonstrate superior pricing accuracy and adaptability to market changes compared to existing literature. When integrated into trading strategies, these models yield significant excess returns and alpha.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:45:32.433746
61208aa7bc89fbf7,THE SPECULATIVE DEMAND FOR MONEY - AN ALTERNATIVE APPROACH,"THE SPECULATIVE DEMAND FOR MONEY HAS OCCUPIED AN IMPORTANT ROLE IN KEYNES' GENERAL THEORY.  SINCE THEN IT HAS RECEIVED ONLY SPORADIC ATTENTION, DUE LARGELY TO THE FACT THAT THE THEORY IN ITS ORIGINAL FORM HAS USUALLY FAILED TO SURVIVE THE EMPIRICAL TESTS.  THE SPECULATIVE DEMAND FOR MONEY IS ESTIMATED USING THE GENERAL FRAMEWORK OF THE 'EFFICIENT MARKETS THEORY'.  THE PERIOD COVERED IS OF A RELATIVELY STABLE INSTITUTIONAL SETTING FOLLOWING THE 1951 U.S.  TREASURY-FEDERAL RESERVE ACCORD.  THE RESULTS FOR THIS PERIOD STRONGLY INDICATE THE EXISTENCE OF THE SPECULATIVE DEMAND FOR MONEY.  TABLE.  NOTES.",,1976,10.1111/j.1536-7150.1976.tb01210.x,,proquest,"This paper estimates the speculative demand for money using the efficient markets theory framework, focusing on the period after the 1951 U.S. Treasury-Federal Reserve Accord. The results suggest the existence of speculative demand for money during this stable institutional period.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:45:41.057656
1adc7c7a8c852e5d,Technological bias at the exchange rate market,"Prediction of exchange rates has been a topic for debate in economic literature since the late 1980s. The recent development of machine learning techniques has spurred a plethora of studies that further improves the prediction models for currency markets. This high‐tech progress may create challenges for market efficiency along with information asymmetry and irrationality of decision‐making. This technological bias emerges from the fact that recent innovative approaches have been used to solve trading tasks and to find the best trading strategies. This paper demonstrates that traders can leverage technological bias for financial market forecasting. Those traders who adapt faster to the changes in market innovations will get excess returns. To support this hypothesis we compare the performance of deep learning methods, shallow neural networks with baseline prediction methods and a random walk model using daily closing rate between three currency pairs: Euro and US Dollar (EUR/USD), British Pound and US Dollar (GBP/USD), and US Dollar and Japanese Yen (USD/JPY). The results demonstrate that deep learning achieves higher accuracy than alternate methods. The shallow neural network outperforms the random walk model, but cannot surpass ARIMA accuracy significantly. The paper discusses possible outcomes of the technological shift for financial market development and accounting conforming also to adaptive market hypothesis.",,2017,10.1002/isaf.1408,,proquest,"This paper investigates the impact of technological advancements, specifically machine learning, on exchange rate market efficiency and forecasting. It demonstrates that traders can exploit this 'technological bias' for excess returns by adapting faster to innovations. The study compares deep learning, shallow neural networks, and baseline models (ARIMA, random walk) for predicting EUR/USD, GBP/USD, and USD/JPY exchange rates, finding deep learning to be the most accurate.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:45:44.793683
187c6ade28f04d09,Term structure of risk under alternative econometric specifications,"This paper characterizes the term structure of risk measures such as value at risk (VaR) and expected shortfall under different econometric approaches including multivariate regime switching, GARCH-in-mean models with Student-t errors, two-component GARCH models and a nonparametric bootstrap. We show how to derive the risk measures for each of these models and document large variations in term structures across econometric specifications. An out-of-sample forecasting experiment applied to stock, bond and cash portfolios suggests that the best model is asset- and horizon specific but that the bootstrap and regime switching model are best overall for VaR levels of 5% and 1%, respectively. (c) 2005 Elsevier B.V. All rights reserved.","Guidolin, M; Timmermann, A",2006,10.1016/j.jeconom.2005.01.033,,wos,"This paper compares different econometric models (multivariate regime switching, GARCH-in-mean with Student-t errors, two-component GARCH, and nonparametric bootstrap) for estimating risk measures like VaR and expected shortfall. It highlights significant differences in term structures across these models and finds that the best model for out-of-sample forecasting is asset- and horizon-specific, with the bootstrap and regime switching models performing best overall for VaR at 5% and 1% levels, respectively.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:45:53.341954
3d256d8a11b4dd5d,Testing for two-regime threshold cointegration in vector error-correction models,"This paper examines a two-regime vector error-correction model with a single cointegrating vector and a threshold effect in the error-correction term. We propose a relatively simple algorithm to obtain maximum likelihood estimation of the complete threshold cointegration model for the bivariate case. We propose a SupLM test for the presence of a threshold. We derive the null asymptotic distribution, show how to simulate asymptotic critical values, and present a bootstrap approximation. We investigate the performance of the test using Monte Carlo simulation, and find that the test works quite well. Applying our methods to the term structure model of interest rates, we find strong evidence for a threshold effect. (C) 2002 Published by Elsevier Science B.V.","Hansen, BE; Seo, B",2002,10.1016/s0304-4076(02)00097-0,,wos,"This paper proposes a method for testing two-regime threshold cointegration in vector error-correction models, including an algorithm for maximum likelihood estimation and a SupLM test for the threshold effect. Monte Carlo simulations show the test performs well, and an application to the term structure of interest rates provides evidence for a threshold effect.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:45:56.634064
3eebe90718f24024,Testing the expectations theory of the term structure of interest rates in threshold models,"We test the expectations theory of the term structure of U.S. interest rates in nonlinear systems. These models allow the response of the change in short rates to past values of the spread to depend upon the level of the spread. The nonlinear system is tested against a linear system, and the results of testing the expectations theory in both models are contrasted. We find that the results of tests of the implications of the expectations theory depend on the size and sign of the spread. The long maturity spread predicts future changes of the short rate only when it is high. © 2008 Elsevier B.V., All rights reserved.","Clements, M.P.; Galvão, A.B.",2003,10.1017/s1365100502020163,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0141636266&doi=10.1017%2FS1365100502020163&partnerID=40&md5=1acc28231c51f29898d54323e04bb347,scopus,"This study empirically tests the expectations theory of the term structure of U.S. interest rates using nonlinear threshold models. These models allow the relationship between short rates and the spread to vary based on the spread's level. The findings indicate that the predictive power of the long maturity spread for future short rate changes is contingent on the spread being high, suggesting that the expectations theory's implications are sensitive to the spread's magnitude and sign.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:46:14.038312
74695cb70436aa62,"Testing the uncovered interest parity using traded volatility, a time-varying risk premium and heterogeneous expectations","This paper carries out an empirical investigation of an extended version of Flood and Marion's (2000, Self-fulfilling risk predictions: an application to speculative attacks. Journal of International Economics 50, 245-268) UIP model, which incorporates a nonlinear time-varying risk premium that depends on both the expected variance of the future exchange rate and the relative worldwide private holdings of domestic and foreign government bonds. A novel contribution of our paper is the use of traded currency volatility, which is directly observable in the market place, to measure expectations about the future volatility of the exchange rate. Another contribution is the explicit modelling of heterogeneous exchange rate expectations formed by forward-looking fundamentalists and backward-looking chartists. Our overall empirical evidence provides strong support for the extended nonlinear UIP model. We also investigate for the first time the role of traded volatility in the dynamic behaviour of exchange rates, and find that high currency volatility is likely to produce oscillatory and unstable exchange rate paths. © 2006 Elsevier Ltd. All rights reserved. © 2006 Elsevier B.V., All rights reserved.","Sarantis, N.",2006,10.1016/j.jimonfin.2006.08.002,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750960093&doi=10.1016%2Fj.jimonfin.2006.08.002&partnerID=40&md5=5f02c4167892f6e8da7fd7b515be19f7,scopus,"This paper empirically investigates an extended version of the Flood and Marion (2000) UIP model, incorporating a nonlinear time-varying risk premium and heterogeneous expectations. It uses traded currency volatility to measure expected future volatility and explicitly models expectations formed by fundamentalists and chartists. The findings strongly support the extended model and suggest that high currency volatility leads to unstable exchange rate paths.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:46:24.897294
5b51de8e2d09e5f3,The American foreign exchange option in time-dependent one-dimensional diffusion model for exchange rate,"The classical Garman-Kohlhagen model for the currency exchange assumes that the domestic and foreign currency risk-free interest rates are constant and the exchange rate follows a log-normal diffusion process. In this paper we consider the general case, when exchange rate evolves according to arbitrary one-dimensional diffusion process with local volatility that is the function of time and the current exchange rate and where the domestic and foreign currency risk-free interest rates may be arbitrary continuous functions of time. First non-trivial problem we encounter in time-dependent case is the continuity in time argument of the value function of the American put option and the regularity properties of the optimal exercise boundary. We establish these properties based on systematic use of the monotonicity in volatility for the value functions of the American as well as European options with convex payoffs together with the Dynamic Programming Principle and we obtain certain type of comparison result for the value functions and corresponding exercise boundaries for the American puts with different strikes, maturities and volatilities. Starting from the latter fact that the optimal exercise boundary curve is left continuous with right-hand limits we give a mathematically rigorous and transparent derivation of the significant early exercise premium representation for the value function of the American foreign exchange put option as the sum of the European put option value function and the early exercise premium. The proof essentially relies on the particular property of the stochastic integral with respect to arbitrary continuous semimartingale over the predictable subsets of its zeros. We derive from the latter the nonlinear integral equation for the optimal exercise boundary which can be studied by numerical methods. © 2008 Springer Science+Business Media, LLC. © 2012 Elsevier B.V., All rights reserved.","Rehman, N.; Shashiashvili, M.",2009,10.1007/s00245-008-9056-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-63049128694&doi=10.1007%2Fs00245-008-9056-7&partnerID=40&md5=5005bfa644091fda79c4d7e25bdfdd4e,scopus,"This paper generalizes the Garman-Kohlhagen model for currency exchange options by allowing for time-dependent interest rates and exchange rates following a general one-dimensional diffusion process with local volatility. It rigorously derives properties of the American put option's value function and optimal exercise boundary, establishing an early exercise premium representation and a nonlinear integral equation for the boundary, suitable for numerical study.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:46:28.893790
5c693775f7a5ce82,The COVID-19 pandemic and Bitcoin: Perspective from investor attention,"The response of the Bitcoin market to the novel coronavirus (COVID-19) pandemic is an example of how a global public health crisis can cause drastic market adjustments or even a market crash. Investor attention on the COVID-19 pandemic is likely to play an important role in this response. Focusing on the Bitcoin futures market, this paper aims to investigate whether pandemic attention can explain and forecast the returns and volatility of Bitcoin futures. Using the daily Google search volume index for the ""coronavirus"" keyword from January 2020 to February 2022 to represent pandemic attention, this paper implements the Granger causality test, Vector Autoregression (VAR) analysis, and several linear effects analyses. The findings suggest that pandemic attention is a granger cause of Bitcoin returns and volatility. It appears that an increase in pandemic attention results in lower returns and excessive volatility in the Bitcoin futures market, even after taking into account the interactive effects and the influence of controlling other financial markets. In addition, this paper carries out the out-of-sample forecasts and finds that the predictive models with pandemic attention do improve the out-of-sample forecast performance, which is enhanced in the prediction of Bitcoin returns while diminished in the prediction of Bitcoin volatility as the forecast horizon is extended. Finally, the predictive models including pandemic attention can generate significant economic benefits by constructing portfolios among Bitcoin futures and risk-free assets. All the results demonstrate that pandemic attention plays an important and non-negligible role in the Bitcoin futures market. This paper can provide enlightens for subsequent research on Bitcoin based on investor attention sparked by public emergencies.The response of the Bitcoin market to the novel coronavirus (COVID-19) pandemic is an example of how a global public health crisis can cause drastic market adjustments or even a market crash. Investor attention on the COVID-19 pandemic is likely to play an important role in this response. Focusing on the Bitcoin futures market, this paper aims to investigate whether pandemic attention can explain and forecast the returns and volatility of Bitcoin futures. Using the daily Google search volume index for the ""coronavirus"" keyword from January 2020 to February 2022 to represent pandemic attention, this paper implements the Granger causality test, Vector Autoregression (VAR) analysis, and several linear effects analyses. The findings suggest that pandemic attention is a granger cause of Bitcoin returns and volatility. It appears that an increase in pandemic attention results in lower returns and excessive volatility in the Bitcoin futures market, even after taking into account the interactive effects and the influence of controlling other financial markets. In addition, this paper carries out the out-of-sample forecasts and finds that the predictive models with pandemic attention do improve the out-of-sample forecast performance, which is enhanced in the prediction of Bitcoin returns while diminished in the prediction of Bitcoin volatility as the forecast horizon is extended. Finally, the predictive models including pandemic attention can generate significant economic benefits by constructing portfolios among Bitcoin futures and risk-free assets. All the results demonstrate that pandemic attention plays an important and non-negligible role in the Bitcoin futures market. This paper can provide enlightens for subsequent research on Bitcoin based on investor attention sparked by public emergencies.",,2023,10.3389/fpubh.2023.1147838,,proquest,"This paper investigates the impact of investor attention on the COVID-19 pandemic on the Bitcoin futures market. Using Google search volume for ""coronavirus"" as a proxy for pandemic attention, the study employs Granger causality tests, VAR analysis, and linear effects analyses. Findings indicate that pandemic attention Granger-causes Bitcoin returns and volatility, leading to lower returns and increased volatility. The study also demonstrates that incorporating pandemic attention improves out-of-sample forecasts for Bitcoin returns and can generate economic benefits through portfolio construction. The research highlights the significant role of pandemic attention in the Bitcoin futures market and suggests avenues for future research on investor attention during public emergencies.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:46:31.240328
32219b4eb50b7726,The Co-Integrated Vector Autoregression with Errors–in–Variables,"The co-integrated vector autoregression is extended to allow variables to be observed with classical measurement errors (ME). For estimation, the model is parametrized as a time invariant state-space form, and an accelerated expectation-maximization algorithm is derived. A simulation study shows that (i) the finite-sample properties of the maximum likelihood (ML) estimates and reduced rank test statistics are excellent (ii) neglected measurement errors will generally distort unit root inference due to a moving average component in the residuals, and (iii) the moving average component may–in principle–be approximated by a long autoregression, but a pure autoregression cannot identify the autoregressive structure of the latent process, and the adjustment coefficients are estimated with a substantial asymptotic bias. An application to the zero-coupon yield-curve is given. © 2021 Elsevier B.V., All rights reserved.","Nielsen, H.B.",2016,10.1080/07474938.2013.806853,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948710369&doi=10.1080%2F07474938.2013.806853&partnerID=40&md5=c5d9ff605a01be7d486ad7381bf29666,scopus,"This paper extends the co-integrated vector autoregression model to account for measurement errors in variables. It proposes a state-space form and an expectation-maximization algorithm for estimation. A simulation study demonstrates the model's effectiveness, highlighting the distortions caused by unaddressed measurement errors in unit root inference and the limitations of pure autoregressions in capturing latent process structures. An application to the zero-coupon yield curve is presented.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:46:33.752732
cafdecb4b42b0a46,The London Business School with Gower Publishing,"Collapsing oil prices and a falling dollar set the background to a Budget in which the Chancellor, hamstrung by lower oil revenues, was seen as having little room for manoeuvre. In fact the sharp fall in the sterling price of oil has provided him with the perfect excuse for not making significant cuts in personal income tax that were largely irrelevant to the needs of the economy. Instead of a boost to household demand we have had, thanks to OPEC, a transfer to companies in the form of a reduction in costs. This should enable them to expand output against a background of falling inflation. Our post‐Budget assessment of macroeconomic prospects (Section I), made on the Treasury's assumption of a $15 oil price, shows output growing by 2 1/2 per cent this year and inflation falling below 3 per cent in 1987. We are thus less optimistic than the Treasury about output but more optimistic about inflation. How was the Chancellor able, within the confines of the Medium‐Term Financial Strategy, to give anything away having lost so much oil revenue? A detailed analysis of the PSBR forecast (Section II) reveals good reasons why non‐oil tax revenues should be some £3 1/2n higher than forecast this time last year. But, because we still expect public spending to be above the official figures, our PSBR forecast is £1bn higher than the Treasury's. Although the macroeconomic impact of the Budget was small (especially in relation to that of the fall in oil prices which preceded it), it continued the process of tax reform. We focus, in Section III, on the new proposals to deal with the problem of the pension fund surpluses to which we drew attention in the November issue of Financial Outlook. We conclude that the proposed measures could have a larger effect on tax revenues in the longer term than is indicated by the Treasury's Budget estimates. Copyright © 1986, Wiley Blackwell. All rights reserved © 2016 Elsevier B.V., All rights reserved.","Dicks, G.; Keating, G.; Robinson, B.",1986,10.1111/j.1468-0319.1986.tb00132.x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978583037&doi=10.1111%2Fj.1468-0319.1986.tb00132.x&partnerID=40&md5=b54956c2c887c359c6614df6985def4e,scopus,"This article analyzes the UK's budget in the context of falling oil prices and a weakening dollar. It discusses the Chancellor's limited room for maneuver, the shift in benefits from households to companies, and macroeconomic forecasts for output and inflation. The analysis also delves into the Public Sector Borrowing Requirement (PSBR) forecast and tax reforms, particularly concerning pension fund surpluses, suggesting potential long-term impacts on tax revenues.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:46:36.077516
0f494f7b776c3aa9,The Macroeconomics of Financial Speculation,"I review the literature on financial speculation driven by belief disagreements from a macroeconomics perspective. To highlight unifying themes, I develop a stylized macroeconomic model that embeds several mechanisms. With short-selling constraints, speculation can generate overvaluation and speculative bubbles. Leverage can substantially inflate speculative bubbles, and leverage limits depend on perceived downside risks. Shifts in beliefs about downside tail scenarios can explain the emergence and the collapse of leveraged speculative bubbles. Speculative bubbles are related to rational bubbles, but they match better the empirical evidence on the predictability of asset returns. Even without short-selling constraints, speculation induces procyclical asset valuation. When speculation affects the price of aggregate assets, it also influences macroeconomic outcomes such as aggregate consumption, investment, and output. Speculation in the boom years reduces asset prices, aggregate demand, and output in the subsequent recession. Macroprudential policies that restrict speculation in the boom can improve macroeconomic stability and social welfare.","Simsek, Alp",2021,10.1146/annurev-economics-092120-050543,,wos,"This paper reviews the literature on financial speculation driven by belief disagreements from a macroeconomic perspective. It presents a model where short-selling constraints and leverage can lead to speculative bubbles, affecting macroeconomic outcomes like consumption, investment, and output. The paper suggests that macroprudential policies can enhance stability by restricting speculation during boom periods.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:46:42.024408
403a1d83ec233556,The Relationship between Default Risk and Asset Pricing: Empirical Evidence from Pakistan,"This paper examines the efficacy of the default risk factor in an emerging market context using the Fama-French five-factor model. Our aim is to test whether the Fama-French five-factor model augmented with a default risk factor improves the predictability of returns of portfolios sorted on the firm’s characteristics as well as on industry. The default risk factor is constructed by estimating the probability of default using a hybrid version of dynamic panel probit and artificial neural network (ANN) to proxy default risk. This study also provides evidence on the temporal stability of risk premiums obtained using the Fama-MacBeth approach. Using a sample of 3,806 firm-year observations on non-financial listed companies of Pakistan over 2006–2015 we found that the augmented model performed better when tested across size-investment-default sorted portfolios. The investment factor contains some default-related information, but default risk is independently priced and bears a significantly positive risk premium. The risk premiums are also found temporally stable over the full sample and more recent sample period 2010–2015 as evidence by the Fama-MacBeth regressions. The finding suggests that the default risk factor is not a useless factor and due to mispricing, default risk anomaly prevails in the Pakistani equity market. © 2021 Elsevier B.V., All rights reserved.","Khan, U.E.; Iqbal, J.",2021,10.13106/jafeb.2021.vol8.no3.0717,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102257576&doi=10.13106%2Fjafeb.2021.vol8.no3.0717&partnerID=40&md5=0a2f393054f1fd8ea20a186359d1a9cc,scopus,"This study investigates the effectiveness of a default risk factor within the Fama-French five-factor model in Pakistan's emerging market. It constructs a default risk factor using a hybrid approach of dynamic panel probit and artificial neural networks (ANN). The findings indicate that the augmented model, incorporating default risk, enhances return predictability for portfolios sorted by firm characteristics and industry. Default risk is found to be independently priced with a positive risk premium, and this premium is temporally stable. The study concludes that default risk is a significant factor in the Pakistani equity market, suggesting a default risk anomaly due to mispricing.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:46:44.507614
97060010610a3aec,The Term Structure of Machine Learning Alpha,"Machine learning (ML) models for predicting stock returns are typically trained on one-month forward returns. Although these models show impressive full-sample gross alphas, their performance net of transaction costs post-2004 is close to zero. By training on longer prediction horizons and using efficient portfolio construction rules, the authors demonstrate that ML-based investment strategies can still yield significant positive net returns. Longer-horizon strategies select slower signals and load more on traditional asset pricing factors but still unlock unique alpha. The authors conclude that design choices are critical for the success of ML models in real-life applications. © 2023 Elsevier B.V., All rights reserved.","Blitz, D.; Hanauer, M.X.; Hoogteijling, T.; Howard, C.",2023,10.3905/jfds.2023.1.135,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176099492&doi=10.3905%2Fjfds.2023.1.135&partnerID=40&md5=d9c1c7c51b12768f2f8c95b1d8c8e9bc,scopus,"This study investigates the effectiveness of machine learning (ML) models in predicting stock returns, finding that while short-term models show high gross alphas, their net returns are negligible after transaction costs. By extending prediction horizons and optimizing portfolio construction, the authors show that ML strategies can achieve significant positive net returns, suggesting that design choices are crucial for successful real-world ML applications.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:46:50.753335
7964653838d9f322,The Use of Simulation in Vascular Surgery Education: Current State and Future Directions,"Simulation-based training (SBT) has become essential in vascular surgery education, providing a risk-free environment for skill development. This scoping review evaluates the current state of vascular surgery simulation, highlighting validated models, educational impact, and areas for improvement. A systematic literature search was conducted in PubMed, Embase, and Scopus, following PRISMA-ScR guidelines. Studies assessing validated simulation models for open and endovascular procedures, vascular anastomosis, carotid interventions, peripheral vascular interventions, and nontechnical skills training were included. Data extraction focused on fidelity, skill acquisition, procedural efficiency, and accessibility. Validated high-fidelity models, including 3D-printed, virtual reality (VR), and pulsatile cadaveric systems, significantly enhance technical proficiency and confidence. Bench and porcine models improve vascular anastomosis training, while VR-based simulators enhance catheter manipulation and decision-making. However, simulation remains limited by high costs, accessibility challenges, and lack of standardized nontechnical skills training. Simulation improves competency in vascular surgery but requires further integration into training curricula. AI-driven assessments, hybrid simulation models, and expanded cost-effective solutions are needed to bridge existing gaps. Standardization and broader adoption of simulation will enhance competency-based training and improve patient outcomes.Simulation-based training (SBT) has become essential in vascular surgery education, providing a risk-free environment for skill development. This scoping review evaluates the current state of vascular surgery simulation, highlighting validated models, educational impact, and areas for improvement. A systematic literature search was conducted in PubMed, Embase, and Scopus, following PRISMA-ScR guidelines. Studies assessing validated simulation models for open and endovascular procedures, vascular anastomosis, carotid interventions, peripheral vascular interventions, and nontechnical skills training were included. Data extraction focused on fidelity, skill acquisition, procedural efficiency, and accessibility. Validated high-fidelity models, including 3D-printed, virtual reality (VR), and pulsatile cadaveric systems, significantly enhance technical proficiency and confidence. Bench and porcine models improve vascular anastomosis training, while VR-based simulators enhance catheter manipulation and decision-making. However, simulation remains limited by high costs, accessibility challenges, and lack of standardized nontechnical skills training. Simulation improves competency in vascular surgery but requires further integration into training curricula. AI-driven assessments, hybrid simulation models, and expanded cost-effective solutions are needed to bridge existing gaps. Standardization and broader adoption of simulation will enhance competency-based training and improve patient outcomes.",,2025,10.1053/j.semvascsurg.2025.03.001,,proquest,"This scoping review examines the current use and future potential of simulation-based training (SBT) in vascular surgery education. It identifies validated simulation models (3D-printed, VR, cadaveric) that improve technical skills and confidence. Challenges include cost, accessibility, and standardized nontechnical skills training. The review suggests AI-driven assessments and hybrid models for future integration to enhance competency-based training and patient outcomes.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:46:54.945869
2d7d94f5cc68cb41,The VIX Premium,"Ex ante estimates of the volatility premium embedded in VIX futures, known as the VIX premium, fall or stay flat when ex ante measures of risk rise. This is not an artifact of mismeasurement: (i) ex ante premiums reliably predict ex post returns to VIX futures with a coefficient near one, and (ii) falling ex ante premiums predict increasing ex post market and investment risk, creating profitable trading opportunities. Falling hedging demand helps explain this behavior, as premiums and trader exposures tend to fall together when risk rises. These facts provide a puzzle for theories of why investors hedge volatility. Received January 13, 2017; editorial decision April 26, 2018 by Editor Stijn Van Nieuwerburgh. Authors have furnished an Internet Appendix, which is available on the Oxford University Press Web site next to the link to the final published paper online.","Cheng, Ing-Haw",2019,10.1093/rfs/hhy062,,wos,"This paper examines the VIX premium, which represents the ex ante estimate of the volatility premium in VIX futures. It finds that this premium declines when risk measures increase, which is not due to measurement errors. The study shows that falling VIX premiums predict future market and investment risk, offering trading opportunities. Reduced hedging demand is suggested as a reason for this phenomenon, as premiums and trader exposures decrease together during periods of heightened risk. This behavior presents a challenge to existing theories on why investors hedge volatility.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:46:59.385482
85e5ea3195695843,The advantages of CBOE credit VIXs for corporate bond investors in North America: A sectoral analysis,"This paper examines the safe-haven role of the recently introduced CBOE credit VIXs for investment-grade and high-yield corporate bonds, at both aggregate and sectoral levels. Using a time-varying quantile-based framework and daily data from June 5, 2014 to December 10, 2023, the safe-haven role of credit VIX is confirmed irrespective of bond sector. The safe-haven property of credit VIX is pronounced for high-yield bonds which embed a high credit risk-premium. This result stands when taking into account interest rate volatility, as measured by the MOVE index. A time-varying analysis shows the persistence of credit VIX as a safe-haven for all bond sectors after the COVID-19 pandemic and during a high US interest-rate regime. Corporate bond investors and traders can use these findings to refine their investment and trading decisions and offset credit risk during both normal and turbulent periods.","Iqbal, Najaf; Bouri, Elie; Ozkan, Oktay",2025,10.1016/j.ribaf.2024.102607,,wos,"This paper investigates the safe-haven properties of CBOE credit VIXs for corporate bonds in North America, finding they act as a safe haven for both investment-grade and high-yield bonds across sectors. The safe-haven effect is stronger for high-yield bonds and persists even when considering interest rate volatility and post-COVID-19 periods. The findings can aid investors in managing credit risk.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:47:03.606401
714f332dbdcd0c45,The contribution of wealth concentration to the subprime crisis: a quantitative estimation,"The crisis that broke out in mid-2007 was caused by the fact that the collateralised debt obligation (CDO) market had grown to a size sufficient to wreak general havoc when it suddenly collapsed. Several authors have argued that economic inequality was important to the growth of this market. This paper attempts to strengthen this argument by concentrating attention on global wealth concentration. After summarising recent evidence on the negative impact of investor demand on US bond yields in the pre-crisis period, new evidence regarding the specific contribution of high-net-worth individuals to this negative impact is presented. The paper then goes on to show how, after having helped to cause a yield problem in the major US debt markets, high-net-worth individuals (via hedge funds) continued to be a major source of the pressure on US banks to resolve this yield problem through the mass production of CDOs. Adapted from the source document.",,2014,10.1093/cje/bet061,,proquest,"This paper quantitatively estimates the contribution of global wealth concentration to the subprime crisis. It argues that high-net-worth individuals, through their demand for US bonds, lowered yields, pressuring banks to create Collateralised Debt Obligations (CDOs). The study analyzes investor demand and the role of hedge funds in this process.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:47:06.860961
f5d2f8581abc1e8f,The conundrum of stock versus bond prices,"In a general way, stock and bond prices do not display any significant correlation. Yet, if we concentrate our attention on the specific episodes marked by a crash followed by a rebound, then we observe that stock prices have a strong connection with interest rates on one hand, and with bond yield spreads on the other hand. That second relationship is particularly stable in the course of time having been observed for over 140 years. Throughout the paper we use a quasi-experimental approach. By observing how markets respond to well-defined exogenous shocks (such as the shock of 11 September 2001) we are able to determine how investors organize their ""flight to safety"": which safe haven they select, how long their collective panic lasts, and so on. As rebounds come to an end the correlation of stock and bond prices fades away, a clear sign that the collective behavior of investors loses some of its coherence; this observation can be used as an objective criterion for assessing the end of a market rebound. Based on the behavior of investors, we introduce a distinction between ""genuine stock market rallies"", as opposed to spurious rallies such as those brought about by the buyback programs implemented by large companies. The paper ends with a discussion of testable predictions. © 2003 Elsevier B.V. All rights reserved. © 2008 Elsevier B.V., All rights reserved.","Maslov, S.; Roehner, B.M.",2004,10.1016/j.physa.2003.11.031,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0742272492&doi=10.1016%2Fj.physa.2003.11.031&partnerID=40&md5=37ee85a0dd59a70b6cb37fc7c52bcf8c,scopus,"This paper investigates the relationship between stock and bond prices, particularly during market crashes and rebounds. It uses a quasi-experimental approach, analyzing investor behavior in response to exogenous shocks like 9/11 to understand their 'flight to safety'. The study finds a stable, long-term correlation between stock prices and bond yields during rebounds, which fades as the rebound ends. This observation is proposed as a criterion to distinguish genuine market rallies from spurious ones (e.g., those driven by stock buybacks).",False,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:47:17.840171
8daf101573bc8967,The cost of carbon capture and storage for natural gas combined cycle power plants,"This paper examines the cost of CO(2) capture and storage (CCS) for natural gas combined cycle (NGCC) power plants. Existing studies employ a broad range of assumptions and lack a consistent costing method. This study takes a more systematic approach to analyze plants with an amine-based postcombustion CCS system with 90% CO(2) capture. We employ sensitivity analyses together with a probabilistic analysis to quantify costs for plants with and without CCS under uncertainty or variability in key parameters. Results for new baseload plants indicate a likely increase in levelized cost of electricity (LCOE) of $20-32/MWh (constant 2007$) or $22-40/MWh in current dollars. A risk premium for plants with CCS increases these ranges to $23-39/MWh and $25-46/MWh, respectively. Based on current cost estimates, our analysis further shows that a policy to encourage CCS at new NGCC plants via an emission tax or carbon price requires (at 95% confidence) a price of at least $125/t CO(2) to ensure NGCC-CCS is cheaper than a plant without CCS. Higher costs are found for nonbaseload plants and CCS retrofits.This paper examines the cost of CO(2) capture and storage (CCS) for natural gas combined cycle (NGCC) power plants. Existing studies employ a broad range of assumptions and lack a consistent costing method. This study takes a more systematic approach to analyze plants with an amine-based postcombustion CCS system with 90% CO(2) capture. We employ sensitivity analyses together with a probabilistic analysis to quantify costs for plants with and without CCS under uncertainty or variability in key parameters. Results for new baseload plants indicate a likely increase in levelized cost of electricity (LCOE) of $20-32/MWh (constant 2007$) or $22-40/MWh in current dollars. A risk premium for plants with CCS increases these ranges to $23-39/MWh and $25-46/MWh, respectively. Based on current cost estimates, our analysis further shows that a policy to encourage CCS at new NGCC plants via an emission tax or carbon price requires (at 95% confidence) a price of at least $125/t CO(2) to ensure NGCC-CCS is cheaper than a plant without CCS. Higher costs are found for nonbaseload plants and CCS retrofits.",,2012,10.1021/es204514f,,proquest,"This study systematically analyzes the cost of CO(2) capture and storage (CCS) for natural gas combined cycle (NGCC) power plants using an amine-based postcombustion CCS system with 90% CO(2) capture. It employs sensitivity and probabilistic analyses to quantify costs under uncertainty and variability. Results indicate a likely increase in the levelized cost of electricity (LCOE) for new baseload plants, with a risk premium further increasing these costs. The analysis also suggests a minimum carbon price of $125/t CO(2) is required to incentivize CCS at new NGCC plants.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:47:20.450759
f82cbd04c25cf4f6,The determinants of capitalization rates: evidence from the US real estate markets,"Purpose Establishing the strength of a novel variable-mortgage debt as a fraction of US gross domestic product (GDP)-on forecasting capitalization rates in both the US office and multifamily sectors. Design/methodology/approach The authors specifies a vector error correction model (VECM) to the data. VECM are used to address the nonstationarity issues of financial variables while maintaining the information embedded in the levels of the data, as opposed to their differences. The cap rate series used are from Green Street Advisors and represent transaction cap rates which avoids the problem of artificial smoothness found in appraisal-based cap rates. Findings Using a VECM specified with the novel variable, unemployment and past cap rates contains enough information to produce more robust forecasts than the traditional variables (return expectations and risk premiums). The method is robust both in and out of sample. Practical implications This has direct implications for governmental policy, offering a path to real estate price stability and growth through mortgage access-functions largely influenced by the Fed and the quasi-federal agencies Fannie Mae and Freddie Mac. It also offers a timely alternative to interest rate-based forecasting models, which are likely to be less useful as interest rates are to be held low for the foreseeable future. Originality/value This study offers a new and highly explanatory variable to the literature while being among the only to model either (1) transactional cap rates (versus appraisal) (2) out-of-sample data (versus in-sample) (3) without the use of the traditional variables thought to be integral to cap rate modelling (return expectations and risk premiums).","Larriva, Matt; Linneman, Peter",2022,10.1108/jpif-12-2020-0140,,wos,"This study investigates the impact of mortgage debt as a fraction of US GDP on forecasting capitalization rates in the US office and multifamily sectors. Using a vector error correction model (VECM), the research finds that this novel variable, along with unemployment and past cap rates, provides more robust forecasts than traditional variables like return expectations and risk premiums. The findings have implications for governmental policy aimed at real estate price stability and offer an alternative to interest rate-based forecasting models.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:47:26.224373
601095a482cc9b1e,The evolution of risk premium as a measure for intra-regional equity market integration,"We estimate and test the conditional version of an international capital asset pricing model using a parsimonious multivariate GARCH process and the multivariate nonlinear least squares method. Since our approaches are fully parametric, we can recover any quantity that is a function of the first two conditional moments. Our findings strongly support using a model that includes both regional market and foreign exchange risk. However, both sources of risk are detected only when their prices are allowed to change over time. Our empirical results show clear evidence of market integration to varying degrees, explained by the US term premium and the level of market openness. Though it reaches high values during turmoil periods and exhibits an upward trend toward the end of the estimation period, the Indonesian stock market remains partially integrated into the ASEAN-5 regional market. These results suggest that diversification into Indonesian market assets continues to produce substantial profits and that asset pricing rules should reflect a state of partial integration. © 2015 Elsevier B.V., All rights reserved.","Guesmi, K.; Teulon, F.; Muzaffar, A.T.",2014,10.1016/j.irfa.2014.07.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84909581587&doi=10.1016%2Fj.irfa.2014.07.003&partnerID=40&md5=6d13f0bc7cb045a3f4f9ab77d2cc3801,scopus,"This study estimates and tests a conditional international capital asset pricing model using a multivariate GARCH process and nonlinear least squares. The findings support a model incorporating both regional market and foreign exchange risk, with time-varying risk prices. The Indonesian stock market shows partial integration into the ASEAN-5 regional market, influenced by the US term premium and market openness. Diversification into Indonesian assets remains profitable, and asset pricing should reflect this partial integration.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:47:30.490441
64cac22fea2065b6,The expectations hypothesis of the term structure when interest rates are close to zero,"In an economy where cash can be stored costlessly in nominal terms, the nominal interest rate is bounded below by zero. This paper derives the implications of this non-negativity constraint for the term structure and shows that it induces a nonlinear and convex relation between short- and long-term interest rates. The long-term rate responds asymmetrically to changes in the short-term rate, and by less than that is predicted by the benchmark linear model. In particular, a decrease in the short-term rate produces a smaller response in the long-term rate than an increase of the same magnitude. The empirical predictions of the model are examined using data from Japan. All rights reserved, Elsevier",,2006,10.1016/j.jmoneco.2005.07.014,,proquest,"This paper explores the implications of the zero lower bound on nominal interest rates for the term structure of interest rates. It demonstrates that this constraint leads to a nonlinear and convex relationship between short- and long-term rates, causing asymmetric responses of long-term rates to changes in short-term rates. The model's predictions are tested using Japanese data.",True,True,False,gemini-2.5-flash-lite,Ulrik,M,See if ML,2025-10-13T16:47:57.712560
e0d0deaef6ebe9c8,The impact of variability and correlation of selected geological parameters on the economic assessment of bituminous coal deposits with use of non parametric bootstrap and copula-based Monte Carlo simulation,"This paper presents an assessment of the impact of variability and interdependencies of selected deposit parameters on the net present value (NPV) and internal rate of return (IRR). The subjects of the analyses were three economically viable seams at one of the bituminous coal deposits in Poland. The source of information was the geological model and operational data of the mine X. The simulation was developed based on non-parametric bootstrapping, where the influence of coal quality parameters, seam thickness, spatial density of coal, and waste rock derived from coal partings, floor cutting and dinting, and roof falls, was tested.The interdependencies of geological and mining parameters were replicated in a simulation model using Gaussian and empirical copulas. In the model, the relationship between the amount of total waste rock and operating costs was associated with the use of elaborate mathematical formulas. Economic appraisal was based on an income approach, using the free cash flow for the firm (FCFF) analysis and discounting process.Based on the Gaussian copula, in the X-1 and X-2 seams, the average NPV differences achieved were a maximum of 39%. In the case of IRR, the mean difference did not exceed 3.6% points (pp). The quantified spread between the correlated and uncorrelated average values of NPV was at most 45% and 4.8 pp for IRR. Empirical copula limits the range of variation of input and output parameters, resulting in different values for the average NPV, at a maximum of 11.8%, and IRR, 2.4 pp.If the IRR reflects the level of expected return of investment, it can be stated that the additional risk premium resulting from the volatility and correlation of analysed deposits parameters of bituminous coal should be relatively low and less than 2.4 pp in similar cases. The analyses also revealed that the amount of available geological information is of secondary importance in the valuation process, as it does not negatively affect the regularity and symmetry of predicted outcomes.","Kopacz, Michal; Sobczyk, Eugeniusz J.; Galica, Dominik",2018,10.1016/j.resourpol.2017.11.015,,wos,"This study assesses how variability and interdependencies of geological parameters (coal quality, seam thickness, density, waste rock) affect the economic viability (NPV, IRR) of bituminous coal deposits. Using non-parametric bootstrapping and copula-based Monte Carlo simulations on data from a Polish mine, the research quantifies the impact of these factors on financial metrics. Results show that correlations can lead to significant differences in NPV and IRR, with empirical copulas showing less variation than Gaussian copulas. The study suggests the additional risk from parameter volatility and correlation is relatively low and that the amount of geological information is of secondary importance for valuation.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:48:01.716787
e257b7e9d88f79c0,The impact of word sense disambiguation on stock price prediction,"State-of-the-art decision support systems for stock price prediction incorporate pattern-based event detection in text into their predictions. These systems typically fail to account for word meaning, even though word sense disambiguation is crucial for text understanding. Therefore, we propose an advanced natural language processing pipeline for event-based stock price prediction, that allows for word sense disambiguation to be incorporated in the event detection process. We identify events in natural language news messages and subsequently weight these events for their historical impact on stock prices. We assess the merit of word sense disambiguation in event-based stock price prediction in two evaluation scenarios for NASDAQ-100 companies, based on historical stock prices and news articles retrieved from Dow Jones Newswires over a 2-year period. We evaluate the precision of generated buy and sell signals based on our predicted stock price movements, as well as the excess returns generated by a trading strategy that acts upon these signals. Event-based stock price predictions seem most reliable about 2 days into the future. The number of detected events tends to reduce with over 30% when graph-based word sense disambiguation using a degree centrality measure is applied in the event detection process, thus reducing the noise introduced into the stock price movement predictions by high-impact ambiguous events. As a result, modest improvements in the precision of buy and sell signals generated based on these predictions tend to lead to vast improvements of on average about 70% in the associated excess returns. © 2021 Elsevier B.V., All rights reserved.","Hogenboom, A.; Brojba-Micu, A.; Frasincar, F.",2021,10.1016/j.eswa.2021.115568,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109887638&doi=10.1016%2Fj.eswa.2021.115568&partnerID=40&md5=dfaeda381e54eef7aab7c102e3b6ad12,scopus,"This study proposes an advanced NLP pipeline for event-based stock price prediction that incorporates word sense disambiguation (WSD) to improve event detection and weighting. By applying WSD to news messages, the system aims to reduce noise from ambiguous events, leading to more reliable predictions and potentially higher excess returns from trading strategies. Evaluations on NASDAQ-100 companies over a 2-year period showed that WSD can improve the precision of buy/sell signals and significantly increase excess returns.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:48:04.153504
25fb4c8caf97c256,"The meaning of structural breaks for risk management: new evidence, mechanisms, and innovative views for the post-COVID-19 era","This paper quantitatively reveals the meaning of structural breaks for risk management by analyzing US and major European banking sector stocks. Applying newly extended Glosten-Jagannathan-Runkle generalized autoregressive conditional heteroscedasticity models, we supply the following new evidence. First, we find that incorporating structural breaks is always effective in estimating banking stock volatilities. Second, we clarify that structural breaks partially explain the tail fatness of banking stock returns. Third, we find that when incorporating structural breaks, the estimated volatilities more accurately capture their downside risk, proving that structural breaks matter for risk management. Fourth, our news impact curve and model parameter analyses also uncover that when incorporating structural breaks, the asymmetry in volatility responses to return shocks is more accurately captured. This proves why the estimated volatilities by incorporating structural breaks better explain downside risk. In addition, we further reveal that the estimated volatilities obtained through incorporating structural breaks increase sharply during momentous events such as the Lehman crisis, the European debt crisis, Brexit, and the recent COVID-19 crisis. Moreover, we also clarify that the volatility spreads between models with and without structural breaks rise during the Lehman and COVID-19 crises. Finally, based on our findings, we derive many significant and beneficial interpretations, implications, and innovative views for risk management using artificial intelligence in the post-COVID-19 era.","Tsuji, Chikashi",2022,10.3934/qfe.2022012,,wos,"This paper examines the impact of structural breaks on risk management in the US and European banking sectors. Using an extended GJR-GARCH model, it demonstrates that incorporating structural breaks improves volatility estimation, explains tail fatness in returns, and better captures downside risk and asymmetric volatility responses. The study also highlights increased volatility during major crises (Lehman, European debt, Brexit, COVID-19) and suggests implications for AI-driven risk management post-COVID-19.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:48:06.981844
7234cd73a718c563,The multifactor nature of the volatility of futures markets,"This paper estimates a model of interest rate dynamics containing multi-factor Wiener and single-factor Poisson jump volatility components. Data from the highly liquid but short term futures markets are used. The difficult numerical problem of estimating such multi-factor models is resolved by using a genetic algorithm to carry out the optimization procedure. It is established that the multi-factor Wiener volatility components are adequate to model the interest rate dynamics without the need to incorporate Poisson jump components, the existence of which would create difficulties in the practical use of interest rate models. Reprinted by permission of Springer",,2006,10.1007/s10614-006-9023-9,,proquest,"This paper estimates a model of interest rate dynamics with multi-factor Wiener and single-factor Poisson jump volatility components using futures market data. A genetic algorithm is employed to overcome estimation challenges. The study concludes that multi-factor Wiener volatility components are sufficient for modeling interest rate dynamics, negating the need for Poisson jump components.",True,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:48:08.894526
c7b17c47b92ccbbf,The relationship between risk-neutral and actual default probabilities: the credit risk premium,"The study investigates empirically the relationship between the risk-neutral measure Q and the real-world measure P. We study the ratio between the risk-neutral and actual default intensities, which we call the coverage ratio or the relative credit risk premium. Actual default intensities are derived from rating agencies annual transition matrices, while risk-neutral default intensities are bootstrapped from CDS quotes of European corporates. We quantify the average risk premium and its changes over time. Compared to related literature, special attention is given to the effects of the recent financial and European sovereign crises. We find that average credit risk premia rose substantially and that post-crisis levels are still higher than those observed before the financial crisis. This observation is especially true for high-quality debt and if it persists, it will have an impact on corporates funding costs. The quantification and revision of risk premia contributes to the discussion of the credit spread puzzle and could give extra insights in valuation models that start from real-world estimates. Our work is furthermore important in the context of state aid assessment. The real economic value (REV) methodology, applied by the European Commission to evaluate impaired portfolios, is based on a long-term average risk premium. © 2017 Elsevier B.V., All rights reserved.","Heynderickx, W.; Cariboni, J.; Schoutens, W.; Smits, B.",2016,10.1080/00036846.2016.1150953,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966698707&doi=10.1080%2F00036846.2016.1150953&partnerID=40&md5=b10de6b3c90e0f224539f72a8ec3ddf7,scopus,"This study empirically examines the relationship between risk-neutral and actual default probabilities for European corporates, using rating agency transition matrices and CDS quotes. It quantifies the credit risk premium and finds it increased significantly after the financial and sovereign crises, particularly for high-quality debt, impacting corporate funding costs. The findings contribute to the credit spread puzzle and valuation models, and are relevant for state aid assessment.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:48:11.678897
eac1579c9a56f66f,The risk premia embedded in index options,"We study the dynamic relation between market risks and risk premia using time series of index option surfaces. We find that priced left tail risk cannot be spanned by market volatility (and its components) and introduce a new tail factor. This tail factor has no incremental predictive power for future volatility and jump risks, beyond current and past volatility, but is critical in predicting future market equity and variance risk premia. Our findings suggest a wide wedge between the dynamics of market risks and their compensation, which typically displays a far more persistent reaction following market crises. (C) 2015 Elsevier B.V. All rights reserved.","Andersen, Torben G.; Fusari, Nicola; Todorov, Viktor",2015,10.1016/j.jfineco.2015.06.005,,wos,"This study investigates the relationship between market risks and risk premia using index option data. It identifies a priced left tail risk that is not explained by market volatility alone, introducing a new tail factor. This factor is crucial for predicting future market equity and variance risk premia, indicating a persistent discrepancy between market risk dynamics and compensation, especially after market crises.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:48:18.972786
e3949ad7076546c5,The role of an aligned investor sentiment index in predicting bond risk premia of the U.S,"In this paper, we develop a new investor sentiment index that is aligned to predict the excess returns on U.S. government bonds that have 2–5 years maturities. The new index is constructed by eliminating a common noise component in underlying sentiment proxies using the partial least squares (PLS) approach. The findings show that the new aligned sentiment index has much greater predictive power than the original principal component analysis (PCA)-based sentiment index both in- and out-of-sample. In addition, predictability is statistically significant, especially for bond premia with shorter maturities, even after controlling for a large number of financial and macro factors, as well as investor attention and manager sentiment indexes. Given the role of U.S. Treasury securities in forecasting of output and inflation, as well as in portfolio allocation decisions, our findings have significant implications for investors, policymakers, and researchers interested in accurately the forecasting return dynamics for these assets. © 2020 Elsevier B.V., All rights reserved.","Cepni, O.; Güney, I.E.; Gupta, R.; Wohar, M.E.",2020,10.1016/j.finmar.2020.100541,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079393274&doi=10.1016%2Fj.finmar.2020.100541&partnerID=40&md5=8f38616f6da46e99c620db8243d7aeb2,scopus,"This paper introduces a novel investor sentiment index, constructed using partial least squares (PLS) to remove noise from sentiment proxies, which demonstrates superior predictive power for U.S. government bond risk premia (2-5 year maturities) compared to a PCA-based index. The index's predictability is significant, particularly for shorter maturities, even when accounting for various financial, macro, investor attention, and manager sentiment factors. The findings have implications for forecasting return dynamics of U.S. Treasury securities.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:48:50.497303
4b19ed1da48dc4e8,The role of uncertainty and sentiment for intraday volatility connectedness between oil and financial markets,"We quantify intraday volatility connectedness between oil and key financial assets and assess how it is related to uncertainty and sentiment measures. For that purpose, we integrate the well-known spillover methodology with a TVP VAR model estimated on a unique, vast dataset of roughly 300 thousand 5 min quotations for most heavily traded financial assets: crude oil, the US dollar, S&P 500 index, gold and US treasury bonds. This distinguishes our investigation from previous studies, which usually employ relatively short samples of daily or weekly data and focus on connectedness between two asset classes. We contribute to the literature across three margins. First, we document that market connectedness at intraday frequency presents a different picture on markets co-movement compared to the estimates obtained using daily data. Second, we show that at 5 min frequency volatility is mostly transmitted from the stock market and absorbed by the bond and dollar markets, with oil and gold markets being occasionally important for volatility transmission. Third, we present evidence that daily averages of intraday connectedness measures respond to changes in sentiment and market- specific uncertainty. Interestingly, our results contrast with earlier findings, as they show that connectedness among markets decreases in periods of high volatility owing to market-specific factors. Our study points to the importance of using high-frequency data in order to better understand financial and commodity markets dynamics.","Szafranek, Karol; Rubaszek, Michal; Uddin, Gazi Salah",2024,10.1016/j.eneco.2024.107760,,wos,"This study quantifies intraday volatility connectedness between oil and financial assets (US dollar, S&P 500, gold, US treasury bonds) using a TVP VAR model on 5-minute data. It finds that market connectedness differs from daily estimates, with volatility primarily transmitted from the stock market to bond and dollar markets. Daily connectedness measures are influenced by sentiment and market-specific uncertainty, decreasing during periods of high volatility driven by specific factors. The study emphasizes the value of high-frequency data for understanding market dynamics.",True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:48:53.676378
f275f02d334fb4b6,The shape of the risk premium: Evidence from a semiparametric generalized autoregressive conditional heteroscedasticity model,"We examine the relationship between the risk premium on the Center for Research on Security Prices (CRSP) value-weighted index total return and its conditional variance. We propose a new serniparametric model in which the conditional variance process is parametric and the conditional mean is an arbitrary function of the conditional variance. For monthly CRSP value-weighted excess returns, the relationship between the two moments that we uncover is nonlinear and nonmonotonic.","Linton, O; Perron, B",2003,10.1198/073500103288619052,,wos,This paper investigates the link between the risk premium of the CRSP value-weighted index total return and its conditional variance using a novel semiparametric GARCH model. The findings indicate a nonlinear and nonmonotonic relationship between these two moments for monthly excess returns.,True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:49:01.415628
693d8e2872e52e11,The value of options for time charterparty extension: an artificial neural networks (ANN) approach,"The most frequently associated options in the physical shipping market are options to extend the charter period on time charters and additional shipment options on contracts of affreightment. The value of freight options, in practice, is estimated mostly by referring to forward curves. An option on freight has different properties from its financial counterparts, and the straightforward adoption of theoretical models does not produce promising results. In this paper, extension options, which have the property of options on futures, were transformed into regular European options before the application of the Black-Scholes model (BSM). The efficient market hypothesis, which justifies the parity of the performance of a long-term charter to that of repetitive short-term charters, worked as the basis for the transformation. The option values determined by the BSM were compared with actual realized values. Additionally, the artificial neural networks (ANN) was employed to derive the option values. This study is meaningful as the first-time application of both the closed-form solution and the ANN to the valuation of physical freight options. The research results can contribute to the quality of chartering decisions. The results could also be used in quantifying credit risk, as extension options tend to be granted to charterers with more creditability.","Yun, Heesung; Lim, Sangseop; Lee, Kihwan",2018,10.1080/03088839.2017.1392630,,wos,This paper explores the valuation of time charterparty extension options in the shipping market using both the Black-Scholes model and Artificial Neural Networks (ANN). It addresses the limitations of traditional financial models for freight options and proposes a method to transform extension options into European options for BSM application. The study highlights the novelty of using both closed-form solutions and ANN for valuing physical freight options and suggests implications for chartering decisions and credit risk assessment.,True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:49:04.617338
62055b07417c68fc,The value premium and uncertainty: An approach by support vector regression algorithm,"Risk premium plays an important role in stock investing. Experiments have shown that value stocks typically have a higher average return than growth stocks; however, this effect persists indefinitely, even disappearing in some stages. Some studies suggested high volatility in the series of returns, broken structures, market volatility, or the impact of financial crises. This study aimed to build the uncertainty index and control it in the regression analysis model to solve the limitations above. The empirical analysis in Ho Chi Minh Stock Exchange (HOSE) showed that a value premium exists, and value stocks have a higher average return than growth stocks due to the higher overall risk. Furthermore, this study combined the Support Vector Regression (SVR) algorithm with the risk premium theoretical framework for the forecasting model; consequently, it is the most efficient model.",,2023,10.1080/23322039.2023.2191459,,proquest,This study investigates the value premium in the Ho Chi Minh Stock Exchange using Support Vector Regression (SVR). It proposes an uncertainty index to explain the persistence of the value premium and finds that value stocks yield higher returns due to higher risk. The SVR model combined with the risk premium framework is found to be the most efficient for forecasting.,True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:49:15.566708
d715fc9fe9bf9d9c,The volatility of the instantaneous spot interest rate implied by arbitrage pricing-A dynamic Bayesian approach,"This paper considers the estimation of the volatility of the instantaneous short interest rate from a new perspective. Rather than using discretely compounded market rates as a proxy for the instantaneous short rate of interest, we derive a relationship between observed LIBOR rates and certain unobserved instantaneous forward rates. We determine the stochastic dynamics for these rates under the risk-neutral measure and propose a filtering estimation algorithm for a time-discretised version of the resulting interest rate dynamics based on dynamic Bayesian updating in order to estimate the volatility function. Our time discretisation can be justified by the fact that data are observed discretely in time. The method is applied to US Treasury rates of various maturities to compute a (posterior) distribution for the parameters of the volatility specification. © 2006 Elsevier Ltd. All rights reserved. © 2011 Elsevier B.V., All rights reserved.","Bhar, R.; Chiarella, C.; Hung, H.; Runggaldier, W.J.",2006,10.1016/j.automatica.2005.12.027,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745492982&doi=10.1016%2Fj.automatica.2005.12.027&partnerID=40&md5=ec0449cd3c7a17d3e872a04c83968d09,scopus,This paper proposes a dynamic Bayesian approach to estimate the volatility of the instantaneous short interest rate by deriving a relationship between observed LIBOR rates and unobserved instantaneous forward rates. It uses a filtering estimation algorithm for a time-discretised version of the interest rate dynamics and applies the method to US Treasury rates.,True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:49:22.865524
2eb3060f2d35d3d1,"Tightly Coupled, Graph-Based DVL/IMU Fusion and Decoupled Mapping for SLAM-Centric Maritime Infrastructure Inspection","In this article, we address the problem of simultaneous localization and mapping (SLAM)-centric maritime infrastructure inspection [using unmanned surface vehicles (USVs)] via novel approaches in tightly-coupled, graph-based DVL/IMU fusion and decoupled mapping. As our first contribution, we formalize the preintegration of linear velocity measurements, obtained by a Doppler velocity log (DVL), in combination with angular velocity measurements, obtained by an inertial measurement unit (IMU), as binary factors encoding relative position. To evaluate state estimation improvements imparted by DVL/IMU fusion, we implement our proposed factor within a state-of-the-art, graph-based lidar-visual-inertial (LVI) SLAM system as our second contribution. Accuracy and robustness improvements are demonstrated in simulation by comparing maximum a posteriori pose estimates with and without DVL/IMU fusion against ground truth poses. As our third contribution, we propose a map generation framework for downstream inspection applications decoupled from SLAM. In our framework, volumetric data (captured by sonar, lidar, etc.) is transformed into a common world coordinate frame using extrinsic calibrations and SLAM pose estimates as input. Our framework operates over the complete set of raw volumetric data, whereas SLAM systems (both online and offline) typically operate over a subset of down-sampled volumetric data. To address the processing of additional volumetric data, we present innovations in refined pose correction and staged filtering for user-controlled denoising. We experimentally evaluate our map generation framework against the LVI SLAM system adopted for this study using real-world data and demonstrate improvements to map quality metrics important to inspection.",A. Thoms; G. Earle; N. Charron; S. Narasimhan,2023,10.1109/joe.2023.3265742,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10149804,ieeexplore,"This paper presents a novel approach for SLAM-centric maritime infrastructure inspection using unmanned surface vehicles (USVs). It introduces tightly-coupled, graph-based DVL/IMU fusion for improved state estimation and a decoupled mapping framework for downstream inspection applications. The system leverages preintegrated DVL and IMU measurements as binary factors and transforms volumetric data into a common world coordinate frame using extrinsic calibrations and SLAM pose estimates. Innovations in refined pose correction and staged filtering are also presented to enhance map quality and denoising for inspection purposes.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:49:26.087803
1ad66b307696646b,Time-varying nonlinear regression models: Nonparametric estimation and model selection,"This paper considers a general class of nonparametric time series regression models where the regression function can be time-dependent. We establish an asymptotic theory for estimates of the time-varying regression functions. For this general class of models, an important issue in practice is to address the necessity of modeling the regression function as nonlinear and time-varying. To tackle this, we propose an information criterion and prove its selection consistency property. The results are applied to the U.S. Treasury interest rate data. © 2021 Elsevier B.V., All rights reserved.","Zhang, T.; Wu, W.B.",2015,10.1214/14-aos1299,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924955365&doi=10.1214%2F14-AOS1299&partnerID=40&md5=53a8865b43b98d298f604f1e25a5a74a,scopus,This paper proposes a nonparametric estimation method and an information criterion for selecting nonlinear and time-varying regression models in time series data. The method is applied to U.S. Treasury interest rate data.,True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:49:29.672392
ed3aad09e82d6a77,Twin Picks: Disentangling the Determinants of Risk- Taking in Household Portfolios,"This paper investigates risk-taking in the liquid portfolios held by a large panel of Swedish twins. We document that the portfolio share invested in risky assets is an increasing and concave function of financial wealth, leading to different risk sensitivities across investors. Human capital, which we estimate directly from individual labor income, also affects risk-taking positively, while internal habit and expenditure commitments tend to reduce it. Our microfindings lend strong support to decreasing relative risk aversion and habit formation preferences. Furthermore, heterogeneous risk sensitivities across investors help reconcile individual preferences with representative-agent models.","Calvet, Laurent E.; Sodini, Paolo",2014,10.1111/jofi.12125,,wos,"This study examines risk-taking behavior in household investment portfolios using a large dataset of Swedish twins. It finds that financial wealth, human capital, and habit formation preferences influence risk-taking. The results support theories of decreasing relative risk aversion and habit formation, and suggest that heterogeneous risk sensitivities can bridge individual preferences with representative-agent models.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:49:34.921696
95ecc7b2a3f725c5,Two Derivative Algorithms of Gradient Boosting Decision Tree for Silicon Content in Blast Furnace System Prediction,"The background of the present study complies with silicon content prediction in hot metal in the blast furnace system. The blast furnace system is a highly complex industrial reactor in the conventional process. The system is subject to several problems (e.g., system automation, the thermal state of the blast furnace, and the life prediction of blast furnace) that should be addressed by professionals. To determine the prediction state of the heat in the blast furnace, the silicon content in the blast furnace molten iron commonly acts as a key indicator. Based on the assumption that the blast furnace system exhibits a stable state, the accuracy of hot metal silicon is analyzed by using a range of machine learning algorithms. In the present study, two derivative algorithms of gradient boosting decision tree are adopted to develop a strong boosting predictor based on the extreme gradient boosting (XGBoost) algorithm and the light gradient boosting machine (LightGBM) algorithm for prediction. Compared with the conventional algorithms (e.g., lasso, random forest, support vector machine and gradient boosting decision tree), the prediction by using the two boosting algorithms is capable of more effectively guiding and determining the state of the blast furnace. As revealed from experimentally simulated results, the mentioned two boosting algorithms exhibit better comprehensive prediction performance than the conventional algorithms on the datasets of two practical blast furnace systems, demonstrating that the R-square of the two blast furnaces in the training set is over 0.7. The mentioned two algorithms are of certain guiding significance for exploring blast furnace problems.",S. Luo; T. Chen,2020,10.1109/access.2020.3034566,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9243945,ieeexplore,"This study proposes two gradient boosting decision tree algorithms, XGBoost and LightGBM, for predicting silicon content in blast furnace hot metal. These algorithms were compared to conventional machine learning models, showing superior prediction performance with R-square values over 0.7 on practical blast furnace datasets.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:49:38.987244
49f77c5799aeb94b,Two-Stage Classification Method for Individual Workout Status Prediction with Machine Learning Approach,"The default risk, one of the main risk factors for bonds, should be measured and reflected in the bond yield. Particularly, in the case of financial companies that treat bonds as a major product, failure to properly identify and filter customers' workout status adversely affects returns. This study proposes a two-stage classification algorithm for workout prediction based on the history data of individual customers such as transaction details of financial companies secured after loans, which is collected over 10 years. The first stage is to rank variables that are closely related to the workout application based on feature selection. In the second step, the first to nth cumulative variables input to each machine learning method generate n candidate classifiers, respectively. Among the total candidates, the model with the highest classification accuracy was selected as the optimal one, which is the Gradient Boost combined with F-score-based feature selection.",,2024,10.1080/15366367.2023.2246109,,proquest,"This study proposes a two-stage classification algorithm using machine learning to predict the workout status of individual customers for financial companies. The method involves feature selection to identify relevant variables and then uses these variables to train multiple classifiers, selecting the best performing one (Gradient Boost with F-score feature selection) for optimal accuracy.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:50:12.797554
60fc52bc2a9b4fc3,US Funds’ returns-based ESG extraction and implementation: a multifaceted quantile regression approach,"This study introduces a novel ESG intrinsic-based return factor and its application in asset pricing. This factor is extracted using a parallelized rolling window estimation and extreme value-weighted quantile portfolios. It carries a positive risk premium, indicating that investors are willing to assess its risk exposure. We further show that higher returns can be obtained in the top 30% quantiles using a long-only trading strategy. We apply a Monotone Composite Quantile Regression Neural Network (MCQRNN) model to explain US fund returns and address the needs of investors seeking to optimize their investment strategies. This model surpasses traditional benchmark models by performing deep quantile estimation and considering the nonlinear relationships between fund returns and six firm-based characteristics. This approach empowers investors by explaining the core principles of impact investing and highlighting how our constructed ESG risk factor can generate competitive returns even in volatile markets when its risk is well assessed. © 2025 Elsevier B.V., All rights reserved.","Nasri, F.; Ben Sassi, S.B.",2025,10.1080/20430795.2024.2420916,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209061239&doi=10.1080%2F20430795.2024.2420916&partnerID=40&md5=e6baeb1542709665fb74b6cb180af04d,scopus,"This study develops a new ESG intrinsic-based return factor and demonstrates its use in asset pricing. The factor is derived using parallelized rolling window estimation and extreme value-weighted quantile portfolios, showing a positive risk premium. The research also presents a long-only trading strategy that yields higher returns in the top 30% quantiles. A Monotone Composite Quantile Regression Neural Network (MCQRNN) model is employed to explain US fund returns, outperforming traditional benchmarks by considering nonlinear relationships and performing deep quantile estimation. The findings suggest that the constructed ESG risk factor can deliver competitive returns, even in volatile markets, when its risk is properly assessed.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:50:15.624275
23e3c100156433a3,US-Swiss term structures and exchange rate dynamics,"In this study, a multi-country nonlinear model is constructed to simultaneously estimate the exchange rate dynamics and the term structure of interest rates in the US and in Switzerland. The model has better empirical performance compared to the earlier well-known affine international models. Risk premiums of bond yields vary between the two countries. The estimated state variables exhibit local characteristics. These conclusions imply the potential advantages of international diversification and demonstrate the Home Bias puzzle. Exchange rate dynamics estimated by the models account for the Forward Premium Anomaly. © 2007 Elsevier Inc. All rights reserved. © 2007 Elsevier B.V., All rights reserved.","Inci, A.C.",2007,10.1016/j.gfj.2006.08.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-35448929801&doi=10.1016%2Fj.gfj.2006.08.003&partnerID=40&md5=723f81983d7870a8b99c8ff115b76d95,scopus,"This study develops a multi-country nonlinear model to estimate exchange rate dynamics and term structures of interest rates in the US and Switzerland. The model outperforms existing affine international models, showing varying risk premiums and local characteristics of state variables. It also addresses the Forward Premium Anomaly in exchange rate dynamics and implies benefits of international diversification and the Home Bias puzzle.",True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:50:19.984271
ae8fca5c4958de8d,USING NON-PARAMETRIC SEARCH ALGORITHMS TO FORECAST DAILY EXCESS STOCK RETURNS,"Are the learning procedures of genetic algorithms (GAs) able to generate optimal architectures for artificial neural networks (ANNs) in high frequency data? In this experimental study, GAs are used to identify the best architecture for ANNs. Additional learning is undertaken by the ANNs to forecast daily excess stock returns. No ANN architectures were able to outperform a random walk, despite the finding of non-linearity in the excess returns. This failure is attributed to the absence of suitable ANN structures and further implies that researchers need to be cautious when making inferences from ANN results that use high frequency data. © 2004 Elsevier Ltd. All rights reserved. © 2008 Elsevier B.V., All rights reserved.","Joseph, N.L.; Brée, D.S.; Kalyvas, E.",2004,10.1016/s0731-9053(04)19004-x,https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748517846&doi=10.1016%2FS0731-9053%2804%2919004-X&partnerID=40&md5=5097515a501d6e10702723cf743f9dfd,scopus,"This study investigates whether genetic algorithms (GAs) can optimize artificial neural network (ANN) architectures for forecasting daily excess stock returns using high-frequency data. Despite exploring non-linearity in the data, no ANN architecture outperformed a random walk, suggesting limitations in current ANN structures for this task and cautioning against inferences from high-frequency data.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:50:31.681242
bac2a47404767287,USING NONLINEAR METHODS TO SEARCH FOR RISK PREMIA IN CURRENCY FUTURES,"This paper uses currency futures prices to test the joint null hypotheses of rational expectations and absence of a time-varying risk premium in the foreign exchange market. We find no linear predictability in the logarithm of futures price changes, either using its own past or past interest differentials. Also we establish that there is no non-linear predictability in log price changes, conditioning on its own past, or past interest rate differentials. Thus, if a time-varying risk premium exists in currency futures market, it is not related to its own past or past interest rate differentials.","HSIEH, DA",1993,10.1016/0022-1996(93)90007-k,,wos,"This paper investigates the presence of risk premia in currency futures markets using both linear and nonlinear methods. The study finds no evidence of predictability in currency futures price changes, whether linear or nonlinear, based on past price movements or past interest rate differentials. Therefore, if a time-varying risk premium exists, it is not explained by these factors.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:50:34.477998
0a0c2a619cb3d88f,Uncertainty and Forecasts of US Recessions,"We estimate Boosted Regression Trees (BRT) on a sample of monthly data that extends back to 1889 to recover the predictive value of disaggregated news-based uncertainty indexes for U.S recessions. We control for widely-studied standard predictors and use out-of-sample metrics to assess forecast performance. We find that war-related uncertainty is among the top five predictors of recessions at three different forecast horizons (3, 6, and 12 months). The predictive value of war-related uncertainty has fallen in the second half of the 20th century. Uncertainty regarding the state of securities markets has gained in relative importance. The probability of a recession is a nonlinear function of war-related and securities-markets uncertainty. Receiver-operating-characteristic curves show that uncertainty improves out-of-sample forecast performance at the longer forecast horizons. A dynamic version of the BRT approach sheds light on the importance of various lags of government-related uncertainty for recession forecasting at the long forecast horizon.","Pierdzioch, Christian; Gupta, Rangan",2020,10.1515/snde-2018-0083,,wos,"This study uses Boosted Regression Trees (BRT) on monthly US data from 1889 to assess the predictive power of news-based uncertainty indexes for recessions. It finds that war-related uncertainty is a significant predictor, though its importance has waned. Uncertainty in securities markets has become more relevant. The study also notes the nonlinear relationship between these uncertainties and recession probability, and that uncertainty improves out-of-sample recession forecasts at longer horizons.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:50:57.049608
134ec5431d15e9ae,Uncertainty-Aware Portfolio Management With Risk-Sensitive Multiagent Network,"As deep neural networks (DNNs) have gained considerable attention in recent years, there have been several cases applying DNNs to portfolio management (PM). Although some researchers have experimentally demonstrated its ability to make a profit, it is still insufficient to use in real situations because existing studies have failed to answer how risky investment decisions are. Furthermore, even though the objective of PM is to maximize returns within a risk tolerance, they overlook the predictive uncertainty of DNNs in the process of risk management. To overcome these limitations, we propose a novel framework called risk-sensitive multiagent network (RSMAN), which includes risk-sensitive agents (RSAs) and a risk adaptive portfolio generator (RAPG). Standard DNNs do not understand the risks of their decision, whereas RSA can take risk-sensitive decisions by estimating market uncertainty and parameter uncertainty. Acting as a trader, this agent is trained via reinforcement learning from dynamic trading simulations to estimate the distribution of reward and via unsupervised learning to assess parameter uncertainty without labeled data. We also present an RAPG that can generate a portfolio fitting the user’s risk appetite without retraining by exploiting the estimated information from the RSAs. We tested our framework on the U.S. and Korean real financial markets to demonstrate the practicality of the RSMAN.",K. Park; H. -G. Jung; T. -S. Eom; S. -W. Lee,2024,10.1109/tnnls.2022.3174642,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9779871,ieeexplore,"This paper introduces a novel framework, Risk-Sensitive Multiagent Network (RSMAN), for portfolio management that addresses the limitations of existing deep neural network (DNN) applications by incorporating uncertainty awareness. The framework comprises risk-sensitive agents (RSAs) that estimate market and parameter uncertainty, and a risk adaptive portfolio generator (RAPG) that creates portfolios tailored to user risk appetite without retraining. The RSMAN was tested on U.S. and Korean financial markets.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:50:58.873787
39f83bbe481f5679,Understanding Two Remarkable Findings about Stock Yields and Growth,"Two regularities regarding stock prices and expected inflation have received less attention than they deserve. First, earnings and dividend yields move with long-term expected inflation and risk-free rates. Second, analysts' forecasts of nominal growth, not real growth, vary little with expected inflation. These patterns are remarkable because financial economists predict exactly the opposite. One explanation for these contrary findings is that stock prices are too high (low) when inflation is low (high), because investors confuse nominal and real growth rates. The authors assert that investors are unlikely to be so systematically naive about expected inflation and argue that the contrary evidence is, in fact, consistent with a rational market. The key insight offered by the authors is that reported earnings include inflationary holding gains, which causes higher earnings yields when inflation is high (the first regularity) and, in turn, explains why forecasts of nominal growth need not vary with inflation (the second regularity).","Thomas, Jacob; Zhang, Frank",2009,10.3905/jpm.2009.35.4.158,,wos,"This paper discusses two underappreciated regularities concerning stock prices and expected inflation: earnings and dividend yields correlate with long-term expected inflation and risk-free rates, and analysts' forecasts of nominal growth, not real growth, show little variation with expected inflation. The authors propose that these patterns, contrary to financial economists' predictions, are consistent with a rational market. They explain that reported earnings include inflationary holding gains, which lead to higher earnings yields during high inflation periods, thus explaining the second regularity.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:51:02.832070
a88f01f8d0739b30,Understanding index option returns,"Previous research concludes that options are mispriced based on the high average returns, CAPM alphas, and Sharpe ratios of various put selling strategies. One criticism of these conclusions is that these benchmarks are ill suited to handle the extreme statistical nature of option returns generated by nonlinear payoffs. We propose an alternative way to evaluate the statistical significance of option returns by comparing historical statistics to those generated by option pricing models. The most puzzling finding in the existing literature, the large returns to writing out-of-the-money puts, is not inconsistent (i.e., is statistically insignificant) relative to the Black-Scholes model or the Heston stochastic volatility model due to the extreme sampling uncertainty associated with put returns. This sampling problem can largely be alleviated by analyzing market-neutral portfolios such as straddles or delta-hedged returns. The returns on these portfolios can be explained by jump risk premiums and estimation risk. © 2012 Elsevier B.V., All rights reserved.","Broadie, M.; Chernov, M.; Johannes, M.",2009,10.1093/rfs/hhp032,https://www.scopus.com/inward/record.uri?eid=2-s2.0-64149102384&doi=10.1093%2Frfs%2Fhhp032&partnerID=40&md5=0ede27dbc5c9649e2874de880e44de26,scopus,This paper proposes an alternative method to evaluate the statistical significance of option returns by comparing historical statistics to those generated by option pricing models. It finds that the high average returns to writing out-of-the-money puts are not inconsistent with the Black-Scholes or Heston models due to sampling uncertainty. Market-neutral portfolios like straddles or delta-hedged returns can alleviate this sampling problem and their returns can be explained by jump risk premiums and estimation risk.,False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:51:03.830610
553cda2381c2542a,United States banking stability: An explanation through machine learning,"In this paper, an analysis of the prediction of bank stability in the United States from 1990 to 2017 is carried out, using bank solvency, delinquency and an ad hoc bank stability indicator as variables to measure said stability. Different machine learning assembly models have been used in the study, a random forest is developed because it is the most accurate of all those tested. Another novel element of the work is the use of partial dependency graphs (PDP) and individual conditional expectation curves (ICES) to interpret the results that allow observing for specific values how the banking variables vary, when the macro-financial variables vary.It is concluded that the most determining variables to predict bank solvency in the United States are interest rates, specifically the mortgage rate and the 5 and 10-year interest rates of treasury bonds, reducing solvency as these rates increase. For delinquency, the most important variable is the unemployment rate in the forecast. The financial stability index is made up of the normalized difference between the two factors obtained, one for solvency and the other for delinquency. The index prediction concludes that stability worsens as BBB corporate yield increases.",,2020,10.21511/bbs.15(4).2020.12,,proquest,"This study uses machine learning, specifically a random forest model, to predict bank stability in the United States from 1990 to 2017. It analyzes bank solvency, delinquency, and a composite stability indicator, utilizing variables like interest rates, unemployment, and corporate yield. The research also employs partial dependency graphs and individual conditional expectation curves for result interpretation, concluding that higher interest rates negatively impact solvency, unemployment affects delinquency, and increased BBB corporate yield worsens financial stability.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:51:08.688613
09d07317676ce634,Using Markov-switching models with Markov chain Monte Carlo inference methods in agricultural commodities trading,"In this work, the use of Markov-switching GARCH (MS-GARCH) models is tested in an active trading algorithm for corn and soybean future markets. By assuming that a given investor lives in a two-regime world (with low- and high-volatility time periods), a trading algorithm was simulated (from January 2000 to March 2019), which helped the investor to forecast the probability of being in the high-volatility regime att + 1. Once this probability was known, the investor could decide to invest either in commodities, during low-volatility periods or in the 3-month US Treasury bills, during high-volatility periods. Our results suggest that the Gaussian MS-GARCH model is the most appropriate to generate alpha or extra returns (from a passive investment strategy) in the corn market and thet-Student MS-GARCH is the best one for soybean trading.","De la Torre-Torres, Oscar, V; Aguilasocho-Montoya, Dora; Alvarez-Garcia, Jose; Simonetti, Biagio",2020,10.1007/s00500-019-04629-5,,wos,"This study applies Markov-switching GARCH (MS-GARCH) models with Markov chain Monte Carlo inference to an active trading algorithm for corn and soybean futures. The algorithm simulates a two-regime world (low and high volatility) to forecast the probability of being in a high-volatility regime. Based on this forecast, an investor decides between commodities (low volatility) or US Treasury bills (high volatility). The Gaussian MS-GARCH model proved best for corn, while the t-Student MS-GARCH was optimal for soybean trading, suggesting potential for generating alpha.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:51:12.816231
c77bf0ed0e86b54c,Using proxies for the short rate: When are three months like an instant?,"The dynamics of the unobservable short rate are frequently estimated directly using a proxy. We examine the biases resulting From this practice (the proxy problem). Analytic results show that the proxy problem is not economically significant for single-factor affine models. In the two-factor affine model of Longstaff and Schwartz (1992), the proxy problem is only economically significant for pricing discount bonds with maturities of more than five years. We also describe two different numerical procedures for assessing the magnitude of the proxy problem in a general interest rate model. When applied to a nonlinear single-factor model, they suggest that the proxy problem can be economically significant.","Chapman, DA; Long, JB; Pearson, ND",1999,10.1093/rfs/12.4.763,,wos,"This paper investigates the biases that arise when using proxies for the unobservable short rate in estimating interest rate dynamics. It finds that the 'proxy problem' is not economically significant for single-factor affine models but can be significant for two-factor affine models when pricing long-maturity discount bonds. The study also proposes numerical methods to assess the proxy problem's magnitude in general interest rate models, suggesting it can be significant in nonlinear single-factor models.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:51:19.780102
2212fd81e8d3b6aa,Volatility measures and Value-at-Risk,"We evaluate and compare the abilities of the implied volatility and historical volatility models to provide accurate Value-at-Risk forecasts. Our empirical tests on the S&P 500, Dow Jones Industrial Average and Nasdaq 100 indices over long time series of more than 20 years of daily data indicate that an implied volatility based Value-at-Risk cannot beat, and tends to be outperformed by, a simple GJR-GARCH based Value-at-Risk. This finding is robust to the use of the likelihood ratio, the dynamic quantile test or a statistical loss function for evaluating the Value-at-Risk performance.The poor performance of the option based Value-at-Risk is due to the volatility risk premium embedded in implied volatilities. We apply both non-parametric and parametric adjustments to correct for the negative price of the volatility risk. However, although this adjustment is effective in reducing the bias, it still does not allow the implied volatility to outperform the historical volatility models.These results are in contrast to the volatility forecasting literature, which favors implied volatilities over the historical volatility model. We show that forecasting the volatility and forecasting a quantile of the return distribution are two different objectives. While the implied volatility is useful for the earlier objective function, it is not for the latter, due to the non-linear and regime changing dynamics of the volatility risk premium. (C) 2017 International Institute of Forecasters. Published by Elsevier B.V. All rights reserved.","Bams, Dennis; Blanchard, Gildas; Lehnert, Thorsten",2017,10.1016/j.ijforecast.2017.04.004,,wos,"This study compares implied volatility and historical volatility models for Value-at-Risk (VaR) forecasting using S&P 500, Dow Jones Industrial Average, and Nasdaq 100 indices. Results show that GJR-GARCH based VaR outperforms implied volatility based VaR, even after adjustments for volatility risk premium. The authors suggest that while implied volatility is good for volatility forecasting, it's less effective for VaR prediction due to the non-linear dynamics of the volatility risk premium.",False,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:51:22.185535
960e01a37822bb97,What is the Effect of Restrictions Imposed by Principal Components Analysis on the Empirical Performance of Dynamic Term Structure Models?,"This paper investigates the effect of restrictions imposed by principal components analysis (PCA) on the empirical performance of dynamic term structure models (DTSM). The application of PCA maximizes the explained variance of a linear combination of bond yields by selecting weights that are as uncorrelated as possible. In the context of factor construction, this choice of weights imposes orthogonality on the state variable bringing about restrictions on model estimation. We quantify the effect of these restrictions, measured through internal consistency equations, on the empirical performance of DTSM contained within linear-affine and linear-quadratic state space formulations (SSF) characterized by Gaussian and non-Gaussian transition dynamics for the state variable. When looking across DTSM, we find the smallest effect of restrictions imposed by PCA on empirical performance when it is used in the context of a linear-affine SSF, and the state transition dynamics are postulated based upon the conditional mean and variance. We also document that the magnitude of this effect is more pronounced when the probability distribution for the data is described by the first four moments relative to just the first two and the parameter dependencies defining the relationship between bond yields and factors are more analytically or computationally complicated (e.g., involves a special function like the Bessel function or cumbersome algebraic manipulations). Suggestions for future research are provided. © 2025 Elsevier B.V., All rights reserved.","Juneja, J.",2025,10.1007/s10614-024-10644-y,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003372195&doi=10.1007%2Fs10614-024-10644-y&partnerID=40&md5=62f9386a35827a9677596c284837a0a1,scopus,"This paper examines how Principal Components Analysis (PCA) restrictions impact the empirical performance of Dynamic Term Structure Models (DTSM). PCA aims to maximize explained variance by selecting uncorrelated weights for bond yields, which imposes orthogonality on state variables and restricts model estimation. The study quantifies these restrictions' effects on DTSMs within linear-affine and linear-quadratic state space formulations, considering Gaussian and non-Gaussian dynamics. The findings suggest that PCA restrictions have the least impact on empirical performance within a linear-affine state space formulation with conditional mean and variance-based transition dynamics. The effect is more significant when the data's probability distribution is described by more moments or when the relationship between bond yields and factors is complex.",True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:51:37.809107
d534573971c63b10,"What the current yield curve says, and what the future prices of energy do","Y Policymakers have always looked at the difference between the yields on long- and short-term Treasury securities as an indication of where the economy is heading. In this study, we extend the literature by examining the yield curve's ability to predict the short-term prices of crude oil and other energy products. Using linear and non-linear (parametric quantile) causality tests on daily data from 1986 to February 2020, our findings confirm that changes in the yield spread not only correlate with, but also drive the returns on crude oil, heating oil and natural gas in the short run. This short-run relationship is relatively absent from 1986 to 2003. However, since 2004, the relationship has remained quite strong, confirming that these products have been financialized. Market participants and policy makers may find our findings useful in understanding the nature of relationship between the shape of the term structure and future innovations in energy prices.","Idilbi-Bayaa, Yasmeen; Qadan, Mahmoud",2022,10.1016/j.resourpol.2021.102494,,wos,"This study investigates the predictive power of the yield curve for short-term energy prices (crude oil, heating oil, natural gas). Using causality tests on daily data from 1986-2020, the research finds that yield spread changes drive energy returns, particularly since 2004, suggesting financialization of these products. The findings are relevant for market participants and policymakers.",False,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:51:47.384035
be1da456434c76af,When there is no place to hide: Correlation risk and the cross-section of hedge fund returns,"Using a novel data set on correlation swaps, we study the relation between correlation risk, hedge fund characteristics, and their risk-return profile. We find that the ability of hedge funds to create market-neutral returns is often associated with a significant exposure to correlation risk, which helps to explain the large abnormal returns found in previous models. We also estimate a significant negative market price of correlation risk, which accounts for the cross-section of hedge fund excess returns. Finally, we detect a pronounced nonlinear relation between correlation risk exposure and the tail risk of hedge fund returns. © 2013 The Author 2013. Published by Oxford University Press on behalf of The Society for Financial Studies. All rights reserved. © 2019 Elsevier B.V., All rights reserved.","Buraschi, A.; Kosowski, R.; Trojani, F.",2014,10.1093/rfs/hht070,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892709151&doi=10.1093%2Frfs%2Fhht070&partnerID=40&md5=3a788d460fa87cfbf5f6abca17b1e105,scopus,"This study investigates the link between correlation risk, hedge fund attributes, and their risk-return profiles using correlation swap data. It reveals that hedge funds' market-neutral returns often stem from substantial correlation risk exposure, explaining prior findings of large abnormal returns. A significant negative market price of correlation risk is identified, contributing to the cross-section of hedge fund excess returns. Additionally, a strong nonlinear relationship between correlation risk exposure and tail risk in hedge fund returns is observed.",False,False,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:51:50.421546
e8e54ffb300f3e5d,"Which exogenous driver is informative in forecasting European carbon volatility: Bond, commodity, stock or uncertainty?","This study relies on 45 exogenous drivers to improve the accuracy in forecasting EUA volatility. Several popular linear and nonlinear predictive regressions, including individual factor analysis, the combination forecast method, the diffusion index model and the supervised learning method, are used to generate volatility forecasts at the monthly frequency. Our empirical results reveal that the diffusion index model and combination forecast method can hardly drive the EUA volatility in a data-rich world owing to worse forecasting performance of individual factors; however, the supervised learning method can successfully predict the EUA volatility. Additionally, the WilderHill new energy global innovation index, Euro corporate bond return spread, GSCI gold index and Euro Area government bond yield spread can extremely drive EUA volatility in terms of individual factor analysis, frequency of variable selection and factor importance. Our findings provide crucial implications to market participants and emission companies, who should pay more attention to the price movement of European bond market, gold and clean energy. © 2023 Elsevier B.V., All rights reserved.","Wang, J.; Guo, X.; Tan, X.; Chevallier, J.; Ma, F.",2023,10.1016/j.eneco.2022.106419,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143371148&doi=10.1016%2Fj.eneco.2022.106419&partnerID=40&md5=a98b91635a2961bde62e843cfeb069b3,scopus,"This study investigates the predictive power of 45 exogenous drivers for European carbon (EUA) volatility using various forecasting models, including linear, nonlinear, diffusion index, and supervised learning methods. The supervised learning approach demonstrates success in predicting EUA volatility. Key drivers identified include the WilderHill new energy global innovation index, Euro corporate bond return spread, GSCI gold index, and Euro Area government bond yield spread. The findings suggest market participants should monitor European bond markets, gold, and clean energy prices.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:52:02.321536
1e13e1a829d5e1b8,Who Values Economist Forecasts? Evidence From Trading in Treasury Markets,"While economic forecasting is ubiquitous within the industry, its role in the trading process has received little attention in the literature. We examine how economist forecasts are related to trading activity in the OTC treasury bond market at the participant level. Consistent with models of heterogeneous opinions, we show that the forecasting economists employing institution places a disproportionately large reliance on the forecast. There is pervasive evidence that this reliance is asymmetric. Only forecasts which imply a fall in future treasury bond prices are associated with an abnormal trading reaction consistent with the forecast. Reference dependence and loss aversion offer one possible explanation for this asymmetric trading response. © 2021 Elsevier B.V., All rights reserved.","James, R.; Jarnecic, E.; Leung, H.",2022,10.1016/j.jfi.2021.100934,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117369955&doi=10.1016%2Fj.jfi.2021.100934&partnerID=40&md5=71ce8126b166106e851aa13340ffe07d,scopus,"This study investigates the relationship between economist forecasts and trading activity in the Over-The-Counter (OTC) treasury bond market at the participant level. It finds that institutions place a disproportionately large reliance on their own forecasts, and this reliance is asymmetric: only forecasts predicting a fall in future treasury bond prices are associated with abnormal trading reactions. This asymmetric response may be explained by reference dependence and loss aversion.",False,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:52:15.812396
b79a2c7acc268fae,Wiener chaos expansion and numerical solutions of the Heath–Jarrow–Morton interest rate model,"In this paper, we propose and analyze a simple and fast numerical method for the solution of the stochastic Heath–Jarrow–Morton (HJM) interest rate model under the Musiela parameterization, based on theWiener chaos expansion (WCE). Through the proposed method, the infinite-dimensional HJM equation is approximated by a finite system of partial differential equations (PDEs), which can be addressed by standard techniques. To illustrate the general construction, we approximate the value of the US treasury bond in an HJM framework, and the results are compared with those derived by the Monte Carlo method and the ensemble Kalman filter. The proposed method is computationally efficient compared with the standard techniques, and it provides a convenient way to compute the statistical moments of the solution numerically. Numerical results and useful formulas for estimating the stochastic duration and immunization are presented. © 2017 Elsevier B.V., All rights reserved.","Kalpinelli, E.A.; Frangos, N.E.; Yannacopoulos, A.",2016,10.21314/jcf.2016.211,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973596637&doi=10.21314%2FJCF.2016.211&partnerID=40&md5=e9ecc7c14a8535386c2c97a43a8082bc,scopus,"This paper introduces a numerical method using Wiener chaos expansion (WCE) to solve the stochastic Heath–Jarrow–Morton (HJM) interest rate model. The method approximates the HJM equation with a finite system of PDEs, allowing for efficient computation of bond values and statistical moments. The approach is demonstrated by valuing US treasury bonds and comparing results with Monte Carlo and ensemble Kalman filter methods. It also provides formulas for stochastic duration and immunization.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:52:24.990362
e4b77867f689035a,Would an earlier inception of OMT by the ECB have prevented the 2012 Greek default?,"To avert further debt crises following the Greek default of 2012, the European Central Bank (ECB) adopted outright purchases of sovereign bonds as part of its monetary policy regime. This paper examines whether an earlier inception of such purchases (OMT) could have prevented the observed Greek repudiation. To account for the extraordinary circumstances surrounding the Greek default, I construct a novel model of sovereign finance in which default is political and investors’ reliance on external credit ratings gives rise to slow moving crises. Estimating the model with Greek data, I find that an earlier inception of OMT plausibly could have prevented the observed default, but the resulting counterfactual Greek state would have been so fragile that, absent any further fiscal consolidation, eventual default was effectively inevitable. Moreover, the present Greek state remains sufficiently fragile that a quick return to a predominantly private financing scheme is not advisable. © 2025 Elsevier B.V., All rights reserved.","Mäder, N.",2025,10.1016/j.iref.2025.104356,https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012113857&doi=10.1016%2Fj.iref.2025.104356&partnerID=40&md5=a0410bf8f90a8a60f3cb411b27d80bd5,scopus,"This paper investigates whether the European Central Bank's Outright Monetary Transactions (OMT) could have prevented the 2012 Greek default. Using a novel political sovereign finance model estimated with Greek data, the study suggests that earlier OMT might have averted the default but would have left Greece in a fragile state, making eventual default likely without fiscal consolidation. The current Greek financial situation is also deemed fragile, advising against a rapid return to private financing.",False,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:52:26.628380
4c58711a707af646,Yield Curve Estimation Based on Government Security Prices in the Croatian Financial Market,"This article investigates the estimation of the yield curve based on government security prices using the Nelson-Siegel model in the Croatian financial market. The yield curve was estimated for samples of government securities with and without currency clauses. Since the Croatian financial market is less developed characterized by limited trading activity in government bonds, Treasury bills were also included in the analysis. To examine the difference in the estimation of yield curve parameters between a less developed and a developed market, the U.S. sample was considered. The yield curve was estimated for the full US sample and for artificially created U.S. samples corresponding to the Croatian samples of government bonds with and without currency clauses. Despite the less developed Croatian financial market, it is possible to estimate the yield curve and derive meaningful economic interpretations from the estimates.","Orlovic, Zrinka; Zoricic, Davor; Golubic, Zrinka Lovretin",2024,10.2478/zireb-2024-0016,,wos,"This study estimates the yield curve in the Croatian financial market using the Nelson-Siegel model with government securities, including those with and without currency clauses, and Treasury bills due to limited trading activity. A comparison with U.S. market data was made to understand differences between developed and less developed markets. The findings suggest that yield curve estimation and economic interpretation are feasible even in less developed markets.",False,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:52:38.639560
416e57a3c9d256bd,Yield Spread and Economic Policy Uncertainty: Evidence from Japan,"In this paper, we adopt the nonlinear autoregressive distributed lags (NARDL) model extended by Shin et al. (2014) to investigate the relationship between the treasury yield spread and economic policy uncertainty (EPU) in Japan. This model helps us to explore the short- and long-run asymmetric reactions of explained variables through positive and negative partial sum decompositions of changes in the explanatory variable(s). In our research, the testing of the NARDL specification reveals the existence of a significant long-run asymmetric equilibrium between the yield spread and EPU in Japan. On the other hand, we find a significant positive nexus between the treasury yield spread and EPU reduction in the long run. We speculate that because of low inflation, a poor economic outlook and the low interest rate environment since 1990, financial agents are markedly sensitive to negative shocks resulting from EPU. This means that when facing a good economy, bond agents are quick to sell, especially with higher-risk long-term interest rate bonds. Meanwhile, because the Bank of Japan announced the Stock Purchasing Plan in October 2002 and from the point view of portfolio management, while the influence of a positive economic outlook dominates the negative outlook, flight from quality has no role in asset portfolio adjustment. The empirical implications are that the long history of unconventional monetary policy supports the demand for both bonds and stock markets. When taking the stock market into consideration, the correlations between the yield spread, EPU and stock market capture the full wealth effects of the low interest rate environment in Japan.","Wang, Mei-Chih; Kuo, Pao-Lan; Chen, Chan-Sheng; Chiu, Chien-Liang; Chang, Tsangyao",2020,10.3390/su12104302,,wos,"This study uses the NARDL model to analyze the relationship between the treasury yield spread and economic policy uncertainty (EPU) in Japan, finding a significant long-run asymmetric equilibrium and a positive nexus between the yield spread and EPU reduction. The authors suggest financial agents are sensitive to negative EPU shocks due to Japan's economic conditions and low interest rates, influencing bond market behavior. They also consider the impact of unconventional monetary policy and the stock market on these relationships.",True,True,False,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:52:43.572872
15912911fb10cffd,Yield curve and recession forecasting in a machine learning framework,"In this paper, we investigate the forecasting ability of the yield curve in terms of the U.S. real GDP cycle. More specifically, within a Machine Learning framework, we use data from a variety of short (treasury bills) and long term interest rates (bonds) for the period from 1976:Q3 to 2011:Q4 in conjunction with the real GDP for the same period, to create a model that can successfully forecast output fluctuations (inflation and output gaps) around its long-run trend. We focus our attention in correctly forecasting the instances of output gaps referred for the purposes of our analysis here as recessions. In this effort, we applied a Support Vector Machines technique for classification. The results show that we can achieve an overall forecasting accuracy of 66.7 and 100_% accuracy in forecasting recessions. These results are compared to the alternative standard logit and probit model, to provide further evidence about the significance of our original model. Reprinted by permission of Springer",,2015,10.1007/s10614-014-9432-0,,proquest,"This paper explores the use of a Machine Learning framework, specifically Support Vector Machines, to forecast U.S. real GDP recessions using yield curve data (short and long-term interest rates) from 1976:Q3 to 2011:Q4. The model achieved a 100% accuracy in forecasting recessions and an overall accuracy of 66.7%, outperforming standard logit and probit models.",True,True,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:53:16.456188
4f70c91263ca1522,“Intelligent” finance and treasury management: what we can expect,"Artificial intelligence poses a particular challenge in its application to finance/treasury management because most treasury functions are no longer physical processes, but rather virtual processes that are increasingly highly automated. Most finance/treasury teams are knowledge workers who make decisions and conduct analytics within often dynamic frameworks that must incorporate environmental considerations (foreign exchange rates, GDP forecasts), internal considerations (growth needs, business trends), as well as the impact of any actions on related corporate decisions which are also highly complex (e.g., hedging, investing, capital structure, liquidity levels). Artificial intelligence in finance and treasury is thus most analogous to the complexity of a human nervous system as it encompasses far more than the automation of tasks. Similar to the human nervous system, AI systems in finance/treasury must manage data quickly and accurately, including the capture and classification of data and its integration into larger datasets. At present, the AI network neural system has been gradually improved and is widely used in many fields of treasury management, such as early warning of potential financial crisis, diagnosis of financial risk, control of financial information data quality and mining of hidden financial data, information, etc.",,2020,10.1007/s00146-019-00919-6,,proquest,"This article discusses the application of Artificial Intelligence (AI) in finance and treasury management, highlighting its complexity due to the virtual and automated nature of modern treasury functions. It likens AI in this domain to the human nervous system, emphasizing the need for rapid and accurate data management, including capture, classification, and integration. The abstract notes the current use of AI in treasury management for tasks like financial crisis early warning, risk diagnosis, data quality control, and data mining.",True,False,True,gemini-2.5-flash-lite,Ulrik,N,,2025-10-13T16:53:37.342050
